diff -urN gcc-4.7.3/ChangeLog.STM st40-4.7.3-13080/gcc/ChangeLog.STM
--- gcc-4.7.3/ChangeLog.STM	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/ChangeLog.STM	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,41 @@
+2010-04-12  Christian Bruel  <christian.bruel@st.com>
+
+	* config/mh-mingw (LDFLAGS): Remove wrap rename.
+
+2009-12-07  Yvan Roux  <yvan.roux@st.com>
+
+	* config/mh-mingw (LDFLAGS): Wrap syscall for cygwin path support.
+
+2009-10-22  Christian Bruel  <christian.bruel@st.com>
+
+	* configure.ac: Use include-fixed header path for canadian cross build.
+	* configure: Regenerate.
+
+2009-02-03  Christian Bruel  <christian.bruel@st.com>
+
+	* config/mt-ospace: Don't overwrite CFLAGS_FOR_TARGET.
+	* config/mt-relax: Not supported for c++.
+
+2008-05-26  Christian Bruel  <christian.bruel@st.com>
+
+	* config/mt-relax: New file.
+	* Makefile.in: Add relax fragment.
+	* Makefile.tpl: Likewise
+	* configure.ac: Likewise.
+	* configure: Regenerate.
+
+2008-09-30  Christian Bruel  <christian.bruel@st.com>
+
+	* configure.in: Allow libgloss configure for sh.
+	* configure: Regenerate.
+
+2008-05-26  Christian Bruel  <christian.bruel@st.com>
+
+	* config/mt-alphaieee: Removed.
+	* config/mt-ieee: Renamed from mt-alphaieee.
+	* Makefile.in: alphaieee_frag renamed ieee_frag.
+	ieee_frag must be included after ospace_frag.
+	* Makefile.tpl: Likewise
+	* configure.ac: Likewise. Enable for sh.
+	* configure: Regenerate.
+
diff -urN gcc-4.7.3/config/mh-mingw st40-4.7.3-13080/gcc/config/mh-mingw
--- gcc-4.7.3/config/mh-mingw	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/config/mh-mingw	2012-04-04 14:14:24.000000000 +0200
@@ -6,3 +6,9 @@
 # as GCC turns out to need that much more to pass all the limits-* tests.
 LDFLAGS += -Wl,--stack,12582912
 BOOT_LDFLAGS += -Wl,--stack,12582912
+
+# Activation of CYGPATH feature: Support for cygwin pathes in mingwin32 shell
+#   through syscall wrapping at linker level
+LDFLAGS += -Wl,--wrap,open,--wrap,creat,--wrap,fopen,--wrap,freopen,--wrap,remove,--wrap,unlink,--wrap,stat,--wrap,chdir,--wrap,rmdir,--wrap,opendir,--wrap,access
+
+
diff -urN gcc-4.7.3/config/mt-ospace st40-4.7.3-13080/gcc/config/mt-ospace
--- gcc-4.7.3/config/mt-ospace	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/config/mt-ospace	2012-04-04 14:14:24.000000000 +0200
@@ -1,3 +1,3 @@
 # Build libraries optimizing for space, not speed.
- CFLAGS_FOR_TARGET = -g -Os
- CXXFLAGS_FOR_TARGET = -g -Os
+CFLAGS_FOR_TARGET += -g -Os 
+CXXFLAGS_FOR_TARGET += -g -Os 
diff -urN gcc-4.7.3/fixincludes/ChangeLog.STM st40-4.7.3-13080/gcc/fixincludes/ChangeLog.STM
--- gcc-4.7.3/fixincludes/ChangeLog.STM	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/fixincludes/ChangeLog.STM	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,20 @@
+2008-28-08  Antony King  <antony.king@st.com>
+
+	* check.tpl: Avoid premature termination of script on fgrep -v
+	failure.
+
+2008-27-08  Christian Bruel  <christian.bruel@st.com>
+
+	* fixincl.c (test_test). Dont quote test.
+
+2007-10-02  Antony King  <antony.king@st.com>
+
+	* fixincl.c (cygpath_open): New function.
+	(load_file): Replace open() with cygpath_open().
+	(create_file): Likewise.
+	(process): Likewise.
+	(initialize): Add calls to CYGPATH() and CYGPATH_FREE().
+	(test_test): Add missing quotes.
+	(fix_with_system): Likewise.
+	(fix_with_system): Force use of Unix shell.
+	(main): Redirect stdin to nul: on Windows.
diff -urN gcc-4.7.3/fixincludes/check.tpl st40-4.7.3-13080/gcc/fixincludes/check.tpl
--- gcc-4.7.3/fixincludes/check.tpl	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/fixincludes/check.tpl	2012-04-04 14:14:24.000000000 +0200
@@ -140,9 +140,9 @@
 
 cd $TESTBASE
 
-find * -type f -print | \
+( find * -type f -print | \
 fgrep -v 'CVS/' | \
-fgrep -v '.svn/' > ${TESTDIR}/LIST
+fgrep -v '.svn/' > ${TESTDIR}/LIST ; true )
 
 exitok=`
 exec < ${TESTDIR}/LIST
diff -urN gcc-4.7.3/fixincludes/fixincl.c st40-4.7.3-13080/gcc/fixincludes/fixincl.c
--- gcc-4.7.3/fixincludes/fixincl.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/fixincludes/fixincl.c	2012-04-04 14:14:24.000000000 +0200
@@ -101,6 +101,20 @@
 
 #include "fixincl.x"
 
+static int
+cygpath_open (const char *file, int oflag, mode_t mode)
+{
+  int fd;
+
+#ifdef _O_BINARY
+  oflag |= _O_BINARY;
+#endif
+
+  fd = open (file, oflag, mode);
+
+  return fd;
+}
+
 /* * * * * * * * * * * * * * * * * * *
  *
  *  MAIN ROUTINE
@@ -122,7 +136,11 @@
       and err open so that the proper input file does not get closed
       by accident  */
 
+#if defined(__MSDOS__) || defined(_WIN32)
+  freopen ("nul:", "r", stdin);
+#else
   freopen ("/dev/null", "r", stdin);
+#endif
 
   if (file_name_buf == (char *) NULL)
     {
@@ -211,6 +229,8 @@
 void
 initialize ( int argc, char** argv )
 {
+  char *arg;
+
   xmalloc_set_program_name (argv[0]);
 
   switch (argc)
@@ -221,7 +241,8 @@
     case 2:
       if (strcmp (argv[1], "-v") == 0)
         do_version ();
-      if (freopen (argv[1], "r", stdin) == (FILE*)NULL)
+      arg = argv[1];
+      if (freopen (arg, "r", stdin) == (FILE*)NULL)
         {
           fprintf (stderr, "Error %d (%s) reopening %s as stdin\n",
                    errno, xstrerror (errno), argv[1] );
@@ -325,7 +346,7 @@
       the file size is not a multiple of the page size.  If it is a multiple,
       then this adjustment sometimes fails anyway.  */
   data_map_size = stbf.st_size+1;
-  data_map_fd   = open (fname, O_RDONLY);
+  data_map_fd   = cygpath_open (fname, O_RDONLY, 0);
   ttl_data_size += data_map_size-1;
 
   if (data_map_fd < 0)
@@ -476,7 +497,7 @@
 
   sprintf (fname, "%s/%s", pz_dest_dir, pz_curr_file + find_base_len);
 
-  fd = open (fname, O_WRONLY | O_CREAT | O_TRUNC, S_IRALL);
+  fd = cygpath_open (fname, O_WRONLY | O_CREAT | O_TRUNC, S_IRALL);
 
   /*  We may need to create the directories needed... */
   if ((fd < 0) && (errno == ENOENT))
@@ -501,7 +522,7 @@
         }
 
       /*  Now, lets try the open again... */
-      fd = open (fname, O_WRONLY | O_CREAT | O_TRUNC, S_IRALL);
+      fd = cygpath_open (fname, O_WRONLY | O_CREAT | O_TRUNC, S_IRALL);
     }
   if (fd < 0)
     {
@@ -539,7 +560,7 @@
 test_test (tTestDesc* p_test, char* pz_test_file)
 {
   tSCC cmd_fmt[] =
-"file=%s\n\
+"file='%s'\n\
 if ( test %s ) > /dev/null 2>&1\n\
 then echo TRUE\n\
 else echo FALSE\n\
@@ -852,7 +873,7 @@
 #else
       /* Don't use positional formatting arguments because some lame-o
          implementations cannot cope  :-(.  */
-      tSCC   z_cmd_fmt[] = " %s > %sX ; rm -f %s; mv -f %sX %s";
+      tSCC   z_cmd_fmt[] = " '%s' > '%sX'; rm -f '%s'; mv -f '%sX' '%s'";
 #endif
       tCC**  ppArgs = p_fixd->patch_args;
 
@@ -935,7 +956,34 @@
                pz_temp_file, pz_temp_file, pz_temp_file);
 #endif
     }
+#if 1
+  {
+    char *cmd;
+    char *fname = make_temp_file( 0 );
+    FILE *pf = fopen( fname, "w" );
+    if (pf == NULL)
+      {
+	fprintf (stderr, "Error %d (%s) creating %s\n",
+		 errno, xstrerror (errno), fname);
+	exit (EXIT_FAILURE);
+      }
+    fwrite( pz_cmd, 1, strlen( pz_cmd ), pf );
+    fclose( pf );
+    asprintf( &cmd, "sh %s", fname );
+    if (cmd == NULL)
+      {
+	fprintf (stderr, "Error %d (%s)\n",
+		 errno, xstrerror (errno));
+	exit (EXIT_FAILURE);
+      }
+    system( cmd );
+    free( (void*)cmd );
+    unlink( fname );
+    free( (void*)fname );
+  }
+#else
   system( pz_cmd );
+#endif
   free( (void*)pz_cmd );
 }
 
@@ -1283,7 +1331,7 @@
 
       if (read_fd == -1)
         {
-          read_fd = open (pz_curr_file, O_RDONLY);
+          read_fd = cygpath_open (pz_curr_file, O_RDONLY, 0);
           if (read_fd < 0)
             {
               fprintf (stderr, "Error %d (%s) opening %s\n", errno,
@@ -1337,7 +1385,7 @@
       pz_file_source = pz_temp_file;
     }
 
-  read_fd = open (pz_temp_file, O_RDONLY);
+  read_fd = cygpath_open (pz_temp_file, O_RDONLY, 0);
   if (read_fd < 0)
     {
       if (errno != ENOENT)
diff -urN gcc-4.7.3/gcc/basic-block.h st40-4.7.3-13080/gcc/gcc/basic-block.h
--- gcc-4.7.3/gcc/basic-block.h	2012-10-01 13:18:40.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/basic-block.h	2012-10-03 11:34:38.000000000 +0200
@@ -1,6 +1,7 @@
 /* Define control flow data structures for the CFG.
    Copyright (C) 1987, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004,
    2005, 2006, 2007, 2008, 2009, 2010 Free Software Foundation, Inc.
+   Copyright (c) 2009 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -751,6 +752,9 @@
 extern struct edge_list *pre_edge_lcm (int, sbitmap *, sbitmap *,
 				       sbitmap *, sbitmap *, sbitmap **,
 				       sbitmap **);
+extern struct edge_list *pre_edge_lcm_avs (int, sbitmap *, sbitmap *,
+					   sbitmap *, sbitmap *, sbitmap *,
+					   sbitmap *, sbitmap **, sbitmap **);
 extern struct edge_list *pre_edge_rev_lcm (int, sbitmap *,
 					   sbitmap *, sbitmap *,
 					   sbitmap *, sbitmap **,
diff -urN gcc-4.7.3/gcc/builtins.c st40-4.7.3-13080/gcc/gcc/builtins.c
--- gcc-4.7.3/gcc/builtins.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/builtins.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 1988, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,
    2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011,
    2012 Free Software Foundation, Inc.
+   Copyright (c) 2009 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -10032,7 +10033,12 @@
     {
     case BUILT_IN_ISINF:
       if (!HONOR_INFINITIES (TYPE_MODE (TREE_TYPE (arg))))
+	{
+	  if (warn_non_finite_math)
+	    warning (OPT_Wnon_finite_math,
+		     "non-finite operation %q+F always returns 0", fndecl);
 	return omit_one_operand_loc (loc, type, integer_zero_node, arg);
+	}
 
       if (TREE_CODE (arg) == REAL_CST)
 	{
@@ -10081,7 +10087,11 @@
     case BUILT_IN_ISFINITE:
       if (!HONOR_NANS (TYPE_MODE (TREE_TYPE (arg)))
 	  && !HONOR_INFINITIES (TYPE_MODE (TREE_TYPE (arg))))
+	{
+	  warning (OPT_Wnon_finite_math, "non-finite operation %q+D not honored" ,
+		   fndecl);
 	return omit_one_operand_loc (loc, type, integer_one_node, arg);
+	}
 
       if (TREE_CODE (arg) == REAL_CST)
 	{
@@ -10093,7 +10103,11 @@
 
     case BUILT_IN_ISNAN:
       if (!HONOR_NANS (TYPE_MODE (TREE_TYPE (arg))))
+	{
+	  warning (OPT_Wnon_finite_math, "non-finite operation %q+D not honored",
+		   fndecl);
 	return omit_one_operand_loc (loc, type, integer_zero_node, arg);
+	}
 
       if (TREE_CODE (arg) == REAL_CST)
 	{
@@ -10217,7 +10231,12 @@
   if (unordered_code == UNORDERED_EXPR)
     {
       if (!HONOR_NANS (TYPE_MODE (TREE_TYPE (arg0))))
+	{
+	  if (warn_non_finite_math)
+	    warning (OPT_Wnon_finite_math,
+		     "non-finite operation %q+F always returns 0", fndecl);
 	return omit_two_operands_loc (loc, type, integer_zero_node, arg0, arg1);
+	}
       return fold_build2_loc (loc, UNORDERED_EXPR, type, arg0, arg1);
     }
 
diff -urN gcc-4.7.3/gcc/c-decl.c st40-4.7.3-13080/gcc/gcc/c-decl.c
--- gcc-4.7.3/gcc/c-decl.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/c-decl.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 1988, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000,
    2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012
    Free Software Foundation, Inc.
+   Copyright (c) 2009 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -1844,7 +1845,10 @@
 	      || (DECL_INITIAL (newdecl)
 		  && !prototype_p (TREE_TYPE (newdecl)))))
 	{
-	  warning (OPT_Wshadow, "declaration of %q+D shadows "
+	  if (flag_generate_lto) 
+	    sorry ("non-ANSI declaration shadowing a built-in function");
+	  else
+	    warning (OPT_Wshadow, "declaration of %q+D shadows "
 		   "a built-in function", newdecl);
 	  /* Discard the old built-in function.  */
 	  return false;
diff -urN gcc-4.7.3/gcc/c-family/c.opt st40-4.7.3-13080/gcc/gcc/c-family/c.opt
--- gcc-4.7.3/gcc/c-family/c.opt	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/c-family/c.opt	2013-04-30 11:08:54.000000000 +0200
@@ -1,6 +1,7 @@
 ; Options for the C, ObjC, C++ and ObjC++ front ends.
 ; Copyright (C) 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,
 ; 2011, 2012 Free Software Foundation, Inc.
+; Copyright (c) 2013 STMicroelectronics.
 ;
 ; This file is part of GCC.
 ;
@@ -998,7 +999,7 @@
 Generate run time type descriptor information
 
 fshort-double
-C ObjC C++ ObjC++ Optimization Var(flag_short_double)
+C ObjC C++ ObjC++ Optimization LTO Var(flag_short_double)
 Use the same size for double as for float
 
 fshort-enums
diff -urN gcc-4.7.3/gcc/cfg.c st40-4.7.3-13080/gcc/gcc/cfg.c
--- gcc-4.7.3/gcc/cfg.c	2012-10-01 13:18:40.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/cfg.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 1987, 1988, 1992, 1993, 1994, 1995, 1996, 1997, 1998,
    1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010
    Free Software Foundation, Inc.
+   Copyright (c) 2009 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -715,6 +716,9 @@
       fprintf (file, HOST_WIDEST_INT_PRINT_DEC, e->count);
     }
 
+  if (e->goto_locus)
+    fprintf (file, "locus = %d ", e->goto_locus);
+
   if (e->flags)
     {
       static const char * const bitnames[] = {
diff -urN gcc-4.7.3/gcc/cfgexpand.c st40-4.7.3-13080/gcc/gcc/cfgexpand.c
--- gcc-4.7.3/gcc/cfgexpand.c	2013-04-04 16:25:15.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/cfgexpand.c	2013-04-30 11:08:54.000000000 +0200
@@ -1,6 +1,7 @@
 /* A pass for lowering trees to RTL.
    Copyright (C) 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011
    Free Software Foundation, Inc.
+   Copyright (c) 2009 STMicroelectronics.
 
 This file is part of GCC.
 
diff -urN gcc-4.7.3/gcc/ChangeLog.STM st40-4.7.3-13080/gcc/gcc/ChangeLog.STM
--- gcc-4.7.3/gcc/ChangeLog.STM	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/ChangeLog.STM	2013-08-07 14:40:47.000000000 +0200
@@ -0,0 +1,1280 @@
+2013-07-12  Christian Bruel  <christian.bruel@st.com>
+
+	http://codex.cro.st.com/tracker/?func=detail&aid=221318
+	* gcc/ipa-inline.c (inline_small_functions): increase max_count with
+	 indirect_calls edges.
+
+2013-05-22  Christian Bruel  <christian.bruel@st.com>
+
+	PR debug/57351
+	* config/arm/arm.c (arm_dwarf_register_span): Do not use dbx number.
+
+2013-05-06  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.md (tstdi_t_zero_extract_eq): New.
+	(tsthi_t_zero_extract_eq): New.
+	(tstqi_t_zero_extract_eq): New.
+
+2013-04-26  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/ieee-754-df.S: Move to libgcc.
+	* gcc/config/sh/ieee-754-df.S: Likewise
+
+2013-04-26  Christian Bruel  <christian.bruel@st.com>
+
+	* dwarf2out.c (multiple_reg_loc_descriptor): Use DBX_REGISTER_NUMBER
+	 for spanning registers.
+
+2013-04-22  Christian Bruel  <christian.bruel@st.com>
+
+	* tree-chrec.c (chrec_convert_1): Check modes.
+	* tree-scalar-evolution.c (interpret_rhs_expr): Likewise.
+
+2013-04-19  Christian Bruel  <christian.bruel@st.com>
+
+	Backport from mainline:
+	2012-11-05  Jan Hubicka  <jh@suse.cz>
+
+       * ipa-inline.c (leaf_node_p): Rename to ...
+       (num_calls) ... this one.
+       (want_early_inline_function_p): Allow smal growth on non-leafs.
+
+2013-04-18  Christian Bruel  <christian.bruel@st.com>
+
+	PR target/56995
+	* config/sh/sh.h (enum reg_class): Remove DF_HI_REGS.
+	(REG_CLASS_NAMES): Idem.
+	(REG_CLASS_CONTENTS): Idem.
+	(REGCLASS_HAS_FP_REG): Idem.
+	* config/sh/sh.c (sh_cannot_change_mode_class): Idem.
+	(sh_conditional_register_usage): Idem.
+
+2013-04-12  Laurent Alfonsi  <laurent.alfonsi@st.com>
+
+	* tree-chrec.c (chrec_convert_1): Extend fix PR53676 to unsigned.
+	* tree-scalar-evolution.c (interpret_rhs_expr): Likewise.
+
+2013-04-12  Laurent Alfonsi  <laurent.alfonsi@st.com>
+
+	Backport from mainline:
+	2012-06-27  Richard Guenther  <rguenther@suse.de>
+
+	PR middle-end/53676
+	* tree-chrec.c (chrec_convert_1): Represent truncation to
+	a type with undefined overflow as truncation to an unsigned
+	type converted to the type with undefined overflow.
+	* tree-scalar-evolution.c (interpret_rhs_expr): For computing
+	the scalar evolution of a truncated widened operation avoid
+	looking at the non-existing evolution of the widened operation
+	result.
+
+2013-03-23  Christian Bruel  <christian.bruel@st.com>
+
+	* sh.md (short_cbranch_p, med_branch_p, med_cbranch_p): Remove.
+	(braf_branch_p, braf_cbranch_p); Remove.
+	(length): Rewrite attribute.
+	* sh.c (short_cbranch_p, med_branch_p, med_cbranch_p): New predicate function.
+	(braf_branch_p, braf_cbranch_p); Likewise.
+	(sh_insn_length_adjustment): Adjust padding for braf branches.
+	(output_far_jump): Refine and add assertions.
+	* sh-protos.h (short_cbranch_p, med_branch_p, med_cbranch_p): Declare.
+	(braf_branch_p, braf_cbranch_p); Declare.
+
+2013-02-13  Laurent Alfonsi  <laurent.alfonsi@st.com>
+
+	* tree.c (build_one_cst, build_zero_cst): Use boolean global nodes.
+
+2013-01-31  Christian Bruel  <christian.bruel@st.com>
+
+	* sh.c (sh_expand_prologue): Check args.pretend_args_size to push args.
+
+2013-01-31  Laurent Alfonsi  <laurent.alfonsi@st.com>
+
+	http://codex.cro.st.com/tracker/?func=detail&aid=197859
+	* config/sh/sh.c (sh_insn_length_adjustment): Fix adjustment size for
+	insn located inside the sequences.
+
+2013-01-21  Christian Bruel  <christian.bruel@st.com>
+
+	* sh.h (CASE_VECTOR_SHORTEN_MODE): Pessimize switch mode before
+	 constant pools.
+
+2012-11-23  Christian Bruel  <christian.bruel@st.com>
+
+	* toplev.c (compile_file): Emit __gnu_lto_v1 only if HAVE_LTO_PLUGIN.
+	* collect2.c (scan_prog_file): __gnu_lto_v1 not implemented check.
+
+2013-01-12  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=25892
+	* config/sh/sh.c (sh_expand_prologue): Postpone new_stack mem symbol.
+	(broken_move): Handle UNSPECV_SP_SWITCH_B.
+	* config/sh/sh.md (sp_switch_1): Use set (reg:SI SP_REG).
+
+2013-01-12  DJ Delorie  <dj@redhat.com>
+
+	* config/sh/sh.md (UNSPECV_SP_SWITCH_B): New.
+	(UNSPECV_SP_SWITCH_E): New.
+	(sp_switch_1): Change to an unspec.
+	(sp_switch_2): Change to an unspec.  Don't use post-inc when we
+	replace $r15.
+
+2013-01-10  Laurent Alfonsi  <laurent.alfonsi@st.com>
+
+	* c-family/c.opt (flag_short_double): Useful also for LTO phase.
+	* lto/lto-lang.c (lto_init): LTO initialized with flag_short_double.
+
+2012-12-21  Christian Bruel  <christian.bruel@st.com>
+
+       * configure.ac: Set target_header_dir with build-sysroot.
+       * configure: Regenerate.
+       * config.in: Regenerate.
+
+2012-11-18  Christian Bruel  <christian.bruel@st.com>
+
+        * lto-opts.c (append_to_collect_gcc_options): Check !*first_p.
+
+2012-12-05  Laurent Alfonsi  <laurent.alfonsi@st.com>
+
+	* config/sh/sh.md (*muladdsi3): add clobber register macl.
+
+2012-11-08  Laurent Alfonsi  <laurent.alfonsi@st.com>
+
+	http://codex.cro.st.com/tracker/?func=detail&aid=180343
+	* gcc.c (LINK_COMMAND_SPEC): Skip -lgcov in case of nostdlib.
+
+2012-11-05  Christian Bruel  <christian.bruel@st.com>
+
+	* tree-ssa-tail-merge.c (replace_block_by): Update bb->count.
+
+2012-10-29  Christian Bruel  <christian.bruel@st.com>
+
+	PR target/32163
+	* config/sh/sh.md (stack_protect_test_si): Check stack_protector_block.
+	(sym_label2reg): Revert use of gen_chk_guard_add.
+	(chk_guard_add): Delete.
+	(UNSPEC_CHKADD): Delete.
+	* config/sh/sh.c (stack_protector_block): New function.
+	* config/sh/sh-protos.h (stack_protector_block): Declare.
+
+2012-10-11  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh-mem.c (set_mem_size): Fix operand
+
+2012-08-29  Christian Bruel  <christian.bruel@st.com>
+
+	PR target/54546
+	* config/sh/sh-protos.h (sh_need_epilogue): Delete.
+	(sh_can_use_simple_return_p): Declare.
+	* config/sh/sh.c (sh_can_use_simple_return_p): Define.
+	(sh_need_epilogue, sh_need_epilogue_known): Delete.
+	(sh_output_function_epilogue): Remove sh_need_epilogue_known.
+	* config/sh/sh.md (simple_return, return): Define.
+	(epilogue): Use inline return rtl.
+	(sh_expand_epilogue): Cleanup parameters boolean type.
+	(any_return): New iterator.
+
+2012-08-29  Christian Bruel  <christian.bruel@st.com>
+
+	Backport from mainline
+	2012-06-11  Richard Henderson  <rth@redhat.com>
+	* dwarf2cfi.c (scan_trace): Handle annulled branch-taken delay slots.
+
+2012-08-29  Christian Bruel  <christian.bruel@st.com>
+
+	Backport from mainline
+	2012-04-10  Ulrich Weigand  <ulrich.weigand@linaro.org>
+ 	    Richard Sandiford  <rdsandiford@googlemail.com>
+	* fwprop.c (propagate_rtx): Also set PR_CAN_APPEAR for subregs.
+
+2012-08-09 Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/newlib.h: Add NO_IMPLICIT_EXTERN_C.
+
+2012-07-19  Christian Bruel  <christian.bruel@st.com>
+
+	PR target/54029
+	* config/sh/sh.c (gen_far_branch): Set JUMP_LABEL for return jumps.
+
+2012-06-22  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (*muladdsi3): New pattern.
+
+2012-06-22  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_reorg): Check for return rtx.
+
+2012-06-13  Christian Bruel  <christian.bruel@st.com>
+
+	PR target/53621
+	* config/sh/sh.c (sh_option_override): Don't force
+	 flag_omit_frame_pointer and maccumulate_outgoing_args.
+	* config/sh/sh.opt (maccumulate-outgoing-args): Init as Var.
+
+2012-06-11  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=19749
+	Backport from mainline
+	2012-03-27  Chung-Lin Tang  <cltang@codesourcery.com>
+
+	PR target/52667
+	* config/sh/sh.c (find_barrier): Add equality check of last_got
+	to avoid going above orig insn. Update comments.
+
+2012-06-06  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (arith_shiftsi): New pattern.
+
+2012-05-30  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.c (save_switch): Add user_p parameter.
+	(read_specs): Likewise.
+	(set_specs): Likewise.
+	(validate_switches): Likewise.
+	(validate_switches_from_spec): Likewise.
+	(validate_all_switches): Pass on user_p parameter.
+	(struct spec_list): Add user_p field.
+	(struct switchstr): Add known field.
+	(save_switch): Add known parameter.
+	(INIT_STATIC_SPEC): Initialize user_p;
+	(driver_unknown_option_callbac): Call save_switch if
+	 OPT_SPECIAL_unknown.
+	(driver_handle_option): Propagate OPT_specs.
+	(do_spec_1): Set validated only if known.
+	(check_live_switch): Likewise.
+	(validate_switches): Set validated if known or user_spec.
+	(main): Adjust error message.
+
+2012-05-21  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/superh.h (LIB_SPEC): Use board_link libs for LTO.
+
+2012-04-23  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=18466
+	* config/sh/sh.c (sh_asm_count): Handle .fill directive.
+	(sh_insn_length_adjustment): Fix far jump offset.
+	(output_far_jump): Likewise.
+
+2012-04-23  Christian Bruel  <christian.bruel@st.com>
+
+	* final.c (print_address): New debug function.
+	* insn-addr.h (print_address): Declare.
+
+2012-04-11 Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/gcc/opts.c (default_options_table): Add OPT_fcse_sincos.
+	* gcc/gcc/tree-ssa-math-opts.c (execute_cse_sincos): Test OPT_fcse_sincos.
+	* gcc/doc/invoke.tex (-fcse-sincos): Describe.
+
+2012-03-15  Laurent Alfonsi <laurent.alfonsi@st.com>
+	Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_reorg): Uses eh_label instead of eh_region.
+	(handler_uses_reg): Don't check defs after jump.
+	* except.c (for_each_eh_region): Deleted.
+	(for_each_eh_label): Add parameter.
+	* reload1.c (set_initial_label_offsets): Likewise.
+	 (set_initial_eh_label_offset): Likewise.
+
+2012-03-07  Christian Bruel  <christian.bruel@st.com>
+
+	http://gcc.gnu.org/bugzilla/show_bug.cgi?id=52283
+	* stmt.c (warn_if_unused_value): Skit NOP_EXPR
+	* convert.c (convert_to_integer): Don't force TREE_NO_WARNING.
+
+2012-02-10  Christian Bruel  <christian.bruel@st.com>
+
+	* reload1.c (calculate_elim_costs_all_insns): Allow PARALLEL patterns.
+
+2012-01-18  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (UNSPEC_STR): Fix.
+	(UNSPEC_ROT): Likewise.
+
+2011-12-22  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (MOVE_BY_PIECES_P): Tuned.
+	(MOVE_BY_PIECES_P): Likewise.
+
+2011-11-22  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_hw_workaround): Handle .align in absolute offsets.
+
+2011-11-15  Christian Bruel  <christian.bruel@st.com>
+
+	Port from Stlinux Mon Feb 02 2009 Carl Shaw <carl.shaw@st.com>
+	* config/sh/lib1funcs.asm (_ic_invalidate_syscall): New function.
+	* config/sh/t-linux (LIB1ASMFUNCS_CACHE: Add _ic_invalidate_syscall.
+
+2011-11-15  Christian Bruel  <christian.bruel@st.com>
+
+	* final.c (shorten_branches): Shorten branches even in -O0.
+
+2011-11-15  Christian Bruel  <christian.bruel@st.com>
+
+	* varasm.c (default_unique_section): Fix order of partition strings.
+
+2011-11-14  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/linux.h (SUBTARGET_CPP_SPEC): Define __SH4_300__ if -m4-300.
+
+2011-10-26  Christian Bruel  <christian.bruel@st.com>
+
+        https://bugzilla.stlinux.com/show_bug.cgi?id=14812
+	* final.c (insn_current_reference_address): Use min length to pessimize
+	a forward branch address.
+
+2011-10-13  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_insn_length_adjustment): Use cur_length.
+
+2011-07-09  Christian Bruel  <christian.bruel@st.com>
+
+	* tree-inline.c (tree_inlinable_function_p): Use sorry instead of error.
+
+2011-08-05  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (LEGITIMATE_CONSTANT_P): replace by
+	 sh_legitimate_constant_p().
+	* config/sh/sh.c (sh_legitimate_constant_p): New function from
+	 LEGITIMATE_CONSTANT_P.
+	Don't allow fldi1/fldi0 in reload propagation.
+	(fldi_ok): Check TARGERT_FLDI.
+	* config/sh/sh-protos.h (sh_legitimate_constant_p): Add prototype.
+	* config/sh/sh.opt (-mfldi): New option.
+	* gcc/doc/invoke.tex (-mfldi): Describe.
+
+2011-07-19  Christian Bruel  <christian.bruel@st.com>
+
+	* cgraphunit.c (process_function_and_variable_attributes): don't warn
+	always_inline for static functions.
+
+2011-07-05  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl31163
+	* config/sh/sh.c (fldi_ok): New parameter secondary.
+	(sh_secondary_reload): Don't allow generation of fldi after reload.
+	* config/sh/sh.h (SECONDARY_INPUT_RELOAD_CLASS): Likewise.
+	* config/sh/constraints.md (fldi_ok): Allow fldi0 in constraints.
+	* config/sh/sh-protos.h (fldi_ok): Add secondary parameter.
+
+2011-05-25  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/embed-elf.h (TARGET_BUILTIN_TRAPA): Define.
+	* config/sh/sh.md (trap): Define insn.
+
+2011-04-19  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.h (TARGET_IEEE): Set to 1.
+
+2011-03-21  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/defaults.h (ASM_ALIGN_FUNCTION_LOG): Define.
+	* gcc/varasm.c (assemble_start_function): Use ASM_ALIGN_FUNCTION_LOG.
+	* gcc/config/sh/sh-protos.h (sh_align_function_log): Declare.
+	* gcc/config/sh/sh.c (sh_align_function_log): Define.
+	* gcc/config/sh/sh.h (sh_align_function_log): Define.
+	* gcc/defaults.h (ASM_ALIGN_FUNCTION_LOG): Define.
+
+2011-04-18  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.md (divsi3): Emit barrier after jump.
+
+2011-03-18  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.md (movsf_ie): Don't use R0 for float const reload.
+
+2011-03-07  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.c (expand_block_move): Optimize block copies by chunks of 48 bytes.
+
+2011-03-07  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.c (expand_sfunc_op): Fix REG_EQUAL note.
+	(sh_output_mi_thunk): Fix REG_DEAD note.
+
+2011-04-15  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.c (sh_output_function_epilogue): Reset mdep_reorg_phase.
+	  (sh_output_mi_thunk): Add barrier.
+	* gcc/resource.c (incr_ticks_for_insn): Add assert.
+
+2011-04-15  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config.gcc (sh-*): Compile sh-mem.c for SH targets.
+	* gcc/config/sh/t-shc: Add sh-mem.o dependency.
+	* gcc/config/sh/sh-mem.c: New file.
+
+2011-03-30  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/reorg.c (insn_conflict_latency): New function.
+	(fill_simple_delay_slots): Use insn_conflict_latency.
+
+2011-03-29  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh4_expand_cmpstr): Define.
+	* config/sh/sh.md (cmpstrsi): Define.
+
+2011-02-14  Christian Bruel  <christian.bruel@st.com>
+
+        https://bugzilla.stlinux.com/show_bug.cgi?id=11193
+	* gcc/reload.c (find_reloads): Revert exclusion of alternatives
+	 containing small register_class.
+
+2011-01-24  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/read-rtl.c (print_rtx_ptr_loc): Don't emit #line for .md files
+
+2011-01-24  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.md (movsf_ie): Adjust fp_mode for fldi instructions.
+
+2011-01-12  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.c (handler_uses_reg): Fix landing_pad scan.
+
+2011-01-11  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.c (movsf_ie): Fix fp_mode.
+
+2010-11-30  Christian Bruel  <christian.bruel@st.com>
+
+        https://bugzilla.stlinux.com/show_bug.cgi?id=10586
+	* gcc/config/sh/sh.c (find_barrier): Skip notes.
+	(sh_asm_count): Conservately count aligns before reorg.
+
+2010-11-08  Christian Bruel  <christian.bruel@st.com>
+
+        https://bugzilla.stlinux.com/show_bug.cgi?id=10391
+	* gcc/ira.c (update_equiv_regs): Don't propagate after blockage.
+
+2010-11-03  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh-protos.h (sh_expand_lround): Addto_nearest flag.
+	* gcc/config/sh/sh.c (sh_expand_lround): Use to_nearest flag.
+	* gcc/config/sh/sh.md (lroundsfsi2): Define.
+
+2010-10-13  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh-protos.h (sh_expand_lround): Declare.
+	* gcc/config/sh/sh.c (sh_expand_lround): Define.
+	* gcc/config/sh/sh.md (UNSPEC_BUILTIN_ROUND, lrintsfsi2): Define.
+
+2010-09-29  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (sh_compare_op0, sh_compare_op1): Delete.
+
+2010-09-24  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/gcc.c (process_command): -no-canonical-prefixes set by default.
+
+2010-09-23  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (TARGET_CPU_CPP_BUILTINS): Define __MOVD__.
+	(ROUND_TYPE_ALIGN, MOVE_BY_PIECES_P): Fix test.
+	* config/sh/sh.c (expand_block_move): Don't toggle sz bit.
+
+2010-09-20  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (dump_table): Fixed constants alignments for 
+	TARGET_ALIGN_DOUBLE.
+
+2010-09-02  Christian Bruel  <christian.bruel@st.com>
+
+	* final.c (remap_debug_filename): translate filename for CYGPATH.
+
+2010-08-12  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.opt (mdiv=call-pre1): New option.
+	* config/sh/sh.h (SH_DIV_CALL_PRE1): New sh_div_strategy.
+	* config/sh/sh.md (sdivsi3): Use TARGET_DIVIDE_CALL_PRE1.
+	 (ashlsi3_k): New pattern.
+	* doc/invoke.texi (mdiv=call-pre1): Document.
+
+2010-07-21  Christian Bruel  <christian.bruel@st.com>
+
+        https://bugzilla.stlinux.com/show_bug.cgi?id=9620
+        * config/sh/sh.c (find_barrier): Update alignement after barrier.
+
+2010-07-07  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.opt (mtas): New Target option.
+	* config/sh/sh.h (SUBTARGET_ASM_ISA_SPEC): Pass --tas to assembler
+	(TARGET_CPU_CPP_BUILTINS): Define __HAVE_TAS__.
+	* doc/invoke.texi (mtas,mno-tas): Documents.
+
+2010-07-05  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.c (sh_dwarf_register_span): No span if TARGET_FMOVD.
+	(push_regs): Push FP_REGISTER first.
+	(pop_regs): Pop FP_REGISTER last.
+	(emit_fpu_flip): Switch size if TARGET_FMOVD.
+
+2010-07-02  Christian Bruel  <christian.bruel@st.com>
+
+	* doc/md.texi: Document SH constraints.
+
+2010-06-04  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/supervisor-atomic.asm: (sync_nand_and_fetch): Fix
+
+2010-06-04  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/gthr-generic.c: Change license to GPLv3.
+	* gcc/gthr-generic.h: Likewise
+	* gcc/config/sh/supervisor-atomic.asm: Likewise
+	* gcc/config/sh/ieee-754-df.S: Likewise
+	* gcc/config/sh/ieee-754-df.S: Likewise
+
+2010-06-03  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/crti.asm (_init, _fini): Remove underscore.
+	* config/sh/crt1.asm (_init, _fini): Likewise.
+
+2010-06-02  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/linux.h (TARGET_OS_CPP_BUILTINS): Make __GNUC_STM_RELEASE__.
+
+2010-04-29  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh-protos.h (sh_varying_insn_p): Declare.
+	* gcc/config/sh/sh.c (sh_varying_insn_p): Define.
+	(sh_insn_length_adjustment): Use.
+	* gcc/config/sh/sh.h (VARYING_INSN_P): Define.
+	* gcc/final.c (VARYING_INSN_P): Use.
+
+2010-04-20  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl30850:
+	* config/sh/ieee-754-df.S (nedf2f): Don't check Qbit for NaNs.
+	* config/sh/ieee-754-sf.S (nesf2f): Likewise.
+	* config/sh/sh.md (cmpunsf_i1, cmpundf_i1): Likewise. Clobber R2.
+
+2010-04-09  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/sched-deps.c (sched_analyze_1): Don't extend R0 lifetime.
+	* config/sh/sh.md (movsf_ie): fix clobber constraint.
+
+2010-03-27  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_insn_length_adjustment): Adjust instruction size
+	 for jump_compact.
+
+2010-02-10  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (find_barrier): Don't emit a CP inside the GP setting.
+
+2010-01-04  Christian Bruel  <christian.bruel@st.com>
+
+        https://bugzilla.stlinux.com/show_bug.cgi?id=8178
+	* final.c (shorten_branches): Enable asm statements to vary.
+ 	* config/sh/sh.c (asm_size): Catch multiple .long asm statements.
+	(sh_insn_length_alignment): New function.
+	(sh_asm_count): force max addr if insn_current_address unknown.
+	* config/sh/sh-protos.h (sh_insn_length_alignment): Declare.
+	* config/sh/sh.h (INSN_LENGTH_ALIGNMENT): Call sh_insn_length_alignment.
+
+2010-01-26  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/t-sh: Remove duplicate gt-sh.h dependencies.
+
+2010-01-20  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (OVERRIDE_OPTIONS, OPTIMIZATION_OPTIONS): Don't force
+	flag_schedule_insns for pic.
+
+2009-10-26  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (ACCUMULATE_OUTGOING_ARGS): Define.
+	(MASK_ADJUST_UNROLL): Remove.
+        (OVERRIDE_OPTION): Check and set.
+	* config/sh/sh.opt (maccumulate-outgoing-args): New Target option.
+	(madjust-unroll): Remove.
+	* doc/invoke.texi (maccumulate-outgoing-args, madjust-unroll): Likewise.
+	* gcc/config/sh/sh.c (rounded_frame_size): Alloc outgoing args.
+
+2009-11-03  Christian Bruel  <christian.bruel@st.com>
+
+        https://bugzilla.stlinux.com/show_bug.cgi?id=7377
+ 	* config/sh/sh.c (sh_insn_length_adjustment): Adjust jumps labels with
+	alignment.
+
+2009-10-29  Yvan Roux  <yvan.roux@st.com>
+
+	* doc/invoke.texi (-Wbranch-probabilities-computation): Document.
+	* common.opt (-Wbranch-probabilities-computation): New warning option.
+	* profile.c (compute_branch_probabilities): Ignore inconsistent bb
+	and/or edge counts computation if -Wbranch-probabilities-computation is
+	given.
+
+2009-10-28  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (SUBTARGET_ASM_ISA_SPEC): --isa=sh4-up for generic SH4s.
+
+2009-10-26  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (SUBTARGET_ASM_ISA_SPEC): Fix specs for -m4-singles.
+	* config/sh/sh.opt (SH_ASM_SPEC): Add -mnotas option.
+	* doc/invoke.texi (-mnotas): Document.
+
+2009-10-22  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/lib1funcs.asm (udiv_qrnnd_16): Fix alignment.
+
+2009-10-21  Christian Bruel  <christian.bruel@st.com>
+	    Yvan Roux  <yvan.roux@st.com>
+
+	* config/sh/sh.c (sh_reorg): Fix relax after incoming edges.
+
+2009-10-16  Christian Bruel  <christian.bruel@st.com>
+
+	* cfg.c (dump_edge_info): Print locus.
+	* cfgexpand.c (expand_gimple_basic_block): Initialize goto_locus.
+
+2009-10-14  Antony King  <antony.king@st.com>
+
+	INSbl30528:
+	* gcc.c (do_spec_1): Add support for %M specs.
+	(getenv_spec_function): Allow multiple arguments.
+	* doc/invoke.texi: Likewise.
+
+2009-10-15  Christian Bruel  <christian.bruel@st.com>
+	    Yvan Roux  <yvan.roux@st.com>
+
+	* config/sh/sh.c (handler_uses_reg): New function.
+	(sh_reorg): Call for each region.
+	* except.c (struct eh_region): Move to except.h
+	(for_each_eh_region): Accepts parameter.
+	* except.h (struct eh_region): Move here.
+	* tree-cfg.c (for_each_eh_region): Accepts parameter.
+
+2009-10-12  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_output_mi_thunk): Mark temporary dead.
+
+2009-10-06  Antony King  <antony.king@st.com>
+
+	INSbl30052:
+	* config/sh/t-superh [LIB2FUNCS_EXTRA]: Add.
+	* config/sh/supervisor-atomic.asm: New file.
+
+2009-10-09  Christian Bruel  <christian.bruel@st.com>
+
+	* doc/invoke.texi (mdead-delay): Document.
+	* doc/gcc.info (mdead-delay): Document.
+
+2009-10-05  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_reorg): Call df_analyze for notes.
+
+2009-10-02  Christian Bruel  <christian.bruel@st.com>
+	    Yvan Roux  <yvan.roux@st.com>
+
+	* defaults.h (HOT_TEXT_SECTION_PREFIX,
+	 UNLIKELY_EXECUTED_TEXT_SECTION_PREFIX): New macros.
+	* dwarf2out.c (dwarf2out_init, dwarf2out_finish): unlikely_text_section
+	takes param.		  
+	* predict.c (choose_function_section): Remove.
+	* varasm.c (first_function_block_is_cold): Remove.
+	(initialize_cold_section_name): Handle named unlikely sections.
+	(unlikely_text_section): Takes tree parameter.
+	(unlikely_text_section_p): Remove.
+	(function_section): Handle cold sections.
+	* output.h (first_function_block_is_cold): Remove.
+	(unlikely_text_section_p): Likewise.
+	(unlikely_text_section): Takes tree parameter.
+	* config/i386/i386.c: first_function_block_is_cold renamed 
+	in_cold_section_p.
+
+2009-08-28  Jan Beulich  <jbeulich@novell.com>
+
+	* configure.ac: For in-tree ld, do a plain version check to
+	determine whether comdat groups are supported.
+	* configure: Regenerate.
+
+2009-09-24  Christian Bruel  <christian.bruel@st.com>
+
+	http://gcc.gnu.org/bugzilla/show_bug.cgi?id=41486
+	* config/sh/sh.h (flag_tree_cselim): Unset flag_tree_cselim.
+
+2009-09-24  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_set_return_address): Fix adjustment.
+	* config/sh/sh.h (flag_omit_frame_pointer): Set.
+	* config/sh/sh.md (RTX_FRAME_RELATED_P): Set.
+
+2009-09-24  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_optimization_options): Set flag_omit_frame_pointer.
+
+2009-09-03  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=7000
+	* config/sh/sh.md (movdf_i4): Fix length attribute.
+	* config/sh/sh.c (sh_jump_align): Rework.
+
+2008-05-06  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/28671
+	* tree-ssa-ccp.c (get_symbol_constant_value): Check DECL_WEAK.
+	* c-typeck.c (decl_constant_value): Likewise.
+
+2009-08-14  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/t-linux (LIB1ASMMFUNCS_DIVTABLE): Define.
+	* config/sh/t-sh (libgcc-4-200.a): Create.
+	(LIB1ASMMFUNCS_DIVTABLE): Use.
+	(LIB1ASMFUNCS): Remove _sdivsi3_i4 _udivsi3_i4 _div_table from built.
+	* config/sh/embed-elf.h (LIBGCC_SPEC): Fixed lgcc-X-4-200 specs.
+	* config/sh/lib1funcs.asm (ieee-754-X.S): Guard against L_div_table.
+
+2009-08-10  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh.c (OPTIMIZATION_OPTIONS): Unset fschedule_insns off.
+
+2009-08-07  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh.c (fixup_mova): Fix casesi_worker access.
+	(dump_table): Likewise.
+
+2009-07-30  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config.gcc (fix-proto): Set to no for SH.
+
+2009-07-27  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/t-linux (EXTRA_MULTILIB_PARTS): Set.
+	* config/sh/t-sh (unwind-dw2-Os-4-200.o): Remove.
+
+2009-07-27  Christian Bruel  <christian.bruel@st.com>
+
+        * config/sh/sh.h (OPTIMIZATION_OPTIONS): Set dead-delay if optimizing.
+	* config/sh/sh.opt (mdead-delay): don't force 0.
+
+2009-07-02  Christian Bruel  <christian.bruel@st.com>
+
+	* tree-sra.c (bitfield_overlaps_p): Fix array tree type check.
+
+2009-06-18  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (simultaneous-prefetches): Set for st40-300.
+
+2009-06-18  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=6459
+	* config/sh/sh.md (cbranchdi4_i): Don't define insn.
+
+2009-06-05  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh.c (expand_block_move): Improve 64 bit -mfmovd.
+
+2009-06-09  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (SUBTARGET_ASM_ISA_SPEC): Pass -isa=sh4-nofpu-up
+	 for m4-nofpu.
+
+2009-04-12  Christian Bruel  <christian.bruel@st.com>
+
+	* default.h (TARGET_USES_LEB128): New macro.
+	* config/sh/sh.h (TARGET_USES_LEB128): Redefine.
+	* dwarf2asm.c (TARGET_USES_LEB128): Use instead of HAVE_AS_LEB128.
+	* except.c: Likewise.
+	* doc/tm.texi (TARGET_USES_LEB128): Document.
+	* doc/tm.texi.in (TARGET_USES_LEB128): Document.
+	* doc/gccint.info (TARGET_USES_LEB128): Likewise.
+	
+2009-05-05  Antony King  <antony.king@st.com>
+	    Christian Bruel  <christian.bruel@st.com>
+
+        INSbl30131
+	* lib1funcs.asm: Change local label naming convention.
+	* lib1funcs-Os-4-200.asm: Idem.
+
+2009-04-09  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/t-sh (ic_invalidate_array_4a.o): Fix st40-300 isa build.
+       (ic_invalidate_4a): Idem.
+        * config/sh/embed-elf.h (LIBGCC_SPEC): Fix ic_invalidate*.
+	* config/sh/sh.h (TARGET_CPU_DEFAULT, SUBTARGET_ASM_ISA_SPEC): Idem.
+	(ASM_ISA_SPEC_DEFAULT): Idem.
+
+2009-04-09  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (load_gbr): Fix operand constraint.
+
+2009-03-31  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (broken_move): Fixed.
+
+2009-03-31  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (OVERRIDE_OPTIONS, OPTIMIZATION_OPTIONS): Set 
+	flag_emit_frame_pointer.
+ 
+2009-03-24  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/trap-handler.c (exit): Declare noreturn.
+	* config/sh/t-sh $(CFLAGS_FOR_TARGET): passed to trap-handler build.
+
+2009-03-12  Christian Bruel  <christian.bruel@st.com>
+
+	http://gcc.gnu.org/bugzilla/show_bug.cgi?id=39423
+	* fold-const.c (fold_plusminus_mult_expr): Move canonicalization of
+	 index+cst...
+	* expr.c (expand_expr_real_1): ... here.
+
+2009-03-10  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_expand_epilogue): Don't insert blockage.
+
+2009-03-09  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl21915
+	* config/sh/sh.h (SH_LINK_SPEC): Pass -shared on -pic.
+
+2009-03-09  Christian Bruel  <christian.bruel@st.com>
+
+	* configure.ac: Change BUGURL, PKGVERSION.
+	* configure: Regenerate.
+
+2009-03-03  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (cbranchsi4): Enable.
+
+2009-03-03  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (CASE_VECTOR_MODE): Fix offset size for hwbug.
+	* config/sh/sh.c (sh_insn_length_adjustment): Fix pools for hwbug.
+
+2009-02-16  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/superh.h (SUBTARGET_ASM_RELAX_SPEC): Remove.
+	* config/sh/sh.h (SUBTARGET_ASM_RELAX_SPEC): Likewise.
+	(subtarget_asm_relax_spec). Likewise.
+
+2009-02-05  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (asm_size): Handle alignments.
+	(sh_asm_count): Likewise.
+	(sh_hw_workaround): Redesigned.
+	* config/sh/sh.h (SH_LINK_SPEC): pass --db-page-bug to the linker.
+	(INSN_LENGTH_ALIGNMENT): Fix minimum alignment.
+	* config/sh/linux-atomic.h: DB_ST40300_BUG_WORKAROUND fixes.
+	* config/sh/lib1funcs.asm: Likewise.
+
+2009-01-24  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (ivsi_inv_hitable): Fix alternative.
+	(divsi_inv_qitable): Likewise.
+
+2009-01-24  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/constraints.md (R03): New constraint.
+
+2009-01-24  Christian Bruel  <christian.bruel@st.com>
+
+	* emit-rtl.c (emit_insn_after_1): Update SEQUENCE.
+
+2009-01-20  Christian Bruel  <christian.bruel@st.com>
+
+	* final.c (TARGET_ASM_COUNT): Use.
+	* config/sh/sh-protos.h (sh_asm_count): Declared.
+	* config/sh/sh.h (TARGET_ASM_COUNT): Declared.
+	* config/sh/sh.c (sh_asm_count): Defined.
+
+2009-01-19  Christian Bruel  <christian.bruel@st.com>
+
+	* final.c (asm_insn_count): Check for empty asm.
+
+2009-01-05  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl29600
+	* config/sh/sh.c (sh_dwarf_register_span): New function.
+	(TARGET_DWARF_REGISTER_SPAN): Defined.
+	* config/sh/sh-protos.h (sh_dwarf_register_span): Declared.
+
+2008-12-08  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_insn_length_adjustment): Optimize out delay slot.
+	* config/sh/sh.md (dup_db_insn): New unspec pattern.
+	* config/sh/sh.opt (mdead-delay): New option.
+	* final.c (realloc_insn_lengths): New function.
+	* output.h (realloc_insn_lengths): Declare.
+
+2008-12-08  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (OPVERRIDE_OPTIONS): Don't force function alignment.
+
+2008-11-28  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl29605
+	* config/sh/sh.opt (mfmovd): Document.
+
+2008-11-27  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (CAN_DEBUG_WITHOUT_FP): Defined.
+
+2008-11-14  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.opt (mspace): Removed.
+	* doc/invoke.texi (mspace): Removed.
+	* config/sh/sh.h: Use optimize_size for TARGET_SMALLCODE.
+	* config/sh/sh.c: Likewise.
+	* config/sh/t-sh (TARGET_LIBGCC2_CFLAGS): Defined.
+
+2008-10-30  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_reorg): Allow relaxation within simple loops.
+	
+2008-10-24  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=4907
+	* config/sh/sh.md (casesi_worker_x): Add MEM indirect.
+	* config/sh/sh.c (sh_insn_length_adjustment): Handle casesi_worker.
+
+2008-10-12  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_forward_branch_p): Handle casesi_worker.
+
+2008-05-28  Antony King  <antony.king@st.com>
+
+	Fix INSbl27707:
+	* config/sh/superh.h (LIB_SPEC): Re-order libraries.
+
+2008-08-03  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/24528
+	* config/sh/sh.md (ashrsi2_16): make it a define_expand.
+	(ashrsi2_31): Likewise.
+
+2008-08-03  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (find_barrier): Update lengths for conditional branches.
+
+2008-07-09  Christian Bruel  <christian.bruel@st.com>
+
+	st40-300 hardware bug workaround	
+	* config/sh/linux.h: (SUBTARGET_LINK_SPEC): Options passed to the linker.
+	* config/sh/sh.h (TARGET_CPU_CPP_BUILTINS): Define DB_ST40300_BUG_WORKAROUND.
+	(OVERRIDE_OPTIONS): Set align_functions.
+	* config/sh/sh.c (sh_hw_workaround, sh_forward_branch_p): New function.
+	(sh_insn_length_adjustment): Add length parameter, 
+	adjust length for workaround.
+	* config/sh/sh_protos.h (sh_hw_workaround): Likewise.
+	(sh_insn_length_adjustment): Add length parameter.
+	* final.c (final_scan_insn): call FINAL_PRESCAN_INSN.
+	* config/sh/sh.md (db-page-bug): new option.
+	* config/sh/sh.opt (mdb-page-bug): New option.
+
+2008-07-02  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (consttable_end): set length.
+	* config/sh/sh.h (MD_CAN_REDIRECT_BRANCH): Disable.
+	* final.c (shorten_branches): Add assertion.
+	* config/sh/sh.c (sh_jump_align): Use get_attr_min_length.
+	(barrier_align): Likewise.
+	(find_barrier): Take into account alignments into size.
+	(sh_reorg): use init_insn_lengths instead of INSN_ADDRESSES_FREE.
+
+2008-06-22  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (sh_cfun_naked_p): New function.
+	(sh_handle_fndecl_attribute): Likewise.
+	(sh_attribute_table): Add "naked".
+	(sh_expand_prologue): Check sh_cfun_naked_p.
+	(sh_expand_prologue): Likewise.
+
+2008-06-22  Christian Bruel  <christian.bruel@st.com>
+
+	(expand_cbranchdi4): Shut up warning.
+
+2008-06-22  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/24993
+	* config/sh/elf.h (MAX_OFILE_ALIGNMENT): Define.
+
+2008-06-17  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (doloop_end): Disable when optimizing for size.
+
+2008-04-17  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/28594
+	* config/sh/sh.c (expand_cbranchdi4): Use original operands for
+	msw_skip comparison.
+
+2008-04-25  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/28502
+	* config/sh/sh.c (barrier_align): Skip notes.
+
+2007-12-12  Christian Bruel  <christian.bruel@st.com>
+
+	* store-layout.c (finalize_record_size): Fixed TYPE_ALIGN.
+	* sh.c (expand_block_move): Optimize 64 bits copies if -mfmovd.
+	* sh.h (MOVE_BY_PIECES_P): Handle -mfmov.
+	(ROUND_TYPE_ALIGN): Likewise.
+
+2007-10-23  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/t-sh (_addsub_sf, _mul_sf, _addsub_df,  _extendsfdf2,
+	 _truncdfsf2, _fixunssfsi, _fixsfsi, _floatunssisf, _floatsisf,
+	_fixdfsi _floatunssidf _floatsidf, _muldf3, _divsf3): Renamed.
+	* config/sh/ieee-754-df.S: Likewise.
+	* config/sh/ieee-754-sf.S: Likewise.
+
+2007-10-23  Yvan Roux  <yvan.roux@st.com>
+
+	* config/sh/lib1funcs-4-300.asm (le128_neg): Fixed.
+	
+2007-10-04  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.c (for_each_path): Check just_multi_suffix and multi_suffix.
+
+2007-10-04  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/t-linux (LIB1ASMFUNCS_CACHE): Cleaned up.
+
+2007-10-04  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (TARGET_HAVE_TLS): Removed.
+	* config/sh/linux.h (TARGET_HAVE_TLS): Defined.
+
+2007-10-03  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.md (cmpnedf_i1): Fix.
+
+2007-09-20  Yvan Roux  <yvan.roux@st.com>
+
+	* config/sh/t-sh: (LIB1ASMFUNCS) Add asm functions.
+	* config/sh/ieee-754-df.S: Fixed.
+	* config/sh/IEEE-754/m3/divsf3.S: Fixed.
+	* config/sh/IEEE-754/m3/divdf3.S: Fixed.
+	* config/sh/IEEE-754/m3/addsf3.S: Fixed.
+	* config/sh/IEEE-754/m3/adddf3.S: Fixed.
+	* config/sh/IEEE-754/m3/mulsf3.S: Fixed.
+	* config/sh/IEEE-754/m3muldf3.S: Fixed.
+
+2007-09-07  Christian Bruel  <christian.bruel@st.com>
+
+	* sh.h (SH_DBX_REGISTER_NUMBER): Added fpscr and fixed sr/gbr_regs.
+
+2007-08-16  Antony King  <antony.king@st.com>
+
+	* configure.ac: Relaxed check for .[su]leb128 support.
+	* configure: Regenerate.
+
+2007-08-14  Andrew Stubbs  <andrew.stubbs@st.com>
+
+	* configure.ac (SYSTEM_HEADER_DIR): Adjust for in-tree Newlib.
+	* configure: Regenerate.
+
+2007-07-16  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.h (MOVE_MAX_PIECES): Tuned for TARGET_SH1.
+
+2007-06-26  Christian Bruel  <christian.bruel@st.com>
+
+	* gthr-generic.h: Rename *p to *__p.
+
+2007-05-23  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.opt (align-small-blocks=): New Optimisation.
+	* doc/invoke.texi (align-small-blocks=): Likewise.
+	* config/sh/sh.c (sh_jump_align): Check sh_align_small_blocks.
+	(barrier_align): Check sh_align_small_blocks.
+
+2007-04-30  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh-protos.h (sh_jump_align): New Function.
+	* config/sh/sh.c (sh_jump_align): Likewise.
+	(barrier_align): compute alignment based on TARGET_CACHE32.
+	* config/sh/sh.h (JUMP_ALIGN): Define.
+
+2007-03-29  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc/config/sh/sh.h (OVERRIDE_OPTIONS): Set assembler_dialect for sh1.
+
+2007-03-28  Christian Bruel  <christian.bruel@st.com>
+	* doc/invoke.texi: Document -m4-300.
+
+2007-03-09  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/sh.c (__nesf2): Renamed.
+	(__nedf2): Likewise.
+	* config/sh/ieee-754-df.S (__nesf2): Likewise.
+	* config/sh/ieee-754-sf.S (__nedf2): Likewise.
+	* config/sh/t-sh: Likewise.
+
+2007-01-31  Christian Bruel  <christian.bruel@st.com>
+
+	* basic-block.h (pre_edge_lcm_avs): Declare.
+	* config/i386/i386.h (EMIT_MODE_SET): Add FLIP parameter.
+	* doc/tm.texi (EMIT_MODE_SET): Idem.
+	* doc/tm.texi.in (EMIT_MODE_SET): Idem.
+	* config/sh/sh.h (EMIT_MODE_SET): Idem. Call emit_fpu_flip.
+        (CONDITIONAL_REGISTER_USAGE): Set global_regs[FPSCR_REG].
+	* config/sh/sh-protos.h	(emit_fpu_flip): Add proto.
+	* config/sh/sh.c (emit_fpu_flip): New function.
+	* config/sh/sh.md (toggle_pr): Defined for TARGET_SH4_300.
+	Defined if TARGET_FPU_SINGLE.
+	fpscr_toggle don't go in delay slot (temporary fix).
+	* lcm.c (pre_edge_lcm_avs): Renamed from pre_edge_lcm.
+	Call clear_aux_for_edges. Fix comments.
+	(pre_edge_lcm): New wrapper function to call pre_edge_lcm_avs.
+	(pre_edge_rev_lcm): Idem.
+	* mode-switching.c (init_modes_infos): New function.
+	(bb_has_complex_pred): New function.
+	(free_modes_infos): Idem.
+	(init_modes_infos): Idem
+	(add_mode_set): Idem.
+	(get_mode): Idem.
+	(commit_mode_sets): Idem.
+	(merge_modes): Idem.
+	(set_flip_status): Idem
+	(test_flip_status): Idem.
+	(optimize_mode_switching): Add support to maintain flip mode information.
+2007-01-29  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/IEEE-754/m3/adddf3.S: Fix inf mantissa.
+	* config/sh/IEEE-754/m3/addsf3.S: Likewise.
+	* config/sh/IEEE-754/m3/divsf3.S: Intialize xff000000 label.
+	* config/sh/sh.c (expand_sfunc_op): Use FIRST_FP_PARM_REG for
+	parameters.
+	* config/sh/sh.h (TARGET_OSFP): Disable.
+	* config/sh/sh.md (addsf3, subsf3, mulsf3): Use expand_sfunc_binopt
+	only when TARGET_OSFP.
+	(adddf3, subdf3, muldf3): Likewise.
+	(trunkdfsf2): Likewise.
+
+2007-01-22  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/t-sh (LIB1ASMFUNCS): Remove _add_sub_sf3, _mulsf3,
+	_hypotf, _muldf3, _add_sub_df3, _divsf3, _divdf3, _fixunssfsi,
+	_fixsfsi, _fixunsdfsi, _fixdfsi, _floatunssisf, _floatsisf,
+	_floatunssidf and _floatsidf.
+	(FPBIT, DPBIT, dp-bit.c, fp-bit.c): Re-instated.
+
+2007-01-12  Andrew Stubbs  <andrew.stubbs@st.com>
+
+	* config/sh/trap-handler.c: Call exit like old one used to.
+
+2006-09-02  J"orn Rennecke  <joern.rennecke@st.com>
+
+	config/sh/t-sh: ($(T)ic_invalidate_array_4-100.o): Add -I. .
+	($(T)ic_invalidate_array_4-200.o): Likewise.
+	($(T)ic_invalidate_array_4a.o): Likewise.
+
+2006-09-02  J"orn Rennecke  <joern.rennecke@st.com>
+
+	* sh.md (*movsicc_t_false, *movsicc_t_true): Add mode.
+
+2006-11-10  J"orn Rennecke  <joern.rennecke@st.com> 
+	    Aanchal Khanna   <aanchalk@noida.hcltech.com>
+	    Rakesh Kumar  <rakesh.kumar@noida.hcltech.com>
+
+	PR target/29845
+	* config/sh/sh-protos.h (sh_function_kind): New enumerator
+	SFUNC_FREQUENT.
+	(expand_sfunc_unop, expand_sfunc_binop): Declare.
+	* config/sh/lib1funcs.asm (ieee-754-sf.S, ieee-754-df.S): #include.
+	* config/sh/t-sh (LIB1ASMFUNCS): Add nesf2, _nedf2, _gtsf2t, _gtdf2t,
+	_gesf2f, _gedf2f, _extendsfdf2, , _truncdfsf2, _add_sub_sf3, _mulsf3,
+	_hypotf, _muldf3, _add_sub_df3, _divsf3, _divdf3, _fixunssfsi,
+	_fixsfsi, _fixunsdfsi, _fixdfsi, _floatunssisf, _floatsisf,
+	_floatunssidf and _floatsidf.
+	(FPBIT, DPBIT, dp-bit.c, fp-bit.c): Removed.
+	* config/sh/ieee-754-df.S, config/sh/ieee-754-sf.S: New files.
+	* config/sh/predicates.md (soft_fp_comparison_operand): New predicate.
+	(soft_fp_comparison_operator): Likewise.
+	* config/sh/sh.c (sh_soft_fp_cmp, expand_sfunc_op): New functions.
+	(expand_sfunc_unop, expand_sfunc_binop): Likewise.
+	(from_compare): Add support for software floating point.
+	(function_symbol): Always look up name.  Add SFUNC_FREQUENT case.
+	* config/sh/sh.h (TARGET_SH1_SOFTFP): New macro.
+	(TARGET_SH1_SOFTFP_MODE): Likewise.
+	* config/sh/sh-modes.def (CC_FP_NE, CC_FP_GT, CC_FP_UNLT): New modes.
+	* config/sh/lib1funcs.h (SLC, SLI, SLCMP, DMULU_SAVE): New macros.
+	(DMULUL, DMULUH, DMULU_RESTORE, SHLL4, SHLR4, SHLL6, SHLR6): Likewise.
+	(SHLL12, SHLR12, SHLR19, SHLL23, SHLR24, SHLR21, SHLL21): Likewise.
+	(SHLR11, SHLR22, SHLR23, SHLR20, SHLL20, SHLD_COUNT, SHLRN): Likewise.
+	(SHLLN, DYN_SHIFT): Likewise.
+	(SUPPORT_SH3_OSFP, SUPPORT_SH3E_OSFP): Likewise.
+	(SUPPORT_SH4_NOFPU_OSFP, SUPPORT_SH4_SINGLE_ONLY_OSFP): Likewise.
+	(TARGET_OSFP): Likewise.
+	(OPTIMIZATION_OPTIONS): Always enable TARGET_CBRANCHDI4 and
+	TARGET_EXPAND_CBRANCHDI4.
+	If flag_trapping_math is set, make it 2.
+	(OVERRIDE_OPTIONS): If flag_trapping_math is 2 and non-trapping
+	software floating point is used, clear flag_trapping_math.
+	For SH1, set TARGET_EXPAND_CBRANCHDI4
+	* config/sh/ieee-754-df.S, config/sh/ieee-754-sf.S: New files.
+	* config/sh/IEEE-754/m3/divsf3.S: Likewise.
+	* config/sh/IEEE-754/m3/divdf3.S: Likewise.
+	* config/sh/IEEE-754/m3/floatunssisf.S: Likewise.
+	* config/sh/IEEE-754/m3/floatunssidf.S: Likewise.
+	* config/sh/IEEE-754/m3/fixunsdfsi.S: Likewise.
+	* config/sh/IEEE-754/m3/divdf3-rt.S: Likewise.
+	* config/sh/IEEE-754/m3/addsf3.S: Likewise.
+	* config/sh/IEEE-754/m3/adddf3.S: Likewise.
+	* config/sh/IEEE-754/m3/mulsf3.S: Likewise.
+	* config/sh/IEEE-754/m3/muldf3.S: Likewise.
+	* config/sh/IEEE-754/m3/floatsisf.S: Likewise.
+	* config/sh/IEEE-754/m3/floatsidf.S: Likewise.
+	* config/sh/IEEE-754/m3/fixdfsi.S: Likewise.
+	* config/sh/IEEE-754/divdf3.S: Likewise.
+	* config/sh/IEEE-754/floatunssisf.S: Likewise.
+	* config/sh/IEEE-754/fixunsdfsi.S: Likewise.
+	* config/sh/IEEE-754/adddf3.S: Likewise.
+	* config/sh/IEEE-754/floatsisf.S: Likewise.
+	* config/sh/IEEE-754/muldf3.S: Likewise.
+	* config/sh/IEEE-754/fixdfsi.S: Likewise.
+	* config/sh/IEEE-754/divsf3.S: Likewise.
+	* config/sh/IEEE-754/fixunssfsi.S: Likewise.
+	* config/sh/IEEE-754/floatunssidf.S: Likewise.
+	* config/sh/IEEE-754/addsf3.S: Likewise.
+	* config/sh/IEEE-754/mulsf3.S: Likewise.
+	* config/sh/IEEE-754/floatsidf.S: Likewise.
+	* config/sh/IEEE-754/fixsfsi.S: Likewise.
+	* config/sh/sh.md (SF_NAN_MASK, DF_NAN_MASK, FR4_REG): New constants.
+	(fpcmp_i1, addsf3_i3, subsf3_i3): New patterns.
+	(mulsf3_i3, cmpnesf_i1, cmpgtsf_i1, cmpunltsf_i1): Likewise.
+	(cmpeqsf_i1_finite, cmplesf_i1_finite, cmpunsf_i1): Likewise.
+	(cmpuneqsf_i1, movcc_fp_ne, movcc_fp_gtmovcc_fp_unlt): Likewise.
+	(cmpltgtsf_t, cmporderedsf_t, cmpltgtsf_t_4): Likewise.
+	(cmporderedsf_t_4, abssc2, adddf3_i3_wrap, adddf3_i3): Likewise.
+	(muldf3_i3_wrap, muldf3_i3, cmpnedf_i1, cmpgtdf_i1): Likewise.
+	(cmpunltdf_i1, cmpeqdf_i1_finite, cmpundf_i1, cmpuneqdf_i1): Likewise.
+	(cmpltgtdf_t, cmpordereddf_t_4, extendsfdf2_i1): Likewise.
+	(extendsfdf2_i2e, extendsfdf2_i2e_r0, truncdfsf2_i2e): Likewise.
+	(extendsfdf2_i1_r0, truncdfsf2_i1): Likewise.
+	(cmpun_sdf, sunle, cmpuneq_sdf, bunle, bunlt): Likewise.
+
+2006-11-03  Andrew Stubbs  <andrew.stubbs@st.com>
+
+	* config/sh/crt1.asm (_superh_trap_handler): Remove function.
+	* config/sh/trap-handler.c: New file.
+	* config/sh/t-elf (EXTRA_MULTILIB_PARTS): Add trap-handler.o.
+	* config/sh/t-superh (EXTRA_MULTILIB_PARTS): Likewise.
+	* config/sh/t-sh: Add rule for trap-handler.o.
+	* config/sh/elf.h (STARTFILE_SPEC): Add trap-handler.o.
+	* config/sh/superh.h (STARTFILE_SPEC): Likewise.
+
+2006-04-11  J"orn Rennecke <joern.rennecke@st.com>
+
+	* gthr-generic.h: Update to match
+	http://gcc.gnu.org/ml/gcc-patches/2006-04/msg00237.html .
+	* gthr-generic.c, gthr-objc-generic.c: Likewise.
+	* Makefile.in configure.ac: Likewise.
+	* configure: Regenerate.
+
+2006-01-17  Antony King <anthony.king@st.com>
+            J"orn Rennecke <joern.rennecke@st.com>
+
+	* configure.ac: Recognize 'generic' value for threads.
+	Check for existance of a *.c and gthr-objc-*.c file for thread support.
+	* configure: Regenerate.
+	* gthr-generic.h: New file.
+	* gthr-generic.c: New file.
+	* gthr-objc-generic.c: New file.
diff -urN gcc-4.7.3/gcc/collect2.c st40-4.7.3-13080/gcc/gcc/collect2.c
--- gcc-4.7.3/gcc/collect2.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/collect2.c	2013-04-30 11:08:54.000000000 +0200
@@ -6,6 +6,7 @@
    Contributed by Chris Smith (csmith@convex.com).
    Heavily modified by Michael Meissner (meissner@cygnus.com),
    Per Bothner (bothner@cygnus.com), and John Gilmore (gnu@cygnus.com).
+   Copyright (c) 2013 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -2660,6 +2661,8 @@
           if (found_lto)
             continue;
 
+	  fatal_error ("__gnu_lto_v1 not implemented");
+
           /* Look for the LTO info marker symbol, and add filename to
              the LTO objects list if found.  */
           for (p = buf; (ch = *p) != '\0' && ch != '\n'; p++)
diff -urN gcc-4.7.3/gcc/common/config/sh/sh-common.c st40-4.7.3-13080/gcc/gcc/common/config/sh/sh-common.c
--- gcc-4.7.3/gcc/common/config/sh/sh-common.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/common/config/sh/sh-common.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002,
    2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011
    Free Software Foundation, Inc.
+   Copyright (c) 2013 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -190,18 +191,14 @@
 static void
 sh_option_init_struct (struct gcc_options *opts)
 {
-  /* We can't meaningfully test TARGET_SH2E / TARGET_IEEE
-     here, so leave it to TARGET_OPTION_OVERRIDE to set
-     flag_finite_math_only.  We set it to 2 here so we know if the user
-     explicitly requested this to be on or off.  */
-  opts->x_flag_finite_math_only = 2;
 }
 
 /* Implement TARGET_OPTION_DEFAULT_PARAMS.  */
 static void
 sh_option_default_params (void)
 {
-  set_default_param_value (PARAM_SIMULTANEOUS_PREFETCHES, 2);
+   set_default_param_value (PARAM_SIMULTANEOUS_PREFETCHES,
+ 			   (TARGET_SH4_300 ? 6 : 2));
 }
 
 #undef TARGET_OPTION_OPTIMIZATION_TABLE
diff -urN gcc-4.7.3/gcc/common.opt st40-4.7.3-13080/gcc/gcc/common.opt
--- gcc-4.7.3/gcc/common.opt	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/common.opt	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
 
 ; Copyright (C) 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012
 ; Free Software Foundation, Inc.
+; Copyright (c) 2009 STMicroelectronics.
 ;
 ; This file is part of GCC.
 ;
@@ -542,6 +543,10 @@
 Common Var(flag_fatal_errors)
 Exit on the first error occurred
 
+Wnon-finite-math
+Common Var(warn_non_finite_math) Warning
+Warn if explicit NaNs or infinities are used with -ffinite-math-only
+
 Wframe-larger-than=
 Common RejectNegative Joined UInteger
 -Wframe-larger-than=<number>	Warn if a function's stack frame requires more than <number> bytes
@@ -713,6 +718,10 @@
 Z
 Driver
 
+Wbranch-probabilities-computation
+Common Var(warn_branch_probabilities_computation) Warning
+Warn instead of error in probabilities computation in -fbranch-probabilities
+
 aux-info
 Common Separate Var(aux_info_file_name)
 -aux-info <file>	Emit declaration information into <file>
@@ -1166,6 +1175,10 @@
 Perform redundant load after store elimination in global common subexpression
 elimination
 
+fcse-sincos
+Common Report Var(flag_cse_sincos) Optimization
+Enable sincos merging
+
 fgcse-after-reload
 Common Report Var(flag_gcse_after_reload) Optimization
 Perform global common subexpression elimination after register allocation
diff -urN gcc-4.7.3/gcc/config/arm/arm.c st40-4.7.3-13080/gcc/gcc/config/arm/arm.c
--- gcc-4.7.3/gcc/config/arm/arm.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/config/arm/arm.c	2013-05-23 09:49:51.000000000 +0200
@@ -23873,9 +23873,8 @@
 
   nregs = GET_MODE_SIZE (GET_MODE (rtl)) / 8;
   p = gen_rtx_PARALLEL (VOIDmode, rtvec_alloc (nregs));
-  regno = (regno - FIRST_VFP_REGNUM) / 2;
   for (i = 0; i < nregs; i++)
-    XVECEXP (p, 0, i) = gen_rtx_REG (DImode, 256 + regno + i);
+    XVECEXP (p, 0, i) = gen_rtx_REG (DImode, regno + i);
 
   return p;
 }
diff -urN gcc-4.7.3/gcc/config/i386/i386.h st40-4.7.3-13080/gcc/gcc/config/i386/i386.h
--- gcc-4.7.3/gcc/config/i386/i386.h	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/config/i386/i386.h	2013-03-27 16:11:13.000000000 +0100
@@ -2,6 +2,7 @@
    Copyright (C) 1988, 1992, 1994, 1995, 1996, 1997, 1998, 1999, 2000,
    2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011
    Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -2162,7 +2163,7 @@
    is the set of hard registers live at the point where the insn(s)
    are to be inserted.  */
 
-#define EMIT_MODE_SET(ENTITY, MODE, HARD_REGS_LIVE) 			\
+#define EMIT_MODE_SET(ENTITY, MODE, FLIP, HARD_REGS_LIVE)		\
   ((MODE) != I387_CW_ANY && (MODE) != I387_CW_UNINITIALIZED		\
    ? emit_i387_cw_initialization (MODE), 0				\
    : 0)
diff -urN gcc-4.7.3/gcc/config/sh/constraints.md st40-4.7.3-13080/gcc/gcc/config/sh/constraints.md
--- gcc-4.7.3/gcc/config/sh/constraints.md	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/config/sh/constraints.md	2013-04-30 11:08:54.000000000 +0200
@@ -1,5 +1,6 @@
 ;; Constraint definitions for Renesas / SuperH SH.
 ;; Copyright (C) 2007, 2008, 2011, 2012 Free Software Foundation, Inc.
+;; Copyright (c) 2009 STMicroelectronics.
 ;;
 ;; This file is part of GCC.
 ;;
@@ -90,6 +91,9 @@
 (define_register_constraint "z" "R0_REGS"
   "R0 register.")
 
+(define_register_constraint "R03" "R0R3_REGS"
+  "R0/R3 registers.")
+
 ;; Integer constraints
 (define_constraint "I06"
   "A signed 6-bit constant, as used in SHmedia beqi, bnei and xori."
@@ -167,12 +171,12 @@
 (define_constraint "G"
   "Double constant 0."
   (and (match_code "const_double")
-       (match_test "fp_zero_operand (op) && fldi_ok ()")))
+       (match_test "fp_zero_operand (op) && fldi_ok (false)")))
 
 (define_constraint "H"
   "Double constant 1."
   (and (match_code "const_double")
-       (match_test "fp_one_operand (op) && fldi_ok ()")))
+       (match_test "fp_one_operand (op) && fldi_ok (false)")))
 
 ;; Extra constraints
 (define_constraint "Q"
diff -urN gcc-4.7.3/gcc/config/sh/elf.h st40-4.7.3-13080/gcc/gcc/config/sh/elf.h
--- gcc-4.7.3/gcc/config/sh/elf.h	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/config/sh/elf.h	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 1996, 1997, 2000, 2001, 2002, 2004, 2005, 2007, 2010
    Free Software Foundation, Inc.
    Contributed by Ian Lance Taylor <ian@cygnus.com>.
+   Copyright (c) 2009 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -35,11 +36,10 @@
 #undef WCHAR_TYPE
 /* #define WCHAR_TYPE (TARGET_SH5 ? "int" : "long int") */
 #define WCHAR_TYPE SH_ELF_WCHAR_TYPE
-   
+
 #undef WCHAR_TYPE_SIZE
 #define WCHAR_TYPE_SIZE 32
 
-
 /* The prefix to add to user-visible assembler symbols.  */
 
 #undef LOCAL_LABEL_PREFIX
@@ -75,7 +75,7 @@
 
 #undef STARTFILE_SPEC
 #define STARTFILE_SPEC \
-  "%{!shared: crt1.o%s} crti.o%s \
+  "%{!shared: crt1.o%s trap-handler.o%s} crti.o%s \
    %{!shared:crtbegin.o%s} %{shared:crtbeginS.o%s}"
 
 #undef ENDFILE_SPEC
@@ -88,3 +88,6 @@
 /* ASM_OUTPUT_CASE_LABEL is defined in elfos.h.  With it,
    a redundant .align was generated.  */
 #undef  ASM_OUTPUT_CASE_LABEL
+
+#undef MAX_OFILE_ALIGNMENT
+#define MAX_OFILE_ALIGNMENT (((unsigned int) 1 << 20) * 8)
diff -urN gcc-4.7.3/gcc/config/sh/embed-elf.h st40-4.7.3-13080/gcc/gcc/config/sh/embed-elf.h
--- gcc-4.7.3/gcc/config/sh/embed-elf.h	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/config/sh/embed-elf.h	2013-04-30 11:08:54.000000000 +0200
@@ -1,7 +1,8 @@
-/* Definitions of target machine for GNU compiler for Renesas / SuperH SH 
+/* Definitions of target machine for GNU compiler for Renesas / SuperH SH
    non-Linux embedded targets.
    Copyright (C) 2002, 2003, 2007, 2010, 2011 Free Software Foundation, Inc.
    Contributed by J"orn Rennecke <joern.rennecke@superh.com>
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -22,15 +23,20 @@
 #undef USER_LABEL_PREFIX
 #define USER_LABEL_PREFIX "_"
 
+/* builtin_trap can use trapa.  */
+#undef TARGET_BUILTIN_TRAPA
+#define TARGET_BUILTIN_TRAPA 1
+
 /* While the speed-optimized implementations of udivsi3_i4i / sdivsi3_i4i
    in libgcc are not available for SH2, the space-optimized ones in
    libgcc-Os-4-200 are.  Thus, when not optimizing for space, link
    libgcc-Os-4-200 after libgcc, so that -mdiv=call-table works for -m2.  */
 #define LIBGCC_SPEC "%{!shared: \
-  %{m4-100*:-lic_invalidate_array_4-100} \
-  %{m4-200*:-lic_invalidate_array_4-200} \
-  %{m4-300*|m4-340:-lic_invalidate_array_4a %{!Os: -lgcc-4-300}} \
-  %{m4a*:-lic_invalidate_array_4a}} \
-  %{Os: -lgcc-Os-4-200} \
+  %{!m4-100*:%{!m4-200*:%{!m4-300*:%{!m4a*:-lic_invalidate}}}}	\
+  %{m4-100*:-lic_invalidate_4-100}				\
+  %{m4-200*:-lic_invalidate_4-200}				\
+  %{m4-300*|-m4-340:-lic_invalidate_4a}			        \
+  %{m4a*:-lic_invalidate_4a}}					\
   -lgcc \
-  %{!Os: -lgcc-Os-4-200}"
+  %{Os: -lgcc-Os-4-200}					        \
+  %{!Os: %{m4-300*|-m4-340: -lgcc-4-300} %{!m4-300*:%{!m4-340: -lgcc-4-200}}}"
diff -urN gcc-4.7.3/gcc/config/sh/linux.h st40-4.7.3-13080/gcc/gcc/config/sh/linux.h
--- gcc-4.7.3/gcc/config/sh/linux.h	2013-03-26 12:38:31.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/config/sh/linux.h	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 1999, 2000, 2002, 2003, 2004, 2005, 2006, 2007, 2010, 2011
    Free Software Foundation, Inc.
    Contributed by Kazumoto Kojima <kkojima@rr.iij4u.or.jp>
+   Copyright (c) 2009 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -29,11 +30,13 @@
 #define SUBTARGET_CPP_SPEC "\
    %{posix:-D_POSIX_SOURCE} \
    %{pthread:-D_REENTRANT -D_PTHREADS} \
-"
+   %{m4-300*:-D__SH4_300__} "
 
 #define TARGET_OS_CPP_BUILTINS() \
   do						\
     {						\
+      extern const char version_string[];       \
+      builtin_define_with_value ("__GNUC_STM_RELEASE__", version_string, 1); \
       GNU_USER_TARGET_OS_CPP_BUILTINS();	\
     }						\
   while (0)
diff -urN gcc-4.7.3/gcc/config/sh/newlib.h st40-4.7.3-13080/gcc/gcc/config/sh/newlib.h
--- gcc-4.7.3/gcc/config/sh/newlib.h	2012-10-01 13:18:40.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/config/sh/newlib.h	2013-04-26 13:39:48.000000000 +0200
@@ -27,3 +27,4 @@
 #undef  NO_IMPLICIT_EXTERN_C
 #define NO_IMPLICIT_EXTERN_C 1
 
+
diff -urN gcc-4.7.3/gcc/config/sh/predicates.md st40-4.7.3-13080/gcc/gcc/config/sh/predicates.md
--- gcc-4.7.3/gcc/config/sh/predicates.md	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/config/sh/predicates.md	2013-04-30 11:08:54.000000000 +0200
@@ -1,6 +1,7 @@
 ;; Predicate definitions for Renesas / SuperH SH.
 ;; Copyright (C) 2005, 2006, 2007, 2008, 2009, 2010, 2012
 ;; Free Software Foundation, Inc.
+;; Copyright (c) 2009 STMicroelectronics.;;
 ;;
 ;; This file is part of GCC.
 ;;
@@ -743,6 +744,33 @@
 (define_predicate "symbol_ref_operand"
   (match_code "symbol_ref"))
 
+(define_special_predicate "soft_fp_comparison_operand"
+  (match_code "subreg,reg")
+{
+  switch (GET_MODE (op))
+    {
+    default:
+      return 0;
+    case CC_FP_NEmode: case CC_FP_GTmode: case CC_FP_UNLTmode:
+      break;
+    }
+  return register_operand (op, mode);
+})
+
+(define_predicate "soft_fp_comparison_operator"
+  (match_code "eq, unle, ge")
+{
+  switch (GET_CODE (op))
+    {
+    default:
+      return 0;
+    case EQ:  mode = CC_FP_NEmode;    break;
+    case UNLE:        mode = CC_FP_GTmode;    break;
+    case GE:  mode = CC_FP_UNLTmode;  break;
+    }
+  return register_operand (XEXP (op, 0), mode);
+})
+
 ;; Same as target_reg_operand, except that label_refs and symbol_refs
 ;; are accepted before reload.
 
diff -urN gcc-4.7.3/gcc/config/sh/sh4-300.md st40-4.7.3-13080/gcc/gcc/config/sh/sh4-300.md
--- gcc-4.7.3/gcc/config/sh/sh4-300.md	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/config/sh/sh4-300.md	2012-04-26 11:16:21.000000000 +0200
@@ -186,9 +186,9 @@
 ;; Scheduling runs before reorg, so we approximate this by saying that we
 ;; want the call to be paired with a preceding insn.
 ;; In most cases, the insn that loads the address of the call should have
-;; a nonzero latency (mov rn,rm doesn't make sense since we could use rn
+;; a non-zero latency (mov rn,rm doesn't make sense since we could use rn
 ;; for the address then).  Thus, a preceding insn that can be paired with
-;; a call should be eligible for the delay slot.
+;; a call should be elegible for the delay slot.
 ;;
 ;; calls introduce a longisch delay that is likely to flush the pipelines
 ;; of the caller's instructions.  Ordinary functions tend to end with a
diff -urN gcc-4.7.3/gcc/config/sh/sh.c st40-4.7.3-13080/gcc/gcc/config/sh/sh.c
--- gcc-4.7.3/gcc/config/sh/sh.c	2013-03-26 12:38:31.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/config/sh/sh.c	2013-06-04 11:31:27.000000000 +0200
@@ -4,6 +4,7 @@
    Free Software Foundation, Inc.
    Contributed by Steve Chamberlain (sac@cygnus.com).
    Improved by Jim Wilson (wilson@cygnus.com).
+   Copyright (c) 2011 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -57,7 +58,7 @@
 #include "alloc-pool.h"
 #include "tm-constrs.h"
 #include "opts.h"
-
+#include "except.h"
 
 int code_for_indirect_jump_scratch = CODE_FOR_indirect_jump_scratch;
 
@@ -169,8 +170,7 @@
 static bool shmedia_space_reserved_for_target_registers;
 
 static void split_branches (rtx);
-static int branch_dest (rtx);
-static void force_into (rtx, rtx);
+static unsigned int branch_dest (rtx);
 static void print_slot (rtx);
 static rtx add_constant (rtx, enum machine_mode, rtx);
 static void dump_table (rtx, rtx);
@@ -191,11 +191,13 @@
 static HOST_WIDE_INT rounded_frame_size (int);
 static bool sh_frame_pointer_required (void);
 static rtx mark_constant_pool_use (rtx);
+static int sh_cfun_naked_p (void);
 static tree sh_handle_interrupt_handler_attribute (tree *, tree, tree, int, bool *);
 static tree sh_handle_resbank_handler_attribute (tree *, tree,
 						 tree, int, bool *);
 static tree sh2a_handle_function_vector_handler_attribute (tree *, tree,
 							   tree, int, bool *);
+static tree  sh_handle_fndecl_attribute (tree *, tree, tree, int, bool *);
 static tree sh_handle_sp_switch_attribute (tree *, tree, tree, int, bool *);
 static tree sh_handle_trap_exit_attribute (tree *, tree, tree, int, bool *);
 static tree sh_handle_renesas_attribute (tree *, tree, tree, int, bool *);
@@ -325,7 +327,11 @@
     sh_handle_resbank_handler_attribute, false },
   { "function_vector",   1, 1, true,  false, false,
     sh2a_handle_function_vector_handler_attribute, false },
+  /* don't generate function prologue/epilogue and `ret' command.  */
+  { "naked",             0, 0, true, false, false,
+    sh_handle_fndecl_attribute, false },
   { NULL,                0, 0, false, false, false, NULL, false }
+
 };
 
 /* Initialize the GCC target structure.  */
@@ -593,7 +599,10 @@
   if (optimize > 1 && !optimize_size)
     target_flags |= MASK_SAVE_ALL_TARGET_REGS;
   sh_cpu = PROCESSOR_SH1;
-  assembler_dialect = 0;
+  if (TARGET_SH1)
+    assembler_dialect = 1;
+  else
+    assembler_dialect = 0;
   if (TARGET_SH2)
     sh_cpu = PROCESSOR_SH2;
   if (TARGET_SH2E)
@@ -688,6 +697,8 @@
       else if (! strcmp (sh_div_str, "call-table")
 	       && (TARGET_SH3 || TARGET_SH2A))
 	sh_div_strategy = SH_DIV_CALL_TABLE;
+      else if (! strcmp (sh_div_str, "call-pre1"))	
+ 	sh_div_strategy = SH_DIV_CALL_PRE1;
       else
 	/* Pick one that makes most sense for the target in general.
 	   It is not much good to use different functions depending
@@ -746,31 +757,18 @@
 
   if (targetm.small_register_classes_for_mode_p (VOIDmode))		\
     {
-      /* Never run scheduling before reload, since that can
-	 break global alloc, and generates slower code anyway due
-	 to the pressure on R0.  */
-      /* Enable sched1 for SH4 if the user explicitly requests.
-	 When sched1 is enabled, the ready queue will be reordered by
-	 the target hooks if pressure is high.  We can not do this for
-	 PIC, SH3 and lower as they give spill failures for R0.  */
-      if (!TARGET_HARD_SH4 || flag_pic)
-        flag_schedule_insns = 0;
       /* ??? Current exception handling places basic block boundaries
 	 after call_insns.  It causes the high pressure on R0 and gives
 	 spill failures for R0 in reload.  See PR 22553 and the thread
 	 on gcc-patches
          <http://gcc.gnu.org/ml/gcc-patches/2005-10/msg00816.html>.  */
-      else if (flag_exceptions)
-	{
-	  if (flag_schedule_insns && global_options_set.x_flag_schedule_insns)
-	    warning (0, "ignoring -fschedule-insns because of exception handling bug");
-	  flag_schedule_insns = 0;
-	}
-      else if (flag_schedule_insns
-	       && !global_options_set.x_flag_schedule_insns)
+      if (flag_exceptions)
 	flag_schedule_insns = 0;
     }
 
+  if (TARGET_DBHWBUG)
+       align_functions = 32;
+
   /* Unwind info is not correct around the CFG unless either a frame
      pointer is present or M_A_O_A is set.  Fixing this requires rewriting
      unwind info generation to be aware of the CFG and propagating states
@@ -814,6 +812,8 @@
   else if (align_jumps < (TARGET_SHMEDIA ? 4 : 2))
     align_jumps = TARGET_SHMEDIA ? 4 : 2;
 
+  flag_tree_cselim = 0;
+
   /* Allocation boundary (in *bytes*) for the code of a function.
      SH1: 32 bit alignment is faster, because instructions are always
      fetched as a pair from a longword boundary.
@@ -821,20 +821,6 @@
   if (align_functions == 0)
     align_functions
       = optimize_size ? FUNCTION_BOUNDARY/8 : (1 << CACHE_LOG);
-  /* The linker relaxation code breaks when a function contains
-     alignments that are larger than that at the start of a
-     compilation unit.  */
-  if (TARGET_RELAX)
-    {
-      int min_align
-	= align_loops > align_jumps ? align_loops : align_jumps;
-
-      /* Also take possible .long constants / mova tables int account.	*/
-      if (min_align < 4)
-	min_align = 4;
-      if (align_functions < min_align)
-	align_functions = min_align;
-    }
 
   /* If the -mieee option was not explicitly set by the user, turn it on
      unless -ffinite-math-only was specified.  See also PR 33135.  */
@@ -905,6 +891,12 @@
     }
 }
 
+static int deleted_delay_slot_p (rtx insn)
+{
+  return (GET_CODE (PATTERN (insn)) == UNSPEC_VOLATILE
+	  && XINT (PATTERN (insn), 1) == UNSPECV_DB_INSN);
+}
+
 /* Print operand x (an rtx) in assembler syntax to file stream
    according to modifier code.
 
@@ -943,7 +935,8 @@
     case '.':
       if (final_sequence
 	  && ! INSN_ANNULLED_BRANCH_P (XVECEXP (final_sequence, 0, 0))
-	  && get_attr_length (XVECEXP (final_sequence, 0, 1)))
+	  && (get_attr_length (XVECEXP (final_sequence, 0, 1))
+	      || deleted_delay_slot_p (XVECEXP (final_sequence, 0, 1))))
 	fprintf (stream, ASSEMBLER_DIALECT ? "/s" : ".s");
       break;
     case ',':
@@ -1413,158 +1406,6 @@
     SYMBOL_REF_FLAGS (XEXP (rtl, 0)) |= SYMBOL_FLAG_FUNCVEC_FUNCTION;
 }
 
-/* Like force_operand, but guarantees that VALUE ends up in TARGET.  */
-static void
-force_into (rtx value, rtx target)
-{
-  value = force_operand (value, target);
-  if (! rtx_equal_p (value, target))
-    emit_insn (gen_move_insn (target, value));
-}
-
-/* Emit code to perform a block move.  Choose the best method.
-
-   OPERANDS[0] is the destination.
-   OPERANDS[1] is the source.
-   OPERANDS[2] is the size.
-   OPERANDS[3] is the alignment safe to use.  */
-
-int
-expand_block_move (rtx *operands)
-{
-  int align = INTVAL (operands[3]);
-  int constp = (CONST_INT_P (operands[2]));
-  int bytes = (constp ? INTVAL (operands[2]) : 0);
-
-  if (! constp)
-    return 0;
-
-  /* If we could use mov.l to move words and dest is word-aligned, we
-     can use movua.l for loads and still generate a relatively short
-     and efficient sequence.  */
-  if (TARGET_SH4A_ARCH && align < 4
-      && MEM_ALIGN (operands[0]) >= 32
-      && can_move_by_pieces (bytes, 32))
-    {
-      rtx dest = copy_rtx (operands[0]);
-      rtx src = copy_rtx (operands[1]);
-      /* We could use different pseudos for each copied word, but
-	 since movua can only load into r0, it's kind of
-	 pointless.  */
-      rtx temp = gen_reg_rtx (SImode);
-      rtx src_addr = copy_addr_to_reg (XEXP (src, 0));
-      int copied = 0;
-
-      while (copied + 4 <= bytes)
-	{
-	  rtx to = adjust_address (dest, SImode, copied);
-	  rtx from = adjust_automodify_address (src, BLKmode,
-						src_addr, copied);
-
-	  set_mem_size (from, 4);
-	  emit_insn (gen_movua (temp, from));
-	  emit_move_insn (src_addr, plus_constant (src_addr, 4));
-	  emit_move_insn (to, temp);
-	  copied += 4;
-	}
-
-      if (copied < bytes)
-	move_by_pieces (adjust_address (dest, BLKmode, copied),
-			adjust_automodify_address (src, BLKmode,
-						   src_addr, copied),
-			bytes - copied, align, 0);
-
-      return 1;
-    }
-
-  /* If it isn't a constant number of bytes, or if it doesn't have 4 byte
-     alignment, or if it isn't a multiple of 4 bytes, then fail.  */
-  if (align < 4 || (bytes % 4 != 0))
-    return 0;
-
-  if (TARGET_HARD_SH4)
-    {
-      if (bytes < 12)
-	return 0;
-      else if (bytes == 12)
-	{
-	  rtx func_addr_rtx = gen_reg_rtx (Pmode);
-	  rtx r4 = gen_rtx_REG (SImode, 4);
-	  rtx r5 = gen_rtx_REG (SImode, 5);
-
-	  function_symbol (func_addr_rtx, "__movmemSI12_i4", SFUNC_STATIC);
-	  force_into (XEXP (operands[0], 0), r4);
-	  force_into (XEXP (operands[1], 0), r5);
-	  emit_insn (gen_block_move_real_i4 (func_addr_rtx));
-	  return 1;
-	}
-      else if (! optimize_size)
-	{
-	  const char *entry_name;
-	  rtx func_addr_rtx = gen_reg_rtx (Pmode);
-	  int dwords;
-	  rtx r4 = gen_rtx_REG (SImode, 4);
-	  rtx r5 = gen_rtx_REG (SImode, 5);
-	  rtx r6 = gen_rtx_REG (SImode, 6);
-
-	  entry_name = (bytes & 4 ? "__movmem_i4_odd" : "__movmem_i4_even");
-	  function_symbol (func_addr_rtx, entry_name, SFUNC_STATIC);
-	  force_into (XEXP (operands[0], 0), r4);
-	  force_into (XEXP (operands[1], 0), r5);
-
-	  dwords = bytes >> 3;
-	  emit_insn (gen_move_insn (r6, GEN_INT (dwords - 1)));
-	  emit_insn (gen_block_lump_real_i4 (func_addr_rtx));
-	  return 1;
-	}
-      else
-	return 0;
-    }
-  if (bytes < 64)
-    {
-      char entry[30];
-      rtx func_addr_rtx = gen_reg_rtx (Pmode);
-      rtx r4 = gen_rtx_REG (SImode, 4);
-      rtx r5 = gen_rtx_REG (SImode, 5);
-
-      sprintf (entry, "__movmemSI%d", bytes);
-      function_symbol (func_addr_rtx, entry, SFUNC_STATIC);
-      force_into (XEXP (operands[0], 0), r4);
-      force_into (XEXP (operands[1], 0), r5);
-      emit_insn (gen_block_move_real (func_addr_rtx));
-      return 1;
-    }
-
-  /* This is the same number of bytes as a memcpy call, but to a different
-     less common function name, so this will occasionally use more space.  */
-  if (! optimize_size)
-    {
-      rtx func_addr_rtx = gen_reg_rtx (Pmode);
-      int final_switch, while_loop;
-      rtx r4 = gen_rtx_REG (SImode, 4);
-      rtx r5 = gen_rtx_REG (SImode, 5);
-      rtx r6 = gen_rtx_REG (SImode, 6);
-
-      function_symbol (func_addr_rtx, "__movmem", SFUNC_STATIC);
-      force_into (XEXP (operands[0], 0), r4);
-      force_into (XEXP (operands[1], 0), r5);
-
-      /* r6 controls the size of the move.  16 is decremented from it
-	 for each 64 bytes moved.  Then the negative bit left over is used
-	 as an index into a list of move instructions.  e.g., a 72 byte move
-	 would be set up with size(r6) = 14, for one iteration through the
-	 big while loop, and a switch of -2 for the last part.  */
-
-      final_switch = 16 - ((bytes / 4) % 16);
-      while_loop = ((bytes / 4) / 16 - 1) * 16;
-      emit_insn (gen_move_insn (r6, GEN_INT (while_loop + final_switch)));
-      emit_insn (gen_block_lump_real (func_addr_rtx));
-      return 1;
-    }
-
-  return 0;
-}
-
 /* Prepare operands for a move define_expand; specifically, one of the
    operands must be in a register.  */
 
@@ -2202,7 +2043,6 @@
 	    op1 = force_reg (mode, op1);
         }
     }
-
   if (GET_MODE_CLASS (mode) == MODE_FLOAT)
     {
       if (code == LT
@@ -2414,37 +2254,111 @@
   INSN_DELETED_P (XVECEXP (insn, 0, 1)) = 1;
 }
 
+/* min/max for a 16-bits relative jump */
+#define FAR_JUMP_MIN -32764
+#define FAR_JUMP_MAX 32776
+
 const char *
 output_far_jump (rtx insn, rtx op)
 {
   struct { rtx lab, reg, op; } this_jmp;
   rtx braf_base_lab = NULL_RTX;
   const char *jump;
-  int far;
-  int offset = branch_dest (insn) - INSN_ADDRESSES (INSN_UID (insn));
+  bool far;
+  int offset, baddr;
   rtx prev;
+  int prev_count;
 
   this_jmp.lab = gen_label_rtx ();
 
-  if (TARGET_SH2
-      && offset >= -32764
-      && offset - get_attr_length (insn) <= 32766)
+  /* number of instructions before the jmp.  */
+  prev = prev_nonnote_insn (insn);
+  if (prev && NONJUMP_INSN_P (prev)
+      && INSN_CODE (prev) == CODE_FOR_indirect_jump_scratch)
+    prev_count = 2;
+  else
+    prev_count = 4;
+
+  baddr = INSN_ADDRESSES (INSN_UID (insn)) + prev_count;
+
+  /* First assume a braf_branch_p and see if it fits.  */
+  if (prev_count == 4)
+    {
+      /* The delayed instruction will be emitted BEFORE the braf !!. */
+      if (dbr_sequence_length ())
+	baddr += 2;
+    }
+
+  offset = branch_dest (insn) - baddr;
+
+  if (TARGET_SH2 && offset >= -32768 + 4 && offset <= 32767 + 4)
     {
-      far = 0;
-      jump = "mov.w	%O0,%1; braf	%1";
+      if (TARGET_DBHWBUG && prev_count == 4)
+	{
+	  /* we have */
+	  /* delayed instruction (size on its own)
+	     push  (2)
+	     mov   (2)
+	     bra   (2)
+             pop   (2)
+             .word (2) */
+	  /* or */
+	  /* push  (2)
+	     mov   (2)
+	     bra   (2)
+             pop   (2)
+             .word (2) */
+	  gcc_assert (get_attr_length (insn) == 10);
+	}
+      else if (TARGET_DBHWBUG)
+	{
+	  if (dbr_sequence_length ())
+	    gcc_assert (get_attr_length (insn) == 6);
+	  else
+	    gcc_assert (get_attr_length (insn) == 8);
+	}
+
+      far = false;
+      jump = "mov.w	%O0,%1\n\tbraf	%1";
     }
   else
     {
-      far = 1;
+      if (TARGET_DBHWBUG && NONJUMP_INSN_P ((prev = prev_nonnote_insn (insn)))
+	  && INSN_CODE (prev) == CODE_FOR_indirect_jump_scratch)
+	{
+	  if (dbr_sequence_length ())
+	    gcc_assert (get_attr_length (insn) == 10 || get_attr_length (insn) == 8);
+	  else
+	    gcc_assert (get_attr_length (insn) == 12 || get_attr_length (insn) == 10);
+	}
+      else if (TARGET_DBHWBUG)
+	{
+	  if (dbr_sequence_length ())
+	    {
+	      if (flag_pic)
+		gcc_assert (get_attr_length (insn) == 14);
+	      else
+		gcc_assert (get_attr_length (insn) == 14 || get_attr_length (insn) == 12);
+	    }
+	  else
+	    {
+	      if (flag_pic)
+		gcc_assert (get_attr_length (insn) == 16);
+	      else
+		gcc_assert (get_attr_length (insn) == 16 || get_attr_length (insn) == 14);
+	    }
+	}
+
+      far = true;
       if (flag_pic)
 	{
 	  if (TARGET_SH2)
-	    jump = "mov.l	%O0,%1; braf	%1";
+	    jump = "mov.l	%O0,%1\n\tbraf	%1";
 	  else
-	    jump = "mov.l	r0,@-r15; mova	%O0,r0; mov.l	@r0,%1; add	r0,%1; mov.l	@r15+,r0; jmp	@%1";
+	    jump = "mov.l	r0,@-r15\n\tmova	%O0,r0\n\t mov.l	@r0,%1\n\tadd	r0,%1\n\t mov.l	@r15+,r0\n\tjmp	@%1";
 	}
       else
-	jump = "mov.l	%O0,%1; jmp	@%1";
+	jump = "mov.l	%O0,%1\n\tjmp	@%1";
     }
   /* If we have a scratch register available, use it.  */
   if (NONJUMP_INSN_P ((prev = prev_nonnote_insn (insn)))
@@ -2452,7 +2366,7 @@
     {
       this_jmp.reg = SET_DEST (XVECEXP (PATTERN (prev), 0, 0));
       if (REGNO (this_jmp.reg) == R0_REG && flag_pic && ! TARGET_SH2)
-	jump = "mov.l	r1,@-r15; mova	%O0,r0; mov.l	@r0,r1; add	r1,r0; mov.l	@r15+,r1; jmp	@%1";
+	jump = "mov.l	r1,@-r15\n\t mova	%O0,r0\n\t mov.l	@r0,r1\n\t add	r1,r0\n\t mov.l	@r15+,r1\n\tjmp	@%1";
       output_asm_insn (jump, &this_jmp.lab);
       if (dbr_sequence_length ())
 	print_slot (final_sequence);
@@ -2472,8 +2386,11 @@
 	 the stack.  */
       if (TARGET_SH5)
 	output_asm_insn ("lds	r13, macl", 0);
-      else
-	output_asm_insn ("mov.l	r13,@-r15", 0);
+      else {
+	asm_fprintf (asm_out_file, "\tmov.l	r13,@-r15 \t%s %d\t[length = %d]\n",
+		     ASM_COMMENT_START, INSN_UID (insn),
+		     get_attr_length (insn));
+      }
       output_asm_insn (jump, &this_jmp.lab);
       if (TARGET_SH5)
 	output_asm_insn ("sts	macl, r13", 0);
@@ -2536,8 +2453,12 @@
 	      && ! INSN_ANNULLED_BRANCH_P (XVECEXP (final_sequence, 0, 0))
 	      && get_attr_length (XVECEXP (final_sequence, 0, 1)))
 	    {
-	      asm_fprintf (asm_out_file, "\tb%s%ss\t%LLF%d\n", logic ? "f" : "t",
+	      asm_fprintf (asm_out_file, "\tb%s%ss\t%LLF%d", logic ? "f" : "t",
 	                   ASSEMBLER_DIALECT ? "/" : ".", label);
+
+	      asm_fprintf (asm_out_file, "\t%s %d\t[length = %d]\n",
+			   ASM_COMMENT_START, INSN_UID (insn),
+			   get_attr_length (insn));
 	      print_slot (final_sequence);
 	    }
 	  else
@@ -2641,6 +2562,12 @@
   return templ;
 }
 
+/* Output a code sequence for INSN using TEMPLATE with OPERANDS; but before,
+   fill in operands 9 as a label to the successor insn.
+   We try to use jump threading where possible.
+   IF CODE matches the comparison in the IF_THEN_ELSE of a following jump,
+   we assume the jump is taken.  I.e. EQ means follow jmp and bf, NE means
+   follow jmp and bt, if the address is in range.  */
 const char *
 output_ieee_ccmpeq (rtx insn, rtx *operands)
 {
@@ -2992,7 +2919,7 @@
 	       && CONST_OK_FOR_K08 (INTVAL (x)))
         *total = 1;
       /* prepare_cmp_insn will force costly constants int registers before
-	 the cbranch[sd]i4 patterns can see them, so preserve potentially
+	 the cbrach[sd]i4 pattterns can see them, so preserve potentially
 	 interesting ones not covered by I08 above.  */
       else if (outer_code == COMPARE
 	       && ((unsigned HOST_WIDE_INT) INTVAL (x)
@@ -4081,9 +4008,9 @@
   rtx scan = barrier;
   int i;
   int need_align = 1;
+  int need_align_d = 1;
   rtx lab;
   label_ref_list_t ref;
-  int have_df = 0;
 
   /* Do two passes, first time dump out the HI sized constants.  */
 
@@ -4108,11 +4035,10 @@
 	      scan = emit_insn_after (gen_consttable_window_end (lab), scan);
 	    }
 	}
-      else if (p->mode == DFmode)
-	have_df = 1;
     }
 
   need_align = 1;
+  need_align_d = 1;
 
   if (start)
     {
@@ -4123,85 +4049,15 @@
 	    && recog_memoized (start) == CODE_FOR_casesi_worker_2)
 	  {
 	    rtx src = SET_SRC (XVECEXP (PATTERN (start), 0, 0));
-	    rtx lab = XEXP (XVECEXP (src, 0, 3), 0);
-
-	    scan = emit_label_after (lab, scan);
-	  }
-    }
-  if (TARGET_FMOVD && TARGET_ALIGN_DOUBLE && have_df)
-    {
-      rtx align_insn = NULL_RTX;
-
-      scan = emit_label_after (gen_label_rtx (), scan);
-      scan = emit_insn_after (gen_align_log (GEN_INT (3)), scan);
-      need_align = 0;
-
-      for (i = 0; i < pool_size; i++)
-	{
-	  pool_node *p = &pool_vector[i];
+	    rtx lab;
 
-	  switch (p->mode)
-	    {
-	    case HImode:
-	      break;
-	    case SImode:
-	    case SFmode:
-	      if (align_insn && !p->part_of_sequence_p)
-		{
-		  for (lab = p->label; lab; lab = LABEL_REFS (lab))
-		    emit_label_before (lab, align_insn);
-		  emit_insn_before (gen_consttable_4 (p->value, const0_rtx),
-				    align_insn);
-		  for (ref = p->wend; ref; ref = ref->next)
-		    {
-		      lab = ref->label;
-		      emit_insn_before (gen_consttable_window_end (lab),
-					align_insn);
-		    }
-		  delete_insn (align_insn);
-		  align_insn = NULL_RTX;
-		  continue;
-		}
-	      else
-		{
-		  for (lab = p->label; lab; lab = LABEL_REFS (lab))
-		    scan = emit_label_after (lab, scan);
-		  scan = emit_insn_after (gen_consttable_4 (p->value,
-							    const0_rtx), scan);
-		  need_align = ! need_align;
-		}
-	      break;
-	    case DFmode:
-	      if (need_align)
-		{
-		  scan = emit_insn_after (gen_align_log (GEN_INT (3)), scan);
-		  align_insn = scan;
-		  need_align = 0;
-		}
-	    case DImode:
-	      for (lab = p->label; lab; lab = LABEL_REFS (lab))
+	    gcc_assert (MEM_P (src));
+	    src = XEXP (src, 0);
+	    lab = XEXP (XVECEXP (src, 0, 3), 0);
 		scan = emit_label_after (lab, scan);
-	      scan = emit_insn_after (gen_consttable_8 (p->value, const0_rtx),
-				      scan);
-	      break;
-	    default:
-	      gcc_unreachable ();
-	    }
-
-	  if (p->mode != HImode)
-	    {
-	      for (ref = p->wend; ref; ref = ref->next)
-		{
-		  lab = ref->label;
-		  scan = emit_insn_after (gen_consttable_window_end (lab),
-					  scan);
-		}
 	    }
 	}
 
-      pool_size = 0;
-    }
-
   for (i = 0; i < pool_size; i++)
     {
       pool_node *p = &pool_vector[i];
@@ -4222,8 +4078,17 @@
 	    scan = emit_label_after (lab, scan);
 	  scan = emit_insn_after (gen_consttable_4 (p->value, const0_rtx),
 				  scan);
+
+	  need_align_d = 1;
 	  break;
+
 	case DFmode:
+	  if (TARGET_ALIGN_DOUBLE && need_align_d)
+	    {
+	      need_align = 0;
+	      need_align_d = 0;
+	      scan = emit_insn_after (gen_align_log (GEN_INT (3)), scan);
+	    }
 	case DImode:
 	  if (need_align)
 	    {
@@ -4289,6 +4154,8 @@
 	     order bits end up as.  */
 	  && GET_MODE (SET_DEST (pat)) != QImode
 	  && (CONSTANT_P (SET_SRC (pat))
+	      || (GET_CODE (SET_SRC (pat)) == UNSPEC_VOLATILE
+		  && XINT (SET_SRC (pat), 1) == UNSPECV_SP_SWITCH_B)
 	      /* Match mova_const.  */
 	      || (GET_CODE (SET_SRC (pat)) == UNSPEC
 		  && XINT (SET_SRC (pat), 1) == UNSPEC_MOVA
@@ -4358,6 +4225,10 @@
       wpat0 = XVECEXP (wpat, 0, 0);
       wpat1 = XVECEXP (wpat, 0, 1);
       wsrc = SET_SRC (wpat0);
+
+      gcc_assert (MEM_P (wsrc));
+      wsrc = XEXP (wsrc, 0);
+
       PATTERN (worker) = (gen_casesi_worker_2
 			  (SET_DEST (wpat0), XVECEXP (wsrc, 0, 1),
 			   XEXP (XVECEXP (wsrc, 0, 2), 0), lab,
@@ -4463,11 +4334,23 @@
   si_limit = 1018;
   hi_limit = 510;
 
+  if (TARGET_DBHWBUG)
+    {
+      hi_limit -= 2;
+      si_limit -= 2;
+    }
+
   while (from && count_si < si_limit && count_hi < hi_limit)
     {
       int inc = get_attr_length (from);
       int new_align = 1;
 
+      if (NOTE_P (from))
+	{
+	  from = NEXT_INSN (from);
+	  continue;
+	}
+
       /* If this is a label that existed at the time of the compute_alignments
 	 call, determine the alignment.  N.B.  When find_barrier recurses for
 	 an out-of-reach mova, we might see labels at the start of previously
@@ -4503,14 +4386,17 @@
       if (BARRIER_P (from))
 	{
 	  rtx next;
-
+	  int bar_align = barrier_align (from);
 	  found_barrier = from;
 
 	  /* If we are at the end of the function, or in front of an alignment
 	     instruction, we need not insert an extra alignment.  We prefer
 	     this kind of barrier.  */
-	  if (barrier_align (from) > 2)
-	    good_barrier = from;
+	  if (bar_align > 2)
+	    {
+	      new_align = 1 << bar_align;
+	      good_barrier = from;
+	    }
 
 	  /* If we are at the end of a hot/cold block, dump the constants
 	     here.  */
@@ -4638,12 +4524,20 @@
 	       && ! optimize_size)
 	new_align = 4;
 
-      /* There is a possibility that a bf is transformed into a bf/s by the
-	 delay slot scheduler.  */
-      if (JUMP_P (from) && !JUMP_TABLE_DATA_P (from) 
-	  && get_attr_type (from) == TYPE_CBRANCH
-	  && GET_CODE (PATTERN (NEXT_INSN (PREV_INSN (from)))) != SEQUENCE)
-	inc += 2;
+      /* long jumps will change the alignment for the .long label.  */
+      else if (GET_CODE (from) == JUMP_INSN
+ 	       && GET_CODE (PATTERN (from)) == SET
+ 	       && recog_memoized (from) == CODE_FOR_jump_compact
+ 	       && inc == 10)
+ 	new_align = 4;
+
+      /* There is a possibility that a bf is transformed into a bf/s by
+	 the DS scheduler.  Don't need to check for sequence since we
+	 are before it.  */
+      if (flag_delayed_branch)
+	if (JUMP_P (from) && !JUMP_TABLE_DATA_P (from)
+	    && get_attr_type (from) == TYPE_CBRANCH)
+	  inc += 2;
 
       if (found_si)
 	{
@@ -4654,6 +4548,9 @@
 	      si_align = new_align;
 	    }
 	  count_si = (count_si + new_align - 1) & -new_align;
+
+	  if (new_align < si_align)
+	    si_align = new_align;
 	}
       if (found_hi)
 	{
@@ -4664,6 +4561,9 @@
 	      hi_align = new_align;
 	    }
 	  count_hi = (count_hi + new_align - 1) & -new_align;
+
+	  if (new_align < hi_align)
+	    hi_align = new_align;	
 	}
       from = NEXT_INSN (from);
     }
@@ -4713,7 +4613,7 @@
 	from = PREV_INSN (from);
 
       /* Don't emit a constant table int the middle of global pointer setting,
-	 since that that would move the addressing base GOT into another table. 
+	 since that that would move the addressing base GOT into another table.
 	 We need the first mov instruction before the _GLOBAL_OFFSET_TABLE_
 	 in the pool anyway, so just move up the whole constant pool.
 	 However, avoid doing so when the last single GOT mov is the starting
@@ -4722,13 +4622,6 @@
       if (last_got && last_got != orig)
 	from = PREV_INSN (last_got);
 
-      /* Don't insert the constant pool table at the position which
-	 may be the landing pad.  */
-      if (flag_exceptions
-	  && CALL_P (from)
-	  && find_reg_note (from, REG_EH_REGION, NULL_RTX))
-	from = PREV_INSN (from);
-
       /* Walk back to be just before any jump or label.
 	 Putting it before a label reduces the number of times the branch
 	 around the constant pool table will be hit.  Putting it before
@@ -5168,7 +5061,7 @@
 
   ok = invert_jump (insn, label, 1);
   gcc_assert (ok);
-  
+
   /* If we are branching around a jump (rather than a return), prevent
      reorg from using an insn from the jump target as the delay slot insn -
      when reorg did this, it pessimized code (we rather hide the delay slot)
@@ -5230,6 +5123,29 @@
     }
 }
 
+int
+sh_jump_align (rtx label)
+{
+  rtx insn;
+  int size = 0;
+
+  gcc_assert (label && GET_CODE (label) == CODE_LABEL);
+
+  for (insn = NEXT_INSN (label);
+       insn && GET_CODE (insn) != BARRIER &&
+	 GET_CODE (insn) != CODE_LABEL;
+       insn = NEXT_INSN (insn))
+    {
+      if (INSN_P (insn))
+	size += get_attr_min_length (insn);
+
+      if (size > sh_align_small_blocks)
+	return align_jumps_log;
+    }
+
+  return 0;
+}
+
 /* BARRIER_OR_LABEL is either a BARRIER or a CODE_LABEL immediately following
    a barrier.  Return the base 2 logarithm of the desired alignment.  */
 int
@@ -5341,7 +5257,21 @@
 	}
     }
 
-  return align_jumps_log;
+  while (BARRIER_P (barrier_or_label))
+    barrier_or_label = next_nonnote_insn (barrier_or_label);
+
+  return sh_jump_align (barrier_or_label);
+}
+
+static bool
+in_between(rtx start, rtx end, rtx r)
+{
+  rtx scan;
+  for (scan = NEXT_INSN (start); scan && scan != end; scan = NEXT_INSN (scan))
+    if (scan == r)
+      return 1;
+
+  return 0;
 }
 
 /* If we are inside a phony loop, almost any kind of label can turn up as the
@@ -5368,6 +5298,49 @@
   return align_loops_log;
 }
 
+static int fixup_addr;
+
+/* Check if a register function load is not alive in an exception handler
+   and can be safely removed when relaxing.  */
+
+typedef struct
+{
+  bool ret;
+  rtx reg;
+} rdata;
+
+/* Conservative approach. Will return true even if reg is set in the handler
+so its value could be dead. */
+static void
+handler_uses_reg (rtx scan, void *arg)
+{
+  rdata *rarg = (rdata*)arg;
+  bool seen_jump = false;;
+
+  if (rarg->ret)
+    return;
+
+  for (; scan; scan = NEXT_INSN (scan))
+    {
+      if (INSN_P (scan) || CALL_P (scan))
+        seen_jump = true;
+
+      if (! reg_mentioned_p (rarg->reg, scan))
+        continue;
+
+      if (!seen_jump && reg_set_p (rarg->reg, scan))
+	{
+	  rarg->ret = false;
+	  return;
+	}
+      if (reg_referenced_p (rarg->reg, PATTERN (scan)))
+	{
+	  rarg->ret = true;
+	  return;
+	}
+    }
+}
+
 /* Do a final pass over the function, just before delayed branch
    scheduling.  */
 
@@ -5418,10 +5391,17 @@
 	    }
 	}
 
+      if (df && optimize)
+	{
+	  df_note_add_problem ();
+	  df_analyze ();
+	}
+
       for (insn = first; insn; insn = NEXT_INSN (insn))
 	{
 	  rtx pattern, reg, link, set, scan, dies, label;
-	  int rescan = 0, foundinsn = 0;
+	  bool rescan = false, foundinsn = false;
+	  rdata region_arg;
 
 	  if (CALL_P (insn))
 	    {
@@ -5503,7 +5483,7 @@
 		 the call, and can result in situations where a single call
 		 insn may have two targets depending on where we came from.  */
 
-	      if (LABEL_P (scan) && ! foundinsn)
+	      if (LABEL_P (scan) && (LABEL_NUSES (scan) > 0))
 		break;
 
 	      if (! INSN_P (scan))
@@ -5514,7 +5494,21 @@
                  instructions at the jump destination did not use REG.  */
 
 	      if (JUMP_P (scan))
-		break;
+		{
+		  if (ANY_RETURN_P (PATTERN (scan)))
+		    break;
+
+		  if (simplejump_p (scan))
+		    {
+		      rtx lab = JUMP_LABEL(scan);
+		      rtx next = next_active_insn (lab);
+
+		      if (next && in_between (link, scan, next))
+			continue;
+		    }
+
+		  break;
+		}
 
 	      if (! reg_mentioned_p (reg, scan))
 		continue;
@@ -5531,7 +5525,7 @@
 		  /* There is a function call to this register other
                      than the one we are checking.  If we optimize
                      this call, we need to rescan again below.  */
-		  rescan = 1;
+		  rescan = true;
 		}
 
 	      /* ??? We shouldn't have to worry about SCANSET here.
@@ -5564,6 +5558,15 @@
 	      continue;
 	    }
 
+	  /* If the register is in use in one of the exception handler,
+	     can't relax it.  */
+
+	  region_arg.reg = reg;
+	  region_arg.ret = false;
+	  for_each_eh_label (handler_uses_reg, (void *)&region_arg);
+	  if (region_arg.ret)
+	    continue;
+
 	  /* Create a code label, and put it in a REG_LABEL_OPERAND note
              on the insn which sets the register, and on each call insn
              which uses the register.  In final_prescan_insn we look for
@@ -5573,6 +5576,7 @@
 	  label = gen_label_rtx ();
 	  add_reg_note (link, REG_LABEL_OPERAND, label);
 	  add_reg_note (insn, REG_LABEL_OPERAND, label);
+
 	  if (rescan)
 	    {
 	      scan = link;
@@ -5775,6 +5779,14 @@
 					       gen_rtvec (1, newsrc),
 					       UNSPEC_MOVA);
 		    }
+		  else if (GET_CODE (src) == UNSPEC_VOLATILE
+			   && XINT (src, 1) == UNSPECV_SP_SWITCH_B)
+		    {
+		      newsrc = XVECEXP (src, 0, 0);
+		      XVECEXP (src, 0, 0) = gen_const_mem (mode, newsrc);
+		      INSN_CODE (scan) = -1;
+		      continue;
+		    }
 		  else
 		    {
 		      lab = add_constant (src, mode, 0);
@@ -5794,7 +5806,7 @@
     PUT_MODE (insn, VOIDmode);
 
   mdep_reorg_phase = SH_SHORTEN_BRANCHES1;
-  INSN_ADDRESSES_FREE ();
+  init_insn_lengths ();
   split_branches (first);
 
   /* The INSN_REFERENCES_ARE_DELAYED in sh.h is problematic because it
@@ -5821,6 +5833,8 @@
     REG_USERVAR_P (get_fpscr_rtx ()) = 0;
 #endif
   mdep_reorg_phase = SH_AFTER_MDEP_REORG;
+
+   fixup_addr = 0;
 }
 
 int
@@ -6077,10 +6091,15 @@
    variable length.  This is because the second pass of shorten_branches
    does not bother to update them.  */
 
+static void sh_hw_workaround (rtx insn);
+
 void
 final_prescan_insn (rtx insn, rtx *opvec ATTRIBUTE_UNUSED,
 		    int noperands ATTRIBUTE_UNUSED)
 {
+  if (TARGET_DBHWBUG)
+    sh_hw_workaround (insn);
+
   if (TARGET_DUMPISIZE)
     fprintf (asm_out_file, "\n! at %04x\n", INSN_ADDRESSES (INSN_UID (insn)));
 
@@ -6189,6 +6208,7 @@
 
       if (CONST_OK_FOR_ADD (size))
 	emit_fn (GEN_ADD3 (reg, reg, GEN_INT (size)));
+
       /* Try to do it with two partial adjustments; however, we must make
 	 sure that the stack is properly aligned at all times, in case
 	 an interrupt occurs between the two partial adjustments.  */
@@ -6401,14 +6421,24 @@
 static void
 push_regs (HARD_REG_SET *mask, int interrupt_handler)
 {
-  int i = interrupt_handler ? LAST_BANKED_REG + 1 : 0;
+  int i;
   int skip_fpscr = 0;
 
+  /* Push double first. Keep the strictness alignment in case of -mdalign.  */
+  for (i = FIRST_FP_REG; i <= LAST_FP_REG; i++)
+    if (TEST_HARD_REG_BIT (*mask, i))
+      push (i);
+
+  i = interrupt_handler ? LAST_BANKED_REG + 1 : 0;
+
   /* Push PR last; this gives better latencies after the prologue, and
      candidates for the return delay slot when there are no general
      registers pushed.  */
   for (; i < FIRST_PSEUDO_REGISTER; i++)
     {
+      if (FP_REGISTER_P(i))
+	continue;
+
       /* If this is an interrupt handler, and the SZ bit varies,
 	 and we have to push any floating point register, we need
 	 to switch to the correct precision first.  */
@@ -6874,6 +6904,9 @@
   tree sp_switch_attr
     = lookup_attribute ("sp_switch", DECL_ATTRIBUTES (current_function_decl));
 
+  if (sh_cfun_naked_p ())
+    return;
+
   current_function_interrupt = sh_cfun_interrupt_handler_p ();
 
   /* We have pretend args if we had an object sent partially in registers
@@ -6934,7 +6967,7 @@
   /* Emit the code for SETUP_VARARGS.  */
   if (cfun->stdarg)
     {
-      if (TARGET_VARARGS_PRETEND_ARGS (current_function_decl))
+      if (crtl->args.pretend_args_size)
 	{
 	  /* Push arg regs as if they'd been provided by caller in stack.  */
 	  for (i = 0; i < NPARM_REGS(SImode); i++)
@@ -6964,7 +6997,6 @@
 
       lab = add_constant (sp_switch, SImode, 0);
       newsrc = gen_rtx_LABEL_REF (VOIDmode, lab);
-      newsrc = gen_const_mem (SImode, newsrc);
 
       emit_insn (gen_sp_switch_1 (newsrc));
     }
@@ -7236,6 +7268,9 @@
   int fpscr_deferred = 0;
   int e = sibcall_p ? -1 : 1;
 
+  if (sh_cfun_naked_p ())
+    return;
+
   d = calc_live_regs (&live_regs_mask);
 
   save_size = d;
@@ -7428,11 +7463,7 @@
 	   register.  */
       if (TEST_HARD_REG_BIT (live_regs_mask, PR_REG)
 	  && !sh_cfun_resbank_handler_p ())	
-	{
-	  if (!frame_pointer_needed)
-	    emit_insn (gen_blockage ());
 	  pop (PR_REG);
-	}
 
       /* Banked registers are popped first to avoid being scheduled in the
 	 delay slot. RTE switches banks before the ds instruction.  */
@@ -7479,6 +7510,9 @@
 	{
 	  int j = (FIRST_PSEUDO_REGISTER - 1) - i;
 
+	  if (FP_REGISTER_P(j))
+	    continue;
+
 	  if (j == FPSCR_REG && current_function_interrupt && TARGET_FMOVD
 	      && hard_reg_set_intersect_p (live_regs_mask,
 					  reg_class_contents[DF_REGS]))
@@ -7498,6 +7532,12 @@
 	    pop (FPSCR_REG);
 	}
     }
+
+  /* Pop double last. */
+  for (i = LAST_FP_REG; i >= FIRST_FP_REG; i--)
+    if (TEST_HARD_REG_BIT (live_regs_mask, i))
+      pop (i);
+
   if (target_flags != save_flags && ! current_function_interrupt)
     emit_insn (gen_toggle_sz ());
   target_flags = save_flags;
@@ -7523,24 +7563,6 @@
     emit_use (gen_rtx_REG (SImode, PR_REG));
 }
 
-static int sh_need_epilogue_known = 0;
-
-int
-sh_need_epilogue (void)
-{
-  if (! sh_need_epilogue_known)
-    {
-      rtx epilogue;
-
-      start_sequence ();
-      sh_expand_epilogue (0);
-      epilogue = get_insns ();
-      end_sequence ();
-      sh_need_epilogue_known = (epilogue == NULL ? -1 : 1);
-    }
-  return sh_need_epilogue_known > 0;
-}
-
 /* Emit code to change the current function's return address to RA.
    TEMP is available as a scratch register, if needed.  */
 
@@ -7620,7 +7642,7 @@
 sh_output_function_epilogue (FILE *file ATTRIBUTE_UNUSED,
 			     HOST_WIDE_INT size ATTRIBUTE_UNUSED)
 {
-  sh_need_epilogue_known = 0;
+  mdep_reorg_phase = SH_BEFORE_MDEP_REORG;
 }
 
 static rtx
@@ -8147,14 +8169,13 @@
 {
   unsigned regno = REGNO (reg);
 
-  if (WORDS_BIG_ENDIAN || GET_MODE (reg) != DFmode)
+  if (WORDS_BIG_ENDIAN || GET_MODE (reg) != DFmode || TARGET_FMOVD)
     return NULL_RTX;
 
-  return
-    gen_rtx_PARALLEL (VOIDmode,
-		      gen_rtvec (2,
-				 gen_rtx_REG (SFmode, regno + 1),
-				 gen_rtx_REG (SFmode, regno)));
+  return gen_rtx_PARALLEL (VOIDmode,
+			   gen_rtvec (2,
+				      gen_rtx_REG (SFmode, regno + 1),
+				      gen_rtx_REG (SFmode, regno)));
 }
 
 static enum machine_mode
@@ -8908,6 +8929,22 @@
   return NULL_TREE;
 }
 
+/* Handle an attribute requiring a FUNCTION_DECL;
+   arguments as in struct attribute_spec.handler.  */
+static tree
+sh_handle_fndecl_attribute (tree *node, tree name, tree args ATTRIBUTE_UNUSED,
+			     int flags ATTRIBUTE_UNUSED, bool *no_add_attrs)
+{
+  if (TREE_CODE (*node) != FUNCTION_DECL)
+    {
+      warning (OPT_Wattributes, "%qs attribute only applies to functions",
+	       IDENTIFIER_POINTER (name));
+      *no_add_attrs = true;
+    }
+
+  return NULL_TREE;
+}
+
 /* Handle an "interrupt_handler" attribute; arguments as in
    struct attribute_spec.handler.  */
 static tree
@@ -9144,6 +9181,15 @@
               != NULL_TREE) && TARGET_SH2A);
 }
 
+/* Return nonzero if the current function has attribute naked .  */
+static int
+sh_cfun_naked_p (void)
+{
+  return (lookup_attribute ("naked",
+			    DECL_ATTRIBUTES (current_function_decl))
+	  != NULL_TREE);
+}
+
 /* Implement TARGET_CHECK_PCH_TARGET_FLAGS.  */
 
 static const char *
@@ -9214,9 +9260,12 @@
    choosing an fldi alternative during reload and thus failing to
    allocate a scratch register for the constant loading.  */
 int
-fldi_ok (void)
+fldi_ok (bool secondary)
 {
-  return 1;
+  if (! TARGET_FLDI)
+    return 0;
+
+  return !secondary || (!reload_in_progress && !reload_completed);
 }
 
 /* Return the TLS type for TLS symbols, 0 for otherwise.  */
@@ -9228,14 +9277,76 @@
   return SYMBOL_REF_TLS_MODEL (op);
 }
 
+/* Expand an sfunc operation taking NARGS MODE arguments, using generator
+   function FUN, which needs symbol NAME loaded int a register first.
+   Add a REG_EQUAL note using EQUIV.  */
+static void
+expand_sfunc_op (int nargs, enum machine_mode mode, rtx (*fun) (rtx, rtx),
+		 const char *name, rtx equiv, rtx *operands)
+{
+  int i;
+  rtx addr, first = NULL_RTX, last, insn;
+  /* For now keep all variants ABI compatibilities.
+     Check for TARGET_OSFP: ARG_TO_R4 (see ieee-754-df.S) and _SH_FPU_ANY_.  */
+  int next_reg = FIRST_PARM_REG;
+
+  addr = gen_reg_rtx (Pmode);
+  function_symbol (addr, name, SFUNC_FREQUENT);
+
+  for (i = 1; i <= nargs; i++)
+    {
+      insn = emit_move_insn (gen_rtx_REG (mode, next_reg), operands[i]);
+      if (!first)
+	first = insn;
+      next_reg += GET_MODE_SIZE (mode) / UNITS_PER_WORD;
+    }
+  last = emit_insn ((*fun) (operands[0], addr));
+  add_reg_note (last, REG_EQUAL, equiv);
+
+  /* If flag_non_call_exceptions is in effect, it will stipulate BB boundaries
+     where we don't want them; we must not have a LIBCALL block spanning
+     multiple basic blocks.  */
+  if (flag_non_call_exceptions)
+    {
+      for (insn = first; insn != last; insn = NEXT_INSN (insn))
+	if (may_trap_p (insn))
+	  return;
+    }
+}
+
+/* Expand an sfunc unary operation taking an MODE argument, using generator
+   function FUN, which needs symbol NAME loaded int a register first.
+   Add a REG_EQUAL note using CODE.  */
+void
+expand_sfunc_unop (enum machine_mode mode, rtx (*fun) (rtx, rtx),
+		   const char *name, enum rtx_code code, rtx *operands)
+{
+  rtx equiv = gen_rtx_fmt_e (code, GET_MODE (operands[0]), operands[1]);
+  expand_sfunc_op (1, mode, fun, name, equiv, operands);
+}
+
+/* Expand an sfunc binary operation in MODE, using generator function FUN,
+   which needs symbol NAME loaded int a register first.
+   Add a REG_EQUAL note using CODE.  */
+void
+expand_sfunc_binop (enum machine_mode mode, rtx (*fun) (rtx, rtx),
+		    const char *name, enum rtx_code code, rtx *operands)
+{
+  rtx equiv = gen_rtx_fmt_ee (code, mode, operands[1], operands[2]);
+  expand_sfunc_op (2, mode, fun, name, equiv, operands);
+}
+
 /* Return the destination address of a branch.  */
 
-static int
+static unsigned int
 branch_dest (rtx branch)
 {
   rtx dest = SET_SRC (PATTERN (branch));
   int dest_uid;
 
+  if (! INSN_ADDRESSES_SET_P ())
+    return 0;
+
   if (GET_CODE (dest) == IF_THEN_ELSE)
     dest = XEXP (dest, 1);
   dest = XEXP (dest, 0);
@@ -9460,6 +9571,15 @@
   return gen_rtx_REG (Pmode, 7);
 }
 
+/* This function switches the fpscr.  */
+void
+emit_fpu_flip (void)
+{
+  emit_insn (gen_toggle_pr ());
+  if (TARGET_FMOVD)
+    emit_insn (gen_toggle_sz ());
+}
+
 /* This function will set the fpscr from memory.
    MODE is the mode we are setting it to.  */
 void
@@ -9479,8 +9599,165 @@
 #endif
 
 int
-sh_insn_length_adjustment (rtx insn)
+sh_insn_length_alignment (rtx insn)
 {
+  int align = 1;
+
+  if (INSN_P (insn))
+    {
+      rtx body = PATTERN (insn);
+
+      if (GET_CODE (body) == ASM_INPUT || asm_noperands (body) >= 0)
+	{
+	  const char *templ;
+
+	  if (GET_CODE (body) == ASM_INPUT)
+	    templ = XSTR (body, 0);
+	  else
+	    templ = decode_asm_operands (body, NULL, NULL, NULL, NULL, NULL);
+
+	  (void) sh_asm_count (templ, &align);
+	  return align;
+	}
+
+      return 1 << TARGET_SHMEDIA;
+    }
+
+#if 0
+  (NONJUMP_INSN_P (A_INSN)						\
+   ? 1 << TARGET_SHMEDIA						\
+   : JUMP_P (A_INSN) || CALL_P (A_INSN)					\
+   ? 1 << TARGET_SHMEDIA						\
+   : CACHE_LOG)
+#endif
+
+  align = GET_CODE (insn) == JUMP_INSN
+    && GET_CODE (PATTERN (insn)) == ADDR_DIFF_VEC
+    && GET_MODE (PATTERN (insn)) == HImode
+    ? 0
+    : GET_CODE (insn) == BARRIER
+    ? 0
+    : GET_CODE (insn) == JUMP_INSN || GET_CODE (insn) == CALL_INSN
+    ? 1 << TARGET_SHMEDIA
+    : 1;
+
+  return align;
+}
+
+bool
+sh_varying_insn_p (rtx insn)
+{
+  return (mdep_reorg_phase == SH_AFTER_MDEP_REORG
+	  && GET_CODE (insn) == INSN
+	  && recog_memoized (insn) == CODE_FOR_casesi_worker_1);
+}
+
+extern int insn_last_address;
+
+int
+sh_insn_length_adjustment (rtx insn, const int cur_length)
+{
+  int addlen = 0;
+  rtx prev;
+
+  if (sh_varying_insn_p (insn))
+    {
+      if (recog_memoized (insn) == CODE_FOR_casesi_worker_1)
+	{
+	  rtx src = SET_SRC (XVECEXP (PATTERN (insn), 0, 0));
+	  rtx lab, diff_vec;
+	  int u;
+
+	  if (MEM_P (src))
+	    src = XEXP (src, 0);
+
+	  lab = XEXP (XVECEXP (src, 0, 2), 0);
+	  diff_vec = PATTERN (next_real_insn (lab));
+
+	  u = ADDR_DIFF_VEC_FLAGS (diff_vec).offset_unsigned;
+
+	  if (GET_MODE (diff_vec) == QImode)
+	    {
+	      if (!u && cur_length == 4)
+		return -2;
+	      else if (u && cur_length == 2)
+		return 2;
+	    }
+	}
+
+      return 0;
+    }
+
+  /* optimize DC introduced by reorg.  */
+  if (TARGET_DEAD_DELAY && mdep_reorg_phase == SH_AFTER_MDEP_REORG && INSN_ADDRESSES_SET_P ())
+    {
+      if (deleted_delay_slot_p (insn))
+	return 0;
+
+      if (NONJUMP_INSN_P (insn) && GET_CODE (PATTERN (insn)) == SEQUENCE && cur_length == 4)
+	{
+	  rtx body = PATTERN (insn);
+	  rtx delay_insn = XVECEXP (body, 0, 1);
+	  rtx dpat = PATTERN (delay_insn);
+	  rtx nexti = next_real_insn (delay_insn);
+	  rtx label = NEXT_INSN (delay_insn);
+	  int log = 0;
+
+	  if (label && BARRIER_P (label))
+	    {
+	      for (; label && ! INSN_P (label);
+		   label = NEXT_INSN (label))
+		if (LABEL_P (label))
+		  {
+		    log = label_to_alignment (label);
+		    if (log) break;
+		  }
+	    }
+
+	  if (nexti && GET_CODE (dpat) == SET)
+	    {
+	      rtx jump_insn = XVECEXP (body, 0, 0);
+	      enum attr_type jump_type = get_attr_type (jump_insn);
+
+	      if ((jump_type != TYPE_SFUNC && jump_type != TYPE_CALL)
+		  && GET_CODE (jump_insn) == JUMP_INSN
+		  && rtx_equal_p (PATTERN (nexti), dpat)
+		  && ! reg_overlap_mentioned_p (SET_DEST (dpat), dpat))
+		{
+		  rtx lab = JUMP_LABEL (jump_insn);
+		  rtx prev = prev_real_insn (lab);
+
+		  /* bug 50754 optimize 2 instructions :
+		     br .l
+		     mov r1,r3
+		     .l: mov r1,r3  */
+		  if (nexti == prev)
+		    {
+		      delete_insn (insn);
+		      return -4;
+		    }
+		  /* bug 58105: optimize 1 instruction :
+		     bf/s .l
+		     mov r1,r3
+		     mov r1,r3  */
+		  else if (!log)
+		    {
+		      rtx old_delay = delay_insn;
+		      delay_insn = make_insn_raw (gen_dup_db_insn ());
+
+		      NEXT_INSN (delay_insn) = NEXT_INSN (old_delay);
+		      PREV_INSN (delay_insn) = jump_insn;
+		      NEXT_INSN (jump_insn) = delay_insn;
+		      XVECEXP (body, 0, 1) = delay_insn;
+
+		      INSN_ADDRESSES_NEW (delay_insn, -1);
+		      return -2;
+		    }
+		}
+	    }
+	}
+    }
+
   /* Instructions with unfilled delay slots take up an extra two bytes for
      the nop in the delay slot.  */
   if (((NONJUMP_INSN_P (insn)
@@ -9488,9 +9765,143 @@
 	&& GET_CODE (PATTERN (insn)) != CLOBBER)
        || CALL_P (insn)
        || (JUMP_P (insn) && !JUMP_TABLE_DATA_P (insn)))
-      && GET_CODE (PATTERN (NEXT_INSN (PREV_INSN (insn)))) != SEQUENCE
+      && (mdep_reorg_phase < SH_AFTER_MDEP_REORG ||
+	  GET_CODE (PATTERN (NEXT_INSN (PREV_INSN (insn)))) != SEQUENCE)
       && get_attr_needs_delay_slot (insn) == NEEDS_DELAY_SLOT_YES)
-    return 2;
+    addlen = 2;
+
+  /* At that time, delayed branches are filled up so we should start to have
+     the address correct and qdjust with alignments padding.  */
+
+  if (TARGET_SH2 && mdep_reorg_phase == SH_AFTER_MDEP_REORG &&
+      INSN_ADDRESSES_SET_P ())
+    {
+      /* We are seeing a jmp, whereas a braf could fit as well.  */
+      if (JUMP_P (insn) && !JUMP_TABLE_DATA_P (insn)
+	  && get_attr_type (insn) == TYPE_JUMP &&
+	  (cur_length == 10 || cur_length == 14))
+	{
+	  int baddr = TARGET_DBHWBUG ?
+	    insn_last_address : insn_current_reference_address (insn);
+	  int offset, prev_count;
+
+	  /* number of instructions before the jmp.  */
+	  prev = prev_nonnote_insn (insn);
+	  if (prev && NONJUMP_INSN_P (prev)
+	      && INSN_CODE (prev) == CODE_FOR_indirect_jump_scratch)
+	    prev_count = 2;
+	  else
+	    prev_count = 4;
+
+	  /* braf offset from the start of the insn.  */
+	  /* remove the the prev_count. */
+	  baddr += prev_count;
+
+	  /* This is a braf without scratch.  OK. */
+	  if (cur_length == 10 && prev_count == 4)
+	    {
+	      /*
+			  (2) push
+	                  (2) mov.w	.Lr4
+		baddr ->  (2) jmp	@r4
+			  (2) pop
+		          (2) .L: .word	.L5
+	      */
+
+	      if (TARGET_DBHWBUG)
+		{
+		  /* The delayed instruction will be emitted BEFORE the braf !!. */
+		  if (!addlen)
+		    baddr += 2;
+
+		  offset = branch_dest (insn) - baddr;
+
+		  /* we don't need "addlen" because the DS will be filled up by the pop */
+		  gcc_assert (offset >= -32768 + 4 && offset <= 32767 + 4);
+		}
+
+	      return 0;
+	    }
+
+#if 1
+	  /* braf offset from the start of the insn.  */
+	  /* Testing if this would fit with a med branch */
+	  /* remove the pad (-2). long is word (-2) and the prev_count. */
+	  if (prev_count == 2)
+	    {
+	      gcc_assert (cur_length == 10);
+
+	      offset = branch_dest (insn) - baddr;
+	      /* We have the pad and the long to add.  */
+	      if (offset > 0)
+		offset += 2 + 4;
+	    }
+	  else if (prev_count == 4)
+	    {
+	      gcc_assert (cur_length == 14);
+
+	      /* The delayed instruction will be emitted BEFORE the braf !!. */
+	      if (!addlen)
+		baddr += 2;
+
+	      /* We don't need to insert a nop ! (pop in delay slot) */
+	      addlen = 0;
+
+	      offset = branch_dest (insn) - baddr;
+	      /* We have the push (?xx), the pop and the long to add.  */
+	      if (offset > 0)
+		offset += 2 + 2 + 4;
+	    }
+
+	  if (offset >= -32768 + 4 && offset <= 32767 + 4)
+	    {
+	      if (prev_count == 2)
+		return cur_length - prev_count - 2 + addlen;
+	      else if (prev_count == 4)
+		return cur_length - prev_count - 4 + addlen;
+	    }
+	  else
+#endif
+	  if (TARGET_DBHWBUG)
+	    {
+	      int long_address;
+	      int aligned_long_address;
+	      int pad;
+
+	      if (prev_count == 2)
+		{
+		  /*
+		            (2) mov.l	.L,r4
+		  baddr ->  (2) jmp	@r4
+		                nop
+		               .align 2
+		            (2 ?) pad
+		            (4) .L: .long	.L5
+		  */
+
+		  long_address = baddr + 2 + addlen;
+		}
+	      else
+		{
+		  /*
+		             delayed 
+		             (2) mov.l	r13,@-r15
+		             (2) mov.l	.L,r13
+		    baddr -> (2) jmp	@r13
+		             (2) mov.l	@-r15,r13
+		             (2 ?) pad
+		             (4) .L:	.long	.L5
+		  */
+
+		  long_address = baddr + 4;
+		}
+
+	      aligned_long_address = (long_address + 3) & -4;
+	      pad = 2 - (aligned_long_address - long_address);
+	      return addlen - pad;
+	    }
+	}
+    }
 
   /* SH2e has a bug that prevents the use of annulled branches, so if
      the delay slot is not filled, we'll have to put a NOP in it.  */
@@ -9516,7 +9927,7 @@
 	templ
 	  = decode_asm_operands (body, NULL, NULL, NULL, NULL, NULL);
       else
-	return 0;
+	return addlen;
       do
 	{
 	  int ppi_adjust = 0;
@@ -9553,9 +9964,10 @@
       while (c);
       return sum;
     }
-  return 0;
+  return addlen;
 }
 
+
 /* Return TRUE for a valid displacement for the REG+disp addressing
    with MODE.  */
 
@@ -10002,6 +10414,7 @@
   return lab;
 }
 
+
 /* Return true if it's possible to redirect BRANCH1 to the destination
    of an unconditional jump BRANCH2.  We only want to do this if the
    resulting branch will have a short displacement.  */
@@ -10033,6 +10446,7 @@
 	    distance += get_attr_length (insn);
 	}
     }
+
   return 0;
 }
 
@@ -10703,9 +11117,6 @@
 sh_optimize_target_register_callee_saved (bool after_prologue_epilogue_gen)
 {
   HARD_REG_SET dummy;
-#if 0
-  rtx insn;
-#endif
 
   if (! shmedia_space_reserved_for_target_registers)
     return 0;
@@ -11142,10 +11553,10 @@
 
 static tree
 sh_media_builtin_decl (unsigned code, bool initialize_p ATTRIBUTE_UNUSED)
-{        
+{
   if (code >= ARRAY_SIZE (bdesc))
     return error_mark_node;
-          
+
   return bdesc[code].fndecl;
 }
 
@@ -11205,10 +11616,10 @@
 
 static tree
 sh_builtin_decl (unsigned code, bool initialize_p ATTRIBUTE_UNUSED)
-{        
+{
   if (TARGET_SHMEDIA)
     return sh_media_builtin_decl (code, initialize_p);
-          
+
   return error_mark_node;
 }
 
@@ -11312,6 +11723,61 @@
 }
 
 void
+sh_expand_lround (rtx op0, rtx op1, bool to_nearest)
+{
+  rtx tmp3;
+  rtx tmp2 = gen_reg_rtx (SImode);
+  rtx tmp1 = gen_reg_rtx (SImode);
+  rtx ftmp1 = gen_reg_rtx (SFmode);
+  rtx ftmp0 = gen_reg_rtx (SFmode);
+  rtx fpul = gen_rtx_REG (SImode, FPUL_REG);
+
+  emit_insn (gen_movsi_i (tmp2, GEN_INT (1 << 31)));
+
+  emit_move_insn (ftmp0, op1);
+
+  emit_move_insn (fpul, gen_lowpart (SImode, ftmp0));
+  emit_move_insn (tmp1, fpul);
+  emit_insn (gen_andsi3 (tmp2, tmp2, tmp1));
+
+  tmp3 = gen_lowpart (SImode,
+		      force_reg (SFmode,
+				 CONST_DOUBLE_ATOF ("0.5", SFmode)));
+
+  emit_insn (gen_iorsi3 (tmp3, tmp3, tmp2));
+
+  emit_insn (gen_addsf3 (ftmp0, ftmp0, gen_lowpart (SFmode, tmp3)));
+
+  emit_sf_insn (gen_fix_truncsfsi2_i4 (fpul, ftmp0, get_fpscr_rtx ()));
+
+  emit_move_insn (op0, fpul);
+
+  if (to_nearest)
+    {
+      rtx lab = gen_label_rtx ();
+
+      emit_sf_insn (gen_floatsisf2_i4 (ftmp1, fpul, get_fpscr_rtx ()));
+
+      emit_sf_insn (gen_cmpeqsf_t_i4 (ftmp1, ftmp0, get_fpscr_rtx ()));
+
+      emit_jump_insn (gen_branch_false (lab));
+
+      emit_move_insn (tmp3, const1_rtx);
+      emit_insn (gen_andsi3 (tmp3, tmp3, op0));
+      emit_insn (gen_cmpeqsi_t (tmp3, const0_rtx));
+      emit_jump_insn (gen_branch_true (lab));
+
+      emit_insn (gen_cmpeqsi_t (tmp2, const0_rtx));
+      emit_insn (gen_movt (tmp2));
+      emit_insn (gen_ashlsi_c (tmp2, tmp2));
+      emit_insn (gen_addsi3 (tmp2, tmp2, GEN_INT (-1)));
+      emit_insn (gen_subsi3 (op0, op0, tmp2));
+
+      emit_label (lab);
+    }
+}
+
+void
 sh_expand_binop_v2sf (enum rtx_code code, rtx op0, rtx op1, rtx op2)
 {
   rtx op = gen_rtx_fmt_ee (code, SFmode, op1, op2);
@@ -11443,7 +11909,7 @@
       else
 	{
 	  if (GET_MODE_SIZE (from) < 8)
-	    return reg_classes_intersect_p (DF_HI_REGS, rclass);
+	    return reg_classes_intersect_p (DF_REGS, rclass);
 	}
     }
   return 0;
@@ -11488,7 +11954,7 @@
 sh_register_move_cost (enum machine_mode mode,
 		       reg_class_t srcclass, reg_class_t dstclass)
 {
-  if (dstclass == T_REGS || dstclass == PR_REGS)
+  if (dstclass == T_REGS)
     return 10;
 
   if (dstclass == MAC_REGS && srcclass == MAC_REGS)
@@ -11514,7 +11980,7 @@
       /* Discourage trying to use fp regs for a pointer.  This also
 	 discourages fp regs with SImode because Pmode is an alias
 	 of SImode on this target.  See PR target/48596.  */
-      int addend = (mode == Pmode) ? 40 : 0;
+      int addend = (mode == Pmode) ? 200 : 0;
 
       return (((TARGET_SHMEDIA ? 4 : TARGET_FMOVD ? 8 : 12) + addend)
 	      * ((GET_MODE_SIZE (mode) + 7) / 8U));
@@ -11526,6 +11992,10 @@
 	  && REGCLASS_HAS_GENERAL_REG (dstclass)))
     return 5;
 
+  if ((srcclass == PR_REGS && REGCLASS_HAS_FP_REG (dstclass))
+      || (dstclass == PR_REGS && REGCLASS_HAS_FP_REG (srcclass)))
+    return 7;
+
   if ((dstclass == FPUL_REGS
        && (srcclass == PR_REGS || srcclass == MAC_REGS || srcclass == T_REGS))
       || (srcclass == FPUL_REGS
@@ -11591,6 +12061,8 @@
 
   emit_note (NOTE_INSN_PROLOGUE_END);
 
+  emit_barrier ();
+
   /* Find the "this" pointer.  We have such a wide range of ABIs for the
      SH that it's best to do this completely machine independently.
      "this" is passed as first argument, unless a structure return pointer
@@ -11735,10 +12207,12 @@
       emit_move_insn (scratch2, funexp);
       funexp = gen_rtx_MEM (FUNCTION_MODE, scratch2);
       sibcall = gen_sibcall (funexp, const0_rtx, NULL_RTX);
+      add_reg_note (sibcall, REG_DEAD, scratch2);
     }
   sibcall = emit_call_insn (sibcall);
   SIBLING_CALL_P (sibcall) = 1;
   use_reg (&CALL_INSN_FUNCTION_USAGE (sibcall), this_rtx);
+
   emit_barrier ();
 
   /* Run just enough of rest_of_compilation to do scheduling and get
@@ -11770,11 +12244,10 @@
 {
   rtx sym;
 
-  /* If this is not an ordinary function, the name usually comes from a
-     string literal or an sprintf buffer.  Make sure we use the same
+  /* The name usually comes from a string literal or an sprintf buffer.
+     Make sure we use the same
      string consistently, so that cse will be able to unify address loads.  */
-  if (kind != FUNCTION_ORDINARY)
-    name = IDENTIFIER_POINTER (get_identifier (name));
+  name = IDENTIFIER_POINTER (get_identifier (name));
   sym = gen_rtx_SYMBOL_REF (Pmode, name);
   SYMBOL_REF_FLAGS (sym) = SYMBOL_FLAG_FUNCTION;
   if (flag_pic)
@@ -11782,6 +12255,10 @@
       {
       case FUNCTION_ORDINARY:
 	break;
+      case SFUNC_FREQUENT:
+	if (!optimize || optimize_size)
+	  break;
+	/* Fall through.  */
       case SFUNC_GOT:
 	{
 	  rtx reg = target ? target : gen_reg_rtx (Pmode);
@@ -12288,7 +12765,7 @@
 	return 1;
     }
 
-  return 0;  
+  return 0;
 }
 
 /* FNADDR is the MEM expression from a call expander.  Return an address
@@ -12368,7 +12845,7 @@
 	  && ! TARGET_SHMEDIA
 	  && immediate_operand ((x), mode)
 	  && ! ((fp_zero_operand (x) || fp_one_operand (x))
-		&& mode == SFmode && fldi_ok ()))
+		&& mode == SFmode && fldi_ok (true)))
 	switch (mode)
 	  {
 	  case SFmode:
@@ -12475,6 +12952,8 @@
   for (regno = 0; regno < FIRST_PSEUDO_REGISTER; regno ++)
     if (! VALID_REGISTER_P (regno))
       fixed_regs[regno] = call_used_regs[regno] = 1;
+  if (TARGET_SH4A_FP || TARGET_SH4_300)
+    global_regs[FPSCR_REG] = 1;
   /* R8 and R9 are call-clobbered on SH5, but not on earlier SH ABIs.  */
   if (TARGET_SH5)
     {
@@ -12489,6 +12968,10 @@
       CLEAR_HARD_REG_SET (reg_class_contents[FP0_REGS]);
       regno_reg_class[FIRST_FP_REG] = FP_REGS;
     }
+  if (TARGET_R0R3_TO_REG_MUL < 2)
+    regno_reg_class[R1_REG] = regno_reg_class[R2_REG]
+      = regno_reg_class[R3_REG] = GENERAL_REGS;
+    /* The peephole2s needs reg_class_contents[R0R3_REGS].  */ 
   if (flag_pic)
     {
       fixed_regs[PIC_OFFSET_TABLE_REGNUM] = 1;
@@ -12500,9 +12983,6 @@
       call_really_used_regs[MACH_REG] = 0;
       call_really_used_regs[MACL_REG] = 0;
     }
-  for (regno = FIRST_FP_REG + (TARGET_LITTLE_ENDIAN != 0);
-       regno <= LAST_FP_REG; regno += 2)
-    SET_HARD_REG_BIT (reg_class_contents[DF_HI_REGS], regno);
   if (TARGET_SHMEDIA)
     {
       for (regno = FIRST_TARGET_REG; regno <= LAST_TARGET_REG; regno ++)
@@ -12528,7 +13008,11 @@
 	     || !TARGET_SHMEDIA_FPU
 	     || TARGET_SHMEDIA64)
 	  : (GET_CODE (x) != CONST_DOUBLE
-	     || mode == DFmode || mode == SFmode
+	     || mode == DFmode
+	     || (mode == SFmode
+		 && (!TARGET_FLDI
+		     || ((!fp_one_operand (x) && !fp_zero_operand (x))
+			 || reload_completed)))
 	     || mode == DImode || GET_MODE (x) == VOIDmode));
 }
 
@@ -12540,4 +13024,787 @@
   init_sync_libfuncs (UNITS_PER_WORD);
 }
 
+static int asm_size (char *s, int addr, int *seen_align)
+{
+  char *pt;
+
+  if (*s == ';' || *s == '\n' || *s == '\0')
+    return 0;
+
+  else if (strstr (s, ".long"))
+    {
+      int n = 1;
+      /* parse .long	1, 3 syntax.  */
+      while (*s != '\n' && *s != '\0')
+	{
+	  s++;
+	  if (*s == ',')  n++;
+	}
+      return 2 * n;
+    }
+
+  else if (strstr (s, ".short") || strstr (s, ".word"))
+    {
+      int n = 1;
+      /* parse .short	1, 3 syntax.  */
+      while (*s != '\n' && *s != '\0')
+	{
+	  s++;
+	  if (*s == ',')  n++;
+	}
+      return n;
+    }
+
+  else if (insn_current_address != -1 && strstr (s, ".balign"))
+    {
+      long int align;
+      int new_address;
+
+      while (*s != '\t' && *s != ' ') s++;
+      align = strtol (s, NULL, 10);
+      if (errno == ERANGE || errno == EINVAL)
+	{
+	  warning (OPT_mdb_page_bug, "unsupported %s asm for w/a.", s);
+	  return 0;
+	}
+
+      /* return log.  */
+      if (seen_align)
+	*seen_align = exact_log2 (align);
+      new_address = (addr + align - 1) & -align;
+      /* return size / insn_default_length().  */
+      return (new_address - addr) / 2;
+    }
+
+  else if (insn_current_address != -1 && strstr (s, ".align"))
+    {
+      long int align;
+      int new_address;
+
+      while (*s != '\t' && *s != ' ') s++;
+      align = strtol (s, NULL, 10);
+      if (errno == ERANGE || errno == EINVAL)
+	{
+	  warning (OPT_mdb_page_bug, "unsupported %s asm for w/a.", s);
+	  return 0;
+	}
+
+      /* return log.  */
+      if (seen_align)
+	*seen_align = align;
+
+      align = 1 << align;
+      new_address = (addr + align - 1) & -align;
+      /* return size / insn_default_length().  */
+      return (new_address - addr) / 2;
+    }
+
+  else if (strstr (s, ".space") || strstr (s, ".skip"))
+    {
+      long int align;
+      errno = 0;
+      while (*s != '\t' && *s != ' ') s++;
+      align = strtol (s, NULL, 10);
+      if (errno == ERANGE || errno == EINVAL)
+	{
+	  warning (OPT_mdb_page_bug, "unsupported %s asm for w/a.", s);
+	  return 0;
+	}
+      return align / 2;
+    }
+
+  else if (strstr (s, ".fill"))
+    {
+      char delim[] = ",\n";
+      char *size;
+      char *n;
+      while (*s != '\t' && *s != ' ') s++;
+      size = strtok(s, delim);
+      n = strtok(NULL, delim);
+      if (n)
+	{
+	  (void) strtok(NULL, delim);
+	  return strtol (size, NULL, 10) * strtol (n, NULL, 10) / 2;
+	}
+      return 1;
+    }
+
+  else if ((pt = strrchr (s, ':')) != NULL)
+    {
+      while (*pt == '\t' || *pt == ' ' || *pt == ':') pt++;
+      return asm_size (pt, addr, seen_align);
+    }
+
+  if (*s == '.' && mdep_reorg_phase == SH_AFTER_MDEP_REORG)
+    warning (OPT_mdb_page_bug, "unsupported %s asm for w/a.", s);
+
+  return 1;
+}
+
+int
+sh_align_function_log(tree fn)
+{
+  int first, last;
+
+  if (! INSN_ADDRESSES_SET_P () || optimize <= 0)
+    return align_functions_log;
+
+  if (lookup_attribute ("cold", DECL_ATTRIBUTES (fn)))
+    return 1;
+
+  first = INSN_ADDRESSES (INSN_UID (get_insns()));
+  last = INSN_ADDRESSES (INSN_UID (get_last_insn ()));
+
+ if (last - first < 32)
+    return 2;
+  else
+    return align_functions_log;
+}
+
+int
+sh_asm_count (const char *templ, int *seen_align)
+{
+  int count = 0;
+  char *s, *lt;
+  char delim[] = ";\n";
+  int in_sub = 0;
+  int addr;
+
+  addr = mdep_reorg_phase == SH_AFTER_MDEP_REORG && INSN_ADDRESSES_SET_P () ?
+    insn_current_address : 2;
+
+  lt = (char *) alloca (strlen (templ) + 1);
+  strcpy (lt, templ);
+
+  s = strtok(lt, delim);
+
+  while (s != NULL)
+    {
+      while (*s == '\t' || *s == ' ') s++;
+
+      if (strstr (s, ".pushsection") || strstr (s, ".section"))
+	in_sub++;
+
+      if (! in_sub)
+	count += asm_size (s, addr + (count * 2), seen_align);
+
+      if (strstr (s, ".popsection") || strstr (s, ".previous"))
+	in_sub--;
+
+      s = strtok(NULL, delim);
+    }
+
+  return count;
+}
+
+static int align_next_insn;
+
+static void
+sh_hw_workaround (rtx insn)
+{
+  int uid_address = INSN_ADDRESSES (INSN_UID (insn));
+  int real_address = uid_address + fixup_addr;
+
+  if (GET_CODE (insn) == CODE_LABEL)
+    {
+      rtx barrier = prev_nonnote_insn (insn);
+      if (barrier && BARRIER_P (barrier))
+	{
+	  int log = label_to_alignment (insn);
+	  int align = 1 << log;
+
+	  int aligned_real_address;
+	  int last_unaligned_uid_address = INSN_ADDRESSES (INSN_UID (barrier));
+
+	  real_address -= (uid_address - last_unaligned_uid_address);
+	  aligned_real_address = (real_address + align - 1) & -align;
+
+	  fixup_addr = aligned_real_address - uid_address;
+	  return;
+	}
+    }
+
+  if (INSN_P (insn))
+    {
+      rtx body = PATTERN (insn);
+
+      if (GET_CODE (body) == UNSPEC_VOLATILE && XINT (body, 1) == UNSPECV_ALIGN)
+	{
+	  int log = INTVAL (XVECEXP (body, 0, 0));
+	  int align = 1 << log;
+	  int aligned_real_address = (real_address + align - 1) & -align;
+	  int aligned_current_address = (uid_address + align - 1) & -align;
+
+	  fixup_addr = aligned_real_address - aligned_current_address;
+	  return;
+	}
+
+      if (align_next_insn)
+	{
+	  align_next_insn = 0;
+	  fixup_addr = -uid_address;
+	  fprintf (asm_out_file, ".align 5\t\t! for hw workaround \n");
+	}
+
+      if (GET_CODE (body) == ASM_INPUT || asm_noperands (body) >= 0)
+	{
+	  int align = 0;
+	  const char *templ;
+
+	  if (GET_CODE (body) == ASM_INPUT)
+	    templ = XSTR (body, 0);
+	  else
+	    templ = decode_asm_operands (body, NULL, NULL, NULL, NULL, NULL);
+
+	  (void) sh_asm_count (templ, &align);
+	  if (align)
+	    {
+	      align_next_insn = 1;
+	      return;
+	    }
+	}
+
+      gcc_assert (! (real_address % 2));
+
+      /* +2 because we check that the ds is not aligned on 32.  */
+      real_address += 2;
+
+      if (recog_memoized (insn) == CODE_FOR_cmpgtudi_t
+	  || recog_memoized (insn) == CODE_FOR_cmpgeudi_t
+	  || recog_memoized (insn) == CODE_FOR_cmpgtdi_t
+	  || recog_memoized (insn) == CODE_FOR_cmpgedi_t)
+	if (!((real_address + 2) % 32))
+	  {
+	    fprintf (asm_out_file,
+		     "\tnop\t\t! for hw workaround @%d\n", real_address);
+	    fixup_addr += 2;
+	    return;
+	  }
+
+      if (recog_memoized (insn) == CODE_FOR_tls_global_dynamic
+	  || recog_memoized (insn) == CODE_FOR_tls_local_dynamic)
+	{
+	  int aligned_real_address;
+	  int align = 4;
+
+	  if (!((real_address + 8) % 32) || !((real_address + 12) % 32))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address);
+	      fixup_addr += 2;
+	      real_address += get_attr_length (insn);
+	    }
+	  else
+	    real_address += get_attr_length (insn) - 2;
+
+	  aligned_real_address = (real_address + align - 1) & -align;
+	  fixup_addr += aligned_real_address - real_address;
+	  return;
+	}
+
+      if (recog_memoized (insn) == CODE_FOR_tls_initial_exec)
+	{
+	  int aligned_real_address;
+	  int align = 4;
+
+	  if (!((real_address + 6) % 32))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address);
+	      fixup_addr += 2;
+	      real_address += get_attr_length (insn);
+	    }
+	  else
+	    real_address += get_attr_length (insn) - 2;
+
+	  aligned_real_address = (real_address + align - 1) & -align;
+	  fixup_addr += aligned_real_address - real_address;
+	  return;
+	}
+
+      if (recog_memoized (insn) == CODE_FOR_jump_compact)
+	{
+	  int offset = branch_dest (insn) - INSN_ADDRESSES (INSN_UID (insn));
+	  int far;
+
+	  far = ! (offset >= FAR_JUMP_MIN && offset <= FAR_JUMP_MAX);
+
+	  /* length = 6
+	     mov.w	.L8588,r1
+	     braf	r1
+	     mov	#81,r4	         [length = 2]
+	     .L8588: .word .L12-.L8588
+
+	     length = 8
+	     mov.w	.L8588,r1
+	     braf	r1
+	     nop
+	     .L8588: .word .L12-.L8588
+
+	     length = 10
+	     mov	#81,r4	         [length = 2]
+	     mov.l	r13,@-r15
+	     mov.w	.L,r13
+	     braf	r13
+	     mov.l	@r15+,r13
+	     .L: .word
+	  */
+	  if (!far)
+	    {
+	      if (get_attr_length (insn) == 6 || get_attr_length (insn) == 8)
+		real_address += 2;
+	      if (get_attr_length (insn) == 10)
+		{
+		  if (dbr_sequence_length ())
+		    real_address += 6;
+		  else
+		    real_address += 4;
+		}
+	    }
+	  /* length = 8/10 depending on alignment
+	     mov.l	.L8586,r4
+	     jmp	@r4
+	     mov	#81,r4         [length = 2]
+	     .align	2
+	     .L8586:  .long	.L5
+
+	     length = 10/12 depending on alignment
+	     mov.l	.L8589,r3
+	     jmp	@r3
+	     nop
+	     .align	2
+	     .L8589:  .long	.L2242
+
+	     length = 12/14 depending on alignment
+	     mov.l	r13,@-r15
+	     mov.l	.L4981,r13
+	     jmp	@r13
+	     mov.l	@r15+,r13
+	     .align	2
+	     .L4981:	.long	.L16
+	  */
+	  else
+	    {
+	      int long_address;
+	      int uid_long_address;
+	      int aligned_long_address;
+	      int aligned_uid_long_address;
+
+	      if (get_attr_length (insn) == 8 || get_attr_length (insn) == 10)
+		{
+		  if (!((real_address + 2) % 32))
+		    {
+		      fprintf (asm_out_file,
+			       "\tnop\t\t! for hw workaround @%d\n", real_address);
+		      real_address += 2;
+		    }
+
+		  long_address = real_address + 4;
+		  uid_long_address = uid_address + 6;
+		  aligned_long_address = (long_address + 3) & -4;
+		  aligned_uid_long_address = (uid_long_address + 3) & -4;
+
+		  fixup_addr = aligned_long_address - aligned_uid_long_address;
+		  if (fixup_addr && (fixup_addr % 4))
+		    fixup_addr -= 4;
+
+		  return;
+	      }
+	      else if (get_attr_length (insn) == 12)
+		{
+		  rtx prev;
+
+		  if (!((real_address + 2) % 32))
+		    {
+		      fprintf (asm_out_file,
+			       "\tnop\t\t! for hw workaround @%d\n", real_address);
+		      real_address += 2;
+		    }
+
+		if (GET_CODE ((prev = prev_nonnote_insn (insn))) == INSN
+		    && INSN_CODE (prev) == CODE_FOR_indirect_jump_scratch)
+		  {
+		    long_address = real_address + 4;
+		    uid_long_address = uid_address + 6;
+		  }
+		else
+		  {
+		    long_address = real_address + 6;
+		    uid_long_address = uid_address + 8;
+		  }
+
+		  aligned_long_address = (long_address + 3) & -4;
+		  aligned_uid_long_address = (uid_long_address + 3) & -4;
+
+		  fixup_addr = aligned_long_address - aligned_uid_long_address;
+		  if (fixup_addr && (fixup_addr % 4))
+		    fixup_addr -= 4;
+
+		  return;
+		}
+	      else if (get_attr_length (insn) == 14)
+		{
+		  if (!((real_address + 4) % 32))
+		    {
+		      fprintf (asm_out_file,
+			       "\tnop\t\t! for hw workaround @%d\n", real_address);
+		      real_address += 2;
+		    }
+
+		  long_address = real_address + 6;
+		  uid_long_address = uid_address + 8;
+		  aligned_long_address = (long_address + 3) & -4;
+		  aligned_uid_long_address = (uid_long_address + 3) & -4;
+
+		  fixup_addr = aligned_long_address - aligned_uid_long_address;
+		  if (fixup_addr && (fixup_addr % 4))
+		    fixup_addr -= 4;
+
+		  return;
+		}
+	    }
+
+	  if (!(real_address % 32))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround 1 @%d\n", real_address);
+	      fixup_addr += 2;
+	      return;
+	    }
+	}
+
+      /* we have bt; (aligned)bra; nop; avoid nop ; (aligned)bt; bra; nop.  */
+      /* or bt; delayed instruction; (aligned)bra.  */
+      if ((recog_memoized (insn) == CODE_FOR_branch_true
+	   || recog_memoized (insn) == CODE_FOR_branch_false)
+	  && get_attr_length (insn) == 6)
+	{
+	  if (!((real_address + 2) % 32))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address-2);
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address);
+	      fixup_addr += 4;
+	    }
+	  else if (!(real_address % 32))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address);
+	      fixup_addr += 2;
+	    }
+	  else if (!((real_address + 4) % 32)
+		   && (dbr_sequence_length ()
+		       && ! INSN_ANNULLED_BRANCH_P (XVECEXP (final_sequence, 0, 0))
+		       && get_attr_length (XVECEXP (final_sequence, 0, 1))))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address);
+	      fixup_addr += 2;
+	    }
+	}
+
+      if ((GET_CODE (insn) == JUMP_INSN
+	   && GET_CODE (PATTERN (insn)) != ADDR_DIFF_VEC
+	   && GET_CODE (PATTERN (insn)) != ADDR_VEC))
+	{
+	  if (!(real_address % 32)
+	      && (dbr_sequence_length ()
+		  && ! INSN_ANNULLED_BRANCH_P (XVECEXP (final_sequence, 0, 0))
+		  && get_attr_length (XVECEXP (final_sequence, 0, 1))))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address);
+	      fixup_addr += 2;
+	    }
+	  else if (GET_CODE (insn) == CALL_INSN
+		   && !(real_address % 32))
+	    {
+	      fprintf (asm_out_file,
+		       "\tnop\t\t! for hw workaround @%d\n", real_address);
+	      fixup_addr += 2;
+	    }
+	}
+
+	if ((GET_CODE (insn) == CALL_INSN || INSN_P (insn))
+	    && !(real_address % 32)
+	    && get_attr_needs_delay_slot (insn) == NEEDS_DELAY_SLOT_YES)
+	{
+	  fprintf (asm_out_file,
+		   "\tnop\t\t! for hw workaround @%d\n", real_address);
+	  fixup_addr += 2;
+	}
+    }
+}
+
+/* Return true if it is appropriate to emit `ret' instructions in the
+   body of a function.  */
+
+bool
+sh_can_use_simple_return_p (void)
+{
+  HARD_REG_SET live_regs_mask;
+  int d = calc_live_regs (&live_regs_mask);
+
+  if (! reload_completed || frame_pointer_needed)
+    return false;
+
+  /* Moving prologue around does't reduce the size.  */
+  if (optimize_function_for_size_p (cfun))
+    return false;
+
+  /* Finally, allow for pr save.  */
+  d = calc_live_regs (&live_regs_mask);
+
+  if (rounded_frame_size (d) > 4)
+   return false;
+
+  return true;
+}
+
+/* When the stack protector inserts codes after R0 is set,
+   a load of @(rX, r12) will cause a spill failure for R0.  Avoid combining
+   (set A (plus rX r12)) and (set op0 (mem A)) when R0 is alive.  */
+bool
+stack_protector_block (rtx insn, rtx op)
+{
+  rtx addr;
+
+  if (!MEM_P (op))
+    return false;
+
+  addr = XEXP (op, 0);
+
+  if (GET_CODE (addr) == PLUS
+      && REG_P (XEXP (addr, 0)) && REG_P (XEXP (addr, 1)))
+    {
+      bool r0_seen = false;
+
+      for (insn = next_real_insn (insn); insn; insn = next_real_insn (insn))
+	{
+	  rtx pat = PATTERN (insn);
+
+	  if (dead_or_set_regno_p (insn, R0_REG))
+	    return false;
+
+	  if (GET_CODE (insn) == JUMP_INSN)
+	    {
+	      /* Must have a jump_insn after the SP test.  Check if R0 is alive here.  */
+	      if (r0_seen)
+		for (insn = NEXT_INSN (JUMP_LABEL (insn));
+		     insn; insn = NEXT_INSN (insn))
+		  if (INSN_P (insn)
+		      && refers_to_regno_p (R0_REG, R0_REG+1, PATTERN (insn), (rtx *)0))
+		    return true;
+
+	      /* No need to check further.  */
+	      return false;
+	    }
+
+	  /* Find stack-protector test. After this point R0 is under pressure.  */
+	  if (GET_CODE (pat) == PARALLEL)
+	    {
+	      pat = XVECEXP (pat, 0, 0);
+	      if (GET_CODE (pat) == SET)
+		{
+		  rtx src = XEXP (pat, 1);
+		  if (GET_CODE (src) == UNSPEC && (XINT (src, 1) == UNSPEC_SP_TEST))
+		    r0_seen = true;
+		}
+	    }
+	}
+    }
+
+  return false;
+}
+
+/*
+; If a conditional branch destination is within -252..258 bytes away
+; from the instruction it can be 2 bytes long.  Something in the
+; range -4090..4100 bytes can be 6 bytes long.  All other conditional
+; branches are initially assumed to be 16 bytes long.
+; In machine_dependent_reorg, we split all branches that are longer than
+; 2 bytes.
+
+;; The maximum range used for SImode constant pool entries is 1018.  A final
+;; instruction can add 8 bytes while only being 4 bytes in size, thus we
+;; can have a total of 1022 bytes in the pool.  Add 4 bytes for a branch
+;; instruction around the pool table, 2 bytes of alignment before the table,
+;; and 30 bytes of alignment after the table.  That gives a maximum total
+;; pool size of 1058 bytes.
+;; Worst case code/pool content size ratio is 1:2 (using asms).
+;; Thus, in the worst case, there is one instruction in front of a maximum
+;; sized pool, and then there are 1052 bytes of pool for every 508 bytes of
+;; code.  For the last n bytes of code, there are 2n + 36 bytes of pool.
+;; If we have a forward branch, the initial table will be put after the
+;; unconditional branch.
+;;
+;; ??? We could do much better by keeping track of the actual pcloads within
+;; the branch range and in the pcload range in front of the branch range.
+*/
+
+bool short_cbranch_p (rtx insn)
+{
+  int baddr, offset;
+
+  if (mdep_reorg_phase <= SH_FIXUP_PCLOAD)
+    return false;
+
+  baddr = (mdep_reorg_phase == SH_AFTER_MDEP_REORG) &&
+    TARGET_DBHWBUG && INSN_ADDRESSES_SET_P () ?
+    insn_last_address : insn_current_reference_address (insn);
+
+  offset = branch_dest (insn) - baddr;
+
+  if (offset >= -256 + 4 && offset <= 254 + 4)
+    return true;
+
+  return false;
+}
+
+bool med_branch_p (rtx insn)
+{
+  int baddr;
+  int offset;
+
+  baddr = (mdep_reorg_phase == SH_AFTER_MDEP_REORG) &&
+    TARGET_DBHWBUG && INSN_ADDRESSES_SET_P () ?
+    insn_last_address : insn_current_reference_address (insn);
+
+  offset = branch_dest (insn) - baddr;
+
+  if (offset >= -4096 + 4 && offset <= 4094 + 4)
+    {
+      if (mdep_reorg_phase <= SH_FIXUP_PCLOAD)
+	return (offset >= -990 && offset <= 998);
+
+      return true;
+    }
+
+  return false;
+}
+
+bool med_cbranch_p (rtx insn)
+{
+  int baddr, offset;
+
+  baddr = (mdep_reorg_phase == SH_AFTER_MDEP_REORG) &&
+    TARGET_DBHWBUG && INSN_ADDRESSES_SET_P () ?
+    insn_last_address : insn_current_reference_address (insn);
+
+  /* we'll have
+     bt .l2
+     bra .l
+     nop
+     .2:
+  */
+
+  /* we'll start at bra, next instruction */
+  baddr += 2;
+
+  offset = branch_dest (insn) - baddr;
+
+  if (offset >= -4096 + 4 && offset <= 4094 + 4)
+    {
+      if (mdep_reorg_phase <= SH_FIXUP_PCLOAD)
+	return (offset >= -988 && offset <= 998);
+
+      return true;
+    }
+
+  return false;
+}
+
+bool braf_branch_p (rtx insn)
+{
+  rtx prev;
+  int offset, prev_count, baddr;
+
+  if (! TARGET_SH2)
+    return false;
+
+  prev = prev_nonnote_insn (insn);
+  if (prev && NONJUMP_INSN_P (prev)
+      && INSN_CODE (prev) == CODE_FOR_indirect_jump_scratch)
+    prev_count = 2;
+  else
+    prev_count = 4;
+
+  baddr = (mdep_reorg_phase == SH_AFTER_MDEP_REORG) &&
+    TARGET_DBHWBUG && INSN_ADDRESSES_SET_P () ?
+    insn_last_address : insn_current_reference_address (insn);
+
+  baddr += prev_count;
+
+  /* remove me: we must have a sequence ? */
+  if (NEXT_INSN (PREV_INSN (insn)) != insn)
+    gcc_assert (GET_CODE (PATTERN (NEXT_INSN (PREV_INSN (insn)))) == SEQUENCE);
+
+  /* The delayed instruction will be emitted BEFORE the braf !!. */
+  if (NEXT_INSN (PREV_INSN (insn)) != insn && prev_count == 4)
+    baddr += 2;
+
+  offset = branch_dest (insn) - baddr;
+
+  if (offset >= -32768 + 4 && offset <= 32767 + 4)
+    {
+      if (mdep_reorg_phase <= SH_FIXUP_PCLOAD)
+	return (offset >= -10330 && offset <= 10330);
+      return true;
+    }
+
+  return false;
+}
+
+bool braf_cbranch_p (rtx insn)
+{
+  rtx prev;
+  int baddr, offset;
+
+  if (! TARGET_SH2)
+    return false;
+
+  prev = prev_nonnote_insn (insn);
+
+  gcc_assert (! (prev &&
+		 NONJUMP_INSN_P (prev) &&
+		 INSN_CODE (prev) == CODE_FOR_indirect_jump_scratch));
+
+  baddr = (mdep_reorg_phase == SH_AFTER_MDEP_REORG) &&
+    TARGET_DBHWBUG && INSN_ADDRESSES_SET_P () ?
+    insn_last_address : insn_current_reference_address (insn);
+
+  /* we'll have
+     bt .l2
+     mov  .l,r1
+     braf .l
+     nop
+     .word
+     .2:
+  */
+
+  /* we'll start at bra, next instruction avec the mov. */
+  baddr += 4;
+
+  /* remove me: we must have a sequence ? */
+  if (NEXT_INSN (PREV_INSN (insn)) != insn)
+    gcc_assert (GET_CODE (PATTERN (NEXT_INSN (PREV_INSN (insn)))) == SEQUENCE);
+
+  /* The delayed instruction will be emitted BEFORE the braf !!. */
+  if (NEXT_INSN (PREV_INSN (insn)) != insn)
+    baddr += 2;
+
+  offset = branch_dest (insn) - baddr;
+
+  if (offset >= -32768 + 4 && offset <= 32767 + 4)
+    {
+      if (mdep_reorg_phase <= SH_FIXUP_PCLOAD)
+	return (offset >= -10328 && offset <= 10330);
+      return true;
+    }
+
+  return false;
+}
+
 #include "gt-sh.h"
+
diff -urN gcc-4.7.3/gcc/config/sh/sh.h st40-4.7.3-13080/gcc/gcc/config/sh/sh.h
--- gcc-4.7.3/gcc/config/sh/sh.h	2013-03-26 12:38:31.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/config/sh/sh.h	2013-04-19 09:19:59.000000000 +0200
@@ -4,6 +4,7 @@
    Free Software Foundation, Inc.
    Contributed by Steve Chamberlain (sac@cygnus.com).
    Improved by Jim Wilson (wilson@cygnus.com).
+   Copyright (c) 2011  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -33,6 +34,10 @@
 
 #define TARGET_CPU_CPP_BUILTINS() \
 do { \
+  if (TARGET_DBHWBUG) \
+      builtin_define_with_value ("DB_ST40300_BUG_WORKAROUND", "32", 0); \
+  if (TARGET_TAS) \
+      builtin_define ("__HAVE_TAS__"); \
   builtin_define ("__sh__"); \
   builtin_assert ("cpu=sh"); \
   builtin_assert ("machine=sh"); \
@@ -133,6 +138,11 @@
 #define TARGET_FPU_DOUBLE \
   ((target_flags & MASK_SH4) != 0 || TARGET_SH2A_DOUBLE)
 
+#define TARGET_SH1_SOFTFP (TARGET_SH1 && !TARGET_FPU_DOUBLE)
+
+#define TARGET_SH1_SOFTFP_MODE(MODE) \
+  (TARGET_SH1_SOFTFP && (!TARGET_SH2E || (MODE) == DFmode))
+
 /* Nonzero if an FPU is available.  */
 #define TARGET_FPU_ANY (TARGET_SH2E || TARGET_FPU_DOUBLE)
 
@@ -167,13 +177,16 @@
 /* Nonzero if we should generate code using SHmedia FPU instructions.  */
 #define TARGET_SHMEDIA_FPU (TARGET_SHMEDIA && TARGET_FPU_DOUBLE)
 
+/* builtin_trap can uses abort() by default.  */
+#define TARGET_BUILTIN_TRAPA 0
+
 /* This is not used by the SH2E calling convention  */
 #define TARGET_VARARGS_PRETEND_ARGS(FUN_DECL) \
   (TARGET_SH1 && ! TARGET_SH2E && ! TARGET_SH5 \
    && ! (TARGET_HITACHI || sh_attr_renesas_p (FUN_DECL)))
 
 #ifndef TARGET_CPU_DEFAULT
-#define TARGET_CPU_DEFAULT SELECT_SH1
+#define TARGET_CPU_DEFAULT SELECT_SH4
 #define SUPPORT_SH1 1
 #define SUPPORT_SH2E 1
 #define SUPPORT_SH4 1
@@ -197,7 +210,9 @@
 #define TARGET_DIVIDE_INV_CALL2 (sh_div_strategy == SH_DIV_INV_CALL2)
 #define TARGET_DIVIDE_CALL_DIV1 (sh_div_strategy == SH_DIV_CALL_DIV1)
 #define TARGET_DIVIDE_CALL_FP (sh_div_strategy == SH_DIV_CALL_FP)
-#define TARGET_DIVIDE_CALL_TABLE (sh_div_strategy == SH_DIV_CALL_TABLE)
+#define TARGET_DIVIDE_CALL_PRE1 (sh_div_strategy == SH_DIV_CALL_PRE1)
+#define TARGET_DIVIDE_CALL_TABLE (sh_div_strategy == SH_DIV_CALL_TABLE \
+   || TARGET_DIVIDE_CALL_PRE1)
 
 #define SELECT_SH1               (MASK_SH1)
 #define SELECT_SH2               (MASK_SH2 | SELECT_SH1)
@@ -232,6 +247,42 @@
 #define SELECT_SH5_COMPACT       (MASK_SH5 | MASK_SH4 | SELECT_SH3E)
 #define SELECT_SH5_COMPACT_NOFPU (MASK_SH5 | SELECT_SH3)
 
+/* Check if we have support for optimized software floating point using
+   dynamic shifts - then some function calls clobber fewer registers.  */
+#ifdef SUPPORT_SH3
+#define SUPPORT_SH3_OSFP 1
+#else
+#define SUPPORT_SH3_OSFP 0
+#endif
+
+#ifdef SUPPORT_SH3E
+#define SUPPORT_SH3E_OSFP 1
+#else
+#define SUPPORT_SH3E_OSFP 0
+#endif
+
+#if defined(SUPPORT_SH4_NOFPU) || defined(SUPPORT_SH3_OSFP)
+#define SUPPORT_SH4_NOFPU_OSFP 1
+#else
+#define SUPPORT_SH4_NOFPU_OSFP 0
+#endif
+
+#if defined(SUPPORT_SH4_SINGLE_ONLY) || defined (SUPPORT_SH3E_OSFP)
+#define SUPPORT_SH4_SINGLE_ONLY_OSFP 1
+#else
+#define SUPPORT_SH4_SINGLE_ONLY_OSFP 0
+#endif
+
+#ifdef notyet
+#define TARGET_OSFP (0 \
+ || (TARGET_SH3 && !TARGET_SH2E && SUPPORT_SH3_OSFP) \
+ || (TARGET_SH3E && SUPPORT_SH3E_OSFP) \
+ || (TARGET_HARD_SH4 && !TARGET_SH2E && SUPPORT_SH4_NOFPU_OSFP) \
+ || (TARGET_HARD_SH4 && TARGET_SH2E && SUPPORT_SH4_SINGLE_ONLY_OSFP))
+#else
+#define TARGET_OSFP (0)
+#endif
+
 #if SUPPORT_SH1
 #define SUPPORT_SH2 1
 #endif
@@ -293,7 +344,7 @@
 #endif
 
 #ifndef TARGET_OPT_DEFAULT
-#define TARGET_OPT_DEFAULT  MASK_ADJUST_UNROLL
+#define TARGET_OPT_DEFAULT 0
 #endif
 
 #define TARGET_DEFAULT \
@@ -326,20 +377,13 @@
   { "subtarget_link_emul_suffix", SUBTARGET_LINK_EMUL_SUFFIX },	\
   { "subtarget_link_spec", SUBTARGET_LINK_SPEC },		\
   { "subtarget_asm_endian_spec", SUBTARGET_ASM_ENDIAN_SPEC },	\
-  { "subtarget_asm_relax_spec", SUBTARGET_ASM_RELAX_SPEC },	\
   { "subtarget_asm_isa_spec", SUBTARGET_ASM_ISA_SPEC },		\
   { "subtarget_asm_spec", SUBTARGET_ASM_SPEC },			\
   SUBTARGET_EXTRA_SPECS
 
-#if TARGET_CPU_DEFAULT & MASK_HARD_SH4
-#define SUBTARGET_ASM_RELAX_SPEC "%{!m1:%{!m2:%{!m3*:%{!m5*:-isa=sh4-up}}}}"
-#else
-#define SUBTARGET_ASM_RELAX_SPEC "%{m4*:-isa=sh4-up}"
-#endif
-
 #define SH_ASM_SPEC \
- "%(subtarget_asm_endian_spec) %{mrelax:-relax %(subtarget_asm_relax_spec)}\
-%(subtarget_asm_isa_spec) %(subtarget_asm_spec)\
+"%(subtarget_asm_endian_spec) %{mrelax:-relax} \
+%(subtarget_asm_isa_spec) %(subtarget_asm_spec) \
 %{m2a:--isa=sh2a} \
 %{m2a-single:--isa=sh2a} \
 %{m2a-single-only:--isa=sh2a} \
@@ -347,7 +391,8 @@
 %{m5-compact*:--isa=SHcompact} \
 %{m5-32media*:--isa=SHmedia --abi=32} \
 %{m5-64media*:--isa=SHmedia --abi=64} \
-%{m4al:-dsp} %{mcut2-workaround:-cut2-workaround}"
+%{m4al:-dsp} %{mcut2-workaround:-cut2-workaround} \
+%{mtas:--tas}"
 
 #define ASM_SPEC SH_ASM_SPEC
 
@@ -363,14 +408,18 @@
 /* Strict nofpu means that the compiler should tell the assembler
    to reject FPU instructions. E.g. from ASM inserts.  */
 #if TARGET_CPU_DEFAULT & MASK_HARD_SH4 && !(TARGET_CPU_DEFAULT & MASK_SH_E)
-#define SUBTARGET_ASM_ISA_SPEC "%{!m1:%{!m2:%{!m3*:%{m4-nofpu|!m4*:%{!m5:-isa=sh4-nofpu}}}}}"
+#define SUBTARGET_ASM_ISA_SPEC "%{!m1:%{!m2:%{!m3*:%{m4-nofpu|!m4*:%{!m5:--isa=sh4-nofpu}}}}}"
 #else
 /* If there were an -isa option for sh5-nofpu then it would also go here. */
 #define SUBTARGET_ASM_ISA_SPEC \
- "%{m4-nofpu:-isa=sh4-nofpu} " ASM_ISA_DEFAULT_SPEC
+ "%{m4-nofpu:--isa=sh4-nofpu} " ASM_ISA_DEFAULT_SPEC
 #endif
 #else /* ! STRICT_NOFPU */
-#define SUBTARGET_ASM_ISA_SPEC ASM_ISA_DEFAULT_SPEC
+#define SUBTARGET_ASM_ISA_SPEC "%{m4-nofpu:--isa=sh4-nofpu-up} \
+ %{m4|m4-single*:--isa=sh4-up} \
+ %{m4-300-nofpu:--isa=st40-300-nofpu} \
+ %{m4-300|m4-300-single|m4-300-single-only:--isa=st40-300}" \
+ ASM_ISA_DEFAULT_SPEC
 #endif
 
 #ifndef SUBTARGET_ASM_SPEC
@@ -398,8 +447,14 @@
 #define ASM_ISA_DEFAULT_SPEC \
 " %{!m1:%{!m2*:%{!m3*:%{!m4*:%{!m5*:" ASM_ISA_SPEC_DEFAULT "}}}}}"
 #else /* !MASK_SH5 */
-#define LINK_DEFAULT_CPU_EMUL ""
+#if TARGET_CPU_DEFAULT & MASK_SH4
+#define ASM_ISA_SPEC_DEFAULT "--isa=sh4-up"
+#define ASM_ISA_DEFAULT_SPEC \
+" %{!m1:%{!m2*:%{!m3*:%{!m4*:%{!m5*:" ASM_ISA_SPEC_DEFAULT "}}}}}"
+#else /* !MASK_SH4 */
 #define ASM_ISA_DEFAULT_SPEC ""
+#endif
+#define LINK_DEFAULT_CPU_EMUL ""
 #endif /* MASK_SH5 */
 
 #define SUBTARGET_LINK_EMUL_SUFFIX ""
@@ -414,6 +469,8 @@
 %{m5-64media*:64}\
 %{!m1:%{!m2:%{!m3*:%{!m4*:%{!m5*:%(link_default_cpu_emul)}}}}}\
 %(subtarget_link_emul_suffix) \
+%{mdb-page-bug:--db-page-bug} \
+%{shared:-shared} \
 %{mrelax:-relax} %(subtarget_link_spec)"
 
 #ifndef SH_DIV_STR_FOR_SIZE
@@ -460,6 +517,7 @@
   SH_DIV_CALL_DIV1, /* No FPU, medium size, highest latency.  */
   SH_DIV_CALL_FP,     /* FPU needed, small size, high latency.  */
   SH_DIV_CALL_TABLE,  /* No FPU, large size, medium latency. */
+  SH_DIV_CALL_PRE1,  /* Preheader to optimize return 1 cases. */
   SH_DIV_INTRINSIC
 };
 
@@ -574,6 +632,18 @@
    multiple of this.  */
 #define STRUCTURE_SIZE_BOUNDARY (TARGET_PADSTRUCT ? 32 : 8)
 
+/* Define this macro as an expression for the alignment of a structure
+   (given by STRUCT as a tree node) if the alignment computed in the
+   usual way is COMPUTED and the alignment explicitly specified was
+   SPECIFIED.
+*/
+#define ROUND_TYPE_ALIGN(STRUCT, COMPUTED, SPECIFIED)	\
+    ((TARGET_ALIGN_DOUBLE &&						       \
+      TREE_CODE (STRUCT) == RECORD_TYPE && TYPE_FIELDS (STRUCT) != 0 && \
+      TREE_INT_CST_LOW (TYPE_SIZE (STRUCT)) > 64)	\
+     ? MAX (MAX ((COMPUTED), (SPECIFIED)), 64)		\
+     : MAX ((COMPUTED), (SPECIFIED)))
+
 /* Set this nonzero if move instructions will actually fail to work
    when given unaligned data.  */
 #define STRICT_ALIGNMENT 1
@@ -582,6 +652,8 @@
 #define LABEL_ALIGN_AFTER_BARRIER(LABEL_AFTER_BARRIER) \
   barrier_align (LABEL_AFTER_BARRIER)
 
+#define JUMP_ALIGN(LABEL) sh_jump_align (LABEL)
+
 #define LOOP_ALIGN(A_LABEL) \
   ((! optimize || TARGET_HARD_SH4 || optimize_size) \
    ? 0 : sh_loop_align (A_LABEL))
@@ -600,12 +672,10 @@
 #define ADDR_VEC_ALIGN(ADDR_VEC) 2
 
 /* The base two logarithm of the known minimum alignment of an insn length.  */
-#define INSN_LENGTH_ALIGNMENT(A_INSN)					\
-  (NONJUMP_INSN_P (A_INSN)						\
-   ? 1 << TARGET_SHMEDIA						\
-   : JUMP_P (A_INSN) || CALL_P (A_INSN)					\
-   ? 1 << TARGET_SHMEDIA						\
-   : CACHE_LOG)
+/* After a addr_diff_vec:HI the log align is 1.  Update it so the  next
+   insn_current_address can correctly be computed in final.  */
+#define INSN_LENGTH_ALIGNMENT(X) sh_insn_length_alignment (X)
+
 
 /* Standard register usage.  */
 
@@ -1057,6 +1127,7 @@
 {
   NO_REGS,
   R0_REGS,
+  R0R3_REGS,
   PR_REGS,
   T_REGS,
   MAC_REGS,
@@ -1066,7 +1137,6 @@
   GENERAL_REGS,
   FP0_REGS,
   FP_REGS,
-  DF_HI_REGS,
   DF_REGS,
   FPSCR_REGS,
   GENERAL_FP_REGS,
@@ -1083,6 +1153,7 @@
 {			\
   "NO_REGS",		\
   "R0_REGS",		\
+  "R0R3_REGS",		\
   "PR_REGS",		\
   "T_REGS",		\
   "MAC_REGS",		\
@@ -1092,7 +1163,6 @@
   "GENERAL_REGS",	\
   "FP0_REGS",		\
   "FP_REGS",		\
-  "DF_HI_REGS",		\
   "DF_REGS",		\
   "FPSCR_REGS",		\
   "GENERAL_FP_REGS",	\
@@ -1111,6 +1181,8 @@
   { 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00000000 },	\
 /* R0_REGS:  */								\
   { 0x00000001, 0x00000000, 0x00000000, 0x00000000, 0x00000000 },	\
+/* R0R3_REGS:  */							\
+  { 0x0000000f, 0x00000000, 0x00000000, 0x00000000, 0x00000000 },	\
 /* PR_REGS:  */								\
   { 0x00000000, 0x00000000, 0x00000000, 0x00000000, 0x00040000 },	\
 /* T_REGS:  */								\
@@ -1129,8 +1201,6 @@
   { 0x00000000, 0x00000000, 0x00000001, 0x00000000, 0x00000000 },	\
 /* FP_REGS:  */								\
   { 0x00000000, 0x00000000, 0xffffffff, 0xffffffff, 0x00000000 },	\
-/* DF_HI_REGS:  Initialized in TARGET_CONDITIONAL_REGISTER_USAGE.  */		\
-  { 0x00000000, 0x00000000, 0xffffffff, 0xffffffff, 0x0000ff00 },	\
 /* DF_REGS:  */								\
   { 0x00000000, 0x00000000, 0xffffffff, 0xffffffff, 0x0000ff00 },	\
 /* FPSCR_REGS:  */							\
@@ -1264,7 +1334,7 @@
     && ! TARGET_SHMEDIA							\
     && immediate_operand ((X), (MODE))					\
     && ! ((fp_zero_operand (X) || fp_one_operand (X))			\
-	  && (MODE) == SFmode && fldi_ok ()))				\
+	  && (MODE) == SFmode && fldi_ok (true)))				\
    ? R0_REGS								\
    : ((CLASS) == FPUL_REGS						\
       && ((REG_P (X)							\
@@ -1752,12 +1822,13 @@
                                            ? 0 : TARGET_SH1)
 
 #define MOVE_BY_PIECES_P(SIZE, ALIGN) \
-  (move_by_pieces_ninsns (SIZE, ALIGN, MOVE_MAX_PIECES + 1) \
-   < (optimize_size ? 2 : ((ALIGN >= 32) ? 16 : 2)))
+     ((TARGET_ALIGN_DOUBLE) ? ((SIZE)*8 <= 64 || ALIGN != 64)	\
+      : (move_by_pieces_ninsns ((SIZE), ALIGN, MOVE_MAX_PIECES + 1)	\
+	 <= (optimize_size ? 2 : ((ALIGN >= 32) ? 16 : 4))))
 
 #define STORE_BY_PIECES_P(SIZE, ALIGN) \
   (move_by_pieces_ninsns (SIZE, ALIGN, STORE_MAX_PIECES + 1) \
-   < (optimize_size ? 2 : ((ALIGN >= 32) ? 16 : 2)))
+   <= (optimize_size ? 2 : ((ALIGN >= 32) ? 16 : 4)))
 
 #define SET_BY_PIECES_P(SIZE, ALIGN) STORE_BY_PIECES_P(SIZE, ALIGN)
 
@@ -1928,13 +1999,16 @@
 #define CASE_VECTOR_MODE ((! optimize || TARGET_BIGTABLE) ? SImode : HImode)
 
 #define CASE_VECTOR_SHORTEN_MODE(MIN_OFFSET, MAX_OFFSET, BODY) \
-((MIN_OFFSET) >= 0 && (MAX_OFFSET) <= 127 \
+(mdep_reorg_phase <= SH_FIXUP_PCLOAD ? SImode               \
+ : (MIN_OFFSET) >= 0 && (MAX_OFFSET) <= 127		    \
  ? (ADDR_DIFF_VEC_FLAGS (BODY).offset_unsigned = 0, QImode) \
  : (MIN_OFFSET) >= 0 && (MAX_OFFSET) <= 255 \
  ? (ADDR_DIFF_VEC_FLAGS (BODY).offset_unsigned = 1, QImode) \
  : (MIN_OFFSET) >= -32768 && (MAX_OFFSET) <= 32767 ? HImode \
  : SImode)
 
+#define VARYING_INSN_P(INSN) sh_varying_insn_p(INSN) 
+
 /* Define as C expression which evaluates to nonzero if the tablejump
    instruction expects the table to contain offsets from the address of the
    table.
@@ -1972,7 +2046,7 @@
 
 /* Max number of bytes we want move_by_pieces to be able to copy
    efficiently.  */
-#define MOVE_MAX_PIECES (TARGET_SH4 || TARGET_SHMEDIA ? 8 : 4)
+#define MOVE_MAX_PIECES (TARGET_SH1 || TARGET_SH5 ? 8 : 4)
 
 /* Define if operations between registers always perform the operation
    on the full register even if a narrower mode is specified.  */
@@ -2078,7 +2152,7 @@
 
 #define REGCLASS_HAS_FP_REG(CLASS) \
   ((CLASS) == FP0_REGS || (CLASS) == FP_REGS \
-   || (CLASS) == DF_REGS || (CLASS) == DF_HI_REGS)
+   || (CLASS) == DF_REGS)
 
 /* ??? Perhaps make MEMORY_MOVE_COST depend on compiler option?  This
    would be so that people with slow memory systems could generate
@@ -2242,9 +2316,13 @@
   if ((LOG) != 0)			\
     fprintf ((FILE), "\t.align %d\n", (LOG))
 
+#define ASM_ALIGN_FUNCTION_LOG(DECL) sh_align_function_log(DECL)
+
 /* Globalizing directive for a label.  */
 #define GLOBAL_ASM_OP "\t.global\t"
 
+#define TARGET_ASM_COUNT(TEMP, ALIGNP) sh_asm_count (TEMP, ALIGNP)
+
 /* #define ASM_OUTPUT_CASE_END(STREAM,NUM,TABLE)	    */
 
 /* Output a relative address table.  */
@@ -2360,7 +2438,8 @@
    sh-dsp parallel processing insns are four bytes long.  */
 
 #define ADJUST_INSN_LENGTH(X, LENGTH)				\
-  (LENGTH) += sh_insn_length_adjustment (X);
+  (LENGTH) += sh_insn_length_adjustment (X, LENGTH);
+
 
 /* Define this macro if it is advisable to hold scalars in registers
    in a wider mode than that declared by the program.  In such cases,
@@ -2390,7 +2469,6 @@
   (TARGET_HARD_SH4 ? 1	\
    : (TARGET_SH3 || TARGET_SH2A) ? (optimize_size ? 1 : 2) : 20)
 
-
 #define NUM_MODES_FOR_MODE_SWITCHING { FP_MODE_NONE }
 
 #define OPTIMIZE_MODE_SWITCHING(ENTITY) (TARGET_SH4 || TARGET_SH2A_DOUBLE)
@@ -2426,11 +2504,16 @@
 #define MODE_PRIORITY_TO_MODE(ENTITY, N) \
   ((TARGET_FPU_SINGLE != 0) ^ (N) ? FP_MODE_SINGLE : FP_MODE_DOUBLE)
 
-#define EMIT_MODE_SET(ENTITY, MODE, HARD_REGS_LIVE) \
-  fpscr_set_from_mem ((MODE), (HARD_REGS_LIVE))
+#define EMIT_MODE_SET(ENTITY, MODE, FLIP, HARD_REGS_LIVE) \
+  ((TARGET_SH4A_FP || TARGET_SH4_300)                     \
+   && (FLIP) ? emit_fpu_flip ()                           \
+   : fpscr_set_from_mem ((MODE), (HARD_REGS_LIVE)))
 
+/* Too conservative, if distances are not computed get_attr_length is too
+   much conservative. better let it go and split_branches afterwards.
 #define MD_CAN_REDIRECT_BRANCH(INSN, SEQ) \
   sh_can_redirect_branch ((INSN), (SEQ))
+ */
 
 #define DWARF_FRAME_RETURN_COLUMN \
   (TARGET_SH5 ? DWARF_FRAME_REGNUM (PR_MEDIA_REG) : DWARF_FRAME_REGNUM (PR_REG))
@@ -2478,4 +2561,7 @@
 /* FIXME: middle-end support for highpart optimizations is missing.  */
 #define high_life_started reload_in_progress
 
+#define TARGET_USES_LEB128 \
+  (! TARGET_RELAX || (!flag_unwind_tables && !flag_exceptions))
+
 #endif /* ! GCC_SH_H */
diff -urN gcc-4.7.3/gcc/config/sh/sh.md st40-4.7.3-13080/gcc/gcc/config/sh/sh.md
--- gcc-4.7.3/gcc/config/sh/sh.md	2013-03-26 12:38:31.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/config/sh/sh.md	2013-06-05 12:58:25.000000000 +0200
@@ -4,6 +4,7 @@
 ;;  Free Software Foundation, Inc.
 ;;  Contributed by Steve Chamberlain (sac@cygnus.com).
 ;;  Improved by Jim Wilson (wilson@cygnus.com).
+;;  Copyright (c) 2009  STMicroelectronics.
 
 ;; This file is part of GCC.
 
@@ -33,9 +34,6 @@
 ;; ??? The MAC.W and MAC.L instructions are not supported.  There is no
 ;; way to generate them.
 
-;; ??? The cmp/str instruction is not supported.  Perhaps it can be used
-;; for a str* inline function.
-
 ;; BSR is not generated by the compiler proper, but when relaxing, it
 ;; generates .uses pseudo-ops that allow linker relaxation to create
 ;; BSR.  This is actually implemented in bfd/{coff,elf32}-sh.c
@@ -47,6 +45,8 @@
 ;;    l -- pr
 ;;    z -- r0
 ;;
+;;    R03 -- r0, r1, r2 or r3  - experimental constraint for SH4-300
+;;
 ;; Special formats used for outputting SH instructions:
 ;;
 ;;   %.  --  print a .s if insn needs delay slot
@@ -107,6 +107,7 @@
   (DR0_REG	64)
   (DR2_REG	66)
   (DR4_REG	68)
+  (FR4_REG	68)
   (FR23_REG	87)
 
   (TR0_REG	128)
@@ -150,7 +151,6 @@
   (UNSPEC_DIV_INV_TABLE	37)
   (UNSPEC_ASHIFTRT	35)
   (UNSPEC_THUNK		36)
-  (UNSPEC_CHKADD	38)
   (UNSPEC_SP_SET	40)
   (UNSPEC_SP_TEST	41)
   (UNSPEC_MOVUA		42)
@@ -166,6 +166,15 @@
   ;; (unspec [OFFSET ANCHOR] UNSPEC_PCREL_SYMOFF) == OFFSET - (ANCHOR - .).
   (UNSPEC_PCREL_SYMOFF	46)
 
+  (UNSPEC_BUILTIN_ROUND	47)
+
+  (UNSPEC_STR		49)
+  (UNSPEC_ROT		50)
+
+  (UNSPECV_SP_SWITCH_B 51)
+  (UNSPECV_SP_SWITCH_E 52)
+
+
   ;; These are used with unspec_volatile.
   (UNSPECV_BLOCKAGE	0)
   (UNSPECV_ALIGN	1)
@@ -175,8 +184,25 @@
   (UNSPECV_WINDOW_END	10)
   (UNSPECV_CONST_END	11)
   (UNSPECV_EH_RETURN	12)
+  (UNSPECV_DB_INSN	13)
+
+  ;; NaN handling for software floating point:
+  ;; We require one bit specific for a precision to be set in all NaNs,
+  ;; so that we can test them with a not / tst sequence.
+  ;; ??? Ironically, this is the quiet bit for now, because that is the
+  ;; only bit set by __builtin_nan ("").
+  ;; ??? Should really use one bit lower and force it set by using
+  ;; a custom encoding function.
+  (SF_NAN_MASK		0x7fc00000)
+  (DF_NAN_MASK		0x7ff80000)
 ])
 
+;; <optab> expands to the name of the optab for a particular code.
+
+(define_code_iterator any_return [return simple_return])
+;;(define_code_attr code [(return "return")
+;;			 (simple_return "simple_return")])
+
 ;; -------------------------------------------------------------------------
 ;; Attributes
 ;; -------------------------------------------------------------------------
@@ -320,89 +346,6 @@
 ;; This attribute is only used for the Renesas ABI.
 (define_attr "fp_set" "single,double,unknown,none" (const_string "none"))
 
-; If a conditional branch destination is within -252..258 bytes away
-; from the instruction it can be 2 bytes long.  Something in the
-; range -4090..4100 bytes can be 6 bytes long.  All other conditional
-; branches are initially assumed to be 16 bytes long.
-; In machine_dependent_reorg, we split all branches that are longer than
-; 2 bytes.
-
-;; The maximum range used for SImode constant pool entries is 1018.  A final
-;; instruction can add 8 bytes while only being 4 bytes in size, thus we
-;; can have a total of 1022 bytes in the pool.  Add 4 bytes for a branch
-;; instruction around the pool table, 2 bytes of alignment before the table,
-;; and 30 bytes of alignment after the table.  That gives a maximum total
-;; pool size of 1058 bytes.
-;; Worst case code/pool content size ratio is 1:2 (using asms).
-;; Thus, in the worst case, there is one instruction in front of a maximum
-;; sized pool, and then there are 1052 bytes of pool for every 508 bytes of
-;; code.  For the last n bytes of code, there are 2n + 36 bytes of pool.
-;; If we have a forward branch, the initial table will be put after the
-;; unconditional branch.
-;;
-;; ??? We could do much better by keeping track of the actual pcloads within
-;; the branch range and in the pcload range in front of the branch range.
-
-;; ??? This looks ugly because genattrtab won't allow if_then_else or cond
-;; inside an le.
-(define_attr "short_cbranch_p" "no,yes"
-  (cond [(match_test "mdep_reorg_phase <= SH_FIXUP_PCLOAD")
-	 (const_string "no")
-	 (leu (plus (minus (match_dup 0) (pc)) (const_int 252)) (const_int 506))
-	 (const_string "yes")
-	 (match_test "NEXT_INSN (PREV_INSN (insn)) != insn")
-	 (const_string "no")
-	 (leu (plus (minus (match_dup 0) (pc)) (const_int 252)) (const_int 508))
-	 (const_string "yes")
-         ] (const_string "no")))
-
-(define_attr "med_branch_p" "no,yes"
-  (cond [(leu (plus (minus (match_dup 0) (pc)) (const_int 990))
-	      (const_int 1988))
-	 (const_string "yes")
-	 (match_test "mdep_reorg_phase <= SH_FIXUP_PCLOAD")
-	 (const_string "no")
-	 (leu (plus (minus (match_dup 0) (pc)) (const_int 4092))
-	      (const_int 8186))
-	 (const_string "yes")
-	 ] (const_string "no")))
-
-(define_attr "med_cbranch_p" "no,yes"
-  (cond [(leu (plus (minus (match_dup 0) (pc)) (const_int 988))
-	      (const_int 1986))
-	 (const_string "yes")
-	 (match_test "mdep_reorg_phase <= SH_FIXUP_PCLOAD")
-	 (const_string "no")
-	 (leu (plus (minus (match_dup 0) (pc)) (const_int 4090))
-	       (const_int 8184))
-	 (const_string "yes")
-	 ] (const_string "no")))
-
-(define_attr "braf_branch_p" "no,yes"
-  (cond [(match_test "! TARGET_SH2")
-	 (const_string "no")
-	 (leu (plus (minus (match_dup 0) (pc)) (const_int 10330))
-	      (const_int 20660))
-	 (const_string "yes")
-	 (match_test "mdep_reorg_phase <= SH_FIXUP_PCLOAD")
-	 (const_string "no")
-	 (leu (plus (minus (match_dup 0) (pc)) (const_int 32764))
-	      (const_int 65530))
-	 (const_string "yes")
-	 ] (const_string "no")))
-
-(define_attr "braf_cbranch_p" "no,yes"
-  (cond [(match_test "! TARGET_SH2")
-	 (const_string "no")
-	 (leu (plus (minus (match_dup 0) (pc)) (const_int 10328))
-	      (const_int 20658))
-	 (const_string "yes")
-	 (match_test "mdep_reorg_phase <= SH_FIXUP_PCLOAD")
-	 (const_string "no")
-	 (leu (plus (minus (match_dup 0) (pc)) (const_int 32762))
-	      (const_int 65528))
-	 (const_string "yes")
-	 ] (const_string "no")))
 
 ; An unconditional jump in the range -4092..4098 can be 2 bytes long.
 ; For wider ranges, we need a combination of a code and a data part.
@@ -417,37 +360,41 @@
 ;; but getattrtab doesn't understand this.
 (define_attr "length" ""
   (cond [(eq_attr "type" "cbranch")
-	 (cond [(eq_attr "short_cbranch_p" "yes")
+	 (cond [(match_test "short_cbranch_p (insn)")
 		(const_int 2)
-		(eq_attr "med_cbranch_p" "yes")
+		(match_test "med_cbranch_p (insn)")
 		(const_int 6)
-		(eq_attr "braf_cbranch_p" "yes")
+		(match_test "braf_cbranch_p (insn)")
 		(const_int 12)
 ;; ??? using pc is not computed transitively.
 		(ne (match_dup 0) (match_dup 0))
-		(const_int 14)
-		(match_test "flag_pic")
-		(const_int 24)
+		(const_int 2)
+;; ??? is it necessary use pcrel braf instead of jmp. why ?
+;;		(match_test "flag_pic")
+;;		(const_int 24)
 		] (const_int 16))
 	 (eq_attr "type" "jump")
-	 (cond [(eq_attr "med_branch_p" "yes")
+	 (cond [(match_test "med_branch_p (insn)")
 		(const_int 2)
 		(and (match_test "prev_nonnote_insn (insn)")
-		     (and (eq (symbol_ref "GET_CODE (prev_nonnote_insn (insn))")			      (symbol_ref "INSN"))
-			  (eq (symbol_ref "INSN_CODE (prev_nonnote_insn (insn))")			      (symbol_ref "code_for_indirect_jump_scratch"))))
-                (cond [(eq_attr "braf_branch_p" "yes")
+		     (and (eq (symbol_ref "GET_CODE (prev_nonnote_insn (insn))") (symbol_ref "INSN"))
+			  (eq (symbol_ref "INSN_CODE (prev_nonnote_insn (insn))") (symbol_ref "code_for_indirect_jump_scratch"))))
+                (cond [(match_test "braf_branch_p (insn)")
                        (const_int 6)
-                       (not (match_test "flag_pic"))
-                       (const_int 10)
-                       (match_test "TARGET_SH2")
-                       (const_int 10)] (const_int 18))
-		(eq_attr "braf_branch_p" "yes")
+		       (and (match_test "flag_pic")
+			    (match_test "! TARGET_SH2"))
+                       (const_int 18)
+;; not braf_branch_p but reg to use.
+		       ] (const_int 10))
+		(match_test "braf_branch_p (insn)")
 		(const_int 10)
 ;; ??? using pc is not computed transitively.
 		(ne (match_dup 0) (match_dup 0))
-		(const_int 12)
-		(match_test "flag_pic")
-		(const_int 22)
+		(const_int 2)
+;; ??? is it necessary use pcrel braf instead of jmp. why ?
+;;		(match_test "flag_pic")
+;;		(const_int 22)
+;; not braf_branch_p and no reg to use.
 		] (const_int 14))
 	 (eq_attr "type" "pt_media")
 	 (if_then_else (match_test "TARGET_SHMEDIA64")
@@ -654,7 +601,49 @@
 
 (define_insn "tstsi_t_zero_extract_eq"
   [(set (reg:SI T_REG)
-	(eq:SI (zero_extract:SI (match_operand 0 "logical_operand" "z")
+	(eq:SI (zero_extract:SI (match_operand:SI 0 "logical_operand" "z")
+		(match_operand:SI 1 "const_int_operand")
+		(match_operand:SI 2 "const_int_operand"))
+         (const_int 0)))]
+  "TARGET_SH1
+   && CONST_OK_FOR_K08 (ZERO_EXTRACT_ANDMASK (operands[1], operands[2]))"
+{
+  operands[1] = GEN_INT (ZERO_EXTRACT_ANDMASK (operands[1], operands[2]));
+  return "tst	%1,%0";
+}
+  [(set_attr "type" "mt_group")])
+
+(define_insn "tsthi_t_zero_extract_eq"
+  [(set (reg:SI T_REG)
+	(eq:SI (zero_extract:SI (match_operand:HI 0 "logical_operand" "z")
+		(match_operand:SI 1 "const_int_operand")
+		(match_operand:SI 2 "const_int_operand"))
+         (const_int 0)))]
+  "TARGET_SH1
+   && CONST_OK_FOR_K08 (ZERO_EXTRACT_ANDMASK (operands[1], operands[2]))"
+{
+  operands[1] = GEN_INT (ZERO_EXTRACT_ANDMASK (operands[1], operands[2]));
+  return "tst	%1,%0";
+}
+  [(set_attr "type" "mt_group")])
+
+(define_insn "tstqi_t_zero_extract_eq"
+  [(set (reg:SI T_REG)
+	(eq:SI (zero_extract:SI (match_operand:QI 0 "logical_operand" "z")
+		(match_operand:SI 1 "const_int_operand")
+		(match_operand:SI 2 "const_int_operand"))
+         (const_int 0)))]
+  "TARGET_SH1
+   && CONST_OK_FOR_K08 (ZERO_EXTRACT_ANDMASK (operands[1], operands[2]))"
+{
+  operands[1] = GEN_INT (ZERO_EXTRACT_ANDMASK (operands[1], operands[2]));
+  return "tst	%1,%0";
+}
+  [(set_attr "type" "mt_group")])
+
+(define_insn "tstdi_t_zero_extract_eq"
+  [(set (reg:SI T_REG)
+	(eq:SI (zero_extract:SI (match_operand:DI 0 "logical_operand" "z")
 		(match_operand:SI 1 "const_int_operand")
 		(match_operand:SI 2 "const_int_operand"))
          (const_int 0)))]
@@ -760,6 +749,14 @@
 	cmp/eq	%1,%0"
    [(set_attr "type" "mt_group")])
 
+(define_insn "fpcmp_i1"
+  [(set (reg:SI T_REG)
+	(match_operator:SI 1 "soft_fp_comparison_operator"
+	  [(match_operand 0 "soft_fp_comparison_operand" "r") (const_int 0)]))]
+  "TARGET_SH1_SOFTFP"
+  "tst	%0,%0"
+   [(set_attr "type" "mt_group")])
+
 (define_insn "cmpgtsi_t"
   [(set (reg:SI T_REG)
 	(gt:SI (match_operand:SI 0 "arith_reg_operand" "r,r")
@@ -881,18 +878,16 @@
     }
 }")
 
-(define_insn_and_split "cbranchdi4_i"
+(define_split
   [(set (pc)
 	(if_then_else (match_operator 0 "comparison_operator"
-			[(match_operand:DI 1 "arith_operand" "r,r")
-			 (match_operand:DI 2 "arith_operand" "rN,I08")])
+			[(match_operand:DI 1 "arith_operand" "")
+			 (match_operand:DI 2 "arith_operand" "")])
 		      (label_ref (match_operand 3 "" ""))
 		      (pc)))
-   (clobber (match_scratch:SI 4 "=X,&r"))
+   (clobber (match_scratch:SI 4 ""))
    (clobber (reg:SI T_REG))]
-  "TARGET_CBRANCHDI4"
-  "#"
-  "&& reload_completed"
+  "TARGET_CBRANCHDI4 && reload_completed"
   [(pc)]
   "
 {
@@ -1299,7 +1294,7 @@
 
 (define_insn "*movsicc_t_false"
   [(set (match_operand:SI 0 "arith_reg_dest" "=r,r")
-	(if_then_else (eq (reg:SI T_REG) (const_int 0))
+	(if_then_else:SI (eq (reg:SI T_REG) (const_int 0))
 		      (match_operand:SI 1 "general_movsrc_operand" "r,I08")
 		      (match_operand:SI 2 "arith_reg_operand" "0,0")))]
   "TARGET_PRETEND_CMOVE
@@ -1312,7 +1307,7 @@
 
 (define_insn "*movsicc_t_true"
   [(set (match_operand:SI 0 "arith_reg_dest" "=r,r")
-	(if_then_else (ne (reg:SI T_REG) (const_int 0))
+	(if_then_else:SI (ne (reg:SI T_REG) (const_int 0))
 		      (match_operand:SI 1 "general_movsrc_operand" "r,I08")
 		      (match_operand:SI 2 "arith_reg_operand" "0,0")))]
   "TARGET_PRETEND_CMOVE
@@ -1415,6 +1410,68 @@
     }
 }")
 
+;; Combiner can transform add sequences into
+;;  r1 = r0 + x
+;;  r2 = r1 + x
+;;  r3 = r2 + x
+;;  r4 = r3 + x
+;;  =>
+;;  r2 = r0 + 2x
+;;  r4 = r2 + 2x
+;;  =>
+;;  r4 = r0 + 4x
+
+(define_insn_and_split "*muladdsi3"
+  [(set (match_operand:SI 0 "arith_reg_dest" "=r")
+        (plus:SI (mult:SI (match_operand:SI 1 "arith_reg_operand" "%r")
+			  (match_operand:SI 2 "const_int_operand" "i"))
+	  (match_operand:SI 3 "arith_operand" "rI08")))
+   (clobber (reg:SI MACL_REG))]
+  "! (REG_P(operands[0]) && REG_POINTER (operands[0])) &&
+   ! (REG_P(operands[1]) && REG_POINTER (operands[1]))"
+  "#"
+  "&& can_create_pseudo_p ()"
+  [(set (match_dup 0) (plus:SI (match_dup 4) (match_dup 3)))]
+  "
+{
+   rtx tmp = gen_reg_rtx (SImode);
+   int n = INTVAL (operands[2]);
+   operands[4] = gen_reg_rtx (SImode);
+
+#if 0
+    printf (\"%d: %d %d %d\n\", floor_log2 (n), TARGET_SH1, TARGET_HARD_SH4, TARGET_SH3, TARGET_SH2A); 
+#endif
+
+   if ((TARGET_SH1 && !TARGET_HARD_SH4 &&
+        !satisfies_constraint_P27 (GEN_INT (floor_log2 (n)))) ||
+       (exact_log2 (n) == -1 && n > 16) || n < 0)
+   {
+      emit_move_insn (tmp, operands[2]);
+      emit_insn (gen_mulsi3 (operands[4], tmp, operands[1]));
+   }
+   else
+   {
+      int log;
+
+      log = floor_log2 (n);
+      gcc_assert (log > 0);
+
+      emit_insn (gen_ashlsi3 (operands[4], operands[1], GEN_INT (log)));
+
+      while ((n = (n - (1 << log))))
+      {
+          log = floor_log2 (n);
+
+          emit_move_insn (tmp, operands[1]);
+	  if (log)
+             emit_insn (gen_ashlsi3 (tmp, tmp, GEN_INT (log)));
+
+	  emit_insn (gen_addsi3 (operands[4], operands[4], tmp));
+      }
+   }
+}"
+  [(set_attr "type" "arith")])
+
 (define_insn "*adddi3_media"
   [(set (match_operand:DI 0 "arith_reg_dest" "=r,r")
 	(plus:DI (match_operand:DI 1 "arith_reg_operand" "%r,r")
@@ -2142,6 +2199,7 @@
   "
 {
   rtx last;
+  rtx lab2 = NULL_RTX;
 
   operands[3] = gen_reg_rtx (Pmode);
   /* Emit the move of the address to a pseudo outside of the libcall.  */
@@ -2280,9 +2338,44 @@
       function_symbol (operands[3], sh_divsi3_libfunc, SFUNC_GOT);
       last = gen_divsi3_i1 (operands[0], operands[3]);
     }
+
+   if (TARGET_DIVIDE_CALL_PRE1) 
+   {
+      rtx tmp = gen_reg_rtx (SImode);
+      rtx lab = gen_label_rtx ();
+      rtx jump;
+
+      lab2 = gen_label_rtx ();
+
+      operands[1] = force_reg (SImode, operands[1]);
+      operands[2] = force_reg (SImode, operands[2]);
+
+      emit_move_insn (tmp, operands[1]);
+      emit_insn (gen_iorsi3 (tmp, tmp, operands[2]));
+      emit_insn (gen_ashlsi3_k (tmp, tmp, GEN_INT (1)));
+      emit_jump_insn (gen_branch_true (lab));
+      emit_move_insn (tmp, operands[1]); 
+      emit_insn (gen_subc (tmp, tmp, operands[2]));
+
+      emit_jump_insn (gen_branch_true (lab));
+
+      emit_insn (gen_subc (tmp, tmp, operands[2]));
+      emit_jump_insn (gen_branch_false (lab));
+
+      emit_move_insn (operands[0], GEN_INT (1));
+      jump = emit_jump_insn (gen_jump_compact (lab2));
+      emit_barrier_after (jump);
+
+      emit_label (lab);
+    }
+
   emit_move_insn (gen_rtx_REG (SImode, 4), operands[1]);
   emit_move_insn (gen_rtx_REG (SImode, 5), operands[2]);
   emit_insn (last);
+
+  if (TARGET_DIVIDE_CALL_PRE1)
+    emit_label (lab2);
+
   DONE;
 }")
 
@@ -2297,8 +2390,7 @@
 				    (match_operand:DI 2 "register_operand" "r")]
 			 UNSPEC_DIV_INV_TABLE)))]
   "TARGET_SHMEDIA"
-  "@
-	ldx.ub	%1, %2, %0"
+  "ldx.ub	%1, %2, %0"
   [(set_attr "type" "load_media")
    (set_attr "highpart" "user")])
 
@@ -2309,8 +2401,7 @@
 				    (match_operand:DI 2 "register_operand" "r")]
 			 UNSPEC_DIV_INV_TABLE)))]
   "TARGET_SHMEDIA"
-  "@
-	ldx.w	%1, %2, %0"
+  "ldx.w	%1, %2, %0"
   [(set_attr "type" "load_media")
    (set_attr "highpart" "user")])
 
@@ -2856,6 +2947,16 @@
   "mul.l	%1,%0"
   [(set_attr "type" "dmpy")])
 
+(define_insn "mulr03"
+  [(set (match_operand:SI 0 "arith_reg_operand" "=r")
+	(mult:SI (match_operand:SI 1 "arith_reg_operand" "%0")
+		 (match_operand:SI 2 "arith_reg_operand" "R03")))]
+  "TARGET_R0R3_TO_REG_MUL - !reload_completed >= 1"
+  "mulr	%2,%0"
+  [(set_attr "type" "dmpy")])
+
+;; ??? should we also use mulr if we'd need two reg-reg copies?
+
 (define_expand "mulsi3"
   [(set (reg:SI MACL_REG)
 	(mult:SI  (match_operand:SI 1 "arith_reg_operand" "")
@@ -2865,7 +2966,12 @@
   "TARGET_SH1"
   "
 {
-  if (!TARGET_SH2)
+    if (TARGET_R0R3_TO_REG_MUL == 2)
+    {
+       emit_insn (gen_mulr03 (operands[0], operands[1], operands[2]));
+       DONE;
+    }
+   else if (!TARGET_SH2)
     {
       /* The address must be set outside the libcall,
 	 since it goes into a pseudo.  */
@@ -3548,7 +3654,7 @@
   DONE;
 }")
 
-(define_insn "*rotlhi3_8"
+(define_insn "rotlhi3_8"
   [(set (match_operand:HI 0 "arith_reg_dest" "=r")
 	(rotate:HI (match_operand:HI 1 "arith_reg_operand" "r")
 		   (const_int 8)))]
@@ -3570,6 +3676,17 @@
 ;;
 ;; shift left
 
+(define_insn "ashlsi3_k"
+  [(set (match_operand:SI 0 "arith_reg_dest" "=r")
+	(ashift:SI (match_operand:SI 1 "arith_reg_operand" "0")
+		   (match_operand:SI 2 "const_int_operand" "M")))
+   (set (reg:SI T_REG)
+	(lt:SI (match_dup 1) (const_int 0)))]
+  "TARGET_SH1"
+  "shal	%0"
+  [(set_attr "type" "arith")])
+
+
 ;; This pattern is used by init_expmed for computing the costs of shift
 ;; insns.
 
@@ -3735,44 +3852,28 @@
 ;; code, so just let the machine independent code widen the mode.
 ;; That's why we don't have ashrhi3_k / lshrhi3_k / lshrhi3_m / lshrhi3 .
 
-
-;; ??? This should be a define expand.
-
-(define_insn "ashrsi2_16"
-  [(set (match_operand:SI 0 "arith_reg_dest" "=r")
-        (ashiftrt:SI (match_operand:SI 1 "arith_reg_operand" "r")
-                     (const_int 16)))]
-  "TARGET_SH1"
-  "#"
-  [(set_attr "length" "4")])
-
-(define_split
-  [(set (match_operand:SI 0 "arith_reg_dest" "")
+(define_expand "ashrsi2_16"
+  [(parallel [(set (match_operand:SI 0 "arith_reg_dest" "")
         (ashiftrt:SI (match_operand:SI 1 "arith_reg_operand" "")
-		     (const_int 16)))]
+				(const_int 16)))
+	      (clobber (reg:SI T_REG))])]
   "TARGET_SH1"
-  [(set (match_dup 0) (rotate:SI (match_dup 1) (const_int 16)))
-   (set (match_dup 0) (sign_extend:SI (match_dup 2)))]
-  "operands[2] = gen_lowpart (HImode, operands[0]);")
+  "
+{
+  rtx low0 = gen_lowpart (HImode, operands[0]);
 
-;; ??? This should be a define expand.
+  emit_insn (gen_rotlsi3_16 (operands[0], operands[1]));
+  emit_insn (gen_extendhisi2 (operands[0], low0));
+  DONE;
+}
+")
 
-(define_insn "ashrsi2_31"
-  [(set (match_operand:SI 0 "arith_reg_dest" "=r")
+(define_expand "ashrsi2_31"
+  [(parallel [(set (match_operand:SI 0 "arith_reg_dest" "=r")
 	(ashiftrt:SI (match_operand:SI 1 "arith_reg_operand" "0")
 		     (const_int 31)))
-   (clobber (reg:SI T_REG))]
-  "TARGET_SH1"
-  "#"
-  [(set_attr "length" "4")])
-
-(define_split
-  [(set (match_operand:SI 0 "arith_reg_dest" "")
-	(ashiftrt:SI (match_operand:SI 1 "arith_reg_operand" "")
-		     (const_int 31)))
-   (clobber (reg:SI T_REG))]
+	      (clobber (reg:SI T_REG))])]
   "TARGET_SH1"
-  [(const_int 0)]
   "
 {
   emit_insn (gen_ashlsi_c (operands[0], operands[1]));
@@ -4962,8 +5063,9 @@
   "")
 
 (define_insn "pop_fpul"
-  [(set (reg:SF FPUL_REG) (mem:SF (post_inc:SI (reg:SI SP_REG))))]
-  "TARGET_SH2E && ! TARGET_SH5"
+  [(parallel [(set (reg:SF FPUL_REG) (mem:SF (post_inc:SI (reg:SI SP_REG))))
+	      (clobber (scratch:SI))])]
+  "TARGET_SH1 && ! TARGET_SH5"
   "lds.l	@r15+,fpul"
   [(set_attr "type" "load")
    (set_attr "hit_stack" "yes")])
@@ -5043,7 +5145,10 @@
    && ! TARGET_SH2E
    && ! TARGET_SH2A
    && (register_operand (operands[0], SImode)
-       || register_operand (operands[1], SImode))"
+       || register_operand (operands[1], SImode))
+   && (!flag_stack_protect || TARGET_SHMEDIA
+       || reload_completed || reload_in_progress || !virtuals_instantiated
+       || !stack_protector_block (insn, operands[1]))"
   "@
 	mov.l	%1,%0
 	mov	%1,%0
@@ -5072,12 +5177,15 @@
 ;; TARGET_FMOVD is in effect, and mode switching is done before reload.
 (define_insn "movsi_ie"
   [(set (match_operand:SI 0 "general_movdst_operand"
-	    "=r,r,r,r,r,t,r,r,r,r,m,<,<,x,l,x,l,y,<,r,y,r,*f,y,*f,y")
+	    "=r,r,r,r,r,t,r,r,r,r,m,<,<,x,l,x,l,y,<,r,y,*r,*f,y,*f,y")
 	(match_operand:SI 1 "general_movsrc_operand"
-	 "Q,r,I08,I20,I28,r,mr,x,l,t,r,x,l,r,r,>,>,>,y,i,r,y,y,*f,*f,y"))]
+	 "Q,r,I08,I20,I28,r,mr,x,l,t,r,x,l,r,r,>,>,>,y,i,*r,y,y,*f,*f,y"))]
   "(TARGET_SH2E || TARGET_SH2A)
    && (register_operand (operands[0], SImode)
-       || register_operand (operands[1], SImode))"
+       || register_operand (operands[1], SImode))
+   && (!flag_stack_protect || TARGET_SHMEDIA
+       || reload_completed || reload_in_progress || !virtuals_instantiated
+       || !stack_protector_block (insn, operands[1]))"
   "@
 	mov.l	%1,%0
 	mov	%1,%0
@@ -5974,7 +6082,7 @@
 ;; instructions.  And when not optimizing, no splits are done before fixing
 ;; up pcloads, so we need usable length information for that.
 (define_insn "movdf_i4"
-  [(set (match_operand:DF 0 "general_movdst_operand" "=d,r,d,d,m,r,r,m,!??r,!???d")
+  [(set (match_operand:DF 0 "general_movdst_operand" "=d,r,d,d,m,r,*r,*m,!??r,!???d")
 	(match_operand:DF 1 "general_movsrc_operand"  "d,r,F,m,d,FQ,m,r,d,r"))
    (use (match_operand:PSI 2 "fpscr_operand"          "c,c,c,c,c,c,c,c,c,c"))
    (clobber (match_scratch:SI 3                      "=X,X,&z,X,X,X,X,X,X,X"))]
@@ -6002,7 +6110,7 @@
      [(if_then_else (eq_attr "fmovd" "yes") (const_int 4) (const_int 8))
       (const_int 4)
       (if_then_else (eq_attr "fmovd" "yes") (const_int 4) (const_int 6))
-      (if_then_else (eq_attr "fmovd" "yes") (const_int 4) (const_int 6))
+      (const_int 4)
       (if_then_else (eq_attr "fmovd" "yes") (const_int 4) (const_int 6))
       (const_int 4)
       (const_int 8) (const_int 8) ;; these need only 8 bytes for @(r0,rn)
@@ -6822,9 +6930,26 @@
       (const_int 2)
       (const_int 2)
       (const_int 0)])
-   (set (attr "fp_mode") (if_then_else (eq_attr "fmovd" "yes")
+  (set_attr_alternative "fp_mode"
+     [(if_then_else (eq_attr "fmovd" "yes") (const_string "single") (const_string "none"))
+      (const_string "none")
+      (const_string "single")
 					   (const_string "single")
-					   (const_string "single")))])
+      (const_string "none")
+      (if_then_else (eq_attr "fmovd" "yes") (const_string "single") (const_string "none"))
+      (if_then_else (eq_attr "fmovd" "yes") (const_string "single") (const_string "none"))
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")
+      (const_string "none")])])
 
 (define_split
   [(set (match_operand:SF 0 "register_operand" "")
@@ -6945,7 +7070,7 @@
 
 (define_insn "*movsi_y"
   [(set (match_operand:SI 0 "register_operand" "=y,y")
-	(match_operand:SI 1 "immediate_operand" "Qi,I08"))
+	(match_operand 1 "immediate_operand" "Qi,I08"))
    (clobber (match_scratch:SI 2 "=&z,r"))]
   "TARGET_SH2E
    && (reload_in_progress || reload_completed)"
@@ -7012,7 +7137,8 @@
    (set (pc) (unspec [(const_int 0)] UNSPEC_BBR))]
   "TARGET_SH1"
   ""
-  [(set_attr "length" "0")])
+  [(set_attr "length" "0")
+   (set_attr "cond_delay_slot" "no")])
 
 ;; This one is used to preemt an insn from beyond the bra / braf / jmp
 ;; being pulled into the delay slot of a condbranch that has been made to
@@ -7175,6 +7301,50 @@
   "b%o3%'	%N2, %N1, %0%>"
   [(set_attr "type" "cbranch_media")])
 
+(define_expand "cmpun_sdf"
+  [(unordered (match_operand 0 "" "") (match_operand 1 "" ""))]
+  ""
+  "
+{
+  HOST_WIDE_INT mask;
+  switch (GET_MODE (operands[0]))
+    {
+    case SFmode:
+      mask = SF_NAN_MASK;
+      break;
+    case DFmode:
+      mask = DF_NAN_MASK;
+      break;
+    default:
+      FAIL;
+    }
+  emit_insn (gen_cmpunsf_i1 (operands[0], operands[1],
+			     force_reg (SImode, GEN_INT (mask))));
+  DONE;
+}")
+
+(define_expand "cmpuneq_sdf"
+  [(uneq (match_operand 0 "" "") (match_operand 1 "" ""))]
+  ""
+  "
+{
+  HOST_WIDE_INT mask;
+  switch (GET_MODE (operands[0]))
+    {
+    case SFmode:
+      mask = SF_NAN_MASK;
+      break;
+    case DFmode:
+      mask = DF_NAN_MASK;
+      break;
+    default:
+      FAIL;
+    }
+  emit_insn (gen_cmpuneqsf_i1 (operands[0], operands[1],
+			       force_reg (SImode, GEN_INT (mask))));
+  DONE;
+}")
+
 ;; combiner splitter for test-and-branch on single bit in register.  This
 ;; is endian dependent because the non-paradoxical subreg looks different
 ;; on big endian.
@@ -7219,7 +7389,7 @@
 	      (set (match_dup 0)
 		   (plus:SI (match_dup 0) (const_int -1)))
 	      (clobber (reg:SI T_REG))])]
-  "TARGET_SH2"
+  "TARGET_SH2 && !optimize_size"
   "
 {
   if (GET_MODE (operands[0]) != SImode)
@@ -7259,10 +7429,10 @@
   "TARGET_SH1 && !find_reg_note (insn, REG_CROSSING_JUMP, NULL_RTX)"
   "*
 {
-  /* The length is 16 if the delay slot is unfilled.  */
+ /* The length is 16 if the delay slot is unfilled.  */
   if (get_attr_length(insn) > 4)
     return output_far_jump(insn, operands[0]);
-  else
+ else
     return   \"bra	%l0%#\";
 }"
   [(set_attr "type" "jump")
@@ -8373,7 +8543,7 @@
   ""
   "
 {
-  sh_expand_epilogue (1);
+  sh_expand_epilogue (true);
   if (TARGET_SHCOMPACT)
     {
       rtx insn, set;
@@ -8480,6 +8650,14 @@
   DONE;
 }")
 
+(define_insn "dup_db_insn"
+  [(unspec_volatile [(const_int 0)] UNSPECV_DB_INSN)]
+  "TARGET_DEAD_DELAY"
+  ""
+  [(set_attr "length" "0")
+   (set_attr "in_delay_slot" "yes")])
+
+
 ;; ------------------------------------------------------------------------
 ;; Misc insns
 ;; ------------------------------------------------------------------------
@@ -8633,22 +8811,6 @@
   i++;
 }")
 
-;; op0 = op1 + r12 but hide it before reload completed.  See the comment
-;; in symGOT_load expand.
-
-(define_insn_and_split "chk_guard_add"
-  [(set (match_operand:SI 0 "register_operand" "=&r")
-	(unspec:SI [(match_operand:SI 1 "register_operand" "r")
-		    (reg:SI PIC_REG)]
-		   UNSPEC_CHKADD))]
-  "TARGET_SH1"
-  "#"
-  "TARGET_SH1 && reload_completed"
-  [(set (match_dup 0) (reg:SI PIC_REG))
-   (set (match_dup 0) (plus:SI (match_dup 0) (match_dup 1)))]
-  ""
-  [(set_attr "type" "arith")])
-
 (define_expand "sym_label2reg"
   [(set (match_operand:SI 0 "" "")
 	(const:SI (unspec:SI [(match_operand:SI 1 "" "")
@@ -8691,20 +8853,6 @@
   else
     emit_move_insn (operands[2], operands[1]);
 
-  /* When stack protector inserts codes after the result is set to
-     R0, @(rX, r12) will cause a spill failure for R0.  Use a unspec
-     insn to avoid combining (set A (plus rX r12)) and (set op0 (mem A))
-     when rX is a GOT address for the guard symbol.  Ugly but doesn't
-     matter because this is a rare situation.  */
-  if (!TARGET_SHMEDIA
-      && flag_stack_protect
-      && GET_CODE (operands[1]) == CONST
-      && GET_CODE (XEXP (operands[1], 0)) == UNSPEC
-      && GET_CODE (XVECEXP (XEXP (operands[1], 0), 0, 0)) == SYMBOL_REF
-      && strcmp (XSTR (XVECEXP (XEXP (operands[1], 0), 0, 0), 0),
-		 \"__stack_chk_guard\") == 0)
-    emit_insn (gen_chk_guard_add (operands[3], operands[2]));
-  else
     emit_move_insn (operands[3], gen_rtx_PLUS (Pmode, operands[2],
 					       gen_rtx_REG (Pmode, PIC_REG)));
 
@@ -9037,8 +9185,8 @@
 
 (define_insn "casesi_worker_0"
   [(set (match_operand:SI 0 "register_operand" "=r,r")
-	(unspec:SI [(match_operand:SI 1 "register_operand" "0,r")
-		 (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI))
+	(mem:SI (unspec:SI [(match_operand:SI 1 "register_operand" "0,r")
+		 (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI)))
    (clobber (match_scratch:SI 3 "=X,1"))
    (clobber (match_scratch:SI 4 "=&z,z"))]
   "TARGET_SH1"
@@ -9046,38 +9194,38 @@
 
 (define_split
   [(set (match_operand:SI 0 "register_operand" "")
-	(unspec:SI [(match_operand:SI 1 "register_operand" "")
-		    (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI))
+	(mem:SI (unspec:SI [(match_operand:SI 1 "register_operand" "")
+		    (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI)))
    (clobber (match_scratch:SI 3 ""))
    (clobber (match_scratch:SI 4 ""))]
   "TARGET_SH1 && ! TARGET_SH2 && reload_completed"
   [(set (reg:SI R0_REG) (unspec:SI [(label_ref (match_dup 2))] UNSPEC_MOVA))
    (parallel [(set (match_dup 0)
-	      (unspec:SI [(reg:SI R0_REG) (match_dup 1)
-			  (label_ref (match_dup 2))] UNSPEC_CASESI))
+	      (mem:SI (unspec:SI [(reg:SI R0_REG) (match_dup 1)
+			  (label_ref (match_dup 2))] UNSPEC_CASESI)))
 	      (clobber (match_dup 3))])
    (set (match_dup 0) (plus:SI (match_dup 0) (reg:SI R0_REG)))]
   "if (GET_CODE (operands[2]) == CODE_LABEL) LABEL_NUSES (operands[2])++;")
 
 (define_split
   [(set (match_operand:SI 0 "register_operand" "")
-	(unspec:SI [(match_operand:SI 1 "register_operand" "")
-		    (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI))
+	(mem:SI (unspec:SI [(match_operand:SI 1 "register_operand" "")
+		    (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI)))
    (clobber (match_scratch:SI 3 ""))
    (clobber (match_scratch:SI 4 ""))]
   "TARGET_SH2 && reload_completed"
   [(set (reg:SI R0_REG) (unspec:SI [(label_ref (match_dup 2))] UNSPEC_MOVA))
    (parallel [(set (match_dup 0)
-	      (unspec:SI [(reg:SI R0_REG) (match_dup 1)
-			  (label_ref (match_dup 2))] UNSPEC_CASESI))
+	      (mem:SI (unspec:SI [(reg:SI R0_REG) (match_dup 1)
+			  (label_ref (match_dup 2))] UNSPEC_CASESI)))
 	      (clobber (match_dup 3))])]
   "if (GET_CODE (operands[2]) == CODE_LABEL) LABEL_NUSES (operands[2])++;")
 
 (define_insn "casesi_worker_1"
   [(set (match_operand:SI 0 "register_operand" "=r,r")
-	(unspec:SI [(reg:SI R0_REG)
+	(mem:SI (unspec:SI [(reg:SI R0_REG)
 		    (match_operand:SI 1 "register_operand" "0,r")
-		    (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI))
+		    (label_ref (match_operand 2 "" ""))] UNSPEC_CASESI)))
    (clobber (match_scratch:SI 3 "=X,1"))]
   "TARGET_SH1"
   "*
@@ -9104,10 +9252,10 @@
 
 (define_insn "casesi_worker_2"
   [(set (match_operand:SI 0 "register_operand" "=r,r")
-	(unspec:SI [(reg:SI R0_REG)
+	(mem:SI (unspec:SI [(reg:SI R0_REG)
 		    (match_operand:SI 1 "register_operand" "0,r")
 		    (label_ref (match_operand 2 "" ""))
-		    (label_ref (match_operand 3 "" ""))] UNSPEC_CASESI))
+		    (label_ref (match_operand 3 "" ""))] UNSPEC_CASESI)))
    (clobber (match_operand:SI 4 "" "=X,1"))]
   "TARGET_SH2 && reload_completed && flag_pic"
   "*
@@ -9199,9 +9347,13 @@
 }"
   [(set_attr "type" "load_media")])
 
+(define_expand "simple_return"
+  [(simple_return)]
+ "0 && sh_can_use_simple_return_p ()")
+
 (define_expand "return"
   [(return)]
-  "reload_completed && ! sh_need_epilogue ()"
+ "reload_completed && epilogue_completed"
   "
 {
   if (TARGET_SHMEDIA)
@@ -9218,8 +9370,8 @@
     }
 }")
 
-(define_insn "*return_i"
-  [(return)]
+(define_insn "*<code>_i"
+  [(any_return)]
   "TARGET_SH1 && ! (TARGET_SHCOMPACT
 		    && (crtl->args.info.call_cookie
 			& CALL_COOKIE_RET_TRAMP (1)))
@@ -9245,6 +9397,20 @@
   "%@"
   [(set_attr "type" "return")])
 
+
+;; Unconditional traps are assumed to have (const_int 1) for the condition.
+(define_insn "trap"
+  [(trap_if (const_int 1) (const_int 42))]
+  "TARGET_BUILTIN_TRAPA"
+  "*
+{
+  static char templ[16];
+
+  sprintf (templ, \"trapa\t#%d\", 42);
+  return templ;
+}"
+  [(set_attr "in_delay_slot" "no")])
+
 (define_expand "shcompact_return_tramp"
   [(return)]
   "TARGET_SHCOMPACT
@@ -9354,12 +9520,7 @@
 (define_expand "epilogue"
   [(return)]
   ""
-  "
-{
-  sh_expand_epilogue (0);
-  emit_jump_insn (gen_return ());
-  DONE;
-}")
+  "sh_expand_epilogue (false);")
 
 (define_expand "eh_return"
   [(use (match_operand 0 "register_operand" ""))]
@@ -9580,6 +9741,19 @@
    DONE;
 ")
 
+(define_expand "sunle"
+  [(set (match_operand:SI 0 "arith_reg_operand" "")
+	(match_dup 1))]
+  "TARGET_SH1_SOFTFP"
+  "
+{
+  if (! currently_expanding_to_rtl)
+    FAIL;
+    sh_emit_compare_and_branch (operands, DFmode);
+  emit_insn (gen_movt (operands[0]));
+  DONE;
+}")
+
 ;; sne moves the complement of the T reg to DEST like this:
 ;;      cmp/eq ...
 ;;      mov    #-1,temp
@@ -9788,7 +9962,8 @@
   [(unspec_volatile [(const_int 0)] UNSPECV_CONST_END)]
   ""
   "* return output_jump_label_table ();"
-  [(set_attr "in_delay_slot" "no")])
+  [(set_attr "length" "0")
+   (set_attr "in_delay_slot" "no")])
 
 ; emitted at the end of the window in the literal table.
 
@@ -9881,6 +10056,43 @@
   [(set_attr "type" "sfunc")
    (set_attr "needs_delay_slot" "yes")])
 
+(define_insn "cmpstr_t"
+  [(set (reg:SI T_REG)
+	(unspec:SI [
+	  (match_operand:SI 0 "register_operand" "r")
+          (match_operand:SI 1 "register_operand" "r")
+        ] UNSPEC_STR))]
+  "TARGET_SH1"
+  "cmp/str	%0,%1"
+  [(set_attr "type" "mt_group")])
+
+(define_insn "rotcr_t"
+  [(set (match_operand:SI 0 "register_operand" "+r")
+	(unspec:SI [
+          (match_dup 0)
+          (reg:SI T_REG)
+	] UNSPEC_ROT))
+   (clobber (reg:SI T_REG))]
+  "TARGET_SH1"
+  "rotcr	%0"
+  [(set_attr "type" "mt_group")])
+
+(define_expand "cmpstrsi"
+  [(match_operand:SI 0 "register_operand" "")
+   (match_operand 1 "register_operand" "")
+   (match_operand 2 "register_operand" "")
+   (match_operand 3 "register_operand" "")
+   ]
+  "TARGET_HARD_SH4"
+  "
+{   
+   if (! optimize_insn_for_size_p () && sh4_expand_cmpstr(operands))
+      DONE; 
+
+   else FAIL;
+}")
+
+
 ;; -------------------------------------------------------------------------
 ;; Floating point instructions.
 ;; -------------------------------------------------------------------------
@@ -9972,15 +10184,10 @@
   "fschg"
   [(set_attr "type" "fpscr_toggle") (set_attr "fp_set" "unknown")])
 
-;; There's no way we can use it today, since optimize mode switching
-;; doesn't enable us to know from which mode we're switching to the
-;; mode it requests, to tell whether we can use a relative mode switch
-;; (like toggle_pr) or an absolute switch (like loading fpscr from
-;; memory).
 (define_insn "toggle_pr"
   [(set (reg:PSI FPSCR_REG)
 	(xor:PSI (reg:PSI FPSCR_REG) (const_int 524288)))]
-  "TARGET_SH4A_FP && ! TARGET_FPU_SINGLE"
+  "(TARGET_SH4A_FP || TARGET_SH4_300)" 
   "fpchg"
   [(set_attr "type" "fpscr_toggle")])
 
@@ -9988,7 +10195,7 @@
   [(set (match_operand:SF 0 "arith_reg_operand" "")
 	(plus:SF (match_operand:SF 1 "arith_reg_operand" "")
 		 (match_operand:SF 2 "arith_reg_operand" "")))]
-  "TARGET_SH2E || TARGET_SHMEDIA_FPU"
+  "TARGET_SH2E || (TARGET_SH3 && TARGET_OSFP) || TARGET_SHMEDIA_FPU"
   "
 {
   if (TARGET_SH2E)
@@ -9996,6 +10203,12 @@
       expand_sf_binop (&gen_addsf3_i, operands);
       DONE;
     }
+  else if (TARGET_OSFP)
+    {
+      expand_sfunc_binop (SFmode, &gen_addsf3_i3, \"__addsf3\", PLUS,
+			  operands);
+      DONE;
+    }
 }")
 
 (define_insn "*addsf3_media"
@@ -10094,6 +10307,22 @@
 }"
   [(set_attr "type" "fparith_media")])
 
+(define_insn "addsf3_i3"
+  [(set (match_operand:SF 0 "arith_reg_dest" "=z")
+	(plus:SF (reg:SF R4_REG) (reg:SF R5_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (clobber (reg:SI R6_REG))
+   (clobber (reg:SI R7_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_OSFP && ! TARGET_SH2E"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
 (define_insn "addsf3_i"
   [(set (match_operand:SF 0 "fp_arith_reg_operand" "=f")
 	(plus:SF (match_operand:SF 1 "fp_arith_reg_operand" "%0")
@@ -10108,7 +10337,7 @@
   [(set (match_operand:SF 0 "fp_arith_reg_operand" "")
 	(minus:SF (match_operand:SF 1 "fp_arith_reg_operand" "")
 		  (match_operand:SF 2 "fp_arith_reg_operand" "")))]
-  "TARGET_SH2E || TARGET_SHMEDIA_FPU"
+  "TARGET_SH2E || (TARGET_SH3 && TARGET_OSFP) || TARGET_SHMEDIA_FPU"
   "
 {
   if (TARGET_SH2E)
@@ -10116,6 +10345,12 @@
       expand_sf_binop (&gen_subsf3_i, operands);
       DONE;
     }
+  else if (TARGET_OSFP)
+    {
+      expand_sfunc_binop (SFmode, &gen_subsf3_i3, \"__subsf3\", MINUS,
+			  operands);
+      DONE;
+    }
 }")
 
 (define_insn "*subsf3_media"
@@ -10126,6 +10361,23 @@
   "fsub.s	%1, %2, %0"
   [(set_attr "type" "fparith_media")])
 
+(define_insn "subsf3_i3"
+  [(set (match_operand:SF 0 "arith_reg_dest" "=z")
+	(minus:SF (reg:SF R4_REG) (reg:SF R5_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (clobber (reg:SI R5_REG))
+   (clobber (reg:SI R6_REG))
+   (clobber (reg:SI R7_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_OSFP && ! TARGET_SH2E"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
 (define_insn "subsf3_i"
   [(set (match_operand:SF 0 "fp_arith_reg_operand" "=f")
 	(minus:SF (match_operand:SF 1 "fp_arith_reg_operand" "0")
@@ -10140,8 +10392,16 @@
   [(set (match_operand:SF 0 "fp_arith_reg_operand" "")
 	(mult:SF (match_operand:SF 1 "fp_arith_reg_operand" "")
 		 (match_operand:SF 2 "fp_arith_reg_operand" "")))]
-  "TARGET_SH2E || TARGET_SHMEDIA_FPU"
-  "")
+  "TARGET_SH2E || (TARGET_SH3 && TARGET_OSFP) || TARGET_SHMEDIA_FPU"
+  "
+{
+  if (!TARGET_SH2E && TARGET_OSFP)
+    {
+      expand_sfunc_binop (SFmode, &gen_mulsf3_i3, \"__mulsf3\", MULT,
+                         operands);
+      DONE;
+    }
+}")
 
 (define_insn "*mulsf3_media"
   [(set (match_operand:SF 0 "fp_arith_reg_operand" "=f")
@@ -10182,6 +10442,22 @@
   [(set_attr "type" "fp")
    (set_attr "fp_mode" "single")])
 
+(define_insn "mulsf3_i3"
+  [(set (match_operand:SF 0 "arith_reg_dest" "=z")
+	(mult:SF (reg:SF R4_REG) (reg:SF R5_REG)))
+   (clobber (reg:SI MACH_REG))
+   (clobber (reg:SI MACL_REG))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_OSFP && ! TARGET_SH2E"
+   "jsr	@%1%#"
+   [(set_attr "type" "sfunc")
+    (set_attr "needs_delay_slot" "yes")])
+
 (define_insn "mac_media"
   [(set (match_operand:SF 0 "fp_arith_reg_operand" "=f")
 	(plus:SF (mult:SF (match_operand:SF 1 "fp_arith_reg_operand" "%f")
@@ -10351,6 +10627,155 @@
   [(set_attr "type" "fp_cmp")
    (set_attr "fp_mode" "single")])
 
+ (define_insn "cmpnesf_i1"
+   [(set (match_operand:CC_FP_NE 0 "register_operand" "=z")
+ 	(compare:CC_FP_NE (reg:SF R4_REG) (reg:SF R5_REG)))
+    (clobber (reg:SI T_REG))
+    (clobber (reg:SI PR_REG))
+    (clobber (reg:SI R1_REG))
+    (clobber (reg:SI R2_REG))
+    (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+   "TARGET_SH1 && ! TARGET_SH2E"
+   "jsr	@%1%#"
+   [(set_attr "type" "sfunc")
+    (set_attr "needs_delay_slot" "yes")])
+
+ (define_insn "cmpgtsf_i1"
+   [(set (match_operand:CC_FP_GT 0 "register_operand" "=z")
+ 	(compare:CC_FP_GT (reg:SF R4_REG) (reg:SF R5_REG)))
+    (clobber (reg:SI T_REG))
+    (clobber (reg:SI PR_REG))
+    (clobber (reg:SI R1_REG))
+    (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+   "TARGET_SH1 && ! TARGET_SH2E"
+   "jsr	@%1%#"
+   [(set_attr "type" "sfunc")
+    (set_attr "needs_delay_slot" "yes")])
+
+ (define_insn "cmpunltsf_i1"
+   [(set (match_operand:CC_FP_UNLT 0 "register_operand" "=z")
+ 	(compare:CC_FP_UNLT (reg:SF R4_REG) (reg:SF R5_REG)))
+    (clobber (reg:SI T_REG))
+    (clobber (reg:SI PR_REG))
+    (clobber (reg:SI R1_REG))
+    (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+   "TARGET_SH1 && ! TARGET_SH2E"
+   "jsr	@%1%#"
+   [(set_attr "type" "sfunc")
+    (set_attr "needs_delay_slot" "yes")])
+
+ (define_insn "cmpeqsf_i1_finite"
+   [(set (reg:SI T_REG)
+ 	(eq:SI (match_operand:SF 0 "arith_reg_operand" "r,r,r")
+ 	       (match_operand:SF 1 "arith_reg_operand" "r,r,r")))
+    (clobber (match_scratch:SI 2 "=0,1,?r"))]
+   "TARGET_SH1 && ! TARGET_SH2E && flag_finite_math_only"
+   "*
+ {
+   if (which_alternative == 0)
+      output_asm_insn (\"cmp/eq\t%0,%1\;or\t%1,%2\;bt\t0f\", operands);
+   else if (which_alternative == 1)
+      output_asm_insn (\"cmp/eq\t%0,%1\;or\t%0,%2\;bt\t0f\", operands);
+   else
+     output_asm_insn (\"cmp/eq\t%0,%1\;mov\t%0,%2\;bt\t0f\;or\t%1,%2\",
+ 		     operands);
+   return \"add\t%2,%2\;tst\t%2,%2\\n0:\";
+ }"
+   [(set_attr "length" "10,10,12")])
+
+ (define_insn "cmplesf_i1_finite"
+   [(set (reg:SI T_REG)
+ 	(le:SI (match_operand:SF 0 "arith_reg_operand" "r,r,r")
+ 	       (match_operand:SF 1 "arith_reg_operand" "r,r,r")))
+    (clobber (match_scratch:SI 2 "=0,1,r"))]
+   "TARGET_SH1 && ! TARGET_SH2E && flag_finite_math_only"
+   "*
+ {
+   output_asm_insn (\"cmp/pz\t%0\", operands);
+   if (which_alternative == 2)
+     output_asm_insn (\"mov\t%0,%2\", operands);
+   if (TARGET_SH2)
+     output_asm_insn (\"bf/s\t0f\;cmp/hs\t%1,%0\;cmp/ge\t%0,%1\", operands);
+   else
+     output_asm_insn (\"bt\t1f\;bra\t0f\;cmp/hs\t%1,%0\\n1:\tcmp/ge\t%0,%1\",
+ 		     operands);
+   if (which_alternative == 1)
+     output_asm_insn (\"or\t%0,%2\", operands);
+   else
+     output_asm_insn (\"or\t%1,%2\", operands);
+   return \"bt\t0f\;add\t%2,%2\;tst\t%2,%2\\n0:\";
+ }"
+   [(set_attr "length" "18,18,20")])
+
+ (define_insn "cmpunsf_i1"
+   [(set (reg:SI T_REG)
+ 	(unordered:SI (match_operand:SF 0 "arith_reg_operand" "r")
+ 		      (match_operand:SF 1 "arith_reg_operand" "r")))
+    (use (match_operand:SI 2 "arith_reg_operand" "r"))
+    (clobber (match_scratch:SI 3 "=&r"))]
+   "TARGET_SH1 && ! TARGET_SH2E"
+   "not\t%0,%3\;tst\t%2,%3\;bt.s\t0f
+\tnot\t%1,%3\;tst\t%2,%3\;bt.s\t0f
+\tmov\t#96,%3\;shll16\t%3\;xor\t%3,%2
+\tnot\t%0,%3\;tst\t%2,%3\;bt.s\t0f
+\tnot\t%1,%3\;tst\t%2,%3
+0:"
+   [(set_attr "length" "28")])
+
+ ;; ??? This is a lot of code with a lot of branches; a library function
+ ;; might be better.
+ (define_insn "cmpuneqsf_i1"
+   [(set (reg:SI T_REG)
+ 	(uneq:SI (match_operand:SF 0 "arith_reg_operand" "r")
+ 		 (match_operand:SF 1 "arith_reg_operand" "r")))
+    (use (match_operand:SI 2 "arith_reg_operand" "r"))
+    (clobber (match_scratch:SI 3 "=&r"))]
+   "TARGET_SH1 && ! TARGET_SH2E"
+   "*
+ {
+   output_asm_insn (\"not\t%0,%3\;tst\t%2,%3\;not\t%1,%3\", operands);
+   output_asm_insn (\"bt\t0f\;tst\t%2,%3\;bt\t0f\;cmp/eq\t%0,%1\", operands);
+   output_asm_insn (\"mov\t%0,%3\;bt\t0f\;or\t%1,%3\", operands);
+   return \"add\t%3,%3\;tst\t%3,%3\\n0:\";
+ }"
+   [(set_attr "length" "24")])
+
+ (define_insn "movcc_fp_ne"
+   [(set (match_operand:CC_FP_NE 0 "general_movdst_operand"
+ 	    "=r,r,m")
+ 	(match_operand:CC_FP_NE 1 "general_movsrc_operand"
+ 	 "rI08,mr,r"))]
+   "TARGET_SH1"
+   "@
+ 	mov	%1,%0
+ 	mov.l	%1,%0
+ 	mov.l	%1,%0"
+   [(set_attr "type" "move,load,store")])
+
+ (define_insn "movcc_fp_gt"
+   [(set (match_operand:CC_FP_GT 0 "general_movdst_operand"
+ 	    "=r,r,m")
+ 	(match_operand:CC_FP_GT 1 "general_movsrc_operand"
+ 	 "rI08,mr,r"))]
+   "TARGET_SH1"
+   "@
+ 	mov	%1,%0
+ 	mov.l	%1,%0
+ 	mov.l	%1,%0"
+   [(set_attr "type" "move,load,store")])
+
+ (define_insn "movcc_fp_unlt"
+   [(set (match_operand:CC_FP_UNLT 0 "general_movdst_operand"
+ 	    "=r,r,m")
+ 	(match_operand:CC_FP_UNLT 1 "general_movsrc_operand"
+ 	 "rI08,mr,r"))]
+   "TARGET_SH1"
+   "@
+ 	mov	%1,%0
+ 	mov.l	%1,%0
+ 	mov.l	%1,%0"
+   [(set_attr "type" "move,load,store")])
+
 (define_insn "cmpeqsf_t"
   [(set (reg:SI T_REG)
 	(eq:SI (match_operand:SF 0 "fp_arith_reg_operand" "f")
@@ -10369,6 +10794,21 @@
   "* return output_ieee_ccmpeq (insn, operands);"
   [(set_attr "length" "4")])
 
+(define_insn "*cmpltgtsf_t"
+  [(set (reg:SI T_REG)
+	(ltgt:SI (match_operand:SF 0 "fp_arith_reg_operand" "f")
+		 (match_operand:SF 1 "fp_arith_reg_operand" "f")))]
+  "TARGET_SH2E && ! (TARGET_SH4 || TARGET_SH2A_SINGLE)"
+  "fcmp/gt\t%1,%0\;bt\t0f\;fcmp/gt\t%0,%1\\n0:"
+  [(set_attr "length" "6")])
+
+(define_insn "*cmporderedsf_t"
+  [(set (reg:SI T_REG)
+	(ordered:SI (match_operand:SF 0 "fp_arith_reg_operand" "f")
+		    (match_operand:SF 1 "fp_arith_reg_operand" "f")))]
+  "TARGET_SH2E && ! (TARGET_SH4 || TARGET_SH2A_SINGLE)"
+  "fcmp/eq\t%0,%0\;bf\t0f\;fcmp/eq\t%1,%1\\n0:"
+  [(set_attr "length" "6")])
 
 (define_insn "cmpgtsf_t_i4"
   [(set (reg:SI T_REG)
@@ -10401,6 +10841,26 @@
   [(set_attr "length" "4")
    (set_attr "fp_mode" "single")])
 
+(define_insn "*cmpltgtsf_t_4"
+  [(set (reg:SI T_REG)
+	(ltgt:SI (match_operand:SF 0 "fp_arith_reg_operand" "f")
+		 (match_operand:SF 1 "fp_arith_reg_operand" "f")))
+   (use (match_operand:PSI 2 "fpscr_operand" "c"))]
+  "TARGET_SH4 || TARGET_SH2A_SINGLE"
+  "fcmp/gt\t%1,%0\;bt\t0f\;fcmp/gt\t%0,%1\\n0:"
+  [(set_attr "length" "6")
+   (set_attr "fp_mode" "single")])
+
+(define_insn "*cmporderedsf_t_4"
+  [(set (reg:SI T_REG)
+	(ordered:SI (match_operand:SF 0 "fp_arith_reg_operand" "f")
+		    (match_operand:SF 1 "fp_arith_reg_operand" "f")))
+   (use (match_operand:PSI 2 "fpscr_operand" "c"))]
+  "TARGET_SH4 || TARGET_SH2A_SINGLE"
+  "fcmp/eq\t%0,%0\;bf\t0f\;fcmp/eq\t%1,%1\\n0:"
+  [(set_attr "length" "6")
+   (set_attr "fp_mode" "single")])
+
 (define_insn "cmpeqsf_media"
   [(set (match_operand:SI 0 "register_operand" "=r")
 	(eq:SI (match_operand:SF 1 "fp_arith_reg_operand" "f")
@@ -10649,11 +11109,39 @@
   [(set_attr "type" "fmove")
    (set_attr "fp_mode" "single")])
 
+(define_expand "abssc2"
+  [(set (match_operand:SF 0 "fp_arith_reg_operand" "")
+	(abs:SF (match_operand:SC 1 "fp_arith_reg_operand" "")))]
+  "TARGET_OSFP && ! TARGET_SH2E"
+  "
+{
+  expand_sfunc_unop (SCmode, &gen_abssc2_i3, \"__hypotf\", ABS, operands);
+  DONE;
+}")
+
+(define_insn "abssc2_i3"
+  [(set (match_operand:SF 0 "arith_reg_dest" "=z")
+	(abs:SF (reg:SC R4_REG)))
+   (clobber (reg:SI MACH_REG))
+   (clobber (reg:SI MACL_REG))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (clobber (reg:SI R4_REG))
+   (clobber (reg:SI R5_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_OSFP && ! TARGET_SH2E"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
 (define_expand "adddf3"
   [(set (match_operand:DF 0 "fp_arith_reg_operand" "")
 	(plus:DF (match_operand:DF 1 "fp_arith_reg_operand" "")
 		 (match_operand:DF 2 "fp_arith_reg_operand" "")))]
-  "(TARGET_SH4 || TARGET_SH2A_DOUBLE) || TARGET_SHMEDIA_FPU"
+  "TARGET_FPU_DOUBLE || (TARGET_SH3 && TARGET_OSFP)"
   "
 {
   if (TARGET_SH4 || TARGET_SH2A_DOUBLE)
@@ -10661,6 +11149,12 @@
       expand_df_binop (&gen_adddf3_i, operands);
       DONE;
     }
+  else if (TARGET_SH3 && TARGET_OSFP)
+    {
+      expand_sfunc_binop (DFmode, &gen_adddf3_i3_wrap, \"__adddf3\", PLUS,
+			  operands);
+      DONE;
+    }
 }")
 
 (define_insn "*adddf3_media"
@@ -10681,6 +11175,30 @@
   [(set_attr "type" "dfp_arith")
    (set_attr "fp_mode" "double")])
 
+(define_expand "adddf3_i3_wrap"
+  [(match_operand:DF 0 "" "") (match_operand:SI 1 "" "")]
+  "TARGET_SH3"
+  "
+{
+  emit_insn (gen_adddf3_i3 (operands[1]));
+  emit_move_insn (operands[0], gen_rtx_REG (DFmode, R0_REG));
+  DONE;
+}")
+
+(define_insn "adddf3_i3"
+  [(set (reg:DF R0_REG)
+	(plus:DF (reg:DF R4_REG) (reg:DF R6_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:DI R2_REG))
+   (clobber (reg:DF R4_REG))
+   (clobber (reg:DF R6_REG))
+   (use (match_operand:SI 0 "arith_reg_operand" "r"))]
+  "TARGET_SH3"
+  "jsr	@%0%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
 (define_expand "subdf3"
   [(set (match_operand:DF 0 "fp_arith_reg_operand" "")
 	(minus:DF (match_operand:DF 1 "fp_arith_reg_operand" "")
@@ -10717,7 +11235,7 @@
   [(set (match_operand:DF 0 "fp_arith_reg_operand" "")
 	(mult:DF (match_operand:DF 1 "fp_arith_reg_operand" "")
 		 (match_operand:DF 2 "fp_arith_reg_operand" "")))]
-  "(TARGET_SH4 || TARGET_SH2A_DOUBLE) || TARGET_SHMEDIA_FPU"
+  "TARGET_FPU_DOUBLE || (TARGET_SH3 && TARGET_OSFP)"
   "
 {
   if (TARGET_SH4 || TARGET_SH2A_DOUBLE)
@@ -10725,6 +11243,12 @@
       expand_df_binop (&gen_muldf3_i, operands);
       DONE;
     }
+  else if (TARGET_SH3 && TARGET_OSFP)
+    {
+      expand_sfunc_binop (DFmode, &gen_muldf3_i3_wrap, \"__muldf3\", MULT,
+			  operands);
+      DONE;
+    }
 }")
 
 (define_insn "*muldf3_media"
@@ -10745,6 +11269,32 @@
   [(set_attr "type" "dfp_mul")
    (set_attr "fp_mode" "double")])
 
+(define_expand "muldf3_i3_wrap"
+  [(match_operand:DF 0 "" "") (match_operand:SI 1 "" "")]
+  "TARGET_SH3"
+   "
+ {
+   emit_insn (gen_muldf3_i3 (operands[1]));
+   emit_move_insn (operands[0], gen_rtx_REG (DFmode, R0_REG));
+   DONE;
+ }")
+
+ (define_insn "muldf3_i3"
+   [(set (reg:DF R0_REG)
+ 	(mult:DF (reg:DF R4_REG) (reg:DF R6_REG)))
+    (clobber (reg:SI MACH_REG))
+    (clobber (reg:SI MACL_REG))
+    (clobber (reg:SI T_REG))
+    (clobber (reg:SI PR_REG))
+    (clobber (reg:DI R2_REG))
+    (clobber (reg:DF R4_REG))
+    (clobber (reg:DF R6_REG))
+    (use (match_operand:SI 0 "arith_reg_operand" "r"))]
+   "TARGET_SH3"
+   "jsr	@%0%#"
+   [(set_attr "type" "sfunc")
+    (set_attr "needs_delay_slot" "yes")])
+
 (define_expand "divdf3"
   [(set (match_operand:DF 0 "fp_arith_reg_operand" "")
 	(div:DF (match_operand:DF 1 "fp_arith_reg_operand" "")
@@ -10874,6 +11424,79 @@
 ;; 	      (use (match_dup 2))])
 ;;    (set (match_dup 0) (reg:SI FPUL_REG))])
 
+(define_insn "cmpnedf_i1"
+  [(set (match_operand:CC_FP_NE 0 "register_operand" "=z")
+	(compare:CC_FP_NE (reg:DF R4_REG) (reg:DF R6_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
+(define_insn "cmpgtdf_i1"
+  [(set (match_operand:CC_FP_GT 0 "register_operand" "=z")
+	(compare:CC_FP_GT (reg:DF R4_REG) (reg:DF R6_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
+(define_insn "cmpunltdf_i1"
+  [(set (match_operand:CC_FP_UNLT 0 "register_operand" "=z")
+	(compare:CC_FP_UNLT (reg:DF R4_REG) (reg:DF R6_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
+(define_insn "cmpeqdf_i1_finite"
+  [(set (reg:SI T_REG)
+	(eq:SI (match_operand:DF 0 "arith_reg_operand" "r")
+	       (match_operand:DF 1 "arith_reg_operand" "r")))
+   (clobber (match_scratch:SI 2 "=&r"))]
+  "TARGET_SH1_SOFTFP && flag_finite_math_only"
+  "cmp/eq\t%R0,%R1\;mov\t%S0,%2\;bf\t0f\;cmp/eq\t%S0,%S1\;bt\t0f\;or\t%S1,%2\;add\t%2,%2\;or\t%R0,%2\;tst\t%2,%2\\n0:"
+  [(set_attr "length" "18")])
+
+(define_insn "cmpundf_i1"
+  [(set (reg:SI T_REG)
+	(unordered:SI (match_operand:DF 0 "arith_reg_operand" "r")
+		      (match_operand:DF 1 "arith_reg_operand" "r")))
+   (use (match_operand:SI 2 "arith_reg_operand" "r"))
+   (clobber (match_scratch:SI 3 "=&r"))]
+  "TARGET_SH1 && ! TARGET_SH2E"
+   "not\t%S0,%3\;tst\t%2,%3\;bt.s\t0f
+  \tnot\t%S1,%3\;tst\t%2,%3\;bt.s\t0f
+  \tmov\t#12,%3\;shll16\t%3\;xor\t%3,%2
+  \tnot\t%S0,%3\;tst\t%2,%3\;bt.s\t0f
+  \tnot\t%S1,%3\;tst\t%2,%3
+0:"
+  [(set_attr "length" "28")])
+
+;; ??? This is a lot of code with a lot of branches; a library function
+;; might be better.
+(define_insn "cmpuneqdf_i1"
+  [(set (reg:SI T_REG)
+	(uneq:SI (match_operand:DF 0 "arith_reg_operand" "r")
+		 (match_operand:DF 1 "arith_reg_operand" "r")))
+   (use (match_operand:SI 2 "arith_reg_operand" "r"))
+   (clobber (match_scratch:SI 3 "=&r"))]
+  "TARGET_SH1_SOFTFP"
+  "not\t%S0,%3\;tst\t%2,%3\;not\t%S1,%3\;bt\t0f\;tst\t%2,%3\;bt\t0f\;cmp/eq\t%R0,%R1\; bf\t0f\;cmp/eq\t%S0,%S1\;bt\t0f\;mov\t%S0,%3\;or\t%S1,%3\;add\t%3,%3\;or\t%R0,%3\;tst\t%3,%3\\n0:"
+  [(set_attr "length" "30")])
+
 (define_insn "cmpgtdf_t"
   [(set (reg:SI T_REG)
 	(gt:SI (match_operand:DF 0 "arith_reg_operand" "f")
@@ -10905,6 +11528,26 @@
   [(set_attr "length" "4")
    (set_attr "fp_mode" "double")])
 
+(define_insn "*cmpltgtdf_t"
+  [(set (reg:SI T_REG)
+	(ltgt:SI (match_operand:DF 0 "fp_arith_reg_operand" "f")
+		 (match_operand:DF 1 "fp_arith_reg_operand" "f")))
+   (use (match_operand:PSI 2 "fpscr_operand" "c"))]
+  "TARGET_SH4 || TARGET_SH2A_DOUBLE"
+  "fcmp/gt\t%1,%0\;bt\t0f\;fcmp/gt\t%0,%1\\n0:"
+  [(set_attr "length" "6")
+   (set_attr "fp_mode" "double")])
+
+(define_insn "*cmpordereddf_t_4"
+  [(set (reg:SI T_REG)
+	(ordered:SI (match_operand:DF 0 "fp_arith_reg_operand" "f")
+		    (match_operand:DF 1 "fp_arith_reg_operand" "f")))
+   (use (match_operand:PSI 2 "fpscr_operand" "c"))]
+  "TARGET_SH4 || TARGET_SH2A_SINGLE"
+  "fcmp/eq\t%0,%0\;bf\t0f\;fcmp/eq\t%1,%1\\n0:"
+  [(set_attr "length" "6")
+   (set_attr "fp_mode" "double")])
+
 (define_insn "cmpeqdf_media"
   [(set (match_operand:SI 0 "register_operand" "=r")
 	(eq:SI (match_operand:DF 1 "fp_arith_reg_operand" "f")
@@ -11046,7 +11689,7 @@
 (define_expand "extendsfdf2"
   [(set (match_operand:DF 0 "fp_arith_reg_operand" "")
 	(float_extend:DF (match_operand:SF 1 "fpul_operand" "")))]
-  "(TARGET_SH4 || TARGET_SH2A_DOUBLE) || TARGET_SHMEDIA_FPU"
+  "TARGET_FPU_DOUBLE || (TARGET_SH3 && TARGET_OSFP) || TARGET_SHMEDIA_FPU"
   "
 {
   if (TARGET_SH4 || TARGET_SH2A_DOUBLE)
@@ -11055,6 +11698,18 @@
 					get_fpscr_rtx ()));
       DONE;
     }
+  if (TARGET_SH2E && TARGET_OSFP)
+    {
+      expand_sfunc_unop (SFmode, &gen_extendsfdf2_i2e, \"__extendsfdf2\",
+ 		 FLOAT_EXTEND, operands);
+      DONE;
+    }
+  else if (TARGET_SH1 && TARGET_OSFP)
+    {
+      expand_sfunc_unop (SFmode, &gen_extendsfdf2_i1, \"__extendsfdf2\",
+			 FLOAT_EXTEND, operands);
+      DONE;
+    }
 }")
 
 (define_insn "*extendsfdf2_media"
@@ -11073,10 +11728,76 @@
   [(set_attr "type" "fp")
    (set_attr "fp_mode" "double")])
 
+;; ??? In order to use this efficiently, we'd have to have an extra
+;; register class for r0 and r1 - and that would cause repercussions in
+;; register allocation elsewhere.  So just say we clobber r0 / r1, and
+;; that we can use an arbitrary target.  */
+(define_insn_and_split "extendsfdf2_i1"
+  [(set (match_operand:DF 0 "arith_reg_dest" "=r")
+	(float_extend:DF (reg:SF R4_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R0_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP && !TARGET_SH2E"
+  "#"
+  "&& reload_completed"
+  [(set (match_dup 0) (reg:DF R0_REG))]
+  "emit_insn (gen_extendsfdf2_i1_r0 (operands[1]));"
+  [(set_attr "type" "sfunc")])
+
+(define_insn "extendsfdf2_i1_r0"
+  [(set (reg:DF R0_REG) (float_extend:DF (reg:SF R4_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (use (match_operand:SI 0 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP && !TARGET_SH2E"
+  "jsr	@%0%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
+(define_insn_and_split "extendsfdf2_i2e"
+  [(set (match_operand:DF 0 "arith_reg_dest" "=r")
+	(float_extend:DF (reg:SF FR4_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R0_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (clobber (reg:SI R4_REG))
+   (clobber (reg:SI FPUL_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP && TARGET_SH2E"
+  "#"
+  "&& reload_completed"
+  [(set (match_dup 0) (reg:DF R0_REG))]
+  "emit_insn (gen_extendsfdf2_i2e_r0 (operands[1]));"
+  [(set_attr "type" "sfunc")])
+
+(define_insn "extendsfdf2_i2e_r0"
+  [(set (reg:DF R0_REG) (float_extend:DF (reg:SF FR4_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (clobber (reg:SI R4_REG))
+   (clobber (reg:SI FPUL_REG))
+   (use (match_operand:SI 0 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP && TARGET_SH2E"
+  "jsr	@%0%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
 (define_expand "truncdfsf2"
   [(set (match_operand:SF 0 "fpul_operand" "")
 	(float_truncate:SF (match_operand:DF 1 "fp_arith_reg_operand" "")))]
-  "(TARGET_SH4 || TARGET_SH2A_DOUBLE) || TARGET_SHMEDIA_FPU"
+  "TARGET_FPU_DOUBLE || (TARGET_SH3 && TARGET_OSFP) || TARGET_SHMEDIA_FPU"
   "
 {
   if (TARGET_SH4 || TARGET_SH2A_DOUBLE)
@@ -11085,6 +11806,18 @@
 				       get_fpscr_rtx ()));
       DONE;
     }
+  else if (TARGET_SH2E && TARGET_OSFP)
+    {
+      expand_sfunc_unop (DFmode, &gen_truncdfsf2_i2e, \"__truncdfsf2\",
+			 FLOAT_TRUNCATE, operands);
+      DONE;
+    }
+  else if (TARGET_SH1 && TARGET_OSFP)
+    {
+      expand_sfunc_unop (DFmode, &gen_truncdfsf2_i1, \"__truncdfsf2\",
+			 FLOAT_TRUNCATE, operands);
+      DONE;
+    }
 }")
 
 (define_insn "*truncdfsf2_media"
@@ -11103,6 +11836,36 @@
   [(set_attr "type" "fp")
    (set_attr "fp_mode" "double")])
 
+(define_insn "truncdfsf2_i1"
+  [(set (match_operand:SF 0 "arith_reg_dest" "=z")
+	(float_truncate:SF (reg:DF R4_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP && !TARGET_SH2E"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
+(define_insn "truncdfsf2_i2e"
+  [(set (match_operand:SF 0 "arith_reg_dest" "=w")
+	(float_truncate:SF (reg:DF R4_REG)))
+   (clobber (reg:SI T_REG))
+   (clobber (reg:SI PR_REG))
+   (clobber (reg:SI FPUL_REG))
+   (clobber (reg:SI R0_REG))
+   (clobber (reg:SI R1_REG))
+   (clobber (reg:SI R2_REG))
+   (clobber (reg:SI R3_REG))
+   (use (match_operand:SI 1 "arith_reg_operand" "r"))]
+  "TARGET_SH1_SOFTFP && TARGET_SH2E"
+  "jsr	@%1%#"
+  [(set_attr "type" "sfunc")
+   (set_attr "needs_delay_slot" "yes")])
+
 ;; Bit field extract patterns.  These give better code for packed bitfields,
 ;; because they allow auto-increment addresses to be generated.
 
@@ -11476,6 +12239,28 @@
 	bxor.b\\t%2,@(0,%t1)\;movt\\t%0"
   [(set_attr "length" "6,6")])
 
+(define_expand "lrintsfsi2"
+  [(set (match_operand:SI 0 "general_operand" "")
+	(unspec:SI [(match_operand:SF 1 "fp_arith_reg_operand" "")]
+		   UNSPEC_BUILTIN_ROUND))]
+  "(TARGET_SH4 || TARGET_SH2A_SINGLE) && !optimize_size"
+  "
+{
+  sh_expand_lround (operand0, operand1, 1);
+  DONE;
+}")
+
+(define_expand "lroundsfsi2"
+  [(set (match_operand:SI 0 "general_operand" "")
+	(unspec:SI [(match_operand:SF 1 "fp_arith_reg_operand" "")]
+		   UNSPEC_BUILTIN_ROUND))]
+  "(TARGET_SH4 || TARGET_SH2A_SINGLE) && !optimize_size"
+  "
+{
+  sh_expand_lround (operand0, operand1, 0);
+  DONE;
+}")
+
 
 ;; -------------------------------------------------------------------------
 ;; Peepholes
@@ -11652,24 +12437,30 @@
    && reg_unused_after (operands[0], insn)"
   "fmov{.s|}	@(%0,%1),%2")
 
-;; Switch to a new stack with its address in sp_switch (a SYMBOL_REF).  */
+;; Switch to a new stack with its address in sp_switch (a SYMBOL_REF).
 (define_insn "sp_switch_1"
-  [(const_int 1) (match_operand:SI 0 "symbol_ref_operand" "s")]
+  [(set (reg:SI SP_REG) (unspec_volatile [(match_operand:SI 0 "" "")]
+    UNSPECV_SP_SWITCH_B))]
   "TARGET_SH1"
-  "*
 {
-  output_asm_insn (\"mov.l r0,@-r15\;mov.l %0,r0\", operands);
-  output_asm_insn (\"mov.l @r0,r0\;mov.l r15,@-r0\", operands);
-  return \"mov r0,r15\";
-}"
+  return       "mov.l	r0,@-r15"	"\n"
+	 "	mov.l	%0,r0"		"\n"
+	 "	mov.l	@r0,r0"		"\n"
+	 "	mov.l	r15,@-r0"	"\n"
+	 "	mov	r0,r15";
+}
   [(set_attr "length" "10")])
 
 ;; Switch back to the original stack for interrupt functions with the
-;; sp_switch attribute.  */
+;; sp_switch attribute.
 (define_insn "sp_switch_2"
-  [(const_int 2)]
+  [(unspec_volatile [(const_int 0)]
+    UNSPECV_SP_SWITCH_E)]
   "TARGET_SH1"
-  "mov.l @r15+,r15\;mov.l @r15+,r0"
+{
+  return       "mov.l	@r15,r15"	"\n"
+	 "	mov.l	@r15+,r0";
+}
   [(set_attr "length" "4")])
 
 ;; Integer vector moves
diff -urN gcc-4.7.3/gcc/config/sh/sh-mem.c st40-4.7.3-13080/gcc/gcc/config/sh/sh-mem.c
--- gcc-4.7.3/gcc/config/sh/sh-mem.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/config/sh/sh-mem.c	2012-10-12 15:35:26.000000000 +0200
@@ -0,0 +1,507 @@
+/* Output routines for GCC for Renesas / SuperH SH.
+   Copyright (C) 2011.
+   Free Software Foundation, Inc.
+   Copyright (c) 2011 STMicroelectronics.
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation; either version 3, or (at your option)
+any later version.
+
+GCC is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with GCC; see the file COPYING3.  If not see
+<http://www.gnu.org/licenses/>.  */
+
+#include "config.h"
+#include "system.h"
+#include "coretypes.h"
+#include "tm.h"
+#include "insn-config.h"
+#include "rtl.h"
+#include "tree.h"
+#include "flags.h"
+#include "expr.h"
+#include "optabs.h"
+#include "function.h"
+#include "regs.h"
+#include "insn-attr.h"
+#include "recog.h"
+#include "integrate.h"
+#include "dwarf2.h"
+#include "tm_p.h"
+#include "target.h"
+#include "basic-block.h"
+
+/* Like force_operand, but guarantees that VALUE ends up in TARGET.  */
+static void
+force_into (rtx value, rtx target)
+{
+  value = force_operand (value, target);
+  if (! rtx_equal_p (value, target))
+    emit_insn (gen_move_insn (target, value));
+}
+
+/* Emit code to perform a block move.  Choose the best method.
+
+   OPERANDS[0] is the destination.
+   OPERANDS[1] is the source.
+   OPERANDS[2] is the size.
+   OPERANDS[3] is the alignment safe to use.  */
+
+int
+expand_block_move (rtx *operands)
+{
+  int align = INTVAL (operands[3]);
+  int constp = (CONST_INT_P (operands[2]));
+  int bytes = (constp ? INTVAL (operands[2]) : 0);
+
+  if (! constp)
+    return 0;
+
+  if ((TARGET_SH4 || TARGET_SH2A_DOUBLE)
+      && TARGET_FMOVD
+      && !optimize_size && align == 8 && bytes > 4)
+  {
+      rtx dest = copy_rtx (operands[0]);
+      rtx src = copy_rtx (operands[1]);
+      rtx src_addr = copy_addr_to_reg (XEXP (src, 0));
+
+      int copied = 0;
+
+      while (copied + 48 <= bytes)
+	{
+	  rtx temp0 = gen_reg_rtx (DFmode);
+	  rtx temp1 = gen_reg_rtx (DFmode);
+	  rtx temp2 = gen_reg_rtx (DFmode);
+	  rtx temp3 = gen_reg_rtx (DFmode);
+	  rtx temp4 = gen_reg_rtx (DFmode);
+	  rtx temp5 = gen_reg_rtx (DFmode);
+
+	  rtx to0 = adjust_address (dest, DFmode, copied);
+	  rtx to1 = adjust_address (dest, DFmode, copied+8);
+	  rtx to2 = adjust_address (dest, DFmode, copied+16);
+	  rtx to3 = adjust_address (dest, DFmode, copied+24);
+	  rtx to4 = adjust_address (dest, DFmode, copied+32);
+	  rtx to5 = adjust_address (dest, DFmode, copied+40);
+
+	  rtx from0 = adjust_automodify_address (src, DFmode, src_addr, copied);
+	  rtx from1 = adjust_automodify_address (src, DFmode, src_addr, copied + 8);
+	  rtx from2 = adjust_automodify_address (src, DFmode, src_addr, copied + 16);
+	  rtx from3 = adjust_automodify_address (src, DFmode, src_addr, copied + 24);
+	  rtx from4 = adjust_automodify_address (src, DFmode, src_addr, copied + 32);
+	  rtx from5 = adjust_automodify_address (src, DFmode, src_addr, copied + 40);
+
+	  emit_move_insn (temp0, from0);
+	  emit_move_insn (src_addr, plus_constant (src_addr, 8));
+
+	  emit_move_insn (temp1, from1);
+	  emit_move_insn (src_addr, plus_constant (src_addr, 8));
+
+	  emit_move_insn (temp2, from2);
+	  emit_move_insn (src_addr, plus_constant (src_addr, 8));
+
+	  emit_move_insn (temp3, from3);
+	  emit_move_insn (src_addr, plus_constant (src_addr, 8));
+
+	  emit_move_insn (temp4, from4);
+	  emit_move_insn (src_addr, plus_constant (src_addr, 8));
+
+	  emit_move_insn (temp5, from5);
+	  emit_move_insn (src_addr, plus_constant (src_addr, 8));
+
+	  emit_move_insn (to0, temp0);
+	  emit_move_insn (to1, temp1);
+	  emit_move_insn (to2, temp2);
+	  emit_move_insn (to3, temp3);
+	  emit_move_insn (to4, temp4);
+	  emit_move_insn (to5, temp5);
+
+	  copied += 48;
+	}
+
+      while (copied + 8 <= bytes)
+	{
+	  rtx temp0 = gen_reg_rtx (DFmode);
+	  rtx to0 = adjust_address (dest, DFmode, copied);
+	  rtx from0 = adjust_automodify_address (src, DFmode, src_addr, copied);
+
+	  emit_move_insn (temp0, from0);
+	  emit_move_insn (src_addr, plus_constant (src_addr, 8));
+	  emit_move_insn (to0, temp0);
+	  copied += 8;
+	}
+
+      if (copied < bytes)
+	move_by_pieces (adjust_address (dest, BLKmode, copied),
+			adjust_automodify_address (src, BLKmode,
+						   src_addr, copied),
+			bytes - copied, align, 0);
+
+      return 1;
+  }
+
+
+  /* If we could use mov.l to move words and dest is word-aligned, we
+     can use movua.l for loads and still generate a relatively short
+     and efficient sequence.  */
+  if (TARGET_SH4A_ARCH && align < 4
+      && MEM_ALIGN (operands[0]) >= 32
+      && can_move_by_pieces (bytes, 32))
+    {
+      rtx dest = copy_rtx (operands[0]);
+      rtx src = copy_rtx (operands[1]);
+      /* We could use different pseudos for each copied word, but
+	 since movua can only load into r0, it's kind of
+	 pointless.  */
+      rtx temp = gen_reg_rtx (SImode);
+      rtx src_addr = copy_addr_to_reg (XEXP (src, 0));
+      int copied = 0;
+
+      while (copied + 4 <= bytes)
+	{
+	  rtx to = adjust_address (dest, SImode, copied);
+	  rtx from = adjust_automodify_address (src, BLKmode,
+						src_addr, copied);
+
+	  set_mem_size (from, 4);
+	  emit_insn (gen_movua (temp, from));
+	  emit_move_insn (src_addr, plus_constant (src_addr, 4));
+	  emit_move_insn (to, temp);
+	  copied += 4;
+	}
+
+      if (copied < bytes)
+	move_by_pieces (adjust_address (dest, BLKmode, copied),
+			adjust_automodify_address (src, BLKmode,
+						   src_addr, copied),
+			bytes - copied, align, 0);
+
+      return 1;
+    }
+
+  /* If it isn't a constant number of bytes, or if it doesn't have 4 byte
+     alignment, or if it isn't a multiple of 4 bytes, then fail.  */
+  if (align < 4 || (bytes % 4 != 0))
+    return 0;
+
+  if (TARGET_HARD_SH4)
+    {
+      if (bytes < 12)
+	return 0;
+      else if (bytes == 12)
+	{
+	  rtx func_addr_rtx = gen_reg_rtx (Pmode);
+	  rtx r4 = gen_rtx_REG (SImode, 4);
+	  rtx r5 = gen_rtx_REG (SImode, 5);
+
+	  function_symbol (func_addr_rtx, "__movmemSI12_i4", SFUNC_STATIC);
+	  force_into (XEXP (operands[0], 0), r4);
+	  force_into (XEXP (operands[1], 0), r5);
+	  emit_insn (gen_block_move_real_i4 (func_addr_rtx));
+	  return 1;
+	}
+      else if (! optimize_size)
+	{
+	  const char *entry_name;
+	  rtx func_addr_rtx = gen_reg_rtx (Pmode);
+	  int dwords;
+	  rtx r4 = gen_rtx_REG (SImode, 4);
+	  rtx r5 = gen_rtx_REG (SImode, 5);
+	  rtx r6 = gen_rtx_REG (SImode, 6);
+
+	  entry_name = (bytes & 4 ? "__movmem_i4_odd" : "__movmem_i4_even");
+	  function_symbol (func_addr_rtx, entry_name, SFUNC_STATIC);
+	  force_into (XEXP (operands[0], 0), r4);
+	  force_into (XEXP (operands[1], 0), r5);
+
+	  dwords = bytes >> 3;
+	  emit_insn (gen_move_insn (r6, GEN_INT (dwords - 1)));
+	  emit_insn (gen_block_lump_real_i4 (func_addr_rtx));
+	  return 1;
+	}
+      else
+	return 0;
+    }
+  if (bytes < 64)
+    {
+      char entry[30];
+      rtx func_addr_rtx = gen_reg_rtx (Pmode);
+      rtx r4 = gen_rtx_REG (SImode, 4);
+      rtx r5 = gen_rtx_REG (SImode, 5);
+
+      sprintf (entry, "__movmemSI%d", bytes);
+      function_symbol (func_addr_rtx, entry, SFUNC_STATIC);
+      force_into (XEXP (operands[0], 0), r4);
+      force_into (XEXP (operands[1], 0), r5);
+      emit_insn (gen_block_move_real (func_addr_rtx));
+      return 1;
+    }
+
+  /* This is the same number of bytes as a memcpy call, but to a different
+     less common function name, so this will occasionally use more space.  */
+  if (! optimize_size)
+    {
+      rtx func_addr_rtx = gen_reg_rtx (Pmode);
+      int final_switch, while_loop;
+      rtx r4 = gen_rtx_REG (SImode, 4);
+      rtx r5 = gen_rtx_REG (SImode, 5);
+      rtx r6 = gen_rtx_REG (SImode, 6);
+
+      function_symbol (func_addr_rtx, "__movmem", SFUNC_STATIC);
+      force_into (XEXP (operands[0], 0), r4);
+      force_into (XEXP (operands[1], 0), r5);
+
+      /* r6 controls the size of the move.  16 is decremented from it
+	 for each 64 bytes moved.  Then the negative bit left over is used
+	 as an index into a list of move instructions.  e.g., a 72 byte move
+	 would be set up with size(r6) = 14, for one iteration through the
+	 big while loop, and a switch of -2 for the last part.  */
+
+      final_switch = 16 - ((bytes / 4) % 16);
+      while_loop = ((bytes / 4) / 16 - 1) * 16;
+      emit_insn (gen_move_insn (r6, GEN_INT (while_loop + final_switch)));
+      emit_insn (gen_block_lump_real (func_addr_rtx));
+      return 1;
+    }
+
+  return 0;
+}
+
+
+/* Emit code to perform a str[n]cmp.  
+
+   OPERANDS[0] is the destination.
+   OPERANDS[1] is the first string.
+   OPERANDS[2] is the second string.
+   OPERANDS[3] is the align.  */
+
+int
+sh4_expand_cmpstr (rtx *operands)
+{ 
+  rtx s1 = copy_rtx (operands[1]);
+  rtx s2 = copy_rtx (operands[2]);
+  rtx s1_addr = copy_addr_to_reg (XEXP (s1, 0));
+  rtx s2_addr = copy_addr_to_reg (XEXP (s2, 0));
+  rtx tmp0 = gen_reg_rtx (SImode);
+  rtx tmp1 = gen_reg_rtx (SImode);
+  rtx tmp2 = gen_reg_rtx (SImode);
+  rtx low_1 = gen_lowpart (HImode, tmp1);
+  rtx low_2 = gen_lowpart (HImode, tmp2);
+  rtx tmp3 = gen_reg_rtx (SImode);
+  rtx tmp4 = gen_reg_rtx (SImode);
+
+  rtx addr1 = adjust_automodify_address (s1, QImode, s1_addr, 0);
+  rtx addr2 = adjust_automodify_address (s2, QImode, s2_addr, 0);
+
+  rtx addr1_l = adjust_automodify_address (s1, SImode, s1_addr, 0);
+  rtx addr2_l = adjust_automodify_address (s2, SImode, s2_addr, 0);
+
+  rtx end_byte = gen_label_rtx ();
+
+  rtx ret = gen_label_rtx ();
+  rtx loop_long = gen_label_rtx ();
+  rtx loop_end = gen_label_rtx ();
+  rtx loop_end1 = gen_label_rtx ();
+  rtx loop_byte = gen_label_rtx ();
+  rtx loop_byte11 = gen_label_rtx ();
+  rtx loop_byte01 = gen_label_rtx ();
+#if 0
+  rtx loop_byte12 = gen_label_rtx ();
+#endif
+  rtx jump;
+
+  emit_move_insn (tmp2, s2_addr);
+  emit_move_insn (tmp0, GEN_INT (3));
+  emit_insn (gen_tstsi_t (tmp0, tmp2));
+  jump = emit_jump_insn (gen_branch_false (loop_byte));
+  add_reg_note (jump, REG_BR_PROB, GEN_INT (REG_BR_PROB_BASE / 4));
+
+  /* tmp2 is aligned, OK to load. */
+  emit_move_insn (tmp2, addr2_l); 
+  emit_move_insn (s2_addr, plus_constant (s2_addr, 4));
+
+  emit_move_insn (tmp1, s1_addr);
+  emit_insn (gen_tstsi_t (tmp0, tmp1));
+      
+  emit_move_insn (tmp0, const0_rtx);
+
+  jump = emit_jump_insn (gen_branch_false (loop_byte01));
+  add_reg_note (jump, REG_BR_PROB, GEN_INT (REG_BR_PROB_BASE / 4));
+
+  /* tmp1 is aligned, OK to load. */
+  emit_move_insn (tmp1, addr1_l); 
+  emit_move_insn (s1_addr, plus_constant (s1_addr, 4));
+
+  /* first iteration out of the loop */
+  /* tmp1, tmp2 ready. */
+  emit_insn (gen_cmpstr_t (tmp0, tmp2));
+
+  jump = emit_jump_insn (gen_branch_true (loop_byte11));
+  add_reg_note (jump, REG_BR_PROB, GEN_INT (REG_BR_PROB_BASE / 4));
+
+  emit_insn (gen_cmpeqsi_t (tmp1, tmp2));
+
+  jump = emit_jump_insn (gen_branch_false (loop_end));
+  add_reg_note (jump, REG_BR_PROB, GEN_INT (REG_BR_PROB_BASE / 4));
+
+  /* ------ start loop -------------- */
+  emit_label (loop_long);
+  
+  emit_move_insn (tmp4, addr2_l); 
+  emit_move_insn (s2_addr, plus_constant (s2_addr, 4));
+
+  emit_move_insn (tmp3, addr1_l); 
+  emit_move_insn (s1_addr, plus_constant (s1_addr, 4));
+
+  /* --- tmp3, tmp4 ready */
+  emit_insn (gen_cmpstr_t (tmp0, tmp4));
+  jump = emit_jump_insn (gen_branch_true (loop_byte11));
+  add_reg_note (jump, REG_BR_PROB, GEN_INT (REG_BR_PROB_BASE / 10));
+
+  emit_move_insn (tmp2, addr2_l); 
+  emit_move_insn (s2_addr, plus_constant (s2_addr, 4));
+
+  emit_insn (gen_cmpeqsi_t (tmp3, tmp4));
+  jump = emit_jump_insn (gen_branch_false (loop_end1));
+  add_reg_note (jump, REG_BR_PROB, GEN_INT (REG_BR_PROB_BASE / 10));
+
+  emit_move_insn (tmp1, addr1_l); 
+  emit_move_insn (s1_addr, plus_constant (s1_addr, 4));
+
+  /* --- tmp1, tmp2 ready */
+  emit_insn (gen_cmpstr_t (tmp0, tmp2));
+  jump = emit_jump_insn (gen_branch_true (loop_byte11));
+  add_reg_note (jump, REG_BR_PROB, GEN_INT (REG_BR_PROB_BASE / 10));
+
+  emit_move_insn (tmp4, addr2_l); 
+  emit_move_insn (s2_addr, plus_constant (s2_addr, 4));
+
+  emit_insn (gen_cmpeqsi_t (tmp1, tmp2));
+  jump = emit_jump_insn (gen_branch_false (loop_end));
+  add_reg_note (jump, REG_BR_PROB, GEN_INT (REG_BR_PROB_BASE / 10));
+
+  emit_move_insn (tmp3, addr1_l); 
+  emit_move_insn (s1_addr, plus_constant (s1_addr, 4));
+
+  /* --- tmp3, tmp4 ready */
+  emit_insn (gen_cmpstr_t (tmp0, tmp4));
+  jump = emit_jump_insn (gen_branch_true (loop_byte11));
+  add_reg_note (jump, REG_BR_PROB, GEN_INT (REG_BR_PROB_BASE / 10));
+
+  emit_move_insn (tmp2, addr2_l); 
+  emit_move_insn (s2_addr, plus_constant (s2_addr, 4));
+
+  emit_insn (gen_cmpeqsi_t (tmp3, tmp4));
+  jump = emit_jump_insn (gen_branch_false (loop_end1));
+  add_reg_note (jump, REG_BR_PROB, GEN_INT (REG_BR_PROB_BASE / 10));
+
+  emit_move_insn (tmp1, addr1_l); 
+  emit_move_insn (s1_addr, plus_constant (s1_addr, 4));
+
+  /* --- tmp1, tmp2 ready */
+  emit_insn (gen_cmpstr_t (tmp0, tmp2));
+  jump = emit_jump_insn (gen_branch_true (loop_byte11));
+  add_reg_note (jump, REG_BR_PROB, GEN_INT (REG_BR_PROB_BASE / 10));
+
+  emit_insn (gen_cmpeqsi_t (tmp1, tmp2));
+
+  /* speculated from falltru. */
+  if (TARGET_LITTLE_ENDIAN) 
+    emit_insn (gen_rotlhi3_8 (low_1, low_1));
+
+  jump = emit_jump_insn (gen_branch_true (loop_long));
+  add_reg_note (jump, REG_BR_PROB, GEN_INT (REG_BR_PROB_BASE / 10));
+  /* end loop */
+
+  /* fall thru. */
+  if (TARGET_LITTLE_ENDIAN) 
+    {
+      emit_insn (gen_rotlhi3_8 (low_2, low_2));
+      emit_insn (gen_rotlsi3_16 (tmp1, tmp1));
+      emit_insn (gen_rotlsi3_16 (tmp2, tmp2));
+      emit_insn (gen_rotlhi3_8 (low_1, low_1));
+      emit_insn (gen_rotlhi3_8 (low_2, low_2));
+    }
+  
+  emit_move_insn (operands[0], GEN_INT (-1));
+  emit_insn (gen_cmpgtusi_t (tmp2, tmp1));
+  emit_insn (gen_rotcr_t (operands[0]));
+  jump = emit_jump_insn (gen_jump_compact (ret));
+  emit_barrier_after (jump);
+
+  /* last long words not equal, but no zero inside. */
+  /* we have the values, can just walk the bytes */
+  emit_label (loop_end);
+  if (TARGET_LITTLE_ENDIAN) 
+    {
+      emit_insn (gen_rotlhi3_8 (low_1, low_1));
+      emit_insn (gen_rotlhi3_8 (low_2, low_2));
+      emit_insn (gen_rotlsi3_16 (tmp1, tmp1));
+      emit_insn (gen_rotlsi3_16 (tmp2, tmp2));
+      emit_insn (gen_rotlhi3_8 (low_1, low_1));
+      emit_insn (gen_rotlhi3_8 (low_2, low_2));
+    }
+  
+  emit_move_insn (operands[0], GEN_INT (-1));
+  emit_insn (gen_cmpgtusi_t (tmp2, tmp1));
+  emit_insn (gen_rotcr_t (operands[0]));
+  jump = emit_jump_insn (gen_jump_compact (ret));
+  emit_barrier_after (jump);
+
+  emit_label (loop_end1);
+  emit_move_insn (tmp1, tmp3);
+  emit_move_insn (tmp2, tmp4);
+  jump = emit_jump_insn (gen_jump_compact (loop_end));
+  emit_barrier_after (jump);
+
+  emit_label (loop_byte01);
+  emit_move_insn (s2_addr, plus_constant (s2_addr, -4));
+  jump = emit_jump_insn (gen_jump_compact (loop_byte));
+  emit_barrier_after (jump);
+
+#if 0
+  emit_label (loop_byte12);
+  emit_move_insn (s1_addr, plus_constant (s1_addr, -4));
+  emit_move_insn (s2_addr, plus_constant (s2_addr, -8));
+  jump = emit_jump_insn (gen_jump_compact (loop_byte));
+  emit_barrier_after (jump);
+#endif
+
+  emit_label (loop_byte11);
+  emit_move_insn (s1_addr, plus_constant (s1_addr, -4));
+  emit_move_insn (s2_addr, plus_constant (s2_addr, -4));
+
+  emit_label (loop_byte);
+
+  /* start loop byte */
+  emit_insn (gen_extendqisi2 (tmp1, addr1));
+  emit_move_insn (s1_addr, plus_constant (s1_addr, 1));
+  emit_insn (gen_extendqisi2 (tmp2, addr2));
+  emit_move_insn (s2_addr, plus_constant (s2_addr, 1));
+  emit_insn (gen_cmpeqsi_t (tmp1, const0_rtx));
+  jump = emit_jump_insn (gen_branch_true (end_byte));
+  add_reg_note (jump, REG_BR_PROB, GEN_INT (REG_BR_PROB_BASE / 4));
+  emit_insn (gen_cmpeqsi_t (tmp1, tmp2));
+  emit_jump_insn (gen_branch_true (loop_byte));
+
+  /* end loop byte */
+
+  emit_label (end_byte);
+
+  emit_insn (gen_zero_extendqisi2 (tmp1, gen_lowpart (QImode, tmp1)));
+  emit_insn (gen_zero_extendqisi2 (tmp2, gen_lowpart (QImode, tmp2)));
+
+  emit_insn (gen_subsi3 (operands[0], tmp1, tmp2));
+
+  emit_label (ret);
+
+  return 1;
+}
+
diff -urN gcc-4.7.3/gcc/config/sh/sh-modes.def st40-4.7.3-13080/gcc/gcc/config/sh/sh-modes.def
--- gcc-4.7.3/gcc/config/sh/sh-modes.def	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/config/sh/sh-modes.def	2013-04-30 11:08:54.000000000 +0200
@@ -1,5 +1,6 @@
-/* SH extra machine modes. 
+/* SH extra machine modes.
    Copyright (C) 2003, 2004, 2005, 2007 Free Software Foundation, Inc.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -22,6 +23,11 @@
 /* PDI mode is used to represent a function address in a target register.  */
 PARTIAL_INT_MODE (DI);
 
+/* For software floating point comparisons.  */
+CC_MODE (CC_FP_NE);
+CC_MODE (CC_FP_GT);
+CC_MODE (CC_FP_UNLT);
+
 /* Vector modes.  */
 VECTOR_MODE  (INT, QI, 2);    /*                 V2QI */
 VECTOR_MODES (INT, 4);        /*            V4QI V2HI */
diff -urN gcc-4.7.3/gcc/config/sh/sh.opt st40-4.7.3-13080/gcc/gcc/config/sh/sh.opt
--- gcc-4.7.3/gcc/config/sh/sh.opt	2013-03-26 12:38:31.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/config/sh/sh.opt	2013-03-27 16:11:13.000000000 +0100
@@ -2,6 +2,7 @@
 
 ; Copyright (C) 2005, 2006, 2007, 2008, 2009, 2010, 2011
 ; Free Software Foundation, Inc.
+; Copyright (c) 2011  STMicroelectronics.
 ;
 ; This file is part of GCC.
 ;
@@ -22,7 +23,7 @@
 ;; Used for various architecture options.
 Mask(SH_E)
 
-;; Set if the default precision of th FPU is single.
+;; Set if the default precision of the FPU is single.
 Mask(FPU_SINGLE)
 
 ;; Set if the a double-precision FPU is present but is restricted to
@@ -209,9 +210,9 @@
 Target Report Var(TARGET_ACCUMULATE_OUTGOING_ARGS) Init(1)
 Reserve space for outgoing arguments in the function prologue
 
-madjust-unroll
-Target Report Mask(ADJUST_UNROLL) Condition(SUPPORT_ANY_SH5)
-Throttle unrolling to avoid thrashing target registers unless the unroll benefit outweighs this
+malign-small-blocks=
+Target RejectNegative Joined UInteger Var(sh_align_small_blocks) Init(32)
+Honor align-jump-loops for basic block bigger than number of instructions.
 
 mb
 Target Report RejectNegative InverseMask(LITTLE_ENDIAN)
@@ -245,9 +246,13 @@
 Target Report RejectNegative Mask(ALIGN_DOUBLE)
 Align doubles at 64-bit boundaries
 
+mdb-page-bug
+Target Report RejectNegative Var(TARGET_DBHWBUG)
+Undocumented
+
 mdiv=
 Target RejectNegative Joined Var(sh_div_str) Init("")
-Division strategy, one of: call, call2, fp, inv, inv:minlat, inv20u, inv20l, inv:call, inv:call2, inv:fp, call-div1, call-fp, call-table
+Division strategy, one of: call, call2, fp, inv, inv:minlat, inv20u, inv20l, inv:call, inv:call2, inv:fp, call-div1, call-fp, call-table, call-pre1
 
 mdivsi3_libfunc=
 Target RejectNegative Joined Var(sh_divsi3_libfunc) Init("")
@@ -257,6 +262,10 @@
 Target RejectNegative Mask(FMOVD)
 Enable the use of 64-bit floating point registers in fmov instructions.  See -mdalign if 64-bit alignment is required.
 
+mfldi
+Target Var(TARGET_FLDI) Init(1)
+Allow the use of fldi0/1 instructions.
+
 mfixed-range=
 Target RejectNegative Joined Var(sh_fixed_range_str)
 Specify range of registers to make fixed
@@ -297,6 +306,14 @@
 Target Report RejectNegative Mask(LITTLE_ENDIAN)
 Generate code in little endian mode
 
+mlate-r0r3-to-reg-mul
+Target RejectNegative Var(TARGET_R0R3_TO_REG_MUL, 1) VarExists
+Assume availability of integer multiply instruction (src only opd in r0-r3), but only try to use this instruction after register allocation.
+
+mdead-delay
+Target Report Mask(DEAD_DELAY)
+Try to eliminate a dead delay slot instruction.
+
 mnomacsave
 Target Report RejectNegative Mask(NOMACSAVE)
 Mark MAC register as call-clobbered
@@ -315,6 +332,10 @@
 Target Report Mask(PT_FIXED) Condition(SUPPORT_ANY_SH5)
 Assume pt* instructions won't trap
 
+mr0r3-to-reg-mul
+Target Var(TARGET_R0R3_TO_REG_MUL, 2) Init(-1)
+Assume availability of integer multiply instruction (src only opd in r0-r3)
+
 mrelax
 Target Report RejectNegative Mask(RELAX)
 Shorten address references during linking
@@ -327,9 +348,9 @@
 Target Report Mask(SOFT_ATOMIC)
 Use software atomic sequences supported by kernel
 
-mspace
-Target RejectNegative Alias(Os)
-Deprecated.  Use -Os instead
+mtas
+Target Var(TARGET_TAS) 
+Allow TAS.B instruction.
 
 multcost=
 Target RejectNegative Joined UInteger Var(sh_multcost) Init(-1)
@@ -344,3 +365,6 @@
 mpretend-cmove
 Target Var(TARGET_PRETEND_CMOVE)
 Pretend a branch-around-a-move is a conditional move.
+
+
+
diff -urN gcc-4.7.3/gcc/config/sh/sh-protos.h st40-4.7.3-13080/gcc/gcc/config/sh/sh-protos.h
--- gcc-4.7.3/gcc/config/sh/sh-protos.h	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/config/sh/sh-protos.h	2013-03-20 08:38:57.000000000 +0100
@@ -4,6 +4,7 @@
    Free Software Foundation, Inc.
    Contributed by Steve Chamberlain (sac@cygnus.com).
    Improved by Jim Wilson (wilson@cygnus.com).
+   Copyright (c) 2011  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -25,8 +26,13 @@
 #define GCC_SH_PROTOS_H
 
 enum sh_function_kind {
-  /* A function with normal C ABI  */
+  /* A function with normal C ABI, or an SH1..SH4 sfunc that may resolved via
+     a PLT.  */
   FUNCTION_ORDINARY,
+  /* A function that is a bit large to put it in every calling dso, but that's
+     typically used often enough so that calling via GOT makes sense for
+     speed.  */
+  SFUNC_FREQUENT,
   /* A special function that guarantees that some otherwise call-clobbered
      registers are not clobbered.  These can't go through the SH5 resolver,
      because it only saves argument passing registers.  */
@@ -52,6 +58,7 @@
 extern const char *output_far_jump (rtx, rtx);
 
 extern rtx sfunc_uses_reg (rtx);
+extern int sh_jump_align (rtx);
 extern int barrier_align (rtx);
 extern int sh_loop_align (rtx);
 extern int fp_zero_operand (rtx);
@@ -66,6 +73,7 @@
 extern void emit_df_insn (rtx);
 extern void output_pic_addr_const (FILE *, rtx);
 extern int expand_block_move (rtx *);
+extern int sh4_expand_cmpstr (rtx *);
 extern int prepare_move_operands (rtx[], enum machine_mode mode);
 extern enum rtx_code prepare_cbranch_operands (rtx *, enum machine_mode mode,
 					       enum rtx_code comparison);
@@ -114,13 +122,20 @@
 extern void expand_df_unop (rtx (*)(rtx, rtx, rtx), rtx *);
 extern void expand_df_binop (rtx (*)(rtx, rtx, rtx, rtx), rtx *);
 extern void expand_fp_branch (rtx (*)(void), rtx (*)(void));
-extern int sh_insn_length_adjustment (rtx);
+extern void expand_sfunc_unop (enum machine_mode, rtx (*) (rtx, rtx),
+			       const char *, enum rtx_code code, rtx *);
+extern void expand_sfunc_binop (enum machine_mode, rtx (*) (rtx, rtx),
+				const char *, enum rtx_code code, rtx *);
+extern int sh_insn_length_adjustment (rtx, const int);
+extern int sh_insn_length_alignment (rtx);
 extern int sh_can_redirect_branch (rtx, rtx);
 extern void sh_expand_unop_v2sf (enum rtx_code, rtx, rtx);
 extern void sh_expand_binop_v2sf (enum rtx_code, rtx, rtx, rtx);
+extern void sh_expand_lround (rtx, rtx, bool);
 extern int sh_expand_t_scc (rtx *);
 extern rtx sh_gen_truncate (enum machine_mode, rtx, int);
 extern bool sh_vector_mode_supported_p (enum machine_mode);
+extern bool stack_protector_block (rtx, rtx);
 #endif /* RTX_CODE */
 
 extern const char *output_jump_label_table (void);
@@ -129,10 +144,9 @@
 extern int sh_media_register_for_return (void);
 extern void sh_expand_prologue (void);
 extern void sh_expand_epilogue (bool);
-extern int sh_need_epilogue (void);
 extern void sh_set_return_address (rtx, rtx);
 extern int initial_elimination_offset (int, int);
-extern int fldi_ok (void);
+extern int fldi_ok (bool);
 extern int sh_hard_regno_rename_ok (unsigned int, unsigned int);
 extern int sh_cfun_interrupt_handler_p (void);
 extern int sh_cfun_resbank_handler_p (void);
@@ -147,6 +161,7 @@
 #ifdef HARD_CONST
 extern void fpscr_set_from_mem (int, HARD_REG_SET);
 #endif
+extern void emit_fpu_flip (void);
 
 extern void sh_pr_interrupt (struct cpp_reader *);
 extern void sh_pr_trapa (struct cpp_reader *);
@@ -157,6 +172,7 @@
 extern int sh_pass_in_reg_p (CUMULATIVE_ARGS *, enum machine_mode, tree);
 extern void sh_init_cumulative_args (CUMULATIVE_ARGS *, tree, rtx, tree, signed int, enum machine_mode);
 extern rtx sh_dwarf_register_span (rtx);
+extern bool sh_varying_insn_p (rtx);
 
 extern rtx replace_n_hard_rtx (rtx, rtx *, int , int);
 extern int shmedia_cleanup_truncate (rtx *, void *);
@@ -168,4 +184,15 @@
 extern int sh2a_is_function_vector_call (rtx);
 extern void sh_fix_range (const char *);
 extern bool sh_hard_regno_mode_ok (unsigned int, enum machine_mode);
+
+extern int sh_asm_count (const char *, int *);
+extern int sh_align_function_log (tree);
+extern bool sh_can_use_simple_return_p (void);
+
+extern bool short_cbranch_p (rtx insn);
+extern bool med_cbranch_p (rtx insn);
+extern bool braf_cbranch_p (rtx insn);
+
+extern bool med_branch_p (rtx insn);
+extern bool braf_branch_p (rtx insn);
 #endif /* ! GCC_SH_PROTOS_H */
diff -urN gcc-4.7.3/gcc/config/sh/superh.h st40-4.7.3-13080/gcc/gcc/config/sh/superh.h
--- gcc-4.7.3/gcc/config/sh/superh.h	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/config/sh/superh.h	2013-04-30 11:08:54.000000000 +0200
@@ -1,5 +1,6 @@
 /* Definitions of target machine for gcc for Super-H using sh-superh-elf.
    Copyright (C) 2001, 2006, 2007, 2011 Free Software Foundation, Inc.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GNU CC.
 
@@ -78,11 +79,6 @@
 #undef SUBTARGET_ASM_SPEC
 #define SUBTARGET_ASM_SPEC "%{m4-100*|m4-200*:-isa=sh4} %{m4-400|m4-340:-isa=sh4-nommu-nofpu} %{m4-500:-isa=sh4-nofpu} %(asruntime)"
 
-/* Override the SUBTARGET_ASM_RELAX_SPEC so it doesn't interfere with the
-   runtime support by adding -isa=sh4 in the wrong place.  */
-#undef SUBTARGET_ASM_RELAX_SPEC
-#define SUBTARGET_ASM_RELAX_SPEC "%{!m4-100*:%{!m4-200*:%{!m4-300*:%{!m4-340:%{!m4-400:%{!m4-500:-isa=sh4}}}}}}"
-
 /* Create the CC1_SPEC to add the runtime support */
 #undef CC1_SPEC
 #define CC1_SPEC "%(cc1runtime)"
@@ -90,10 +86,18 @@
 #undef CC1PLUS_SPEC
 #define CC1PLUS_SPEC "%(cc1runtime)"
 
-
 /* Override the LIB_SPEC to add the runtime support */
+/* board_link defines both --defsyms and libraries. Libraries should be
+   imported from LIB_SPEC that goes at the end of the command line, but
+   redefines user --defsyms, that should to into LINK_SPEC. For the BSP
+   libraries to be added to the command line, make sure that the board_spec
+   is included.  */
 #undef LIB_SPEC
-#define LIB_SPEC "%{!shared:%{!symbolic:%(libruntime) -lc}} %{pg:-lprofile -lc}"
+#define LIB_SPEC "%{!shared:%{!symbolic:%{pg:-lprofile} \
+%{"PLUGIN_COND": \
+%{!nostdlib:%{!nodefaultlibs:%:pass-through-libs(%(board_link))}} \
+}"PLUGIN_COND_CLOSE" \
+%(libruntime) -lc}}"
 
 /* Override STARTFILE_SPEC to add profiling and MMU support.  */
 #undef STARTFILE_SPEC
@@ -101,4 +105,4 @@
   "%{!shared: %{!m4-400*:%{!m4-340*: %{pg:gcrt1-mmu.o%s}%{!pg:crt1-mmu.o%s}}}} \
    %{!shared: %{m4-340*|m4-400*: %{pg:gcrt1.o%s}%{!pg:crt1.o%s}}} \
    crti.o%s \
-   %{!shared:crtbegin.o%s} %{shared:crtbeginS.o%s}"
+   %{!shared:crtbegin.o%s trap-handler.o%s} %{shared:crtbeginS.o%s}"
diff -urN gcc-4.7.3/gcc/config/sh/t-mlib-sh4-300 st40-4.7.3-13080/gcc/gcc/config/sh/t-mlib-sh4-300
--- gcc-4.7.3/gcc/config/sh/t-mlib-sh4-300	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/config/sh/t-mlib-sh4-300	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1 @@
+ML_sh4_300=m4-300/
diff -urN gcc-4.7.3/gcc/config/sh/t-sh st40-4.7.3-13080/gcc/gcc/config/sh/t-sh
--- gcc-4.7.3/gcc/config/sh/t-sh	2013-03-26 12:38:31.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/config/sh/t-sh	2013-04-30 11:08:54.000000000 +0200
@@ -1,5 +1,6 @@
 # Copyright (C) 1993, 1994, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002,
 # 2003, 2004, 2006, 2008, 2009, 2011 Free Software Foundation, Inc.
+# Copyright (c) 2013  STMicroelectronics.#
 #
 # This file is part of GCC.
 #
@@ -22,6 +23,11 @@
 	$(COMPILER) -c $(ALL_COMPILERFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) \
 		$(srcdir)/config/sh/sh-c.c
 
+sh-mem.o: $(srcdir)/config/sh/sh-mem.c \
+  $(CONFIG_H) $(SYSTEM_H) $(TREE_H) $(TM_H) $(TM_P_H) 
+	$(COMPILER) -c $(ALL_COMPILERFLAGS) $(ALL_CPPFLAGS) $(INCLUDES) \
+		$(srcdir)/config/sh/sh-mem.c
+
 DEFAULT_ENDIAN = $(word 1,$(TM_ENDIAN_CONFIG))
 OTHER_ENDIAN = $(word 2,$(TM_ENDIAN_CONFIG))
 
diff -urN gcc-4.7.3/gcc/config.gcc st40-4.7.3-13080/gcc/gcc/config.gcc
--- gcc-4.7.3/gcc/config.gcc	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/config.gcc	2013-04-30 11:08:54.000000000 +0200
@@ -1,6 +1,7 @@
 # GCC target-specific configuration file.
 # Copyright 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007,
 # 2008, 2009, 2010, 2011, 2012 Free Software Foundation, Inc.
+# Copyright (c) 2013  STMicroelectronics.
 
 #This file is part of GCC.
 
@@ -1246,7 +1247,7 @@
 	gnu_ld=yes
 	;;
 i[34567]86-*-linux* | i[34567]86-*-kfreebsd*-gnu | i[34567]86-*-knetbsd*-gnu | i[34567]86-*-gnu* | i[34567]86-*-kopensolaris*-gnu)
-			# Intel 80386's running GNU/*
+			# Intel 80386\'s running GNU/*
 			# with ELF format using glibc 2
 	tm_file="${tm_file} i386/unix.h i386/att.h dbxelf.h elfos.h gnu-user.h glibc-stdint.h"
 	case ${target} in
@@ -2225,6 +2226,7 @@
   sh-*-linux* | sh[2346lbe]*-*-linux* | \
   sh-*-netbsdelf* | shl*-*-netbsdelf* | sh5-*-netbsd* | sh5l*-*-netbsd* | \
   sh64-*-netbsd* | sh64l*-*-netbsd*)
+	extra_objs="sh-mem.o"
 	tmake_file="${tmake_file} sh/t-sh sh/t-elf"
 	if test x${with_endian} = x; then
 		case ${target} in
@@ -3597,7 +3599,7 @@
 
 	powerpc*-*-* | rs6000-*-*)
 		# FIXME: The PowerPC port uses the value set at compile time,
-		# although it's only cosmetic.
+		# although it\'s only cosmetic.
 		if test "x$with_cpu" != x
 		then
 			target_cpu_default2="\\\"$with_cpu\\\""
diff -urN gcc-4.7.3/gcc/configure st40-4.7.3-13080/gcc/gcc/configure
--- gcc-4.7.3/gcc/configure	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/configure	2013-04-30 11:08:54.000000000 +0200
@@ -5,6 +5,7 @@
 # Copyright (C) 1992, 1993, 1994, 1995, 1996, 1998, 1999, 2000, 2001,
 # 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009 Free Software
 # Foundation, Inc.
+# Copyright (c) 2013  STMicroelectronics.
 #
 # This configure script is free software; the Free Software Foundation
 # gives unlimited permission to copy, distribute and modify it.
@@ -11338,7 +11339,7 @@
     target_thread_file='single'
     ;;
   aix | dce | lynx | mipssde | posix | rtems | \
-  single | tpf | vxworks | win32)
+  single | tpf | vxworks | win32 | generic)
     target_thread_file=${enable_threads}
     ;;
   *)
@@ -11865,6 +11866,16 @@
 	CROSS="-DCROSS_DIRECTORY_STRUCTURE"
 	ALL=all.cross
 	SYSTEM_HEADER_DIR=$build_system_header_dir
+
+ 	# For builds with an in-tree newlib, then the headers are not
+ 	# copied to build_system_header_dir, so things like limits.h
+ 	# won't work unless we point at the real headers.
+ 	if test "$with_newlib" = yes \
+ 		&& (test -z "$with_headers" || test "$with_headers" = yes) \
+ 		&& test -d $srcdir/../newlib/libc/include; then
+ 	  SYSTEM_HEADER_DIR="\$(abs_srcdir)/../newlib/libc/include"
+ 	fi
+
 	case "$host","$target" in
 	# Darwin crosses can use the host system's libraries and headers,
 	# because of the fat library support.  Of course, it must be the
@@ -26775,6 +26786,8 @@
   else
     target_header_dir="${with_sysroot}${native_system_header_dir}"
   fi
+elif test x$host != x$build && test "x$with_build_sysroot" != "x"; then
+  target_header_dir="${with_build_sysroot}${native_system_header_dir}"
 else
   target_header_dir=${native_system_header_dir}
 fi
diff -urN gcc-4.7.3/gcc/configure.ac st40-4.7.3-13080/gcc/gcc/configure.ac
--- gcc-4.7.3/gcc/configure.ac	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/configure.ac	2013-04-30 11:08:54.000000000 +0200
@@ -3,6 +3,7 @@
 
 # Copyright 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006,
 # 2007, 2008, 2009, 2010, 2011, 2012 Free Software Foundation, Inc.
+# Copyright (c) 2013  STMicroelectronics.
 
 #This file is part of GCC.
 
@@ -1450,7 +1451,7 @@
     target_thread_file='single'
     ;;
   aix | dce | lynx | mipssde | posix | rtems | \
-  single | tpf | vxworks | win32)
+  single | tpf | vxworks | win32 | generic)
     target_thread_file=${enable_threads}
     ;;
   *)
@@ -1842,6 +1843,16 @@
 	CROSS="-DCROSS_DIRECTORY_STRUCTURE"
 	ALL=all.cross
 	SYSTEM_HEADER_DIR=$build_system_header_dir
+ 
+ 	# For builds with an in-tree newlib, then the headers are not
+ 	# copied to build_system_header_dir, so things like limits.h
+ 	# won't work unless we point at the real headers.
+ 	if test "$with_newlib" = yes \
+ 		&& (test -z "$with_headers" || test "$with_headers" = yes) \
+ 		&& test -d $srcdir/../newlib/libc/include; then
+ 	  SYSTEM_HEADER_DIR="\$(abs_srcdir)/../newlib/libc/include"
+ 	fi
+ 
 	case "$host","$target" in
 	# Darwin crosses can use the host system's libraries and headers,
 	# because of the fat library support.  Of course, it must be the
@@ -4655,6 +4666,8 @@
   else
     target_header_dir="${with_sysroot}${native_system_header_dir}"
   fi
+elif test x$host != x$build && test "x$with_build_sysroot" != "x"; then
+  target_header_dir="${with_build_sysroot}${native_system_header_dir}"
 else
   target_header_dir=${native_system_header_dir}
 fi
diff -urN gcc-4.7.3/gcc/convert.c st40-4.7.3-13080/gcc/gcc/convert.c
--- gcc-4.7.3/gcc/convert.c	2012-06-18 11:00:11.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/convert.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 1987, 1988, 1991, 1992, 1993, 1994, 1995, 1997, 1998,
    2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010
    Free Software Foundation, Inc.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -583,7 +584,6 @@
       else if (outprec >= inprec)
 	{
 	  enum tree_code code;
-	  tree tem;
 
 	  /* If the precision of the EXPR's type is K bits and the
 	     destination mode has more bits, and the sign is changing,
@@ -601,13 +601,7 @@
 	  else
 	    code = NOP_EXPR;
 
-	  tem = fold_unary (code, type, expr);
-	  if (tem)
-	    return tem;
-
-	  tem = build1 (code, type, expr);
-	  TREE_NO_WARNING (tem) = 1;
-	  return tem;
+	  return fold_build1 (code, type, expr);
 	}
 
       /* If TYPE is an enumeral type or a type with a precision less
diff -urN gcc-4.7.3/gcc/cp/ChangeLog.STM st40-4.7.3-13080/gcc/gcc/cp/ChangeLog.STM
--- gcc-4.7.3/gcc/cp/ChangeLog.STM	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/cp/ChangeLog.STM	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,9 @@
+2011-03-21  Christian Bruel  <christian.bruel@st.com>
+
+	Backport from trunk: PH_CPP 82Y23
+	* parser.c: (cp_parser_primary_expressio): Don't warn.
+
+2009-03-26  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl27506
+	* name-lookup.c: (do_nonmember_using_decl): Fixed error handling.
diff -urN gcc-4.7.3/gcc/cp/name-lookup.c st40-4.7.3-13080/gcc/gcc/cp/name-lookup.c
--- gcc-4.7.3/gcc/cp/name-lookup.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/cp/name-lookup.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012
    Free Software Foundation, Inc.
    Contributed by Gabriel Dos Reis <gdr@integrable-solutions.net>
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -2564,7 +2565,11 @@
     {
       *newtype = decls.type;
       if (oldtype && *newtype && !decls_match (oldtype, *newtype))
+	{
 	error ("%qD is already declared in this scope", name);
+	  *newtype = NULL_TREE;
+	}
+
     }
 
     /* If *newval is empty, shift any class or enumeration name down.  */
diff -urN gcc-4.7.3/gcc/cppdefault.h st40-4.7.3-13080/gcc/gcc/cppdefault.h
--- gcc-4.7.3/gcc/cppdefault.h	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/cppdefault.h	2013-04-30 11:08:54.000000000 +0200
@@ -4,6 +4,7 @@
    Contributed by Per Bothner, 1994-95.
    Based on CCCP program by Paul Rubin, June 1986
    Adapted to ANSI C, Richard Stallman, Jan 1987
+   Copyright (c) 2013  STMicroelectronics.
 
    This program is free software; you can redistribute it and/or modify it
    under the terms of the GNU General Public License as published by the
@@ -69,4 +70,11 @@
 /* Return true if the toolchain is relocated.  */
 bool cpp_relocated (void);
 
+extern const char cpp_STANDARD_EXEC_PREFIX[];
+extern const size_t cpp_STANDARD_EXEC_PREFIX_len;
+extern const char *gcc_exec_prefix;
+
+/* Return true if the toolchain is relocated.  */
+bool cpp_relocated (void);
+
 #endif /* ! GCC_CPPDEFAULT_H */
diff -urN gcc-4.7.3/gcc/c-typeck.c st40-4.7.3-13080/gcc/gcc/c-typeck.c
--- gcc-4.7.3/gcc/c-typeck.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/c-typeck.c	2013-03-27 16:11:13.000000000 +0100
@@ -2,6 +2,7 @@
    Copyright (C) 1987, 1988, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998,
    1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011
    Free Software Foundation, Inc.
+   Copyright (c) 2010 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -1752,6 +1753,7 @@
       && !TREE_THIS_VOLATILE (decl)
       && TREE_READONLY (decl)
       && DECL_INITIAL (decl) != 0
+      && !DECL_WEAK (decl)
       && TREE_CODE (DECL_INITIAL (decl)) != ERROR_MARK
       /* This is invalid if initial value is not constant.
 	 If it has either a function call, a memory reference,
diff -urN gcc-4.7.3/gcc/DATESTAMP st40-4.7.3-13080/gcc/gcc/DATESTAMP
--- gcc-4.7.3/gcc/DATESTAMP	2013-04-11 15:46:13.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/DATESTAMP	2013-05-14 13:35:31.000000000 +0200
@@ -1 +1 @@
-20130411
+20130514
diff -urN gcc-4.7.3/gcc/defaults.h st40-4.7.3-13080/gcc/gcc/defaults.h
--- gcc-4.7.3/gcc/defaults.h	2012-10-01 13:18:40.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/defaults.h	2012-10-03 11:34:38.000000000 +0200
@@ -3,6 +3,7 @@
    2005, 2007, 2008, 2009, 2010, 2011
    Free Software Foundation, Inc.
    Contributed by Ron Guilmette (rfg@monkeys.com)
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -311,6 +312,15 @@
 #define TARGET_USES_WEAK_UNWIND_INFO 0
 #endif
 
+/* Use leb128 encoding based on command line options.  */
+#ifndef TARGET_USES_LEB128
+#ifdef HAVE_AS_LEB128
+#define TARGET_USES_LEB128 1
+#else
+#define TARGET_USES_LEB128 0
+#endif
+#endif
+
 /* By default, there is no prefix on user-defined symbols.  */
 #ifndef USER_LABEL_PREFIX
 #define USER_LABEL_PREFIX ""
@@ -882,6 +892,10 @@
 #define ASM_PREFERRED_EH_DATA_FORMAT(CODE,GLOBAL)  DW_EH_PE_absptr
 #endif
 
+#ifndef ASM_ALIGN_FUNCTION_LOG 
+#define ASM_ALIGN_FUNCTION_LOG(DECL) align_functions_log
+#endif
+
 /* By default, the C++ compiler will use the lowest bit of the pointer
    to function to indicate a pointer-to-member-function points to a
    virtual member function.  However, if FUNCTION_BOUNDARY indicates
diff -urN gcc-4.7.3/gcc/doc/invoke.texi st40-4.7.3-13080/gcc/gcc/doc/invoke.texi
--- gcc-4.7.3/gcc/doc/invoke.texi	2013-04-04 16:25:15.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/doc/invoke.texi	2013-04-26 09:42:27.000000000 +0200
@@ -1,6 +1,7 @@
 @c Copyright (C) 1988, 1989, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,
 @c 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012
 @c Free Software Foundation, Inc.
+@c Copyright (c) 2011  STMicroelectronics.
 @c This is part of the GCC manual.
 @c For copying conditions, see the file gcc.texi.
 
@@ -236,6 +237,7 @@
 @gccoptlist{-fsyntax-only  -fmax-errors=@var{n}  -pedantic @gol
 -pedantic-errors @gol
 -w  -Wextra  -Wall  -Waddress  -Waggregate-return  -Warray-bounds @gol
+-Wbranch-probabilities-computation
 -Wno-attributes -Wno-builtin-macro-redefined @gol
 -Wc++-compat -Wc++11-compat -Wcast-align  -Wcast-qual  @gol
 -Wchar-subscripts -Wclobbered  -Wcomment @gol
@@ -256,7 +258,7 @@
 -Wmain -Wmaybe-uninitialized -Wmissing-braces  -Wmissing-field-initializers @gol
 -Wmissing-format-attribute  -Wmissing-include-dirs @gol
 -Wno-mudflap @gol
--Wno-multichar  -Wnonnull  -Wno-overflow @gol
+-Wno-multichar -Wnonnull -Wnon-finite-math -Wno-overflow @gol
 -Woverlength-strings  -Wpacked  -Wpacked-bitfield-compat  -Wpadded @gol
 -Wparentheses  -Wpedantic-ms-format -Wno-pedantic-ms-format @gol
 -Wpointer-arith  -Wno-pointer-to-int-cast @gol
@@ -399,6 +401,7 @@
 -fschedule-insns -fschedule-insns2 -fsection-anchors @gol
 -fselective-scheduling -fselective-scheduling2 @gol
 -fsel-sched-pipelining -fsel-sched-pipelining-outer-loops @gol
+-fcse-sincos @gol
 -fshrink-wrap -fsignaling-nans -fsingle-precision-constant @gol
 -fsplit-ivs-in-unroller -fsplit-wide-types -fstack-protector @gol
 -fstack-protector-all -fstrict-aliasing -fstrict-overflow @gol
@@ -877,16 +880,18 @@
 -m2a-nofpu -m2a-single-only -m2a-single -m2a @gol
 -m3  -m3e @gol
 -m4-nofpu  -m4-single-only  -m4-single  -m4 @gol
+-m4-300-nofpu  -m4-300-single-only  -m4-300-single  -m4-300 @gol
 -m4a-nofpu -m4a-single-only -m4a-single -m4a -m4al @gol
 -m5-64media  -m5-64media-nofpu @gol
 -m5-32media  -m5-32media-nofpu @gol
 -m5-compact  -m5-compact-nofpu @gol
--mb  -ml  -mdalign  -mrelax @gol
+-mb  -ml  -mdalign  -mrelax -malign-small-blocks=@var{block-size} @gol
+-mtas -mno-tas -mfldi -mno-fldi -mmdead-delay @gol
 -mbigtable -mfmovd -mhitachi -mrenesas -mno-renesas -mnomacsave @gol
--mieee -mno-ieee -mbitops  -misize  -minline-ic_invalidate -mpadstruct @gol
--mspace -mprefergot  -musermode -multcost=@var{number} -mdiv=@var{strategy} @gol
+-mieee -mno-ieee  -mbitops  -misize  -minline-ic_invalidate -mpadstruct @gol
+-mprefergot  -musermode -multcost=@var{number} -mdiv=@var{strategy} @gol
 -mdivsi3_libfunc=@var{name} -mfixed-range=@var{register-range} @gol
--madjust-unroll -mindexed-addressing -mgettrcost=@var{number} -mpt-fixed @gol
+-mindexed-addressing -mgettrcost=@var{number} -mpt-fixed @gol
 -maccumulate-outgoing-args -minvalid-symbols -msoft-atomic @gol
 -mbranch-cost=@var{num} -mcbranchdi -mcmpeqdi -mfused-madd -mpretend-cmove}
 
@@ -2835,6 +2840,11 @@
 Generate C header describing the largest structure that is passed by
 value, if any.
 
+@item -Wbranch-probabilities-computation
+@opindex Wbranch-probabilities-computation
+Warn if edge and/or basic block counts computation is not consistent
+when using the @option{-fbranch-probabilities} option.
+
 @end table
 
 @node Language Independent Options
@@ -3042,6 +3052,7 @@
 -Wmaybe-uninitialized @gol
 -Wmissing-braces  @gol
 -Wnonnull  @gol
+-Wnon-finite-math @gol
 -Wparentheses  @gol
 -Wpointer-sign  @gol
 -Wreorder   @gol
@@ -3285,6 +3296,11 @@
 @option{-Wnonnull} is included in @option{-Wall} and @option{-Wformat}.  It
 can be disabled with the @option{-Wno-nonnull} option.
 
+@item -Wnon-finite-math
+@opindex Wnon-finite-math
+@opindex Wno-non-finite-math
+Warn if non-finite builtins are used with -ffinite-math-only.
+
 @item -Winit-self @r{(C, C++, Objective-C and Objective-C++ only)}
 @opindex Winit-self
 @opindex Wno-init-self
@@ -6991,6 +7007,10 @@
 When pipelining loops during selective scheduling, also pipeline outer loops.
 This option has no effect until @option{-fsel-sched-pipelining} is turned on.
 
+@item -fcse-sincos
+@opindex fcse-sincos
+Disable merging of the @samp{sin}, @samp{cos} operations.
+
 @item -fshrink-wrap
 @opindex fshrink-wrap
 Emit function prologues only before parts of the function that need it,
@@ -9955,6 +9975,10 @@
 designated output file of this compilation.  This puts the argument
 into the sequence of arguments that @samp{%o} will substitute later.
 
+@item %M
+If the target supports multilibs substitute the current multilib directory
+otherwise substitute @samp{.}.
+
 @item %o
 Substitutes the names of all the output files, with spaces
 automatically placed around them.  You should write spaces
@@ -10093,11 +10117,11 @@
 
 @table @code
 @item @code{getenv}
-The @code{getenv} spec function takes two arguments: an environment
-variable name and a string.  If the environment variable is not
-defined, a fatal error is issued.  Otherwise, the return value is the
-value of the environment variable concatenated with the string.  For
-example, if @env{TOPDIR} is defined as @file{/path/to/top}, then:
+The @code{getenv} spec function takes two or more arguments: an environment
+variable name and a list of strings.  If the environment variable is not
+defined, a fatal error is issued.  Otherwise, the return value is the value
+of the environment variable concatenated with the strings.  For example, if
+@env{TOPDIR} is defined as @file{/path/to/top}, then:
 
 @smallexample
 %:getenv(TOPDIR /include)
@@ -17925,6 +17949,24 @@
 @opindex m4
 Generate code for the SH4.
 
+@item -m4-300-nofpu
+@opindex m4-300-nofpu
+Generate code for the ST40-300 without a floating-point unit.
+
+@item -m4-300-single-only
+@opindex m4-300-single-only
+Generate code for the ST40-300 with a floating-point unit that only
+supports single-precision arithmetic.
+
+@item -m4-300-single
+@opindex m4-300-single
+Generate code for the ST40-300 assuming the floating-point unit is in
+single-precision mode by default.
+
+@item -m4-300
+@opindex m4-300
+Generate code for the ST40-300.
+
 @item -m4a-nofpu
 @opindex m4a-nofpu
 Generate code for the SH4al-dsp, or for a SH4a in such a way that the
@@ -17964,6 +18006,12 @@
 conventions, and thus some functions from the standard C library will
 not work unless you recompile it first with @option{-mdalign}.
 
+@item -mtas
+@itemx -mno-tas
+@opindex mtas
+@opindex mno-tas
+Allow or disallow the @code{tas.b} instruction.
+
 @item -mrelax
 @opindex mrelax
 Shorten some address references at link time, when possible; uses the
@@ -17978,6 +18026,16 @@
 @opindex mbitops
 Enable the use of bit manipulation instructions on SH2A.
 
+@item -mdead-delay
+@opindex mdead-delay
+Try to eliminate dead delay slot instructions.
+
+@item -mfldi
+@itemx -mno-fldfi
+@opindex mfldi
+@opindex mno-fldi
+Enable or disable the use of the instruction @code{fldi0} and @code{fldi1}. When disabled floating point zero/one constants are loaded from the constant pool. Default is enabled.
+
 @item -mfmovd
 @opindex mfmovd
 Enable the use of the instruction @code{fmovd}.  Check @option{-mdalign} for
@@ -18044,10 +18102,6 @@
 This option is enabled by default when the target is @code{sh-*-linux*}.
 For details on the atomic built-in functions see @ref{__atomic Builtins}.
 
-@item -mspace
-@opindex mspace
-Optimize for space instead of speed.  Implied by @option{-Os}.
-
 @item -mprefergot
 @opindex mprefergot
 When generating position-independent code, emit function calls using
@@ -18175,11 +18229,10 @@
 two registers separated by a dash.  Multiple register ranges can be
 specified separated by a comma.
 
-@item -madjust-unroll
-@opindex madjust-unroll
-Throttle unrolling to avoid thrashing target registers.
-This option only has an effect if the gcc code base supports the
-TARGET_ADJUST_UNROLL_MAX target hook.
+@item -malign-small-blocks=@var{number}
+@opindex align-small-blocks=@var{number}
+Set the size among which basic blocks are aligned on cache line boundaries.
+Default is 16 bytes. 0 means default alignment.
 
 @item -mindexed-addressing
 @opindex mindexed-addressing
diff -urN gcc-4.7.3/gcc/doc/md.texi st40-4.7.3-13080/gcc/gcc/doc/md.texi
--- gcc-4.7.3/gcc/doc/md.texi	2012-10-01 13:18:40.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/doc/md.texi	2013-04-30 11:08:54.000000000 +0200
@@ -1,6 +1,7 @@
 @c Copyright (C) 1988, 1989, 1992, 1993, 1994, 1996, 1998, 1999, 2000, 2001,
 @c 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011
 @c Free Software Foundation, Inc.
+@c Copyright (c) 2013  STMicroelectronics.
 @c This is part of the GCC manual.
 @c For copying conditions, see the file gcc.texi.
 
@@ -3211,6 +3212,37 @@
 
 @end table
 
+@item SH---@file{config/sh/constraints.md}
+@table @code
+@item c
+FPSCR. Floating-point status/control register
+
+@item d
+Any 64-bit Floating-point register
+
+@item f
+Any 32-bit Floating-point register
+
+@item l
+PR register
+
+@item t
+T bit from SR. Status register
+
+@item w
+FR0 floating-point register
+
+@item x
+MAC register (MACH and MACL)
+
+@item y
+FPUL register
+
+@item z
+R0 register
+
+@end table
+
 @item SPU---@file{config/spu/spu.h}
 @table @code
 @item a
diff -urN gcc-4.7.3/gcc/doc/tm.texi st40-4.7.3-13080/gcc/gcc/doc/tm.texi
--- gcc-4.7.3/gcc/doc/tm.texi	2012-10-01 13:18:40.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/doc/tm.texi	2013-04-30 13:42:26.000000000 +0200
@@ -3434,6 +3434,13 @@
 linkage is necessary.  The default is @code{0}.
 @end defmac
 
+@defmac TARGET_USES_LEB128
+A C expression that evaluates to true if the target requires leb128
+to be used for dwarf compression.  Define it to be @code{1} if leb128
+linkage is necessary.  The default is @code{1} if @code{HAVE_AS_LEB128}
+is defined.
+@end defmac
+
 @node Stack Checking
 @subsection Specifying How Stack Checking is Done
 
@@ -9776,10 +9783,10 @@
 @code{num_modes_for_mode_switching[@var{entity}] - 1}.
 @end defmac
 
-@defmac EMIT_MODE_SET (@var{entity}, @var{mode}, @var{hard_regs_live})
+@defmac EMIT_MODE_SET (@var{entity}, @var{mode}, @var{flip}, @var{hard_regs_live})
 Generate one or more insns to set @var{entity} to @var{mode}.
 @var{hard_reg_live} is the set of hard registers live at the point where
-the insn(s) are to be inserted.
+the insn(s) are to be inserted. @var{flip} is a boolean to indicate that current mode can be flipped.
 @end defmac
 
 @node Target Attributes
diff -urN gcc-4.7.3/gcc/doc/tm.texi.in st40-4.7.3-13080/gcc/gcc/doc/tm.texi.in
--- gcc-4.7.3/gcc/doc/tm.texi.in	2012-10-01 13:18:40.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/doc/tm.texi.in	2012-10-03 11:34:38.000000000 +0200
@@ -3414,6 +3414,13 @@
 linkage is necessary.  The default is @code{0}.
 @end defmac
 
+@defmac TARGET_USES_LEB128
+A C expression that evaluates to true if the target requires leb128
+to be used for dwarf compression.  Define it to be @code{1} if leb128
+linkage is necessary.  The default is @code{1} if @code{HAVE_AS_LEB128}
+is defined.
+@end defmac
+
 @node Stack Checking
 @subsection Specifying How Stack Checking is Done
 
@@ -9665,10 +9672,10 @@
 @code{num_modes_for_mode_switching[@var{entity}] - 1}.
 @end defmac
 
-@defmac EMIT_MODE_SET (@var{entity}, @var{mode}, @var{hard_regs_live})
+@defmac EMIT_MODE_SET (@var{entity}, @var{mode}, @var{flip}, @var{hard_regs_live})
 Generate one or more insns to set @var{entity} to @var{mode}.
 @var{hard_reg_live} is the set of hard registers live at the point where
-the insn(s) are to be inserted.
+the insn(s) are to be inserted. @var{flip} is a boolean to indicate that current mode can be flipped.
 @end defmac
 
 @node Target Attributes
diff -urN gcc-4.7.3/gcc/dwarf2asm.c st40-4.7.3-13080/gcc/gcc/dwarf2asm.c
--- gcc-4.7.3/gcc/dwarf2asm.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/dwarf2asm.c	2013-04-30 11:08:54.000000000 +0200
@@ -1,6 +1,7 @@
 /* Dwarf2 assembler output helper routines.
    Copyright (C) 2001, 2002, 2003, 2004, 2005, 2007, 2008, 2009, 2010, 2011
    Free Software Foundation, Inc.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -591,31 +592,33 @@
 
   va_start (ap, comment);
 
-#ifdef HAVE_AS_LEB128
-  fputs ("\t.uleb128 ", asm_out_file);
-  fprint_whex (asm_out_file, value);
-
-  if (flag_debug_asm && comment)
+  if (TARGET_USES_LEB128)
     {
-      fprintf (asm_out_file, "\t%s ", ASM_COMMENT_START);
-      vfprintf (asm_out_file, comment, ap);
+      fputs ("\t.uleb128 ", asm_out_file);
+      fprint_whex (asm_out_file, value);
+
+      if (flag_debug_asm && comment)
+	{
+	  fprintf (asm_out_file, "\t%s ", ASM_COMMENT_START);
+	  vfprintf (asm_out_file, comment, ap);
+	}
     }
-#else
-  {
-    unsigned HOST_WIDE_INT work = value;
-    const char *byte_op = targetm.asm_out.byte_op;
+  else
+    {
+      unsigned HOST_WIDE_INT work = value;
+      const char *byte_op = targetm.asm_out.byte_op;
 
-    if (byte_op)
-      fputs (byte_op, asm_out_file);
-    do
-      {
-	int byte = (work & 0x7f);
-	work >>= 7;
-	if (work != 0)
-	  /* More bytes to follow.  */
-	  byte |= 0x80;
+      if (byte_op)
+	fputs (byte_op, asm_out_file);
+      do
+	{
+	  int byte = (work & 0x7f);
+	  work >>= 7;
+	  if (work != 0)
+	    /* More bytes to follow.  */
+	    byte |= 0x80;
 
-	if (byte_op)
+	  if (byte_op)
 	  {
 	    fprintf (asm_out_file, "%#x", byte);
 	    if (work != 0)
@@ -623,21 +626,21 @@
 	  }
 	else
 	  assemble_integer (GEN_INT (byte), 1, BITS_PER_UNIT, 1);
-      }
-    while (work != 0);
+	}
+      while (work != 0);
 
-  if (flag_debug_asm)
-    {
-      fprintf (asm_out_file, "\t%s uleb128 " HOST_WIDE_INT_PRINT_HEX,
-	       ASM_COMMENT_START, value);
-      if (comment)
+      if (flag_debug_asm)
 	{
-	  fputs ("; ", asm_out_file);
-	  vfprintf (asm_out_file, comment, ap);
+	  fprintf (asm_out_file, "\t%s uleb128 " HOST_WIDE_INT_PRINT_HEX,
+		   ASM_COMMENT_START, value);
+	  if (comment)
+	    {
+	      fputs ("; ", asm_out_file);
+	      vfprintf (asm_out_file, comment, ap);
+	    }
 	}
     }
-  }
-#endif
+
   putc ('\n', asm_out_file);
 
   va_end (ap);
@@ -739,14 +742,15 @@
 
   va_start (ap, comment);
 
-#ifdef HAVE_AS_LEB128
-  fputs ("\t.uleb128 ", asm_out_file);
-  assemble_name (asm_out_file, lab1);
-  putc ('-', asm_out_file);
-  assemble_name (asm_out_file, lab2);
-#else
-  gcc_unreachable ();
-#endif
+  if (TARGET_USES_LEB128)
+    {
+      fputs ("\t.uleb128 ", asm_out_file);
+      assemble_name (asm_out_file, lab1);
+      putc ('-', asm_out_file);
+      assemble_name (asm_out_file, lab2);
+    }
+  else
+    gcc_unreachable ();
 
   if (flag_debug_asm && comment)
     {
diff -urN gcc-4.7.3/gcc/dwarf2cfi.c st40-4.7.3-13080/gcc/gcc/dwarf2cfi.c
--- gcc-4.7.3/gcc/dwarf2cfi.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/dwarf2cfi.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 1992, 1993, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002,
    2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011
    Free Software Foundation, Inc.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -2441,10 +2442,15 @@
 		  HOST_WIDE_INT restore_args_size;
 		  cfi_vec save_row_reg_save;
 
+                 /* If ELT is an instruction from target of an annulled
+                    branch, the effects are for the target only and so
+                    the args_size and CFA along the current path
+                    shouldn't change.  */
 		  add_cfi_insn = NULL;
 		  restore_args_size = cur_trace->end_true_args_size;
 		  cur_cfa = &cur_row->cfa;
-		  save_row_reg_save = VEC_copy (dw_cfi_ref, gc, cur_row->reg_save);
+		  save_row_reg_save
+		    = VEC_copy (dw_cfi_ref, gc, cur_row->reg_save);
 
 		  scan_insn_after (elt);
 
@@ -2457,8 +2463,20 @@
 		  cur_row->cfa = this_cfa;
 		  cur_row->reg_save = save_row_reg_save;
 		  cur_cfa = &this_cfa;
-		  continue;
 		}
+             else
+               {
+                 /* If ELT is a annulled branch-taken instruction (i.e.
+                    executed only when branch is not taken), the args_size
+                    and CFA should not change through the jump.  */
+                 create_trace_edges (control);
+
+                 /* Update and continue with the trace.  */
+                 add_cfi_insn = insn;
+                 scan_insn_after (elt);
+                 def_cfa_1 (&this_cfa);
+               }
+	      continue;
 	    }
 
 	  /* The insns in the delay slot should all be considered to happen
diff -urN gcc-4.7.3/gcc/dwarf2out.c st40-4.7.3-13080/gcc/gcc/dwarf2out.c
--- gcc-4.7.3/gcc/dwarf2out.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/dwarf2out.c	2013-05-06 15:35:37.000000000 +0200
@@ -1,6 +1,7 @@
 /* Output Dwarf2 format symbol table information from GCC.
    Copyright (C) 1992, 1993, 1995, 1996, 1997, 1998, 1999, 2000, 2001, 2002,
    2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012
+   Copyright (c) 2013  STMicroelectronics.
    Free Software Foundation, Inc.
    Contributed by Gary Funck (gary@intrepid.com).
    Derived from DWARF 1 implementation of Ron Guilmette (rfg@monkeys.com).
@@ -10273,25 +10274,27 @@
 multiple_reg_loc_descriptor (rtx rtl, rtx regs,
 			     enum var_init_status initialized)
 {
-  int nregs, size, i;
-  unsigned reg;
+  int size, i;
   dw_loc_descr_ref loc_result = NULL;
 
-  reg = REGNO (rtl);
-#ifdef LEAF_REG_REMAP
-  if (current_function_uses_only_leaf_regs)
-    {
-      int leaf_reg = LEAF_REG_REMAP (reg);
-      if (leaf_reg != -1)
-	reg = (unsigned) leaf_reg;
-    }
-#endif
-  gcc_assert ((unsigned) DBX_REGISTER_NUMBER (reg) == dbx_reg_number (rtl));
-  nregs = hard_regno_nregs[REGNO (rtl)][GET_MODE (rtl)];
-
   /* Simple, contiguous registers.  */
   if (regs == NULL_RTX)
     {
+      unsigned reg = REGNO (rtl);
+      int nregs;
+
+#ifdef LEAF_REG_REMAP
+      if (current_function_uses_only_leaf_regs)
+	{
+	  int leaf_reg = LEAF_REG_REMAP (reg);
+	  if (leaf_reg != -1)
+	    reg = (unsigned) leaf_reg;
+	}
+#endif
+
+      gcc_assert ((unsigned) DBX_REGISTER_NUMBER (reg) == dbx_reg_number (rtl));
+      nregs = hard_regno_nregs[REGNO (rtl)][GET_MODE (rtl)];
+
       size = GET_MODE_SIZE (GET_MODE (rtl)) / nregs;
 
       loc_result = NULL;
@@ -10319,10 +10322,9 @@
     {
       dw_loc_descr_ref t;
 
-      t = one_reg_loc_descriptor (REGNO (XVECEXP (regs, 0, i)),
+      t = one_reg_loc_descriptor (dbx_reg_number (XVECEXP (regs, 0, i)),
 				  VAR_INIT_STATUS_INITIALIZED);
       add_loc_descr (&loc_result, t);
-      size = GET_MODE_SIZE (GET_MODE (XVECEXP (regs, 0, 0)));
       add_loc_descr_op_piece (&loc_result, size);
     }
 
diff -urN gcc-4.7.3/gcc/emit-rtl.c st40-4.7.3-13080/gcc/gcc/emit-rtl.c
--- gcc-4.7.3/gcc/emit-rtl.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/emit-rtl.c	2013-03-27 16:11:13.000000000 +0100
@@ -3,6 +3,7 @@
    1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,
    2010, 2011
    Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -4297,8 +4298,18 @@
   PREV_INSN (first) = after;
   NEXT_INSN (last) = after_after;
   if (after_after)
+
+    {
     PREV_INSN (after_after) = last;
 
+      if (NONJUMP_INSN_P (after_after)
+	  && GET_CODE (PATTERN (after_after)) == SEQUENCE)
+	{
+	  rtx sequence = PATTERN (after_after);
+	  PREV_INSN (XVECEXP (sequence, 0, 0)) = last;
+	}
+    }
+
   if (after == get_last_insn())
     set_last_insn (last);
 
diff -urN gcc-4.7.3/gcc/except.c st40-4.7.3-13080/gcc/gcc/except.c
--- gcc-4.7.3/gcc/except.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/except.c	2013-04-30 11:08:54.000000000 +0200
@@ -1,6 +1,7 @@
 /* Implements exception handling.
    Copyright (C) 1989, 1992, 1993, 1994, 1995, 1996, 1997, 1998,
    1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011
+   Copyright (c) 2013  STMicroelectronics.
    Free Software Foundation, Inc.
    Contributed by Mike Stump <mrs@cygnus.com>.
 
@@ -192,10 +193,10 @@
 
 static void push_uleb128 (VEC (uchar, gc) **, unsigned int);
 static void push_sleb128 (VEC (uchar, gc) **, int);
-#ifndef HAVE_AS_LEB128
+
 static int dw2_size_of_call_site_table (int);
 static int sjlj_size_of_call_site_table (void);
-#endif
+
 static void dw2_output_call_site_table (int, int);
 static void sjlj_output_call_site_table (void);
 
@@ -1547,7 +1548,7 @@
    Only used by reload hackery; should not be used by new code.  */
 
 void
-for_each_eh_label (void (*callback) (rtx))
+for_each_eh_label (void (*callback) (rtx, void *), void *arg)
 {
   eh_landing_pad lp;
   int i;
@@ -1558,7 +1559,7 @@
 	{
 	  rtx lab = lp->landing_pad;
 	  if (lab && LABEL_P (lab))
-	    (*callback) (lab);
+	    (*callback) (lab, arg);
 	}
     }
 }
@@ -2614,7 +2615,6 @@
 }
 
 
-#ifndef HAVE_AS_LEB128
 static int
 dw2_size_of_call_site_table (int section)
 {
@@ -2649,7 +2649,6 @@
 
   return size;
 }
-#endif
 
 static void
 dw2_output_call_site_table (int cs_format, int section)
@@ -2843,13 +2842,10 @@
 output_one_function_exception_table (int section)
 {
   int tt_format, cs_format, lp_format, i;
-#ifdef HAVE_AS_LEB128
   char ttype_label[32];
   char cs_after_size_label[32];
   char cs_end_label[32];
-#else
   int call_site_len;
-#endif
   int have_tt_data;
   int tt_format_size = 0;
 
@@ -2864,11 +2860,11 @@
   else
     {
       tt_format = ASM_PREFERRED_EH_DATA_FORMAT (/*code=*/0, /*global=*/1);
-#ifdef HAVE_AS_LEB128
-      ASM_GENERATE_INTERNAL_LABEL (ttype_label,
-				   section ? "LLSDATTC" : "LLSDATT",
-				   current_function_funcdef_no);
-#endif
+      if (TARGET_USES_LEB128)
+	ASM_GENERATE_INTERNAL_LABEL (ttype_label,
+				     section ? "LLSDATTC" : "LLSDATT",
+				     current_function_funcdef_no);
+
       tt_format_size = size_of_encoded_value (tt_format);
 
       assemble_align (tt_format_size * BITS_PER_UNIT);
@@ -2894,86 +2890,93 @@
   dw2_asm_output_data (1, tt_format, "@TType format (%s)",
 		       eh_data_format_name (tt_format));
 
-#ifndef HAVE_AS_LEB128
-  if (targetm_common.except_unwind_info (&global_options) == UI_SJLJ)
-    call_site_len = sjlj_size_of_call_site_table ();
-  else
-    call_site_len = dw2_size_of_call_site_table (section);
-#endif
+  if (! TARGET_USES_LEB128)
+    {
+      if (targetm_common.except_unwind_info (&global_options) == UI_SJLJ)
+	call_site_len = sjlj_size_of_call_site_table ();
+      else
+	call_site_len = dw2_size_of_call_site_table (section);
+    }
 
   /* A pc-relative 4-byte displacement to the @TType data.  */
   if (have_tt_data)
     {
-#ifdef HAVE_AS_LEB128
-      char ttype_after_disp_label[32];
-      ASM_GENERATE_INTERNAL_LABEL (ttype_after_disp_label,
-				   section ? "LLSDATTDC" : "LLSDATTD",
-				   current_function_funcdef_no);
-      dw2_asm_output_delta_uleb128 (ttype_label, ttype_after_disp_label,
-				    "@TType base offset");
-      ASM_OUTPUT_LABEL (asm_out_file, ttype_after_disp_label);
-#else
-      /* Ug.  Alignment queers things.  */
-      unsigned int before_disp, after_disp, last_disp, disp;
+      if (TARGET_USES_LEB128)
+	{
+	  char ttype_after_disp_label[32];
+	  ASM_GENERATE_INTERNAL_LABEL (ttype_after_disp_label,
+				       section ? "LLSDATTDC" : "LLSDATTD",
+				       current_function_funcdef_no);
+	  dw2_asm_output_delta_uleb128 (ttype_label, ttype_after_disp_label,
+					"@TType base offset");
+	  ASM_OUTPUT_LABEL (asm_out_file, ttype_after_disp_label);
+	}
+      else
+	{
+	  /* Ug.  Alignment queers things.  */
+	  unsigned int before_disp, after_disp, last_disp, disp;
 
-      before_disp = 1 + 1;
-      after_disp = (1 + size_of_uleb128 (call_site_len)
-		    + call_site_len
-		    + VEC_length (uchar, crtl->eh.action_record_data)
-		    + (VEC_length (tree, cfun->eh->ttype_data)
-		       * tt_format_size));
+	  before_disp = 1 + 1;
+	  after_disp = (1 + size_of_uleb128 (call_site_len)
+			+ call_site_len
+			+ VEC_length (uchar, crtl->eh.action_record_data)
+			+ (VEC_length (tree, cfun->eh->ttype_data)
+			   * tt_format_size));
 
-      disp = after_disp;
-      do
-	{
-	  unsigned int disp_size, pad;
+	  disp = after_disp;
+	  do
+	    {
+	      unsigned int disp_size, pad;
 
-	  last_disp = disp;
-	  disp_size = size_of_uleb128 (disp);
-	  pad = before_disp + disp_size + after_disp;
-	  if (pad % tt_format_size)
-	    pad = tt_format_size - (pad % tt_format_size);
-	  else
-	    pad = 0;
-	  disp = after_disp + pad;
-	}
-      while (disp != last_disp);
+	      last_disp = disp;
+	      disp_size = size_of_uleb128 (disp);
+	      pad = before_disp + disp_size + after_disp;
+	      if (pad % tt_format_size)
+		pad = tt_format_size - (pad % tt_format_size);
+	      else
+		pad = 0;
+	      disp = after_disp + pad;
+	    }
+	  while (disp != last_disp);
 
-      dw2_asm_output_data_uleb128 (disp, "@TType base offset");
-#endif
+	  dw2_asm_output_data_uleb128 (disp, "@TType base offset");
+	}
     }
 
   /* Indicate the format of the call-site offsets.  */
-#ifdef HAVE_AS_LEB128
-  cs_format = DW_EH_PE_uleb128;
-#else
-  cs_format = DW_EH_PE_udata4;
-#endif
+ if (TARGET_USES_LEB128)
+   cs_format = DW_EH_PE_uleb128;
+ else
+   cs_format = DW_EH_PE_udata4;
+
   dw2_asm_output_data (1, cs_format, "call-site format (%s)",
 		       eh_data_format_name (cs_format));
 
-#ifdef HAVE_AS_LEB128
-  ASM_GENERATE_INTERNAL_LABEL (cs_after_size_label,
-			       section ? "LLSDACSBC" : "LLSDACSB",
-			       current_function_funcdef_no);
-  ASM_GENERATE_INTERNAL_LABEL (cs_end_label,
-			       section ? "LLSDACSEC" : "LLSDACSE",
-			       current_function_funcdef_no);
-  dw2_asm_output_delta_uleb128 (cs_end_label, cs_after_size_label,
-				"Call-site table length");
-  ASM_OUTPUT_LABEL (asm_out_file, cs_after_size_label);
-  if (targetm_common.except_unwind_info (&global_options) == UI_SJLJ)
-    sjlj_output_call_site_table ();
-  else
-    dw2_output_call_site_table (cs_format, section);
-  ASM_OUTPUT_LABEL (asm_out_file, cs_end_label);
-#else
-  dw2_asm_output_data_uleb128 (call_site_len, "Call-site table length");
-  if (targetm_common.except_unwind_info (&global_options) == UI_SJLJ)
-    sjlj_output_call_site_table ();
-  else
-    dw2_output_call_site_table (cs_format, section);
-#endif
+if (TARGET_USES_LEB128)
+    {
+      ASM_GENERATE_INTERNAL_LABEL (cs_after_size_label,
+				   section ? "LLSDACSBC" : "LLSDACSB",
+				   current_function_funcdef_no);
+      ASM_GENERATE_INTERNAL_LABEL (cs_end_label,
+				   section ? "LLSDACSEC" : "LLSDACSE",
+				   current_function_funcdef_no);
+      dw2_asm_output_delta_uleb128 (cs_end_label, cs_after_size_label,
+				    "Call-site table length");
+      ASM_OUTPUT_LABEL (asm_out_file, cs_after_size_label);
+      if (targetm_common.except_unwind_info (&global_options) == UI_SJLJ)
+	sjlj_output_call_site_table ();
+      else
+	dw2_output_call_site_table (cs_format, section);
+      ASM_OUTPUT_LABEL (asm_out_file, cs_end_label);
+    }
+ else
+   {
+     dw2_asm_output_data_uleb128 (call_site_len, "Call-site table length");
+     if (targetm_common.except_unwind_info (&global_options) == UI_SJLJ)
+       sjlj_output_call_site_table ();
+     else
+       dw2_output_call_site_table (cs_format, section);
+   }
 
   /* ??? Decode and interpret the data for flag_debug_asm.  */
   {
@@ -2992,10 +2995,8 @@
       output_ttype (type, tt_format, tt_format_size);
     }
 
-#ifdef HAVE_AS_LEB128
-  if (have_tt_data)
+  if (TARGET_USES_LEB128 && have_tt_data)
       ASM_OUTPUT_LABEL (asm_out_file, ttype_label);
-#endif
 
   /* ??? Decode and interpret the data for flag_debug_asm.  */
   if (targetm.arm_eabi_unwinder)
diff -urN gcc-4.7.3/gcc/except.h st40-4.7.3-13080/gcc/gcc/except.h
--- gcc-4.7.3/gcc/except.h	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/except.h	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 1996, 1997, 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005,
    2007, 2008, 2009, 2010  Free Software Foundation, Inc.
    Contributed by Mike Stump <mrs@cygnus.com>.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -231,7 +232,7 @@
 
 /* Invokes CALLBACK for every exception handler label.  Only used by old
    loop hackery; should not be used by new code.  */
-extern void for_each_eh_label (void (*) (rtx));
+extern void for_each_eh_label (void (*) (rtx, void*), void*);
 
 extern void init_eh_for_function (void);
 
diff -urN gcc-4.7.3/gcc/final.c st40-4.7.3-13080/gcc/gcc/final.c
--- gcc-4.7.3/gcc/final.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/final.c	2012-04-27 08:59:21.000000000 +0200
@@ -3,6 +3,7 @@
    1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,
    2010, 2011
    Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -374,6 +375,22 @@
     }
 }
 
+#ifdef ADJUST_INSN_LENGTH
+static void realloc_insn_lengths (int uid, char **varying_length)
+{
+  int max_uid = get_max_uid ();
+
+  gcc_assert (insn_lengths);
+
+  insn_lengths = XRESIZEVEC (int, insn_lengths, max_uid);
+  insn_lengths[uid] = 0;
+  insn_lengths_max_uid = max_uid;
+  insn_lengths[uid] = 0;
+  *varying_length = XRESIZEVEC (char, *varying_length, max_uid);
+  (*varying_length)[uid] = 0;
+}
+#endif
+
 /* Obtain the current length of an insn.  If branch shortening has been done,
    get its actual length.  Otherwise, use FALLBACK_FN to calculate the
    length.  */
@@ -657,13 +674,12 @@
 insn_current_reference_address (rtx branch)
 {
   rtx dest, seq;
-  int seq_uid;
 
   if (! INSN_ADDRESSES_SET_P ())
     return 0;
 
   seq = NEXT_INSN (PREV_INSN (branch));
-  seq_uid = INSN_UID (seq);
+
   if (!JUMP_P (branch))
     /* This can happen for example on the PA; the objective is to know the
        offset to address something in front of the start of the function.
@@ -678,7 +694,7 @@
   if (INSN_SHUID (seq) < INSN_SHUID (dest))
     {
       /* Forward branch.  */
-      return (insn_last_address + insn_lengths[seq_uid]
+      return (insn_last_address + insn_min_length (branch)
 	      - align_fuzz (seq, dest, length_unit_log, ~0));
     }
   else
@@ -976,6 +992,11 @@
     }
 #ifdef HAVE_ATTR_length
 
+  gcc_assert (insn_lengths == 0);
+
+  /* New insn might have been created by insn_length_adjustment.  */
+  max_uid = get_max_uid ();
+
   /* Allocate the rest of the arrays.  */
   insn_lengths = XNEWVEC (int, max_uid);
   insn_lengths_max_uid = max_uid;
@@ -1107,7 +1128,10 @@
 	  /* Alignment is handled by ADDR_VEC_ALIGN.  */
 	}
       else if (GET_CODE (body) == ASM_INPUT || asm_noperands (body) >= 0)
+	{
 	insn_lengths[uid] = asm_insn_count (body) * insn_default_length (insn);
+	  varying_length[uid] = 1;
+	}
       else if (GET_CODE (body) == SEQUENCE)
 	{
 	  int i;
@@ -1150,12 +1174,23 @@
       else if (GET_CODE (body) != USE && GET_CODE (body) != CLOBBER)
 	{
 	  insn_lengths[uid] = insn_default_length (insn);
+
+#ifdef VARYING_INSN_P
+	  if (VARYING_INSN_P (insn))
+	    varying_length[uid] = 1;
+	  else
+#endif
 	  varying_length[uid] = insn_variable_length_p (insn);
 	}
 
       /* If needed, do any adjustment.  */
 #ifdef ADJUST_INSN_LENGTH
       ADJUST_INSN_LENGTH (insn, insn_lengths[uid]);
+      if (max_uid != get_max_uid ())
+	{
+	  realloc_insn_lengths (max_uid, &varying_length);
+	  max_uid = get_max_uid ();
+	}
       if (insn_lengths[uid] < 0)
 	fatal_insn ("negative insn length", insn);
 #endif
@@ -1184,7 +1219,7 @@
 	  if (LABEL_P (insn))
 	    {
 	      int log = LABEL_TO_ALIGNMENT (insn);
-	      if (log > insn_current_align)
+	      if (log >= insn_current_align)
 		{
 		  int align = 1 << log;
 		  int new_address= (insn_current_address + align - 1) & -align;
@@ -1335,10 +1370,10 @@
 		}
 	      else
 		insn_current_address += insn_lengths[uid];
-
 	      continue;
 	    }
 
+	  /* Varying_length.  */
 	  if (NONJUMP_INSN_P (insn) && GET_CODE (PATTERN (insn)) == SEQUENCE)
 	    {
 	      int i;
@@ -1360,6 +1395,16 @@
 		  else
 		    inner_length = insn_current_length (inner_insn);
 
+#ifdef ADJUST_INSN_LENGTH
+		  /* If needed, do any adjustment.  */
+		  ADJUST_INSN_LENGTH (inner_insn, inner_length);
+		  if (max_uid != get_max_uid ())
+		    {
+		      realloc_insn_lengths (max_uid, &varying_length);
+		      max_uid = get_max_uid ();
+		    }
+#endif
+
 		  if (inner_length != insn_lengths[inner_uid])
 		    {
 		      insn_lengths[inner_uid] = inner_length;
@@ -1371,7 +1416,20 @@
 	    }
 	  else
 	    {
+	      rtx body = PATTERN (insn);
+
+	      if (GET_CODE (body) == ASM_INPUT || asm_noperands (body) >= 0)
+		new_length = asm_insn_count (body) * insn_default_length (insn);
+	      else  
+		{
+#ifdef VARYING_INSN_P 
+		  if (VARYING_INSN_P (insn))
+		    new_length = insn_lengths[uid];
+		  else
+#endif
 	      new_length = insn_current_length (insn);
+		}
+
 	      insn_current_address += new_length;
 	    }
 
@@ -1380,6 +1438,11 @@
 	  tmp_length = new_length;
 	  ADJUST_INSN_LENGTH (insn, new_length);
 	  insn_current_address += (new_length - tmp_length);
+	  if (max_uid != get_max_uid ())
+	    {
+	      realloc_insn_lengths (max_uid, &varying_length);
+	      max_uid = get_max_uid ();
+	    }
 #endif
 
 	  if (new_length != insn_lengths[uid])
@@ -1388,9 +1451,6 @@
 	      something_changed = 1;
 	    }
 	}
-      /* For a non-optimizing compile, do only a single pass.  */
-      if (!optimize)
-	break;
     }
 
   free (varying_length);
@@ -1427,10 +1487,14 @@
   if (!*templ)
     return 0;
 
+#ifdef TARGET_ASM_COUNT
+  count = TARGET_ASM_COUNT (templ, 0);
+#else
   for (; *templ; templ++)
     if (IS_ASM_LOGICAL_LINE_SEPARATOR (*templ, templ)
 	|| *templ == '\n')
       count++;
+#endif
 
   return count;
 }
@@ -1488,6 +1552,8 @@
   const char *name;
   size_t name_len;
 
+  CYGPATH (filename);
+
   for (map = debug_prefix_maps; map; map = map->next)
     if (filename_ncmp (filename, map->old_prefix, map->old_len) == 0)
       break;
@@ -2114,6 +2180,10 @@
 
 	  if (align && NEXT_INSN (insn))
 	    {
+#ifdef FINAL_PRESCAN_INSN
+	FINAL_PRESCAN_INSN (insn, recog_data.operand, recog_data.n_operands);
+#endif
+
 #ifdef ASM_OUTPUT_MAX_SKIP_ALIGN
 	      ASM_OUTPUT_MAX_SKIP_ALIGN (file, align, max_skip);
 #else
@@ -4558,3 +4628,12 @@
   0                                     /* todo_flags_finish */
  }
 };
+
+int
+print_address (int uid)
+{
+  if (! INSN_ADDRESSES_SET_P ())
+    return 0;
+
+  return INSN_ADDRESSES (uid);
+}
diff -urN gcc-4.7.3/gcc/fold-const.c st40-4.7.3-13080/gcc/gcc/fold-const.c
--- gcc-4.7.3/gcc/fold-const.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/fold-const.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 1987, 1988, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999,
    2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011,
    2012 Free Software Foundation, Inc.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -7092,7 +7093,7 @@
 			  tree arg0, tree arg1)
 {
   tree arg00, arg01, arg10, arg11;
-  tree alt0 = NULL_TREE, alt1 = NULL_TREE, same;
+  tree alt0 = NULL_TREE, alt1 = NULL_TREE, same = NULL_TREE;
 
   /* (A * C) +- (B * C) -> (A+-B) * C.
      (A * C) +- A -> A * (C+-1).
@@ -7146,7 +7147,6 @@
       arg10 = arg1;
       arg11 = build_one_cst (type);
     }
-  same = NULL_TREE;
 
   if (operand_equal_p (arg01, arg11, 0))
     same = arg01, alt0 = arg00, alt1 = arg10;
@@ -7157,10 +7157,18 @@
   else if (operand_equal_p (arg01, arg10, 0))
     same = arg01, alt0 = arg00, alt1 = arg11;
 
+  if (same)
+    {
+      /* Catch base+index gimple trees.  */
+      if (host_integerp (same, 1) && exact_log2 (TREE_INT_CST_LOW (same)) > 0)
+	return NULL_TREE;
+    }
+  else 
+
   /* No identical multiplicands; see if we can find a common
      power-of-two factor in non-power-of-two multiplies.  This
      can help in multi-dimensional array access.  */
-  else if (host_integerp (arg01, 0)
+  if (host_integerp (arg01, 0)
 	   && host_integerp (arg11, 0))
     {
       HOST_WIDE_INT int01, int11, tmp;
@@ -7197,11 +7205,16 @@
     }
 
   if (same)
+    {
+      if (! (host_integerp (alt1, 0) &&
+	     host_integerp (same, 1) &&
+	     exact_log2 (TREE_INT_CST_LOW (same)) > 0))
     return fold_build2_loc (loc, MULT_EXPR, type,
 			fold_build2_loc (loc, code, type,
 				     fold_convert_loc (loc, type, alt0),
 				     fold_convert_loc (loc, type, alt1)),
 			fold_convert_loc (loc, type, same));
+    }
 
   return NULL_TREE;
 }
diff -urN gcc-4.7.3/gcc/fwprop.c st40-4.7.3-13080/gcc/gcc/fwprop.c
--- gcc-4.7.3/gcc/fwprop.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/fwprop.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 2005, 2006, 2007, 2008, 2009, 2010, 2011
    Free Software Foundation, Inc.
    Contributed by Paolo Bonzini and Steven Bosscher.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -664,7 +665,12 @@
     return NULL_RTX;
 
   flags = 0;
-  if (REG_P (new_rtx) || CONSTANT_P (new_rtx))
+  if (REG_P (new_rtx)
+      || CONSTANT_P (new_rtx)
+      || (GET_CODE (new_rtx) == SUBREG
+	  && REG_P (SUBREG_REG (new_rtx))
+	  && (GET_MODE_SIZE (mode)
+	      <= GET_MODE_SIZE (GET_MODE (SUBREG_REG (new_rtx))))))
     flags |= PR_CAN_APPEAR;
   if (!for_each_rtx (&new_rtx, varying_mem_p, NULL))
     flags |= PR_HANDLE_MEM;
diff -urN gcc-4.7.3/gcc/gcc.c st40-4.7.3-13080/gcc/gcc/gcc.c
--- gcc-4.7.3/gcc/gcc.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/gcc.c	2013-03-27 16:11:13.000000000 +0100
@@ -3,6 +3,7 @@
    1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,
    2010, 2011, 2012
    Free Software Foundation, Inc.
+   Copyright (c) 2009, 2012  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -190,8 +191,8 @@
 static void store_arg (const char *, int, int);
 static void insert_wrapper (const char *);
 static char *load_specs (const char *);
-static void read_specs (const char *, int);
-static void set_spec (const char *, const char *);
+static void read_specs (const char *, bool, bool);
+static void set_spec (const char *, const char *, bool);
 static struct compiler *lookup_compiler (const char *, size_t, const char *);
 static char *build_search_list (const struct path_prefix *, const char *,
 				bool, bool);
@@ -227,9 +228,9 @@
 static void do_self_spec (const char *);
 static const char *find_file (const char *);
 static int is_directory (const char *, bool);
-static const char *validate_switches (const char *);
+static const char *validate_switches (const char *, bool);
 static void validate_all_switches (void);
-static inline void validate_switches_from_spec (const char *);
+static inline void validate_switches_from_spec (const char *, bool);
 static void give_switch (int, int);
 static int used_arg (const char *, int);
 static int default_arg (const char *, int);
@@ -341,6 +342,7 @@
  %W{...}
 	like %{...} but mark last argument supplied within
 	as a file to be deleted on failure.
+ %M	substitue the current multilib directory.
  %o	substitutes the names of all the output files, with spaces
 	automatically placed around them.  You should write spaces
 	around the %o as well or the results are undefined.
@@ -678,7 +680,7 @@
     %{fopenmp|ftree-parallelize-loops=*:%:include(libgomp.spec)%(link_gomp)}\
     %{fgnu-tm:%:include(libitm.spec)%(link_itm)}\
     %(mflib) " STACK_SPLIT_SPEC "\
-    %{fprofile-arcs|fprofile-generate*|coverage:-lgcov}\
+    %{!nostdlib:%{fprofile-arcs|fprofile-generate*|coverage:-lgcov}}\
     %{!nostdlib:%{!nodefaultlibs:%(link_ssp) %(link_gcc_c_sequence)}}\
     %{!nostdlib:%{!nostartfiles:%E}} %{T*} }}}}}}"
 #endif
@@ -1176,11 +1178,12 @@
   const char **ptr_spec;	/* pointer to the spec itself.  */
   struct spec_list *next;	/* Next spec in linked list.  */
   int name_len;			/* length of the name */
-  int alloc_p;			/* whether string was allocated */
+  bool user_p;			/* whether string come from file spec.  */
+  bool alloc_p;			/* whether string was allocated */
 };
 
 #define INIT_STATIC_SPEC(NAME,PTR) \
-{ NAME, NULL, PTR, (struct spec_list *) 0, sizeof (NAME) - 1, 0 }
+  { NAME, NULL, PTR, (struct spec_list *) 0, sizeof (NAME) - 1, false, false }
 
 /* List of statically defined specs.  */
 static struct spec_list static_specs[] =
@@ -1484,7 +1487,7 @@
    current spec.  */
 
 static void
-set_spec (const char *name, const char *spec)
+set_spec (const char *name, const char *spec, bool user_p)
 {
   struct spec_list *sl;
   const char *old_spec;
@@ -1536,7 +1539,8 @@
   if (old_spec && sl->alloc_p)
     free (CONST_CAST(char *, old_spec));
 
-  sl->alloc_p = 1;
+  sl->user_p = user_p;
+  sl->alloc_p = true;
 }
 
 /* Accumulate a command (program name and args), and run it.  */
@@ -1692,7 +1696,7 @@
    Anything invalid in the file is a fatal error.  */
 
 static void
-read_specs (const char *filename, int main_p)
+read_specs (const char *filename, bool main_p, bool user_p)
 {
   char *buffer;
   char *p;
@@ -1741,7 +1745,7 @@
 
 	      p[-2] = '\0';
 	      new_filename = find_a_file (&startfile_prefixes, p1, R_OK, true);
-	      read_specs (new_filename ? new_filename : p1, FALSE);
+	      read_specs (new_filename ? new_filename : p1, false, user_p);
 	      continue;
 	    }
 	  else if (!strncmp (p1, "%include_noerr", sizeof "%include_noerr" - 1)
@@ -1762,7 +1766,7 @@
 	      p[-2] = '\0';
 	      new_filename = find_a_file (&startfile_prefixes, p1, R_OK, true);
 	      if (new_filename)
-		read_specs (new_filename, FALSE);
+		read_specs (new_filename, false, user_p);
 	      else if (verbose_flag)
 		fnotice (stderr, "could not find specs file %s\n", p1);
 	      continue;
@@ -1839,7 +1843,7 @@
 #endif
 		}
 
-	      set_spec (p2, *(sl->ptr_spec));
+	      set_spec (p2, *(sl->ptr_spec), user_p);
 	      if (sl->alloc_p)
 		free (CONST_CAST (char *, *(sl->ptr_spec)));
 
@@ -1905,7 +1909,7 @@
 	  if (! strcmp (suffix, "*link_command"))
 	    link_command_spec = spec;
 	  else
-	    set_spec (suffix + 1, spec);
+	    set_spec (suffix + 1, spec, user_p);
 	}
       else
 	{
@@ -2110,8 +2114,8 @@
       size_t multi_dir_len = 0;
       size_t multi_os_dir_len = 0;
       size_t multiarch_len = 0;
-      size_t suffix_len;
-      size_t just_suffix_len;
+      size_t suffix_len = 0;
+      size_t just_suffix_len = 0;
       size_t len;
 
       if (multi_dir)
@@ -2120,8 +2124,10 @@
 	multi_os_dir_len = strlen (multi_os_dir);
       if (multiarch_suffix)
 	multiarch_len = strlen (multiarch_suffix);
-      suffix_len = strlen (multi_suffix);
-      just_suffix_len = strlen (just_multi_suffix);
+      if (multi_suffix)
+	suffix_len = strlen (multi_suffix);
+      if (just_multi_suffix)
+	just_suffix_len = strlen (just_multi_suffix);
 
       if (path == NULL)
 	{
@@ -2136,7 +2142,7 @@
 	  memcpy (path, pl->prefix, len);
 
 	  /* Look first in MACHINE/VERSION subdirectory.  */
-	  if (!skip_multi_dir)
+	  if (!skip_multi_dir && multi_suffix)
 	    {
 	      memcpy (path + len, multi_suffix, suffix_len + 1);
 	      ret = callback (path, callback_info);
@@ -2146,7 +2152,7 @@
 
 	  /* Some paths are tried with just the machine (ie. target)
 	     subdir.  This is used for finding as, ld, etc.  */
-	  if (!skip_multi_dir
+	  if (!skip_multi_dir && just_multi_suffix
 	      && pl->require_machine_suffix == 2)
 	    {
 	      memcpy (path + len, just_multi_suffix, just_suffix_len + 1);
@@ -2838,8 +2844,9 @@
   const char *part1;
   const char **args;
   unsigned int live_cond;
-  unsigned char validated;
-  unsigned char ordering;
+  bool known;
+  bool validated;
+  bool ordering;
 };
 
 static struct switchstr *switches;
@@ -3108,11 +3115,11 @@
 }
 
 /* Save an option OPT with N_ARGS arguments in array ARGS, marking it
-   as validated if VALIDATED.  */
+  as validated if VALIDATED and KNOWN if it is an internal switch.  */
 
 static void
 save_switch (const char *opt, size_t n_args, const char *const *args,
-	     bool validated)
+	     bool validated, bool known)
 {
   alloc_switch ();
   switches[n_switches].part1 = opt + 1;
@@ -3127,6 +3134,7 @@
 
   switches[n_switches].live_cond = 0;
   switches[n_switches].validated = validated;
+  switches[n_switches].known = known;
   switches[n_switches].ordering = 0;
   n_switches++;
 }
@@ -3145,7 +3153,15 @@
 	 diagnosed only if there are warnings.  */
       save_switch (decoded->canonical_option[0],
 		   decoded->canonical_option_num_elements - 1,
-		   &decoded->canonical_option[1], false);
+		   &decoded->canonical_option[1], false, true);
+      return false;
+    }
+  if (decoded->opt_index == OPT_SPECIAL_unknown)
+    {
+      /* Give it a chance to define it a a spec file.  */
+      save_switch (decoded->canonical_option[0],
+		   decoded->canonical_option_num_elements - 1,
+		   &decoded->canonical_option[1], false, false);
       return false;
     }
   else
@@ -3172,7 +3188,7 @@
   else
     save_switch (decoded->canonical_option[0],
 		 decoded->canonical_option_num_elements - 1,
-		 &decoded->canonical_option[1], false);
+		 &decoded->canonical_option[1], false, true);
 }
 
 static const char *spec_lang = 0;
@@ -3316,7 +3332,7 @@
 	compare_debug_opt = NULL;
       else
 	compare_debug_opt = arg;
-      save_switch (compare_debug_replacement_opt, 0, NULL, validated);
+      save_switch (compare_debug_replacement_opt, 0, NULL, validated, true);
       return true;
 
     case OPT_Wa_:
@@ -3401,12 +3417,12 @@
     case OPT_L:
       /* Similarly, canonicalize -L for linkers that may not accept
 	 separate arguments.  */
-      save_switch (concat ("-L", arg, NULL), 0, NULL, validated);
+      save_switch (concat ("-L", arg, NULL), 0, NULL, validated, true);
       return true;
 
     case OPT_F:
       /* Likewise -F.  */
-      save_switch (concat ("-F", arg, NULL), 0, NULL, validated);
+      save_switch (concat ("-F", arg, NULL), 0, NULL, validated, true);
       return true;
 
     case OPT_save_temps:
@@ -3449,7 +3465,7 @@
 	  user_specs_head = user;
 	user_specs_tail = user;
       }
-      do_save = false;
+      validated = true;
       break;
 
     case OPT__sysroot_:
@@ -3478,7 +3494,10 @@
 
     case OPT_B:
       {
-	size_t len = strlen (arg);
+	size_t len;
+
+	CYGPATH (arg);
+	len = strlen (arg);
 
 	/* Catch the case where the user has forgotten to append a
 	   directory separator to the path.  Note, they may be using
@@ -3528,7 +3547,7 @@
       save_temps_prefix = xstrdup (arg);
       /* On some systems, ld cannot handle "-o" without a space.  So
 	 split the option from its argument.  */
-      save_switch ("-o", 1, &arg, validated);
+      save_switch ("-o", 1, &arg, validated, true);
       return true;
 
     case OPT_static_libgcc:
@@ -3551,7 +3570,7 @@
   if (do_save)
     save_switch (decoded->canonical_option[0],
 		 decoded->canonical_option_num_elements - 1,
-		 &decoded->canonical_option[1], validated);
+		 &decoded->canonical_option[1], validated, true);
   return true;
 }
 
@@ -3605,20 +3624,7 @@
 	}
     }
 
-  /* Handle any -no-canonical-prefixes flag early, to assign the function
-     that builds relative prefixes.  This function creates default search
-     paths that are needed later in normal option handling.  */
-
-  for (j = 1; j < decoded_options_count; j++)
-    {
-      if (decoded_options[j].opt_index == OPT_no_canonical_prefixes)
-	{
-	  get_relative_prefix = make_relative_prefix_ignore_links;
-	  break;
-	}
-    }
-  if (! get_relative_prefix)
-    get_relative_prefix = make_relative_prefix;
+  get_relative_prefix = make_relative_prefix_ignore_links;
 
   /* Set up the default search paths.  If there is no GCC_EXEC_PREFIX,
      see if we can create it from the pathname specified in
@@ -3844,7 +3850,7 @@
 	    }
 	  else
 	    fname = xstrdup (arg);
- 
+
           if (strcmp (fname, "-") != 0 && access (fname, F_OK) < 0)
 	    perror_with_name (fname);
           else
@@ -3978,7 +3984,8 @@
 					   NULL);
       switches[n_switches].args = 0;
       switches[n_switches].live_cond = 0;
-      switches[n_switches].validated = 0;
+      switches[n_switches].validated = false;
+      switches[n_switches].known = false;
       switches[n_switches].ordering = 0;
       n_switches++;
       compare_debug = 1;
@@ -4353,7 +4360,7 @@
 	      save_switch (decoded_options[j].canonical_option[0],
 			   (decoded_options[j].canonical_option_num_elements
 			    - 1),
-			   &decoded_options[j].canonical_option[1], false);
+			   &decoded_options[j].canonical_option[1], false, true);
 	      break;
 
 	    default:
@@ -4968,6 +4975,14 @@
 	    }
 	    break;
 
+	  case 'M':
+	    {
+	      const char *mlib = multilib_dir ? multilib_dir : ".";
+	      obstack_grow (&obstack, mlib, strlen (mlib));
+	      arg_going = 1;
+	    }
+	    break;
+
 	  case 'o':
 	    {
 	      int max = n_infiles;
@@ -5227,7 +5242,11 @@
 		    && (have_wildcard || switches[i].part1[len] == '\0'))
 		  {
 		    switches[i].live_cond |= switch_option;
-		    switches[i].validated = 1;
+		    /* User switch be validated from validate_all_switches.
+		       when the definition is seen from the spec file.
+		       If not defined anywhere, will be rejected.  */
+		    if (switches[i].known)
+		      switches[i].validated = true;
 		  }
 
 	      p += len;
@@ -5823,7 +5842,7 @@
       for (i = switchnum + 1; i < n_switches; i++)
 	if (switches[i].part1[0] == 'O')
 	  {
-	    switches[switchnum].validated = 1;
+	    switches[switchnum].validated = true;
 	    switches[switchnum].live_cond = SWITCH_FALSE;
 	    return 0;
 	  }
@@ -5837,7 +5856,9 @@
 	    if (switches[i].part1[0] == name[0]
 		&& ! strcmp (&switches[i].part1[1], &name[4]))
 	      {
-		switches[switchnum].validated = 1;
+		/* --specs are validated with the validate_switches mechanism.  */
+		if (switches[switchnum].known)
+		  switches[switchnum].validated = true;
 		switches[switchnum].live_cond = SWITCH_FALSE;
 		return 0;
 	      }
@@ -5852,7 +5873,9 @@
 		&& switches[i].part1[3] == '-'
 		&& !strcmp (&switches[i].part1[4], &name[1]))
 	      {
-		switches[switchnum].validated = 1;
+		/* --specs are validated with the validate_switches mechanism.  */
+		if (switches[switchnum].known)
+		  switches[switchnum].validated = true;
 		switches[switchnum].live_cond = SWITCH_FALSE;
 		return 0;
 	      }
@@ -5916,7 +5939,7 @@
     }
 
   do_spec_1 (" ", 0, NULL);
-  switches[switchnum].validated = 1;
+  switches[switchnum].validated = true;
 }
 
 /* Search for a file named NAME trying various prefixes including the
@@ -6288,7 +6311,7 @@
   specs_file = find_a_file (&startfile_prefixes, "specs", R_OK, true);
   /* Read the specs file unless it is a default one.  */
   if (specs_file != 0 && strcmp (specs_file, "specs"))
-    read_specs (specs_file, TRUE);
+    read_specs (specs_file, true, false);
   else
     init_spec ();
 
@@ -6301,7 +6324,7 @@
   strcat (specs_file, just_machine_suffix);
   strcat (specs_file, "specs");
   if (access (specs_file, R_OK) == 0)
-    read_specs (specs_file, TRUE);
+    read_specs (specs_file, true, false);
 
   /* Process any configure-time defaults specified for the command line
      options, via OPTION_DEFAULT_SPECS.  */
@@ -6345,7 +6368,7 @@
     {
       obstack_grow (&obstack, "%(sysroot_spec) ", strlen ("%(sysroot_spec) "));
       obstack_grow0 (&obstack, link_spec, strlen (link_spec));
-      set_spec ("link", XOBFINISH (&obstack, const char *));
+      set_spec ("link", XOBFINISH (&obstack, const char *), false);
     }
 #endif
 
@@ -6421,7 +6444,7 @@
     {
       char *filename = find_a_file (&startfile_prefixes, uptr->filename,
 				    R_OK, true);
-      read_specs (filename ? filename : uptr->filename, FALSE);
+      read_specs (filename ? filename : uptr->filename, false, true);
     }
 
   /* Process any user self specs.  */
@@ -6517,11 +6540,11 @@
       xputenv (XOBFINISH (&collect_obstack, char *));
     }
 
-  /* Warn about any switches that no pass was interested in.  */
+  /* Reject switches that no pass was interested in.  */
 
   for (i = 0; (int) i < n_switches; i++)
     if (! switches[i].validated)
-      error ("unrecognized option %<-%s%>", switches[i].part1);
+      error ("unrecognized command line option %<-%s%>", switches[i].part1);
 
   /* Obey some of the options.  */
 
@@ -7071,14 +7094,14 @@
 }
 
 static inline void
-validate_switches_from_spec (const char *spec)
+validate_switches_from_spec (const char *spec, bool user)
 {
   const char *p = spec;
   char c;
   while ((c = *p++))
     if (c == '%' && (*p == '{' || *p == '<' || (*p == 'W' && *++p == '{')))
       /* We have a switch spec.  */
-      p = validate_switches (p + 1);
+      p = validate_switches (p + 1, user);
 }
 
 static void
@@ -7088,20 +7111,20 @@
   struct spec_list *spec;
 
   for (comp = compilers; comp->spec; comp++)
-    validate_switches_from_spec (comp->spec);
+    validate_switches_from_spec (comp->spec, false);
 
   /* Look through the linked list of specs read from the specs file.  */
   for (spec = specs; spec; spec = spec->next)
-    validate_switches_from_spec (*spec->ptr_spec);
+    validate_switches_from_spec (*spec->ptr_spec, spec->user_p);
 
-  validate_switches_from_spec (link_command_spec);
+  validate_switches_from_spec (link_command_spec, false);
 }
 
 /* Look at the switch-name that comes after START
    and mark as valid all supplied switches that match it.  */
 
 static const char *
-validate_switches (const char *start)
+validate_switches (const char *start, bool user_spec)
 {
   const char *p = start;
   const char *atom;
@@ -7138,8 +7161,9 @@
       /* Mark all matching switches as valid.  */
       for (i = 0; i < n_switches; i++)
 	if (!strncmp (switches[i].part1, atom, len)
-	    && (starred || switches[i].part1[len] == 0))
-	  switches[i].validated = 1;
+	    && (starred || switches[i].part1[len] == '\0')
+	    && (switches[i].known || user_spec))
+	  switches[i].validated = true;
     }
 
   if (*p) p++;
@@ -7154,9 +7178,9 @@
 	    {
 	      p++;
 	      if (*p == '{' || *p == '<')
-		p = validate_switches (p+1);
+		p = validate_switches (p+1, user_spec);
 	      else if (p[0] == 'W' && p[1] == '{')
-		p = validate_switches (p+2);
+		p = validate_switches (p+2, user_spec);
 	    }
 	  else
 	    p++;
@@ -7859,7 +7883,7 @@
 /* getenv built-in spec function.
 
    Returns the value of the environment variable given by its first
-   argument, concatenated with the second argument.  If the
+   argument, concatenated with the remaining arguments.  If the
    environment variable is not defined, a fatal error is issued.  */
 
 static const char *
@@ -7869,8 +7893,9 @@
   char *result;
   char *ptr;
   size_t len;
+  int i;
 
-  if (argc != 2)
+  if (argc < 2)
     return NULL;
 
   value = getenv (argv[0]);
@@ -7881,7 +7906,9 @@
      they are not interpreted as active spec characters.  A
      particularly painful case is when we are reading a variable
      holding a windows path complete with \ separators.  */
-  len = strlen (value) * 2 + strlen (argv[1]) + 1;
+  len = strlen (value) * 2 + 1;
+  for (i = 1; i < argc; i++)
+    len += strlen (argv[i]);
   result = XNEWVAR (char, len);
   for (ptr = result; *value; ptr += 2)
     {
@@ -7889,7 +7916,11 @@
       ptr[1] = *value++;
     }
 
-  strcpy (ptr, argv[1]);
+  for (i = 1; i < argc; i++)
+    {
+      strcpy (ptr, argv[i]);
+      ptr += strlen (argv[i]);
+    }
 
   return result;
 }
@@ -8104,7 +8135,7 @@
     abort ();
 
   file = find_a_file (&startfile_prefixes, argv[0], R_OK, true);
-  read_specs (file ? file : argv[0], FALSE);
+  read_specs (file ? file : argv[0], false, false);
 
   return NULL;
 }
diff -urN gcc-4.7.3/gcc/gimple-fold.c st40-4.7.3-13080/gcc/gcc/gimple-fold.c
--- gcc-4.7.3/gcc/gimple-fold.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/gimple-fold.c	2013-04-30 11:08:54.000000000 +0200
@@ -1,6 +1,7 @@
 /* Statement simplification on GIMPLE.
    Copyright (C) 2010, 2011, 2012 Free Software Foundation, Inc.
    Split out from tree-ssa-ccp.c.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -161,7 +162,7 @@
 tree
 get_symbol_constant_value (tree sym)
 {
-  if (const_value_known_p (sym))
+  if (const_value_known_p (sym) && !DECL_WEAK (sym))
     {
       tree val = DECL_INITIAL (sym);
       if (val)
diff -urN gcc-4.7.3/gcc/insn-addr.h st40-4.7.3-13080/gcc/gcc/insn-addr.h
--- gcc-4.7.3/gcc/insn-addr.h	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/insn-addr.h	2013-04-30 11:08:54.000000000 +0200
@@ -1,5 +1,6 @@
 /* Macros to support INSN_ADDRESSES
    Copyright (C) 2000, 2007 Free Software Foundation, Inc.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -62,4 +63,6 @@
 #define INSN_ADDRESSES_NEW(insn, addr)		\
   (insn_addresses_new (insn, addr))
 
+extern int print_address (int uid);
+
 #endif /* ! GCC_INSN_ADDR_H */
diff -urN gcc-4.7.3/gcc/ipa-inline.c st40-4.7.3-13080/gcc/gcc/ipa-inline.c
--- gcc-4.7.3/gcc/ipa-inline.c	2012-06-18 11:00:11.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/ipa-inline.c	2013-07-10 10:22:34.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 2003, 2004, 2007, 2008, 2009, 2010, 2011
    Free Software Foundation, Inc.
    Contributed by Jan Hubicka
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -380,21 +381,20 @@
   return true;
 }
 
+/* Return number of calls in N.  Ignore cheap builtins.  */
 
-/* Return true when N is leaf function.  Accept cheap builtins
-   in leaf functions.  */
-
-static bool
-leaf_node_p (struct cgraph_node *n)
+static int
+num_calls (struct cgraph_node *n)
 {
   struct cgraph_edge *e;
+  int num = 0;
+
   for (e = n->callees; e; e = e->next_callee)
     if (!is_inexpensive_builtin (e->callee->decl))
-      return false;
-  return true;
+      num++;
+  return num;
 }
 
-
 /* Return true if we are interested in inlining small function.  */
 
 static bool
@@ -415,6 +415,8 @@
   else
     {
       int growth = estimate_edge_growth (e);
+      int n;
+
       if (growth <= 0)
 	;
       else if (!cgraph_maybe_hot_edge_p (e)
@@ -428,22 +430,23 @@
 		     growth);
 	  want_inline = false;
 	}
-      else if (!leaf_node_p (callee)
-	       && growth > 0)
+      else if (growth > PARAM_VALUE (PARAM_EARLY_INLINING_INSNS))
 	{
 	  if (dump_file)
 	    fprintf (dump_file, "  will not early inline: %s/%i->%s/%i, "
-		     "callee is not leaf and code would grow by %i\n",
+		     "growth %i exceeds --param early-inlining-insns\n",
 		     xstrdup (cgraph_node_name (e->caller)), e->caller->uid,
 		     xstrdup (cgraph_node_name (callee)), callee->uid,
 		     growth);
 	  want_inline = false;
 	}
-      else if (growth > PARAM_VALUE (PARAM_EARLY_INLINING_INSNS))
+      else if ((n = num_calls (callee)) != 0
+	       && growth * (n + 1) > PARAM_VALUE (PARAM_EARLY_INLINING_INSNS))
 	{
 	  if (dump_file)
 	    fprintf (dump_file, "  will not early inline: %s/%i->%s/%i, "
-		     "growth %i exceeds --param early-inlining-insns\n",
+		     "growth %i exceeds --param early-inlining-insns "
+		     "divided by number of calls\n",
 		     xstrdup (cgraph_node_name (e->caller)), e->caller->uid,
 		     xstrdup (cgraph_node_name (callee)), callee->uid,
 		     growth);
@@ -1360,6 +1363,10 @@
 	for (edge = node->callers; edge; edge = edge->next_caller)
 	  if (max_count < edge->count)
 	    max_count = edge->count;
+
+	for (edge = node->indirect_calls; edge; edge = edge->next_callee)
+	  if (max_count < edge->count)
+	    max_count = edge->count;
       }
 
   overall_size = initial_size;
diff -urN gcc-4.7.3/gcc/ira.c st40-4.7.3-13080/gcc/gcc/ira.c
--- gcc-4.7.3/gcc/ira.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/ira.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 2006, 2007, 2008, 2009, 2010, 2011, 2012
    Free Software Foundation, Inc.
    Contributed by Vladimir Makarov <vmakarov@redhat.com>.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -2763,6 +2764,17 @@
 	     only mark all destinations as having no known equivalence.  */
 	  if (set == 0)
 	    {
+	      if (GET_CODE (PATTERN (insn)) == UNSPEC_VOLATILE)
+		{
+		  int i;
+		  /* UNSPEC_VOLATILE is considered to use and clobber all hard 
+		     registers and all of memory.  This blocks insns from being
+		     combined across this point.  */
+		  for (i = FIRST_PSEUDO_REGISTER; i < VEC_length (reg_equivs_t, reg_equivs); i++)
+		    reg_equiv[i].replace = 0;
+		}
+
+
 	      note_stores (PATTERN (insn), no_equiv, NULL);
 	      continue;
 	    }
diff -urN gcc-4.7.3/gcc/lcm.c st40-4.7.3-13080/gcc/gcc/lcm.c
--- gcc-4.7.3/gcc/lcm.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/lcm.c	2012-04-04 14:14:24.000000000 +0200
@@ -1,6 +1,7 @@
 /* Generic partial redundancy elimination with lazy code motion support.
    Copyright (C) 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2007, 2008,
    2010, 2011 Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -370,17 +371,18 @@
     }
 }
 
-/* Given local properties TRANSP, ANTLOC, AVOUT, KILL return the insert and
-   delete vectors for edge based LCM.  Returns an edgelist which is used to
-   map the insert vector to what edge an expression should be inserted on.  */
+/* Given local properties TRANSP, ANTLOC, AVLOC, KILL return the insert and
+   delete vectors for edge based LCM, and return the AVIN, AVOUT bitmap.
+   Returns an edgelist which is used to map the insert vector to
+   what edge an expression should be inserted on.  */
 
 struct edge_list *
-pre_edge_lcm (int n_exprs, sbitmap *transp,
+pre_edge_lcm_avs (int n_exprs, sbitmap *transp,
 	      sbitmap *avloc, sbitmap *antloc, sbitmap *kill,
+		  sbitmap *avin, sbitmap *avout,
 	      sbitmap **insert, sbitmap **del)
 {
   sbitmap *antin, *antout, *earliest;
-  sbitmap *avin, *avout;
   sbitmap *later, *laterin;
   struct edge_list *edge_list;
   int num_edges;
@@ -402,10 +404,7 @@
 #endif
 
   /* Compute global availability.  */
-  avin = sbitmap_vector_alloc (last_basic_block, n_exprs);
-  avout = sbitmap_vector_alloc (last_basic_block, n_exprs);
   compute_available (avloc, kill, avout, avin);
-  sbitmap_vector_free (avin);
 
   /* Compute global anticipatability.  */
   antin = sbitmap_vector_alloc (last_basic_block, n_exprs);
@@ -431,7 +430,6 @@
 
   sbitmap_vector_free (antout);
   sbitmap_vector_free (antin);
-  sbitmap_vector_free (avout);
 
   later = sbitmap_vector_alloc (num_edges, n_exprs);
 
@@ -470,6 +468,28 @@
   return edge_list;
 }
 
+/* Wrapper to allocate avin/avout and call pre_edge_lcm_avs.  */
+
+struct edge_list *
+pre_edge_lcm (int n_exprs, sbitmap *transp,
+	      sbitmap *avloc, sbitmap *antloc, sbitmap *kill,
+	      sbitmap **insert, sbitmap **del)
+{
+  struct edge_list *edge_list;
+  sbitmap *avin, *avout;
+
+  avin = sbitmap_vector_alloc (last_basic_block, n_exprs);
+  avout = sbitmap_vector_alloc (last_basic_block, n_exprs);
+
+  edge_list = pre_edge_lcm_avs (n_exprs, transp, avloc, antloc, kill,
+				 avin, avout, insert, del);
+
+  sbitmap_vector_free (avout);
+  sbitmap_vector_free (avin);
+
+  return edge_list;
+}
+
 /* Compute the AVIN and AVOUT vectors from the AVLOC and KILL vectors.
    Return the number of passes we performed to iterate to a solution.  */
 
diff -urN gcc-4.7.3/gcc/lto/lto-lang.c st40-4.7.3-13080/gcc/gcc/lto/lto-lang.c
--- gcc-4.7.3/gcc/lto/lto-lang.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/lto/lto-lang.c	2013-04-30 11:08:54.000000000 +0200
@@ -1,6 +1,7 @@
 /* Language-dependent hooks for LTO.
    Copyright 2009, 2010, 2011, 2012 Free Software Foundation, Inc.
    Contributed by CodeSourcery, Inc.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -1133,7 +1134,7 @@
   linemap_add (line_table, LC_ENTER, 0, NULL, 0);
 
   /* Create the basic integer types.  */
-  build_common_tree_nodes (flag_signed_char, /*short_double=*/false);
+  build_common_tree_nodes (flag_signed_char, flag_short_double);
 
   /* The global tree for the main identifier is filled in by
      language-specific front-end initialization that is not run in the
diff -urN gcc-4.7.3/gcc/lto-opts.c st40-4.7.3-13080/gcc/gcc/lto-opts.c
--- gcc-4.7.3/gcc/lto-opts.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/lto-opts.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
 
    Copyright 2009, 2010, 2011, 2012 Free Software Foundation, Inc.
    Contributed by Simon Baldwin <simonb@google.com>
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -44,7 +45,7 @@
 			       bool *first_p, const char *opt)
 {
   const char *p, *q = opt;
-  if (!first_p)
+  if (!*first_p)
     obstack_grow (ob, " ", 1);
   obstack_grow (ob, "'", 1);
   while ((p = strchr (q, '\'')))
diff -urN gcc-4.7.3/gcc/Makefile.in st40-4.7.3-13080/gcc/gcc/Makefile.in
--- gcc-4.7.3/gcc/Makefile.in	2013-04-04 16:25:15.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/Makefile.in	2013-04-15 10:26:30.000000000 +0200
@@ -833,7 +833,7 @@
 # comma in the $(if ...) constructs is significant - do not remove it.
 BASEVER_s   := "\"$(BASEVER_c)\""
 DEVPHASE_s  := "\"$(if $(DEVPHASE_c), ($(DEVPHASE_c)))\""
-DATESTAMP_s := "\"$(if $(DEVPHASE_c), $(DATESTAMP_c))\""
+DATESTAMP_s := "\"$(if $(DATESTAMP_c), $(DATESTAMP_c))\""
 PKGVERSION_s:= "\"@PKGVERSION@\""
 BUGURL_s    := "\"@REPORT_BUGS_TO@\""
 
diff -urN gcc-4.7.3/gcc/mode-switching.c st40-4.7.3-13080/gcc/gcc/mode-switching.c
--- gcc-4.7.3/gcc/mode-switching.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/mode-switching.c	2012-04-04 14:14:24.000000000 +0200
@@ -1,6 +1,7 @@
 /* CPU mode switching
    Copyright (C) 1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2007, 2008,
    2009, 2010 Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -97,6 +98,181 @@
 static void reg_becomes_live (rtx, const_rtx, void *);
 static void make_preds_opaque (basic_block, int);
 
+/* Bitmap to compute mode flipping.  */
+
+static sbitmap *mode_in_flip;  /* flip in mode status for each basic blocks.  */
+static sbitmap *mode_out_flip; /* flip out mode status for each basic blocks.  */
+/* To support mode switching, the algorithm cannot set the modes after
+   the insert and delete bitmaps are computed by pre_edge_lcm, because
+   'avin' is computed iteratively for each possible modes for each entity.
+   The mode emission will be done after all mode are processed.
+   (see commit_mode_sets).  */
+
+static int **modes_needed;  /* modes needs to be inserted on this edge.  */
+
+/* Indicates that edge mode information is unknown. Cannot use 'no_mode'
+   because its value depends of its entity */
+#define NO_MODE -1
+
+
+/* Return true when one of the predecessor edges of BB is marked with
+   EDGE_COMPLEX. (similar to bb_has_eh_pred in basic_block.h).  */
+static bool
+bb_has_complex_pred (basic_block bb)
+{
+  edge e;
+  edge_iterator ei;
+
+  FOR_EACH_EDGE (e, ei, bb->preds)
+    {
+      if (e->flags & EDGE_COMPLEX)
+	return true;
+    }
+  return false;
+}
+
+/* Test avin modes.
+   if 'out' is 'true' we want to know if the mode out of the basic block
+   can be flipped. If 'in' is true we want to know if the mode entering the basic
+   block can be flipped.  */
+
+static int
+test_flip_status(int entity, basic_block bb, bool out)
+{
+  if (out)
+    return TEST_BIT (mode_out_flip[bb->index], entity);
+  else
+    return TEST_BIT (mode_in_flip[bb->index], entity);
+}
+
+/* Merges the avin modes.  */
+
+static void
+set_flip_status (sbitmap *avin, sbitmap *avout)
+{
+  basic_block bb;
+
+  FOR_EACH_BB (bb)
+    {
+      int i = bb->index;
+
+      /* Merge modes for each entity for each bb.
+	 If multiple avin modes are set for the same bb, they are not
+	 exclusive and a flip may not be emitted.
+	 If more that 2 modes can be defined, flip may not be emitted.  */
+      if (! bb_has_complex_pred (bb))
+	{
+	  sbitmap_a_xor_b (mode_in_flip[i], mode_in_flip[i], avin[i]);
+	  sbitmap_a_xor_b (mode_out_flip[i], mode_out_flip[i], avout[i]);
+	}
+    }
+}
+
+/* Allocates and initializes modes_infos.  */
+
+static void
+init_modes_infos (int n_entities)
+{
+  int j;
+  int num_edges = 0;
+  basic_block bb;
+
+  /* How many edges do we have ?  */
+
+  FOR_BB_BETWEEN (bb, ENTRY_BLOCK_PTR, EXIT_BLOCK_PTR, next_bb)
+      num_edges += EDGE_COUNT (bb->succs);
+
+  modes_needed = XNEWVEC (int *, n_entities);
+
+  for (j = 0; j < n_entities; j++)
+    {
+      modes_needed[j] = XNEWVEC (int, num_edges);
+
+      /* Initial NO_MODE value is -1, because 0 is a value mode.  */
+      memset (modes_needed[j], NO_MODE, num_edges * sizeof (int));
+    }
+
+  /* Allocates bitmaps for modes.  */
+  mode_in_flip = sbitmap_vector_alloc (last_basic_block, n_entities);
+  mode_out_flip = sbitmap_vector_alloc (last_basic_block, n_entities);
+  sbitmap_vector_zero (mode_in_flip, last_basic_block);
+  sbitmap_vector_zero (mode_out_flip, last_basic_block);
+}
+
+/* frees memory used to hold the modes information.  */
+
+static void
+free_modes_infos (int n_entities)
+{
+  int j;
+
+  for (j = 0; j < n_entities; j++)
+    free (modes_needed[j]);
+
+  free (modes_needed);
+  sbitmap_vector_free (mode_in_flip);
+  sbitmap_vector_free (mode_out_flip);
+}
+
+/* records the mode associated with edge e for entity j.  */
+
+static void
+add_mode_set (int j, int e, int mode)
+{
+  modes_needed[j][e] = mode;
+}
+
+/* returns the mode needed on edge e for entity j. -1 if none.  */
+
+static int
+get_mode (int j, int e)
+{
+  return modes_needed[j][e];
+}
+
+/* Finally, after all the modes after been inserted after lcm, we can
+   process with the mode emission.  */
+
+static int
+commit_mode_sets (struct edge_list *edge_list, int j)
+{
+  int need_commit = 0;
+  int e;
+
+  for (e = 0; e < NUM_EDGES (edge_list); e++)
+    {
+      HARD_REG_SET live_at_edge;
+      edge eg = INDEX_EDGE (edge_list, e);
+      basic_block src_bb = eg->src;
+      int mode, prev_mode;
+      rtx mode_set;
+
+      if ((mode = get_mode (j, e)) == NO_MODE)
+	continue;
+
+      prev_mode = test_flip_status (j, src_bb, true);
+
+      REG_SET_TO_HARD_REG_SET (live_at_edge, df_get_live_out (src_bb));
+
+      start_sequence ();
+      EMIT_MODE_SET (entity_map[j], mode, prev_mode, live_at_edge);
+
+      mode_set = get_insns ();
+      end_sequence ();
+
+      /* Do not bother to insert empty sequence.  */
+      if (mode_set == NULL_RTX)
+	continue;
+
+      /* We should not get an abnormal edge here.  */
+      gcc_assert (! (eg->flags & EDGE_ABNORMAL));
+	
+      need_commit = 1;
+      insert_insn_on_edge (mode_set, eg);
+    }
+
+  return need_commit;
+}
 
 /* This function will allocate a new BBINFO structure, initialized
    with the MODE, INSN, and basic block BB parameters.  */
@@ -437,7 +613,6 @@
   basic_block bb;
   int need_commit = 0;
   sbitmap *kill;
-  struct edge_list *edge_list;
   static const int num_modes[] = NUM_MODES_FOR_MODE_SWITCHING;
 #define N_ENTITIES ARRAY_SIZE (num_modes)
   int entity_map[N_ENTITIES];
@@ -447,6 +622,8 @@
   int max_num_modes = 0;
   bool emited ATTRIBUTE_UNUSED = false;
   basic_block post_entry ATTRIBUTE_UNUSED, pre_exit ATTRIBUTE_UNUSED;
+  sbitmap *avin, *avout;
+  struct edge_list *edge_list = 0;
 
   for (e = N_ENTITIES - 1, n_entities = 0; e >= 0; e--)
     if (OPTIMIZE_MODE_SWITCHING (e))
@@ -483,6 +660,8 @@
   antic = sbitmap_vector_alloc (last_basic_block, n_entities);
   transp = sbitmap_vector_alloc (last_basic_block, n_entities);
   comp = sbitmap_vector_alloc (last_basic_block, n_entities);
+  avin = sbitmap_vector_alloc (last_basic_block, n_entities);
+  avout = sbitmap_vector_alloc (last_basic_block, n_entities);
 
   sbitmap_vector_ones (transp, last_basic_block);
 
@@ -586,6 +765,9 @@
     }
 
   kill = sbitmap_vector_alloc (last_basic_block, n_entities);
+
+  init_modes_infos (n_entities);
+
   for (i = 0; i < max_num_modes; i++)
     {
       int current_mode[N_ENTITIES];
@@ -615,8 +797,11 @@
 
       FOR_EACH_BB (bb)
 	sbitmap_not (kill[bb->index], transp[bb->index]);
-      edge_list = pre_edge_lcm (n_entities, transp, comp, antic,
-				kill, &insert, &del);
+      edge_list = pre_edge_lcm_avs (n_entities, transp, comp, antic,
+				    kill, avin, avout, &insert, &del);
+
+      /* Merge modes for all entities.  */
+      set_flip_status (avin, avout);
 
       for (j = n_entities - 1; j >= 0; j--)
 	{
@@ -633,10 +818,6 @@
 	  for (e = NUM_EDGES (edge_list) - 1; e >= 0; e--)
 	    {
 	      edge eg = INDEX_EDGE (edge_list, e);
-	      int mode;
-	      basic_block src_bb;
-	      HARD_REG_SET live_at_edge;
-	      rtx mode_set;
 
 	      eg->aux = 0;
 
@@ -645,25 +826,8 @@
 
 	      eg->aux = (void *)1;
 
-	      mode = current_mode[j];
-	      src_bb = eg->src;
-
-	      REG_SET_TO_HARD_REG_SET (live_at_edge, df_get_live_out (src_bb));
-
-	      start_sequence ();
-	      EMIT_MODE_SET (entity_map[j], mode, live_at_edge);
-	      mode_set = get_insns ();
-	      end_sequence ();
-
-	      /* Do not bother to insert empty sequence.  */
-	      if (mode_set == NULL_RTX)
-		continue;
-
-	      /* We should not get an abnormal edge here.  */
-	      gcc_assert (! (eg->flags & EDGE_ABNORMAL));
-
-	      need_commit = 1;
-	      insert_insn_on_edge (mode_set, eg);
+	      /* Remember we need to emit it.  */
+	      add_mode_set(j, e, current_mode[j]);
 	    }
 
 	  FOR_EACH_BB_REVERSE (bb)
@@ -678,6 +842,9 @@
       sbitmap_vector_free (del);
       sbitmap_vector_free (insert);
       clear_aux_for_edges ();
+
+      /* Keep an edge_list for later.  */
+      if (i != max_num_modes - 1)
       free_edge_list (edge_list);
     }
 
@@ -686,9 +853,16 @@
     {
       int no_mode = num_modes[entity_map[j]];
 
+      /* In case there was no mode inserted. the mode information on the edge
+	 might not be complete.
+	 Update mode info on edges and commit pending mode sets.  */
+      need_commit |= commit_mode_sets (edge_list, j);
+
       FOR_EACH_BB_REVERSE (bb)
 	{
 	  struct seginfo *ptr, *next;
+	  int last_mode = test_flip_status (j, bb, false);
+
 	  for (ptr = bb_info[j][bb->index].seginfo; ptr; ptr = next)
 	    {
 	      next = ptr->next;
@@ -697,10 +871,14 @@
 		  rtx mode_set;
 
 		  start_sequence ();
-		  EMIT_MODE_SET (entity_map[j], ptr->mode, ptr->regs_live);
+		  EMIT_MODE_SET (entity_map[j], ptr->mode, last_mode,
+				 ptr->regs_live);
 		  mode_set = get_insns ();
 		  end_sequence ();
 
+		  /* modes are are localy set.  */
+		  last_mode = 1;
+
 		  /* Insert MODE_SET only if it is nonempty.  */
 		  if (mode_set != NULL_RTX)
 		    {
@@ -719,6 +897,9 @@
       free (bb_info[j]);
     }
 
+  free_edge_list (edge_list);
+  free_modes_infos (n_entities);
+
   /* Finished. Free up all the things we've allocated.  */
   sbitmap_vector_free (kill);
   sbitmap_vector_free (antic);
diff -urN gcc-4.7.3/gcc/opts.c st40-4.7.3-13080/gcc/gcc/opts.c
--- gcc-4.7.3/gcc/opts.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/opts.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011
    Free Software Foundation, Inc.
    Contributed by Neil Booth.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -459,6 +460,7 @@
     { OPT_LEVELS_2_PLUS, OPT_fcrossjumping, NULL, 1 },
     { OPT_LEVELS_2_PLUS, OPT_foptimize_sibling_calls, NULL, 1 },
     { OPT_LEVELS_2_PLUS, OPT_fcse_follow_jumps, NULL, 1 },
+    { OPT_LEVELS_2_PLUS, OPT_fcse_sincos, NULL, 1 },
     { OPT_LEVELS_2_PLUS, OPT_fgcse, NULL, 1 },
     { OPT_LEVELS_2_PLUS, OPT_fexpensive_optimizations, NULL, 1 },
     { OPT_LEVELS_2_PLUS, OPT_frerun_cse_after_loop, NULL, 1 },
diff -urN gcc-4.7.3/gcc/output.h st40-4.7.3-13080/gcc/gcc/output.h
--- gcc-4.7.3/gcc/output.h	2012-06-18 11:00:11.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/output.h	2012-06-18 16:10:36.000000000 +0200
@@ -2,6 +2,7 @@
    final.c, and varasm.c.
    Copyright (C) 1987, 1991, 1994, 1997, 1998, 1999, 2000, 2001, 2002,
    2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011
+   Copyright (c) 2009  STMicroelectronics.
    Free Software Foundation, Inc.
 
 This file is part of GCC.
@@ -54,6 +55,9 @@
    any branches of variable length if possible.  */
 extern void shorten_branches (rtx);
 
+/* Returns the actual insn length without adjustment.  */
+int get_insn_current_length (rtx insn);
+
 /* Output assembler code for the start of a function,
    and initialize some of the variables in this file
    for the new function.  The label for the function and associated
diff -urN gcc-4.7.3/gcc/profile.c st40-4.7.3-13080/gcc/gcc/profile.c
--- gcc-4.7.3/gcc/profile.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/profile.c	2013-04-30 11:08:54.000000000 +0200
@@ -5,6 +5,7 @@
    Contributed by James E. Wilson, UC Berkeley/Cygnus Support;
    based on some ideas from Dain Samples of UC Berkeley.
    Further mangling by Bob Manson, Cygnus Support.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -698,8 +699,13 @@
 
       if (bb->count < 0)
 	{
-	  error ("corrupted profile info: number of iterations for basic block %d thought to be %i",
-		 bb->index, (int)bb->count);
+	  if (warn_branch_probabilities_computation)
+	    warning (OPT_Wbranch_probabilities_computation, "corrupted profile "
+		     "info: number of iterations for basic block %d thought to "
+		     "be %i", bb->index, (int)bb->count);
+	  else
+	    error ("corrupted profile info: number of iterations for basic "
+		   "block %d thought to be %i", bb->index, (int)bb->count);
 	  bb->count = 0;
 	}
       FOR_EACH_EDGE (e, ei, bb->succs)
@@ -719,8 +725,14 @@
 	    }
 	  if (e->count < 0 || e->count > bb->count)
 	    {
-	      error ("corrupted profile info: number of executions for edge %d-%d thought to be %i",
-		     e->src->index, e->dest->index,
+	      if (warn_branch_probabilities_computation)
+		warning (OPT_Wbranch_probabilities_computation, "corrupted "
+			 "profile info: number of executions for edge %d-%d "
+			 "thought to be %i", e->src->index, e->dest->index,
+			 (int)e->count);
+	      else 
+		error ("corrupted profile info: number of executions for edge "
+		       "%d-%d thought to be %i", e->src->index, e->dest->index,
 		     (int)e->count);
 	      e->count = bb->count / 2;
 	    }
diff -urN gcc-4.7.3/gcc/read-md.c st40-4.7.3-13080/gcc/gcc/read-md.c
--- gcc-4.7.3/gcc/read-md.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/read-md.c	2013-07-10 10:22:34.000000000 +0200
@@ -173,8 +173,10 @@
 print_md_ptr_loc (const void *ptr)
 {
   const struct ptr_loc *loc = get_md_ptr_loc (ptr);
+#if 0
   if (loc != 0)
     printf ("#line %d \"%s\"\n", loc->lineno, loc->filename);
+#endif
 }
 
 /* Return a condition that satisfies both COND1 and COND2.  Either string
diff -urN gcc-4.7.3/gcc/reload1.c st40-4.7.3-13080/gcc/gcc/reload1.c
--- gcc-4.7.3/gcc/reload1.c	2012-06-18 11:00:11.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/reload1.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 1987, 1988, 1989, 1992, 1993, 1994, 1995, 1996, 1997, 1998,
    1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,
    2011, 2012 Free Software Foundation, Inc.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -1631,6 +1632,9 @@
 	    {
 	      rtx set = single_set (insn);
 
+	      if (set && GET_CODE (set) == PARALLEL)
+		continue;
+
 	      /* Skip insns that only set an equivalence.  */
 	      if (set && REG_P (SET_DEST (set))
 		  && reg_renumber[REGNO (SET_DEST (set))] < 0
@@ -3648,6 +3652,7 @@
     {
       gcc_assert (GET_CODE (PATTERN (insn)) == USE
 		  || GET_CODE (PATTERN (insn)) == CLOBBER
+		  || GET_CODE (PATTERN (insn)) == PARALLEL
 		  || GET_CODE (PATTERN (insn)) == ADDR_VEC
 		  || GET_CODE (PATTERN (insn)) == ADDR_DIFF_VEC
 		  || GET_CODE (PATTERN (insn)) == ASM_INPUT
@@ -3898,7 +3903,7 @@
 /* Subroutine of set_initial_label_offsets called via for_each_eh_label.  */
 
 static void
-set_initial_eh_label_offset (rtx label)
+set_initial_eh_label_offset (rtx label, void *ignored ATTRIBUTE_UNUSED)
 {
   set_label_offsets (label, NULL_RTX, 1);
 }
@@ -3924,7 +3929,7 @@
     if (XEXP (x, 0))
       set_label_offsets (XEXP (x, 0), NULL_RTX, 1);
 
-  for_each_eh_label (set_initial_eh_label_offset);
+  for_each_eh_label (set_initial_eh_label_offset, NULL);
 }
 
 /* Set all elimination offsets to the known values for the code label given
diff -urN gcc-4.7.3/gcc/reorg.c st40-4.7.3-13080/gcc/gcc/reorg.c
--- gcc-4.7.3/gcc/reorg.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/reorg.c	2013-04-30 11:08:54.000000000 +0200
@@ -4,6 +4,7 @@
    Free Software Foundation, Inc.
    Contributed by Richard Kenner (kenner@vlsi1.ultra.nyu.edu).
    Hacked by Michael Tiemann (tiemann@cygnus.com).
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -2035,6 +2036,26 @@
   return label;
 }
 
+static bool
+insn_conflict_latency (rtx trial, rtx insn)
+{
+  int cost = insn_default_latency (trial) + 1;
+  rtx set = single_set (trial);
+
+  if (set)
+    {
+      while (insn && cost--)
+	{
+	  if (reg_referenced_p (SET_DEST (set), PATTERN (insn)))
+	    return true;
+
+	  insn = next_active_insn (insn);
+	}
+    }
+
+  return false;
+}
+
 /* Scan a function looking for insns that need a delay slot and find insns to
    put into the delay slot.
 
@@ -2191,6 +2212,7 @@
 	      if (! insn_references_resource_p (trial, &set, true)
 		  && ! insn_sets_resource_p (trial, &set, true)
 		  && ! insn_sets_resource_p (trial, &needed, true)
+		  && ! insn_conflict_latency (trial, next_active_insn (insn))
 #ifdef HAVE_cc0
 		  /* Can't separate set of cc0 from its use.  */
 		  && ! (reg_mentioned_p (cc0_rtx, pat) && ! sets_cc0_p (pat))
diff -urN gcc-4.7.3/gcc/resource.c st40-4.7.3-13080/gcc/gcc/resource.c
--- gcc-4.7.3/gcc/resource.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/resource.c	2013-04-30 11:08:54.000000000 +0200
@@ -1,6 +1,7 @@
 /* Definitions for computing resource usage of specific insns.
    Copyright (C) 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008,
    2009, 2010 Free Software Foundation, Inc.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -1283,6 +1284,8 @@
 {
   int b = find_basic_block (insn, MAX_DELAY_SLOT_LIVE_SEARCH);
 
+  gcc_assert (b < last_basic_block);
+
   if (b != -1)
     bb_ticks[b]++;
 }
diff -urN gcc-4.7.3/gcc/sched-deps.c st40-4.7.3-13080/gcc/gcc/sched-deps.c
--- gcc-4.7.3/gcc/sched-deps.c	2013-04-11 15:46:13.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/sched-deps.c	2013-04-30 11:08:54.000000000 +0200
@@ -6,6 +6,7 @@
    Free Software Foundation, Inc.
    Contributed by Michael Tiemann (tiemann@cygnus.com) Enhanced by,
    and currently maintained by, Jim Wilson (wilson@cygnus.com)
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -2422,6 +2423,20 @@
       int regno = REGNO (dest);
       enum machine_mode mode = GET_MODE (dest);
 
+      /* Don't extend the lifetime of CLASS_LIKELY_SPILLED registers before RA
+	 since the clobbers due to reload are not yet computed.  */
+      if (!reload_completed && regno < FIRST_PSEUDO_REGISTER)
+	{
+	  int i = hard_regno_nregs[regno][mode];
+	  
+	  while (--i >= 0)
+	    if (targetm.class_likely_spilled_p (REGNO_REG_CLASS (regno + i)))
+	      {
+		flush_pending_lists (deps, insn, false, true);
+		break;
+	      }
+	}
+
       sched_analyze_reg (deps, regno, mode, code, insn);
 
 #ifdef STACK_REGS
diff -urN gcc-4.7.3/gcc/stmt.c st40-4.7.3-13080/gcc/gcc/stmt.c
--- gcc-4.7.3/gcc/stmt.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/stmt.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 1987, 1988, 1989, 1992, 1993, 1994, 1995, 1996, 1997,
    1998, 1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009,
    2010, 2011, 2012 Free Software Foundation, Inc.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -1515,6 +1516,7 @@
 
     case SAVE_EXPR:
     case NON_LVALUE_EXPR:
+    case NOP_EXPR:
       exp = TREE_OPERAND (exp, 0);
       goto restart;
 
diff -urN gcc-4.7.3/gcc/stor-layout.c st40-4.7.3-13080/gcc/gcc/stor-layout.c
--- gcc-4.7.3/gcc/stor-layout.c	2012-10-01 13:18:40.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/stor-layout.c	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 1987, 1988, 1992, 1993, 1994, 1995, 1996, 1996, 1998,
    1999, 2000, 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010,
    2011 Free Software Foundation, Inc.
+   Copyright (c) 2013  STMicroelectronics.
 
 This file is part of GCC.
 
@@ -1492,14 +1493,6 @@
   rli->offset_align = BITS_PER_UNIT;
   normalize_rli (rli);
 
-  /* Determine the desired alignment.  */
-#ifdef ROUND_TYPE_ALIGN
-  TYPE_ALIGN (rli->t) = ROUND_TYPE_ALIGN (rli->t, TYPE_ALIGN (rli->t),
-					  rli->record_align);
-#else
-  TYPE_ALIGN (rli->t) = MAX (TYPE_ALIGN (rli->t), rli->record_align);
-#endif
-
   /* Compute the size so far.  Be sure to allow for extra bits in the
      size in bytes.  We have guaranteed above that it will be no more
      than a single byte.  */
@@ -1509,6 +1502,17 @@
     unpadded_size_unit
       = size_binop (PLUS_EXPR, unpadded_size_unit, size_one_node);
 
+
+  /* Determine the desired alignment.  */
+#ifdef ROUND_TYPE_ALIGN
+  TYPE_SIZE (rli->t) = unpadded_size;
+  TYPE_ALIGN (rli->t) = ROUND_TYPE_ALIGN (rli->t, TYPE_ALIGN (rli->t),
+					  rli->record_align);
+
+#else
+  TYPE_ALIGN (rli->t) = MAX (TYPE_ALIGN (rli->t), rli->record_align);
+#endif
+
   /* Round the size up to be a multiple of the required alignment.  */
   TYPE_SIZE (rli->t) = round_up (unpadded_size, TYPE_ALIGN (rli->t));
   TYPE_SIZE_UNIT (rli->t)
diff -urN gcc-4.7.3/gcc/testsuite/ChangeLog.STM st40-4.7.3-13080/gcc/gcc/testsuite/ChangeLog.STM
--- gcc-4.7.3/gcc/testsuite/ChangeLog.STM	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/ChangeLog.STM	2013-04-29 10:53:57.000000000 +0200
@@ -0,0 +1,194 @@
+2013-04-25  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/debug/dwarf2/dwarf_span.c: New test case.
+
+2013-04-22  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/tree-ssa/scev-bitfield.c: New test.
+
+2013-04-18  Christian Bruel  <christian.bruel@st.com>
+
+	PR target/56995
+	* gcc.target/sh/mfmovd.c: Add new function and check hard_float.
+
+2013-04-08  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.target/sh/mfmovd.c: Add testcase and fix skip list.
+
+2013-01-13  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=25892
+	* gcc.target/sh/sh-switch.c: New testcase.
+
+2012-12-06  Laurent Alfonsi  <laurent.alfonsi@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=24977
+	* gcc.dg/muladdsi3.c: New test.
+
+2012-04-25  Laurent Alfonsi  <laurent.alfonsi@st.com>
+
+        * lib/c-torture.exp (c-torture-execute): Appends 
+	additional linker flag if exists.
+
+2012-09-10  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.target/sh/muladd.c: New test.
+
+2012-08-23  Laurent Alfonsi  <laurent.alfonsi@st.com>
+
+	* lib/scanobj.exp: Added
+	* gcc.dg/profiling/profiling.exp: Added
+	* gcc.dg/profiling/default: New tests.
+	* gcc.dg/profiling/branch-probabilities: New tests.
+	* gcc.dg/profiling/function-section: New tests.
+	* gcc.dg/profiling/branch-probabilities-function-section: New tests.
+
+2012-05-30  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/spec-options.c: New test.
+	* gcc.dg/foo.specs: New file.
+
+2012-04-23  Christian Bruel  <christian.bruel@st.com>
+
+        https://bugzilla.stlinux.com/show_bug.cgi?id=18466
+        * gcc.target/sh/jump_compact_1.c: New test.
+        * gcc.target/sh/jump_compact_2.c: New test.
+
+2010-02-15  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/case-const-1.c: Add cond expr label and cast case.
+	* gcc.dg/case-const-2.c: Likewise.
+	* gcc.dg/case-const-3.c: Likewise.
+
+2012-02-14  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/pr49948.c: Disable if no pthread.
+
+2011-09-02  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=14098
+	* gcc.c-torture/execute/st14098.c: New.
+
+2010-06-30  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.target/sh/sh-trapa.c: Test trapa.
+
+2011-03-18 Christian Bruel  <christian.bruel@st.com>
+
+	* g++.dg/warn/Wstrict-aliasing-float-ref-int-obj.C: Test success.
+
+2011-02-11 Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.c-torture/gcc.dg/cpp/_Pragma3.c: xfail.
+
+2010-12-07  Christian Bruel  <christian.bruel@st.com>
+
+	* lib/lto.exp: Disable whopr.
+	* lib/gcc.exp: Likewise.
+	* lib/c-torture.exp: Likewise.
+
+2010-11-08  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=10391
+	* gcc.dg/ssp.c: New testcase. 
+
+2010-11-03  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.c-torture/execute/lroundf.c: New testcase. 
+	* gcc.c-torture/execute/lroundf.x: New.
+
+2010-10-14  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.c-torture/execute/lrintf.c: New testcase. 
+	* gcc.c-torture/execute/lrintf.x: New.
+
+2010-08-10  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.c-torture/execute/builtin-prefetch-6.c: xfail for sh-linux.
+
+2010-06-15  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=9320
+	* gcc.dg/shlrtst.c: New testcase. 
+
+2010-06-07  Christian Bruel  <christian.bruel@st.com>
+
+	* lib/target-supports.exp (check_effective_target_complex): Define.
+	* gcc.dg/pr42427.c: Check complex available.
+
+2010-04-20  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl30850:
+	* gcc.dg/builtins-nan.c: New test.
+
+2010-01-26  Christian Bruel  <christian.bruel@st.com>
+
+	http://gcc.gnu.org/bugzilla/show_bug.cgi?id=39423
+	* gcc.dg/fold-plusmult.c: Check rtl instead of gimple.
+
+2010-01-26  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.target/sh/20080410-1.c: Remove -fira option.
+
+2009-11-10  Christian Bruel  <christian.bruel@st.com>
+
+	* g++.dg/eh/postreload.C: New test.
+
+2009-10-06  Antony King  <antony.king@st.com>
+
+	INSbl30052:
+	* lib/target-supports.exp (check_effective_target_sync_int_long):
+	Enable atomic builtins for sh*-superh-elf.
+	(check_effective_target_sync_char_short): Likewise.
+
+2009-09-29  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/const-weak.c: Change dump.
+
+2009-09-03  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/memcpy-1.c: xfail for SH.
+
+2009-09-03  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/const-weak.c: Update dg-final rules.
+
+2009-07-03  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/torture/pr36998.c: Add -fno-omit-frame-pointer for SH.
+
+2009-06-18  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/torture/pr37868.c: xfail for SH.
+
+2009-06-26  Christian Bruel  <christian.bruel@st.com>
+
+	* lib/target-supports.exp: Disable profiling for SH when on the simu.
+
+2009-03-12  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/array-index.c: New optimisation test.
+
+2009-05-27  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.dg/cpp/trad/include.c: Don't force __STDC__.
+
+2008-05-06  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/28671
+	* gcc.dg/const-weak.c: New testcase.
+
+2008-04-17  Christian Bruel  <christian.bruel@st.com>
+
+	INSbl/28594
+	* gcc.dg/long-long-compare-1.c: New testcase.
+
+2008-01-28  Christian Bruel  <christian.bruel@st.com>
+
+	https://bugzilla.stlinux.com/show_bug.cgi?id=3313
+	* gcc.dg/packed-array.c: New testcase.
+
+2007-01-31  Christian Bruel  <christian.bruel@st.com>
+
+	* gcc.target/sh/fpchg1.c: New test.
+	* gcc.target/sh/fpchg2.c: Idem.
diff -urN gcc-4.7.3/gcc/testsuite/gcc.c-torture/execute/builtin-prefetch-6.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.c-torture/execute/builtin-prefetch-6.c
--- gcc-4.7.3/gcc/testsuite/gcc.c-torture/execute/builtin-prefetch-6.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.c-torture/execute/builtin-prefetch-6.c	2012-04-04 14:14:24.000000000 +0200
@@ -1,3 +1,6 @@
+/* can trap for SH with RADDERR on MMU with 31th bit set.  */
+/* { dg-do run { xfail sh*-*linux* } } */
+
 /* Test that __builtin_prefetch does no harm.
 
    Data prefetch should not fault if used with an invalid address.  */
diff -urN gcc-4.7.3/gcc/testsuite/gcc.c-torture/execute/lrintf.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.c-torture/execute/lrintf.c
--- gcc-4.7.3/gcc/testsuite/gcc.c-torture/execute/lrintf.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.c-torture/execute/lrintf.c	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,53 @@
+#include <math.h>
+
+extern void abort (void);
+extern void exit (int);
+
+void __attribute__ ((noinline))
+test(float a)
+{
+  int a1 = __builtin_lrintf (a);
+  int a3 = lrintf (a);
+
+  if (a1 != a3)
+    exit (1);
+}
+
+int main()
+{
+  test (__builtin_nanf(""));
+  test (__builtin_inff());
+
+  test (0);
+  test (1);
+
+  test (2.5);
+  test (3.5);
+  test (-2.5);
+  test (-3.5);
+
+  test (2.4);
+  test (3.4);
+  test (-2.4);
+  test (-3.4);
+
+  test (2.0);
+  test (3.0);
+  test (-2.0);
+  test (-3.0);
+
+  test (2.9);
+  test (3.9);
+  test (-2.9);
+  test (-3.9);
+
+  test (2.1);
+  test (3.1);
+  test (-2.1);
+  test (-3.1);
+
+  test (0.1);
+  test (-0.1);
+
+  return 0;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.c-torture/execute/lrintf.x st40-4.7.3-13080/gcc/gcc/testsuite/gcc.c-torture/execute/lrintf.x
--- gcc-4.7.3/gcc/testsuite/gcc.c-torture/execute/lrintf.x	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.c-torture/execute/lrintf.x	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,3 @@
+set additional_flags "-fno-math-errno -std=c99 -fno-builtin -fno-finite-math-only"
+
+return 0
diff -urN gcc-4.7.3/gcc/testsuite/gcc.c-torture/execute/lroundf.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.c-torture/execute/lroundf.c
--- gcc-4.7.3/gcc/testsuite/gcc.c-torture/execute/lroundf.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.c-torture/execute/lroundf.c	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,53 @@
+#include <math.h>
+
+extern void abort (void);
+extern void exit (int);
+
+void __attribute__ ((noinline))
+test(float a)
+{
+  int a1 = __builtin_lroundf (a);
+  int a3 = lroundf (a);
+
+  if (a1 != a3)
+    exit (1);
+}
+
+int main()
+{
+  test (__builtin_nanf(""));
+  test (__builtin_inff());
+
+  test (0);
+  test (1);
+
+  test (2.5);
+  test (3.5);
+  test (-2.5);
+  test (-3.5);
+
+  test (2.4);
+  test (3.4);
+  test (-2.4);
+  test (-3.4);
+
+  test (2.0);
+  test (3.0);
+  test (-2.0);
+  test (-3.0);
+
+  test (2.9);
+  test (3.9);
+  test (-2.9);
+  test (-3.9);
+
+  test (2.1);
+  test (3.1);
+  test (-2.1);
+  test (-3.1);
+
+  test (0.1);
+  test (-0.1);
+
+  return 0;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.c-torture/execute/lroundf.x st40-4.7.3-13080/gcc/gcc/testsuite/gcc.c-torture/execute/lroundf.x
--- gcc-4.7.3/gcc/testsuite/gcc.c-torture/execute/lroundf.x	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.c-torture/execute/lroundf.x	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,3 @@
+set additional_flags "-fno-math-errno -std=c99 -fno-builtin -fno-finite-math-only"
+
+return 0
diff -urN gcc-4.7.3/gcc/testsuite/gcc.c-torture/execute/st14098.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.c-torture/execute/st14098.c
--- gcc-4.7.3/gcc/testsuite/gcc.c-torture/execute/st14098.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.c-torture/execute/st14098.c	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,21 @@
+extern void abort (void);
+
+unsigned long long int i = 0x100000000LL;
+
+int
+foo(void)
+{
+  if( i < 127LL ) return 1;
+
+  if( i == 0x8000 ) return 5;
+
+  return 0;
+}
+
+main()
+{
+  if (foo())
+    abort();
+
+  return 0;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.c-torture/unsorted/dump-noaddr.x st40-4.7.3-13080/gcc/gcc/testsuite/gcc.c-torture/unsorted/dump-noaddr.x
--- gcc-4.7.3/gcc/testsuite/gcc.c-torture/unsorted/dump-noaddr.x	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.c-torture/unsorted/dump-noaddr.x	2012-04-13 11:27:27.000000000 +0200
@@ -10,10 +10,10 @@
     # loop through all the options
     foreach option $option_list {
 	file delete -force dump1
-	file mkdir dump1
+	file mkdir $tmpdir/dump1
 	c-torture-compile $src "$option $options -dumpbase dump1/$dumpbase -DMASK=1 -x c --param ggc-min-heapsize=1 -fdump-ipa-all -fdump-rtl-all -fdump-tree-all -fdump-noaddr"
 	file delete -force dump2
-	file mkdir dump2
+	file mkdir $tmpdir/dump2
 	c-torture-compile $src "$option $options -dumpbase dump2/$dumpbase -DMASK=2 -x c -fdump-ipa-all -fdump-rtl-all -fdump-tree-all -fdump-noaddr"
 	foreach dump1 [lsort [glob -nocomplain dump1/*]] {
 	    regsub dump1/ $dump1 dump2/ dump2
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/always_inline2.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/always_inline2.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/always_inline2.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/always_inline2.c	2012-04-11 13:44:05.000000000 +0200
@@ -1,8 +1,8 @@
 /* { dg-do compile } */
-/* { dg-options "-O2" } */
-inline __attribute__ ((always_inline)) void t(void); /* { dg-error "body not available" } */
+/* { dg-options "-Winline -O2" } */
+inline __attribute__ ((always_inline)) void t(void); /* { dg-warning "body not available" } */
 void
 q(void)
 {
-  t(); 				/* { dg-error "called from here" } */
+  t(); 				/* { dg-warning "called from here" } */
 }
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/always_inline3.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/always_inline3.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/always_inline3.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/always_inline3.c	2012-04-11 13:44:05.000000000 +0200
@@ -1,11 +1,11 @@
 /* { dg-do compile } */
-/* { dg-options "-O2" } */
+/* { dg-options "-Winline -O2" } */
 int do_something_evil (void);
 inline __attribute__ ((always_inline)) void
-q2(void) /* { dg-error "recursive inlining" } */
+q2(void) /* { dg-warning "recursive inlining" } */
 {
   if (do_something_evil ())
     return;
-  q2(); 			/* { dg-error "called from here" } */
+  q2(); 			/* { dg-warning "called from here" } */
   q2(); /* With -O2 we don't warn here, it is eliminated by tail recursion.  */
 }
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/array-index.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/array-index.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/array-index.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/array-index.c	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,15 @@
+/* PR tree-optimization/39423 */
+/* { dg-do compile } */
+/* { dg-options "-O2 -fdump-tree-original" } */
+
+int
+foo (int tab[], int index)
+{
+  return tab [index + 1];
+} 
+
+/* { dg-final { scan-tree-dump-times "\\+ 4" 1 "original" } } */
+/* { dg-final { scan-tree-dump-times "\\+ 1" 0 "original" } } */
+/* { dg-final { scan-tree-dump-times "index \\* 4" 1 "original" } } */
+/* { dg-final { cleanup-tree-dump "original" } } */
+
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/builtins-nan.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/builtins-nan.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/builtins-nan.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/builtins-nan.c	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,54 @@
+/* { dg-do run } */
+/* { dg-options "-mieee" { target sh*-*-* } } */
+
+#include <stdio.h>
+#include <stdlib.h>
+#include <math.h>
+
+static int lisnan(double v)
+{
+  return (v != v);
+}
+
+static int lisnanf(float v)
+{
+  return (v != v);
+}
+
+int main(void)
+{
+  double d;
+  float f;
+
+  /* double */
+  d = __builtin_nans("");
+  if (! lisnan(d))
+    abort();
+
+  if (! __builtin_isnan(d))
+    abort();
+
+  d = __builtin_nan("");
+  if (! lisnan(d))
+    abort();
+
+  if (! __builtin_isnan(d))
+    abort();
+
+  /* float */
+  f = __builtin_nansf("");
+  if (! lisnanf(f))
+    abort();
+
+  if (! __builtin_isnanf(f))
+    abort();
+
+  f = __builtin_nanf("");
+  if (! lisnanf(f))
+    abort();
+
+  if (! __builtin_isnanf(f))
+    abort();
+
+  exit (0);
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/case-const-1.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/case-const-1.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/case-const-1.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/case-const-1.c	2012-04-04 14:14:24.000000000 +0200
@@ -1,9 +1,11 @@
 /* Test for case labels not integer constant expressions but folding
-   to integer constants (used in Linux kernel, PR 39613).  */
+   to integer constants (used in Linux kernel, PR 39613, 52283).  */
 /* { dg-do compile } */
 /* { dg-options "" } */
 
 extern int i;
+extern unsigned int u;
+
 void
 f (int c)
 {
@@ -13,3 +15,13 @@
       ;
     }
 }
+
+void
+b (int c)
+{
+  switch (c)
+    {
+    case (int) (2  | ((4 < 8) ? 8 : u)):
+      ;
+    }
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/case-const-2.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/case-const-2.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/case-const-2.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/case-const-2.c	2012-04-04 14:14:24.000000000 +0200
@@ -1,9 +1,11 @@
 /* Test for case labels not integer constant expressions but folding
-   to integer constants (used in Linux kernel, PR 39613).  */
+   to integer constants (used in Linux kernel, PR 39613, 52283).  */
 /* { dg-do compile } */
 /* { dg-options "-pedantic" } */
 
 extern int i;
+extern unsigned int u;
+
 void
 f (int c)
 {
@@ -13,3 +15,14 @@
       ;
     }
 }
+
+void
+b (int c)
+{
+  switch (c)
+    {
+    case (int) (2  | ((4 < 8) ? 8 : u)): /* { dg-warning "case label is not an integer constant expression" } */
+      ;
+    }
+}
+
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/case-const-3.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/case-const-3.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/case-const-3.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/case-const-3.c	2012-04-04 14:14:24.000000000 +0200
@@ -1,9 +1,11 @@
 /* Test for case labels not integer constant expressions but folding
-   to integer constants (used in Linux kernel, PR 39613).  */
+   to integer constants (used in Linux kernel, PR 39613, 52283, ).  */
 /* { dg-do compile } */
 /* { dg-options "-pedantic-errors" } */
 
 extern int i;
+extern unsigned int u;
+
 void
 f (int c)
 {
@@ -13,3 +15,16 @@
       ;
     }
 }
+
+void
+b (int c)
+{
+  switch (c)
+    {
+    case (int) (2  | ((4 < 8) ? 8 : u)): /* { dg-error "case label is not an integer constant expression" } */
+      ;
+    }
+}
+
+
+
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/const-weak.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/const-weak.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/const-weak.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/const-weak.c	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,16 @@
+/* weak constants can be replaced at link time. */
+
+/* { dg-do compile } */
+/* { dg-options "-O2 -fdump-tree-pre" } */
+
+const int wconst __attribute__((weak)) = 2;
+
+int f(void)
+{
+  return wconst;
+}
+
+/* { dg-final { scan-tree-dump-not "return 2" "pre"} } */
+/* { dg-final { cleanup-tree-dump "pre*]" } } */
+
+	
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/cpp/_Pragma3.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/cpp/_Pragma3.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/cpp/_Pragma3.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/cpp/_Pragma3.c	2012-04-04 14:14:24.000000000 +0200
@@ -1,6 +1,6 @@
 /* Copyright (C) 2002 Free Software Foundation, Inc.  */
 
-/* { dg-do preprocess } */
+/* { dg-do preprocess  { xfail *-*-* } } */
 
 /* Pragma buffers have a NULL "inc" member, which we would dereference
    when getting a file's date and time.
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/cpp/trad/include.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/cpp/trad/include.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/cpp/trad/include.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/cpp/trad/include.c	2012-04-04 14:14:24.000000000 +0200
@@ -7,6 +7,5 @@
    Newlib uses ## when including stdlib.h as of 2007-09-07.  */
 /* { dg-do preprocess { target { { ! vxworks_kernel } && { ! newlib } } } } */
 
-#define __STDC__ 1		/* Stop complaints about non-ISO compilers.  */
 #define stdlib 1
 #include <stdlib.h>		/* { dg-bogus "o such file or directory" } */
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/debug/dwarf2/dwarf_span.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/debug/dwarf2/dwarf_span.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/debug/dwarf2/dwarf_span.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/debug/dwarf2/dwarf_span.c	2013-04-30 10:01:02.000000000 +0200
@@ -0,0 +1,19 @@
+/* { dg-do compile { target "sh*-*-*" } } */
+/* { dg-require-effective-target hard_float } */
+/* { dg-skip-if "" { *-*-* }  { "*-single-only" } { "" } } */
+/* { dg-options "-g -dA" } */
+/* { dg-final { scan-assembler-times "DW_OP_regx" 4 } } */
+
+double
+add_double (register double u, register double v)
+{
+  return u + v;
+}
+
+double
+wack_double (register double u, register double v)
+{
+  register double l = u, r = v;
+  l = add_double (l, r);
+  return l + r;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/fail_always_inline.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/fail_always_inline.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/fail_always_inline.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/fail_always_inline.c	2012-04-11 13:44:05.000000000 +0200
@@ -6,6 +6,5 @@
 void
 f()
 {
-  bar(); 
+  bar();
 }
-
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/fold-plusmult-2.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/fold-plusmult-2.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/fold-plusmult-2.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/fold-plusmult-2.c	2012-04-04 14:14:24.000000000 +0200
@@ -1,20 +1,20 @@
 /* { dg-do compile } */
-/* { dg-options "-fdump-tree-original" } */
+/* { dg-options "-O2 -fdump-tree-original" } */
 
 int foo (int i)
 {
   return 2 + i * 4;
 }
 
-/* We do _not_ want the above to be canonicalized to (i * 2 + 1) * 2.  */
-
-int bar (int i)
+int
+bar (int tab[], int index)
 {
-  return 4 + i * 2;
+  return tab [index+2];
 }
 
-/* But eventually this to be canonicalized to (i + 2) * 2.  */
+
+/* The rational is that it is best not to downsize the multiplier. */
 
 /* { dg-final { scan-tree-dump "i \\\* 4 \\\+ 2" "original" } } */
-/* { dg-final { scan-tree-dump "\\\(i \\\+ 2\\\) \\\* 2" "original" } } */
+/* { dg-final { scan-tree-dump "index \\\* 4\\\) \\\+ 8" "original" } } */
 /* { dg-final { cleanup-tree-dump "original" } } */
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/fold-plusmult.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/fold-plusmult.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/fold-plusmult.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/fold-plusmult.c	2012-04-04 14:14:24.000000000 +0200
@@ -1,5 +1,8 @@
 /* { dg-do compile } */
-/* { dg-options "-fdump-tree-original" } */
+/* moved from gimple to rtl. see
+	http://gcc.gnu.org/bugzilla/show_bug.cgi?id=39423
+*/
+/* { dg-options "-O2 -fdump-rtl-cse2" } */
 
 int test1 (int a)
 {
@@ -11,5 +14,6 @@
   return (a + a)*2;
 }
 
-/* { dg-final { scan-tree-dump-times "<a> \\\* 4" 2 "original" } } */
-/* { dg-final { cleanup-tree-dump "original" } } */
+/* { dg-final { scan-rtl-dump-times "ashift" 2 "cse2" } } */
+/* { dg-final { scan-rtl-dump-times "const_int 2" 2 "cse2" } } */
+/* { dg-final { cleanup-tree-dump "cse2" } } */
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/foo.specs st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/foo.specs
--- gcc-4.7.3/gcc/testsuite/gcc.dg/foo.specs	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/foo.specs	2012-05-31 10:32:42.000000000 +0200
@@ -0,0 +1,2 @@
+*cppruntime:
++ %{tfoo: -DFOO}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/muladdsi3.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/muladdsi3.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/muladdsi3.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/muladdsi3.c	2012-12-17 13:19:22.000000000 +0100
@@ -0,0 +1,19 @@
+/* { dg-do run } */
+
+int test_status=1;
+__attribute__((noinline)) void bar(int a, int b, int c)
+{
+  if (a==33 && b==44 && c==55) 
+     test_status=0;
+}
+
+void foo(int a, int b)
+{
+  bar(11 + 22 * a, 44 * b, 55);
+}
+
+int main()
+{
+  foo(1, 1);
+  return test_status;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/nested-func-4.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/nested-func-4.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/nested-func-4.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/nested-func-4.c	2012-04-04 14:14:24.000000000 +0200
@@ -1,4 +1,3 @@
-/* { dg-do run } */
 /* { dg-options "-pg" } */
 /* { dg-options "-pg -static" { target hppa*-*-hpux* } } */
 /* { dg-require-profiling "-pg" } */
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/pr36998.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/pr36998.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/pr36998.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/pr36998.c	2012-04-04 14:14:24.000000000 +0200
@@ -2,7 +2,7 @@
 /* { dg-do compile } */
 /* { dg-options "-Os -fasynchronous-unwind-tables" } */
 /* { dg-options "-Os -mpreferred-stack-boundary=2 -fasynchronous-unwind-tables" { target { { i?86-*-* x86_64-*-* } && ia32 } } } */
-/* { dg-options "-fno-omit-frame-pointer" { target { avr-*-* } } } */
+/* { dg-options "-fno-omit-frame-pointer" { target { avr-*-* sh-*-* } } } */
 
 void foo (const char *, ...) __attribute__ ((noreturn));
 int bar (const char *, ...);
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/pr42427.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/pr42427.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/pr42427.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/pr42427.c	2012-04-04 14:14:24.000000000 +0200
@@ -2,6 +2,7 @@
 /* { dg-options "-O2 -fexceptions -fnon-call-exceptions -fpeel-loops" } */
 /* { dg-add-options c99_runtime } */
 /* { dg-require-effective-target ilp32 } */
+/* { dg-require-effective-target complex } */
 
 #include <complex.h>
 
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/branch-probabilities/main.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/branch-probabilities/main.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/branch-probabilities/main.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/branch-probabilities/main.c	2012-08-23 10:22:57.000000000 +0200
@@ -0,0 +1,22 @@
+/* { dg-do link } */
+/* { dg-options { -O2 -fno-inline -fprofile-arcs } } */
+/* { dg-additional-sources "others.c others3.c" } */
+/* { dg-do run { target native } } */
+
+main()
+{
+  int i = 0;
+
+  puts ("foo");
+
+  for (i=0; i < 100000; i++)
+    {
+      freq();
+      freq1();
+    }
+
+  unfreq1();
+  unfreq2();
+
+  return 0;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/branch-probabilities/others3.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/branch-probabilities/others3.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/branch-probabilities/others3.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/branch-probabilities/others3.c	2012-08-23 10:22:57.000000000 +0200
@@ -0,0 +1,9 @@
+/* { dg-do assemble } */
+/* { dg-options { -O2 -fno-inline -fbranch-probabilities } } */
+
+never3()
+{
+}
+
+/* { dg-final { scan-obj { <_never3> }    { section .text.unlikely: }          { Disassembly of section } { others3.o } } } */
+/* { dg-final { cleanup-saved-temps ".gcda" } } */
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/branch-probabilities/others.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/branch-probabilities/others.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/branch-probabilities/others.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/branch-probabilities/others.c	2012-08-23 10:22:57.000000000 +0200
@@ -0,0 +1,52 @@
+/* { dg-do assemble } */
+/* { dg-options { -O2 -fno-inline -fbranch-probabilities } } */
+
+void unfreq1() __attribute__ ((cold)) ;
+void freq1() __attribute__ ((hot)) ;
+void notfreq1() __attribute__ ((hot)) ;
+
+void
+unfreq1()
+{
+}
+
+void
+freq1()
+{
+}
+
+void
+notfreq1()
+{
+}
+
+
+freq()
+{
+}
+
+
+never()
+{
+}
+
+unfreq2()
+{
+}
+
+never2()
+{
+}
+
+__attribute__ ((weak)) wnever()
+{
+}
+
+/* { dg-final { scan-obj { <_unfreq1> }   { section .text: }          { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_unfreq2> }   { section .text: }	      { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_freq1> }	  { section .text.hot: }      { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_freq> }	  { section .text.hot: }      { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_notfreq1> }  { section .text.unlikely: } { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_never> }	  { section .text.unlikely: } { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_never2> }    { section .text.unlikely: } { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_wnever> }    { section .text.unlikely: } { Disassembly of section } { others.o } } } */
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/branch-probabilities-function-section/main.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/branch-probabilities-function-section/main.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/branch-probabilities-function-section/main.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/branch-probabilities-function-section/main.c	2012-08-23 10:22:57.000000000 +0200
@@ -0,0 +1,22 @@
+/* { dg-do link } */
+/* { dg-options { -O2 -fno-inline -fprofile-arcs } } */
+/* { dg-additional-sources "others.c others3.c" } */
+/* { dg-do run { target native } } */
+
+main()
+{
+  int i = 0;
+
+  puts ("foo");
+
+  for (i=0; i < 100000; i++)
+    {
+      freq();
+      freq1();
+    }
+
+  unfreq1();
+  unfreq2();
+
+  return 0;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/branch-probabilities-function-section/others3.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/branch-probabilities-function-section/others3.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/branch-probabilities-function-section/others3.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/branch-probabilities-function-section/others3.c	2012-08-23 10:22:57.000000000 +0200
@@ -0,0 +1,9 @@
+/* { dg-do assemble } */
+/* { dg-options { -O2 -fno-inline -fbranch-probabilities -ffunction-sections -fdata-sections -Wl,-gc-section } } */
+
+never3()
+{
+}
+
+/* { dg-final { scan-obj { <_never3> }    { section .text.unlikely.never3: }	      { Disassembly of section } { others3.o } } } */
+/* { dg-final { cleanup-saved-temps ".gcda" } } */
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/branch-probabilities-function-section/others.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/branch-probabilities-function-section/others.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/branch-probabilities-function-section/others.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/branch-probabilities-function-section/others.c	2012-08-23 10:22:57.000000000 +0200
@@ -0,0 +1,52 @@
+/* { dg-do assemble } */
+/* { dg-options { -O2 -fno-inline -fbranch-probabilities -ffunction-sections -fdata-sections -Wl,-gc-section } } */
+
+void unfreq1() __attribute__ ((cold)) ;
+void freq1() __attribute__ ((hot)) ;
+void notfreq1() __attribute__ ((hot)) ;
+
+void
+unfreq1()
+{
+}
+
+void
+freq1()
+{
+}
+
+void
+notfreq1()
+{
+}
+
+
+freq()
+{
+}
+
+
+never()
+{
+}
+
+unfreq2()
+{
+}
+
+never2()
+{
+}
+
+__attribute__ ((weak)) wnever()
+{
+}
+
+/* { dg-final { scan-obj { <_unfreq1> }   { section .text.unfreq1: }           { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_unfreq2> }   { section .text.unfreq2: }	       { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_freq1> }	  { section .text.hot.freq1: }         { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_freq> }	  { section .text.hot.freq: }	       { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_notfreq1> }  { section .text.unlikely.notfreq1: } { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_never> }	  { section .text.unlikely.never: }    { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_never2> }    { section .text.unlikely.never2: }   { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_wnever> }    { section .text.unlikely.wnever: }   { Disassembly of section } { others.o } } } */
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/default/main.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/default/main.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/default/main.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/default/main.c	2012-08-23 10:22:57.000000000 +0200
@@ -0,0 +1,22 @@
+/* { dg-do link } */
+/* { dg-options { -O2 -fno-inline -fprofile-arcs } } */
+/* { dg-additional-sources "others.c others3.c" } */
+/* { dg-do run { target native } } */
+
+main()
+{
+  int i = 0;
+
+  puts ("foo");
+
+  for (i=0; i < 100000; i++)
+    {
+      freq();
+      freq1();
+    }
+
+  unfreq1();
+  unfreq2();
+
+  return 0;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/default/others3.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/default/others3.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/default/others3.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/default/others3.c	2012-08-23 10:22:57.000000000 +0200
@@ -0,0 +1,10 @@
+/* { dg-do assemble } */
+/* { dg-options { -O2 -fno-inline } } */
+
+never3()
+{
+}
+
+/* { dg-final { scan-obj { <_never3> }   { section .text: }	     { Disassembly of section } { others3.o } } } */
+/* { dg-final { cleanup-saved-temps ".gcda" } } */
+
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/default/others.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/default/others.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/default/others.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/default/others.c	2012-08-23 10:22:57.000000000 +0200
@@ -0,0 +1,52 @@
+/* { dg-do assemble } */
+/* { dg-options { -O2 -fno-inline } } */
+
+void unfreq1() __attribute__ ((cold)) ;
+void freq1() __attribute__ ((hot)) ;
+void notfreq1() __attribute__ ((hot)) ;
+
+void
+unfreq1()
+{
+}
+
+void
+freq1()
+{
+}
+
+void
+notfreq1()
+{
+}
+
+
+freq()
+{
+}
+
+
+never()
+{
+}
+
+unfreq2()
+{
+}
+
+never2()
+{
+}
+
+__attribute__ ((weak)) wnever()
+{
+}
+
+/* { dg-final { scan-obj { <_unfreq1> }  { section .text.unlikely: } { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_freq1> }	 { section .text.hot: }      { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_notfreq1> } { section .text.hot: }      { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_freq> }	 { section .text: }	     { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_never> }	 { section .text: }	     { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_unfreq2> }  { section .text: }	     { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_never2> }   { section .text: }	     { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_wnever> }   { section .text: }	     { Disassembly of section } { others.o } } } */
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/function-section/main.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/function-section/main.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/function-section/main.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/function-section/main.c	2012-08-23 10:22:57.000000000 +0200
@@ -0,0 +1,22 @@
+/* { dg-do link } */
+/* { dg-options { -O2 -fno-inline -fprofile-arcs } } */
+/* { dg-additional-sources "others.c others3.c" } */
+/* { dg-do run { target native } } */
+
+main()
+{
+  int i = 0;
+
+  puts ("foo");
+
+  for (i=0; i < 100000; i++)
+    {
+      freq();
+      freq1();
+    }
+
+  unfreq1();
+  unfreq2();
+
+  return 0;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/function-section/others3.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/function-section/others3.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/function-section/others3.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/function-section/others3.c	2012-08-23 10:22:57.000000000 +0200
@@ -0,0 +1,9 @@
+/* { dg-do assemble } */
+/* { dg-options { -O2 -fno-inline -ffunction-sections } } */
+
+never3()
+{
+}
+
+/* { dg-final { scan-obj { <_never3> }   { section .text.never3: }	     { Disassembly of section } { others3.o } } } */
+/* { dg-final { cleanup-saved-temps ".gcda" } } */
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/function-section/others.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/function-section/others.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/function-section/others.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/function-section/others.c	2012-08-23 10:22:57.000000000 +0200
@@ -0,0 +1,52 @@
+/* { dg-do assemble } */
+/* { dg-options { -O2 -fno-inline -ffunction-sections } } */
+
+void unfreq1() __attribute__ ((cold)) ;
+void freq1() __attribute__ ((hot)) ;
+void notfreq1() __attribute__ ((hot)) ;
+
+void
+unfreq1()
+{
+}
+
+void
+freq1()
+{
+}
+
+void
+notfreq1()
+{
+}
+
+
+freq()
+{
+}
+
+
+never()
+{
+}
+
+unfreq2()
+{
+}
+
+never2()
+{
+}
+
+__attribute__ ((weak)) wnever()
+{
+}
+
+/* { dg-final { scan-obj { <_unfreq1> }  { section .text.unlikely.unfreq1: } { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_freq1> }	 { section .text.hot.freq1: }	     { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_notfreq1> } { section .text.hot.notfreq1: }     { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_freq> }	 { section .text.freq: }	     { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_never> }	 { section .text.never: }	     { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_unfreq2> }  { section .text.unfreq2: }	     { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_never2> }   { section .text.never2: }	     { Disassembly of section } { others.o } } } */
+/* { dg-final { scan-obj { <_wnever> }   { section .text.wnever: }	     { Disassembly of section } { others.o } } } */
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/profiling.exp st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/profiling.exp
--- gcc-4.7.3/gcc/testsuite/gcc.dg/profiling/profiling.exp	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/profiling/profiling.exp	2012-08-23 10:22:57.000000000 +0200
@@ -0,0 +1,34 @@
+#   Copyright (C) 2004, 2007 Free Software Foundation, Inc.
+
+# This program is free software; you can redistribute it and/or modify
+# it under the terms of the GNU General Public License as published by
+# the Free Software Foundation; either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU General Public License for more details.
+#
+# You should have received a copy of the GNU General Public License
+# along with GCC; see the file COPYING3.  If not see
+# <http://www.gnu.org/licenses/>.
+
+# Profiling option to add to the existing options set
+# The first argument is the line number of the dg-profile-options directive
+# within the test file. Remaining arguments are as for xfail lists:
+# option { target }
+
+# Load support procs.
+load_lib gcc-dg.exp
+load_lib scanobj.exp
+
+# Initialize `dg'.
+dg-init
+
+# Main loop.
+dg-runtest [lsort [glob -nocomplain $srcdir/$subdir/*/*.c ]] \
+        "" ""
+
+# All done.
+dg-finish
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/shlrtst.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/shlrtst.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/shlrtst.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/shlrtst.c	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,25 @@
+/* { dg-do run } */
+
+extern void abort (void);
+unsigned char test_char[2] ={0x80,0x40};
+
+void Funtion_test(unsigned char *buf, unsigned int num)
+{
+    unsigned int byte = num / 2;
+
+    if(!num)
+      buf[ byte] |= 0x80;
+    else
+      buf[ byte] |= 0x7f;      
+}
+
+main()
+{
+  Funtion_test(test_char, 0);
+
+  if (test_char[0] != 0x80)
+    abort();
+
+  return 0;
+}
+
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/spec-options.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/spec-options.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/spec-options.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/spec-options.c	2012-05-31 10:32:42.000000000 +0200
@@ -0,0 +1,18 @@
+/* Check that -mfoo is accepted if defined in a user spec
+   and that it is not passed on the command line.  */
+/* { dg-do compile } */
+
+/* Must be processed in EXTRA_SPECS to run.  */
+/* { dg-do run { target sh*-*-* } } */
+/* { dg-options "-B${srcdir}/gcc.dg --specs=foo.specs -tfoo" } */
+
+extern void abort(void);
+
+int main(void)
+{
+#ifdef FOO
+  return 0;
+#else
+  abort();
+#endif
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/ssp.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/ssp.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/ssp.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/ssp.c	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,13 @@
+/* { dg-do compile { target fpic } } */
+/* { dg-options "-Os -fpic -fstack-protector-all -fnon-call-exceptions " } */
+/* Causes error: unable to find a register to spill in class 'R0_REGS' on SH4 */
+
+int
+foo (int d, int rp)
+{
+  if (d == 0)
+    if (rp == 0)
+      return 1;
+
+  return 0;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.dg/tree-ssa/scev-bitfield.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/tree-ssa/scev-bitfield.c
--- gcc-4.7.3/gcc/testsuite/gcc.dg/tree-ssa/scev-bitfield.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.dg/tree-ssa/scev-bitfield.c	2013-04-23 17:06:09.000000000 +0200
@@ -0,0 +1,16 @@
+/* { dg-do compile } */
+/* { dg-options "-Os" } */
+
+struct dwarf_frame_register
+{
+  long long value:(sizeof (long long) * 8 - 3);
+};
+
+void
+execute_cfi (int address_size,  struct dwarf_frame_register *fs)
+{
+  long long regno = 0 ;
+
+  for (; regno < 32; ++regno)
+    fs[regno].value = regno * address_size;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.target/sh/executejava_standard.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/executejava_standard.c
--- gcc-4.7.3/gcc/testsuite/gcc.target/sh/executejava_standard.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/executejava_standard.c	2013-03-20 08:38:57.000000000 +0100
@@ -0,0 +1,10235 @@
+/* { dg-do compile { target "sh-*-*" } } */
+/* { dg-options "-w" } */
+
+typedef long long CVMInt64;
+typedef int CVMInt32;
+typedef short CVMInt16;
+typedef signed char CVMInt8;
+typedef unsigned long long CVMUint64;
+typedef unsigned int CVMUint32;
+typedef unsigned short CVMUint16;
+typedef unsigned char CVMUint8;
+typedef float CVMfloat32;
+typedef double CVMfloat64;
+typedef unsigned int CVMAddr;
+typedef unsigned int CVMSize;
+typedef int ptrdiff_t;
+typedef unsigned int size_t;
+typedef long int wchar_t;
+typedef unsigned char __u_char;
+typedef unsigned short int __u_short;
+typedef unsigned int __u_int;
+typedef unsigned long int __u_long;
+typedef signed char __int8_t;
+typedef unsigned char __uint8_t;
+typedef signed short int __int16_t;
+typedef unsigned short int __uint16_t;
+typedef signed int __int32_t;
+typedef unsigned int __uint32_t;
+__extension__ typedef signed long long int __int64_t;
+__extension__ typedef unsigned long long int __uint64_t;
+__extension__ typedef long long int __quad_t;
+__extension__ typedef unsigned long long int __u_quad_t;
+__extension__ typedef __u_quad_t __dev_t;
+__extension__ typedef unsigned int __uid_t;
+__extension__ typedef unsigned int __gid_t;
+__extension__ typedef unsigned long int __ino_t;
+__extension__ typedef __u_quad_t __ino64_t;
+__extension__ typedef unsigned int __mode_t;
+__extension__ typedef unsigned int __nlink_t;
+__extension__ typedef long int __off_t;
+__extension__ typedef __quad_t __off64_t;
+__extension__ typedef int __pid_t;
+__extension__ typedef struct { int __val[2]; } __fsid_t;
+__extension__ typedef long int __clock_t;
+__extension__ typedef unsigned long int __rlim_t;
+__extension__ typedef __u_quad_t __rlim64_t;
+__extension__ typedef unsigned int __id_t;
+__extension__ typedef long int __time_t;
+__extension__ typedef unsigned int __useconds_t;
+__extension__ typedef long int __suseconds_t;
+__extension__ typedef int __daddr_t;
+__extension__ typedef long int __swblk_t;
+__extension__ typedef int __key_t;
+__extension__ typedef int __clockid_t;
+__extension__ typedef void * __timer_t;
+__extension__ typedef long int __blksize_t;
+__extension__ typedef long int __blkcnt_t;
+__extension__ typedef __quad_t __blkcnt64_t;
+__extension__ typedef unsigned long int __fsblkcnt_t;
+__extension__ typedef __u_quad_t __fsblkcnt64_t;
+__extension__ typedef unsigned long int __fsfilcnt_t;
+__extension__ typedef __u_quad_t __fsfilcnt64_t;
+__extension__ typedef int __ssize_t;
+typedef __off64_t __loff_t;
+typedef __quad_t *__qaddr_t;
+typedef char *__caddr_t;
+__extension__ typedef int __intptr_t;
+__extension__ typedef unsigned int __socklen_t;
+struct _IO_FILE;
+typedef struct _IO_FILE FILE;
+typedef struct _IO_FILE __FILE;
+typedef struct
+{
+  int __count;
+  union
+  {
+    unsigned int __wch;
+    char __wchb[4];
+  } __value;
+} __mbstate_t;
+typedef struct
+{
+  __off_t __pos;
+  __mbstate_t __state;
+} _G_fpos_t;
+typedef struct
+{
+  __off64_t __pos;
+  __mbstate_t __state;
+} _G_fpos64_t;
+typedef int _G_int16_t __attribute__ ((__mode__ (__HI__)));
+typedef int _G_int32_t __attribute__ ((__mode__ (__SI__)));
+typedef unsigned int _G_uint16_t __attribute__ ((__mode__ (__HI__)));
+typedef unsigned int _G_uint32_t __attribute__ ((__mode__ (__SI__)));
+typedef __builtin_va_list __gnuc_va_list;
+struct _IO_jump_t; struct _IO_FILE;
+typedef void _IO_lock_t;
+struct _IO_marker {
+  struct _IO_marker *_next;
+  struct _IO_FILE *_sbuf;
+  int _pos;
+};
+enum __codecvt_result
+{
+  __codecvt_ok,
+  __codecvt_partial,
+  __codecvt_error,
+  __codecvt_noconv
+};
+struct _IO_FILE {
+  int _flags;
+  char* _IO_read_ptr;
+  char* _IO_read_end;
+  char* _IO_read_base;
+  char* _IO_write_base;
+  char* _IO_write_ptr;
+  char* _IO_write_end;
+  char* _IO_buf_base;
+  char* _IO_buf_end;
+  char *_IO_save_base;
+  char *_IO_backup_base;
+  char *_IO_save_end;
+  struct _IO_marker *_markers;
+  struct _IO_FILE *_chain;
+  int _fileno;
+  int _flags2;
+  __off_t _old_offset;
+  unsigned short _cur_column;
+  signed char _vtable_offset;
+  char _shortbuf[1];
+  _IO_lock_t *_lock;
+  __off64_t _offset;
+  void *__pad1;
+  void *__pad2;
+  void *__pad3;
+  void *__pad4;
+  size_t __pad5;
+  int _mode;
+  char _unused2[15 * sizeof (int) - 4 * sizeof (void *) - sizeof (size_t)];
+};
+typedef struct _IO_FILE _IO_FILE;
+struct _IO_FILE_plus;
+extern struct _IO_FILE_plus _IO_2_1_stdin_;
+extern struct _IO_FILE_plus _IO_2_1_stdout_;
+extern struct _IO_FILE_plus _IO_2_1_stderr_;
+typedef __ssize_t __io_read_fn (void *__cookie, char *__buf, size_t __nbytes);
+typedef __ssize_t __io_write_fn (void *__cookie, __const char *__buf,
+     size_t __n);
+typedef int __io_seek_fn (void *__cookie, __off64_t *__pos, int __w);
+typedef int __io_close_fn (void *__cookie);
+typedef __io_read_fn cookie_read_function_t;
+typedef __io_write_fn cookie_write_function_t;
+typedef __io_seek_fn cookie_seek_function_t;
+typedef __io_close_fn cookie_close_function_t;
+typedef struct
+{
+  __io_read_fn *read;
+  __io_write_fn *write;
+  __io_seek_fn *seek;
+  __io_close_fn *close;
+} _IO_cookie_io_functions_t;
+typedef _IO_cookie_io_functions_t cookie_io_functions_t;
+struct _IO_cookie_file;
+extern void _IO_cookie_init (struct _IO_cookie_file *__cfile, int __read_write,
+        void *__cookie, _IO_cookie_io_functions_t __fns);
+extern int __underflow (_IO_FILE *);
+extern int __uflow (_IO_FILE *);
+extern int __overflow (_IO_FILE *, int);
+extern int _IO_getc (_IO_FILE *__fp);
+extern int _IO_putc (int __c, _IO_FILE *__fp);
+extern int _IO_feof (_IO_FILE *__fp) __attribute__ ((__nothrow__));
+extern int _IO_ferror (_IO_FILE *__fp) __attribute__ ((__nothrow__));
+extern int _IO_peekc_locked (_IO_FILE *__fp);
+extern void _IO_flockfile (_IO_FILE *) __attribute__ ((__nothrow__));
+extern void _IO_funlockfile (_IO_FILE *) __attribute__ ((__nothrow__));
+extern int _IO_ftrylockfile (_IO_FILE *) __attribute__ ((__nothrow__));
+extern int _IO_vfscanf (_IO_FILE * __restrict, const char * __restrict,
+   __gnuc_va_list, int *__restrict);
+extern int _IO_vfprintf (_IO_FILE *__restrict, const char *__restrict,
+    __gnuc_va_list);
+extern __ssize_t _IO_padn (_IO_FILE *, int, __ssize_t);
+extern size_t _IO_sgetn (_IO_FILE *, void *, size_t);
+extern __off64_t _IO_seekoff (_IO_FILE *, __off64_t, int, int);
+extern __off64_t _IO_seekpos (_IO_FILE *, __off64_t, int);
+extern void _IO_free_backup_area (_IO_FILE *) __attribute__ ((__nothrow__));
+typedef __gnuc_va_list va_list;
+typedef _G_fpos_t fpos_t;
+typedef _G_fpos64_t fpos64_t;
+extern struct _IO_FILE *stdin;
+extern struct _IO_FILE *stdout;
+extern struct _IO_FILE *stderr;
+extern int remove (__const char *__filename) __attribute__ ((__nothrow__));
+extern int rename (__const char *__old, __const char *__new) __attribute__ ((__nothrow__));
+extern int renameat (int __oldfd, __const char *__old, int __newfd,
+       __const char *__new) __attribute__ ((__nothrow__));
+extern FILE *tmpfile (void) __attribute__ ((__warn_unused_result__));
+extern FILE *tmpfile64 (void) __attribute__ ((__warn_unused_result__));
+extern char *tmpnam (char *__s) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern char *tmpnam_r (char *__s) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern char *tempnam (__const char *__dir, __const char *__pfx)
+     __attribute__ ((__nothrow__)) __attribute__ ((__malloc__)) __attribute__ ((__warn_unused_result__));
+extern int fclose (FILE *__stream);
+extern int fflush (FILE *__stream);
+extern int fflush_unlocked (FILE *__stream);
+extern int fcloseall (void);
+extern FILE *fopen (__const char *__restrict __filename,
+      __const char *__restrict __modes) __attribute__ ((__warn_unused_result__));
+extern FILE *freopen (__const char *__restrict __filename,
+        __const char *__restrict __modes,
+        FILE *__restrict __stream) __attribute__ ((__warn_unused_result__));
+extern FILE *fopen64 (__const char *__restrict __filename,
+        __const char *__restrict __modes) __attribute__ ((__warn_unused_result__));
+extern FILE *freopen64 (__const char *__restrict __filename,
+   __const char *__restrict __modes,
+   FILE *__restrict __stream) __attribute__ ((__warn_unused_result__));
+extern FILE *fdopen (int __fd, __const char *__modes) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern FILE *fopencookie (void *__restrict __magic_cookie,
+     __const char *__restrict __modes,
+     _IO_cookie_io_functions_t __io_funcs) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern FILE *fmemopen (void *__s, size_t __len, __const char *__modes)
+  __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern FILE *open_memstream (char **__bufloc, size_t *__sizeloc) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern void setbuf (FILE *__restrict __stream, char *__restrict __buf) __attribute__ ((__nothrow__));
+extern int setvbuf (FILE *__restrict __stream, char *__restrict __buf,
+      int __modes, size_t __n) __attribute__ ((__nothrow__));
+extern void setbuffer (FILE *__restrict __stream, char *__restrict __buf,
+         size_t __size) __attribute__ ((__nothrow__));
+extern void setlinebuf (FILE *__stream) __attribute__ ((__nothrow__));
+extern int fprintf (FILE *__restrict __stream,
+      __const char *__restrict __format, ...);
+extern int printf (__const char *__restrict __format, ...);
+extern int sprintf (char *__restrict __s,
+      __const char *__restrict __format, ...) __attribute__ ((__nothrow__));
+extern int vfprintf (FILE *__restrict __s, __const char *__restrict __format,
+       __gnuc_va_list __arg);
+extern int vprintf (__const char *__restrict __format, __gnuc_va_list __arg);
+extern int vsprintf (char *__restrict __s, __const char *__restrict __format,
+       __gnuc_va_list __arg) __attribute__ ((__nothrow__));
+extern int snprintf (char *__restrict __s, size_t __maxlen,
+       __const char *__restrict __format, ...)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 3, 4)));
+extern int vsnprintf (char *__restrict __s, size_t __maxlen,
+        __const char *__restrict __format, __gnuc_va_list __arg)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 3, 0)));
+extern int vasprintf (char **__restrict __ptr, __const char *__restrict __f,
+        __gnuc_va_list __arg)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 2, 0))) __attribute__ ((__warn_unused_result__));
+extern int __asprintf (char **__restrict __ptr,
+         __const char *__restrict __fmt, ...)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 2, 3))) __attribute__ ((__warn_unused_result__));
+extern int asprintf (char **__restrict __ptr,
+       __const char *__restrict __fmt, ...)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 2, 3))) __attribute__ ((__warn_unused_result__));
+extern int vdprintf (int __fd, __const char *__restrict __fmt,
+       __gnuc_va_list __arg)
+     __attribute__ ((__format__ (__printf__, 2, 0)));
+extern int dprintf (int __fd, __const char *__restrict __fmt, ...)
+     __attribute__ ((__format__ (__printf__, 2, 3)));
+extern int fscanf (FILE *__restrict __stream,
+     __const char *__restrict __format, ...) __attribute__ ((__warn_unused_result__));
+extern int scanf (__const char *__restrict __format, ...) __attribute__ ((__warn_unused_result__));
+extern int sscanf (__const char *__restrict __s,
+     __const char *__restrict __format, ...) __attribute__ ((__nothrow__));
+extern int vfscanf (FILE *__restrict __s, __const char *__restrict __format,
+      __gnuc_va_list __arg)
+     __attribute__ ((__format__ (__scanf__, 2, 0))) __attribute__ ((__warn_unused_result__));
+extern int vscanf (__const char *__restrict __format, __gnuc_va_list __arg)
+     __attribute__ ((__format__ (__scanf__, 1, 0))) __attribute__ ((__warn_unused_result__));
+extern int vsscanf (__const char *__restrict __s,
+      __const char *__restrict __format, __gnuc_va_list __arg)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__scanf__, 2, 0)));
+extern int fgetc (FILE *__stream);
+extern int getc (FILE *__stream);
+extern int getchar (void);
+extern int getc_unlocked (FILE *__stream);
+extern int getchar_unlocked (void);
+extern int fgetc_unlocked (FILE *__stream);
+extern int fputc (int __c, FILE *__stream);
+extern int putc (int __c, FILE *__stream);
+extern int putchar (int __c);
+extern int fputc_unlocked (int __c, FILE *__stream);
+extern int putc_unlocked (int __c, FILE *__stream);
+extern int putchar_unlocked (int __c);
+extern int getw (FILE *__stream);
+extern int putw (int __w, FILE *__stream);
+extern char *fgets (char *__restrict __s, int __n, FILE *__restrict __stream)
+     __attribute__ ((__warn_unused_result__));
+extern char *gets (char *__s) __attribute__ ((__warn_unused_result__));
+extern char *fgets_unlocked (char *__restrict __s, int __n,
+        FILE *__restrict __stream) __attribute__ ((__warn_unused_result__));
+extern __ssize_t __getdelim (char **__restrict __lineptr,
+          size_t *__restrict __n, int __delimiter,
+          FILE *__restrict __stream) __attribute__ ((__warn_unused_result__));
+extern __ssize_t getdelim (char **__restrict __lineptr,
+        size_t *__restrict __n, int __delimiter,
+        FILE *__restrict __stream) __attribute__ ((__warn_unused_result__));
+extern __ssize_t getline (char **__restrict __lineptr,
+       size_t *__restrict __n,
+       FILE *__restrict __stream) __attribute__ ((__warn_unused_result__));
+extern int fputs (__const char *__restrict __s, FILE *__restrict __stream);
+extern int puts (__const char *__s);
+extern int ungetc (int __c, FILE *__stream);
+extern size_t fread (void *__restrict __ptr, size_t __size,
+       size_t __n, FILE *__restrict __stream) __attribute__ ((__warn_unused_result__));
+extern size_t fwrite (__const void *__restrict __ptr, size_t __size,
+        size_t __n, FILE *__restrict __s) __attribute__ ((__warn_unused_result__));
+extern int fputs_unlocked (__const char *__restrict __s,
+      FILE *__restrict __stream);
+extern size_t fread_unlocked (void *__restrict __ptr, size_t __size,
+         size_t __n, FILE *__restrict __stream) __attribute__ ((__warn_unused_result__));
+extern size_t fwrite_unlocked (__const void *__restrict __ptr, size_t __size,
+          size_t __n, FILE *__restrict __stream) __attribute__ ((__warn_unused_result__));
+extern int fseek (FILE *__stream, long int __off, int __whence);
+extern long int ftell (FILE *__stream) __attribute__ ((__warn_unused_result__));
+extern void rewind (FILE *__stream);
+extern int fseeko (FILE *__stream, __off_t __off, int __whence);
+extern __off_t ftello (FILE *__stream) __attribute__ ((__warn_unused_result__));
+extern int fgetpos (FILE *__restrict __stream, fpos_t *__restrict __pos);
+extern int fsetpos (FILE *__stream, __const fpos_t *__pos);
+extern int fseeko64 (FILE *__stream, __off64_t __off, int __whence);
+extern __off64_t ftello64 (FILE *__stream) __attribute__ ((__warn_unused_result__));
+extern int fgetpos64 (FILE *__restrict __stream, fpos64_t *__restrict __pos);
+extern int fsetpos64 (FILE *__stream, __const fpos64_t *__pos);
+extern void clearerr (FILE *__stream) __attribute__ ((__nothrow__));
+extern int feof (FILE *__stream) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern int ferror (FILE *__stream) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern void clearerr_unlocked (FILE *__stream) __attribute__ ((__nothrow__));
+extern int feof_unlocked (FILE *__stream) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern int ferror_unlocked (FILE *__stream) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern void perror (__const char *__s);
+extern int sys_nerr;
+extern __const char *__const sys_errlist[];
+extern int _sys_nerr;
+extern __const char *__const _sys_errlist[];
+extern int fileno (FILE *__stream) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern int fileno_unlocked (FILE *__stream) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern FILE *popen (__const char *__command, __const char *__modes) __attribute__ ((__warn_unused_result__));
+extern int pclose (FILE *__stream);
+extern char *ctermid (char *__s) __attribute__ ((__nothrow__));
+extern char *cuserid (char *__s);
+struct obstack;
+extern int obstack_printf (struct obstack *__restrict __obstack,
+      __const char *__restrict __format, ...)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 2, 3)));
+extern int obstack_vprintf (struct obstack *__restrict __obstack,
+       __const char *__restrict __format,
+       __gnuc_va_list __args)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 2, 0)));
+extern void flockfile (FILE *__stream) __attribute__ ((__nothrow__));
+extern int ftrylockfile (FILE *__stream) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern void funlockfile (FILE *__stream) __attribute__ ((__nothrow__));
+extern __inline int
+getchar (void)
+{
+  return _IO_getc (stdin);
+}
+extern __inline int
+fgetc_unlocked (FILE *__fp)
+{
+  return (__builtin_expect (((__fp)->_IO_read_ptr >= (__fp)->_IO_read_end), 0) ? __uflow (__fp) : *(unsigned char *) (__fp)->_IO_read_ptr++);
+}
+extern __inline int
+getc_unlocked (FILE *__fp)
+{
+  return (__builtin_expect (((__fp)->_IO_read_ptr >= (__fp)->_IO_read_end), 0) ? __uflow (__fp) : *(unsigned char *) (__fp)->_IO_read_ptr++);
+}
+extern __inline int
+getchar_unlocked (void)
+{
+  return (__builtin_expect (((stdin)->_IO_read_ptr >= (stdin)->_IO_read_end), 0) ? __uflow (stdin) : *(unsigned char *) (stdin)->_IO_read_ptr++);
+}
+extern __inline int
+putchar (int __c)
+{
+  return _IO_putc (__c, stdout);
+}
+extern __inline int
+fputc_unlocked (int __c, FILE *__stream)
+{
+  return (__builtin_expect (((__stream)->_IO_write_ptr >= (__stream)->_IO_write_end), 0) ? __overflow (__stream, (unsigned char) (__c)) : (unsigned char) (*(__stream)->_IO_write_ptr++ = (__c)));
+}
+extern __inline int
+putc_unlocked (int __c, FILE *__stream)
+{
+  return (__builtin_expect (((__stream)->_IO_write_ptr >= (__stream)->_IO_write_end), 0) ? __overflow (__stream, (unsigned char) (__c)) : (unsigned char) (*(__stream)->_IO_write_ptr++ = (__c)));
+}
+extern __inline int
+putchar_unlocked (int __c)
+{
+  return (__builtin_expect (((stdout)->_IO_write_ptr >= (stdout)->_IO_write_end), 0) ? __overflow (stdout, (unsigned char) (__c)) : (unsigned char) (*(stdout)->_IO_write_ptr++ = (__c)));
+}
+extern __inline __ssize_t
+getline (char **__lineptr, size_t *__n, FILE *__stream)
+{
+  return __getdelim (__lineptr, __n, '\n', __stream);
+}
+extern __inline int
+__attribute__ ((__nothrow__)) feof_unlocked (FILE *__stream)
+{
+  return (((__stream)->_flags & 0x10) != 0);
+}
+extern __inline int
+__attribute__ ((__nothrow__)) ferror_unlocked (FILE *__stream)
+{
+  return (((__stream)->_flags & 0x20) != 0);
+}
+extern int __sprintf_chk (char *__restrict __s, int __flag, size_t __slen,
+     __const char *__restrict __format, ...) __attribute__ ((__nothrow__));
+extern int __vsprintf_chk (char *__restrict __s, int __flag, size_t __slen,
+      __const char *__restrict __format,
+      __gnuc_va_list __ap) __attribute__ ((__nothrow__));
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+__attribute__ ((__nothrow__)) sprintf (char *__restrict __s, __const char *__restrict __fmt, ...)
+{
+  return __builtin___sprintf_chk (__s, 2 - 1,
+      __builtin_object_size (__s, 2 > 1), __fmt, __builtin_va_arg_pack ());
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+__attribute__ ((__nothrow__)) vsprintf (char *__restrict __s, __const char *__restrict __fmt, __gnuc_va_list __ap)
+{
+  return __builtin___vsprintf_chk (__s, 2 - 1,
+       __builtin_object_size (__s, 2 > 1), __fmt, __ap);
+}
+extern int __snprintf_chk (char *__restrict __s, size_t __n, int __flag,
+      size_t __slen, __const char *__restrict __format,
+      ...) __attribute__ ((__nothrow__));
+extern int __vsnprintf_chk (char *__restrict __s, size_t __n, int __flag,
+       size_t __slen, __const char *__restrict __format,
+       __gnuc_va_list __ap) __attribute__ ((__nothrow__));
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+__attribute__ ((__nothrow__)) snprintf (char *__restrict __s, size_t __n, __const char *__restrict __fmt, ...)
+{
+  return __builtin___snprintf_chk (__s, __n, 2 - 1,
+       __builtin_object_size (__s, 2 > 1), __fmt, __builtin_va_arg_pack ());
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+__attribute__ ((__nothrow__)) vsnprintf (char *__restrict __s, size_t __n, __const char *__restrict __fmt, __gnuc_va_list __ap)
+{
+  return __builtin___vsnprintf_chk (__s, __n, 2 - 1,
+        __builtin_object_size (__s, 2 > 1), __fmt, __ap);
+}
+extern int __fprintf_chk (FILE *__restrict __stream, int __flag,
+     __const char *__restrict __format, ...);
+extern int __printf_chk (int __flag, __const char *__restrict __format, ...);
+extern int __vfprintf_chk (FILE *__restrict __stream, int __flag,
+      __const char *__restrict __format, __gnuc_va_list __ap);
+extern int __vprintf_chk (int __flag, __const char *__restrict __format,
+     __gnuc_va_list __ap);
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+fprintf (FILE *__restrict __stream, __const char *__restrict __fmt, ...)
+{
+  return __fprintf_chk (__stream, 2 - 1, __fmt,
+   __builtin_va_arg_pack ());
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+printf (__const char *__restrict __fmt, ...)
+{
+  return __printf_chk (2 - 1, __fmt, __builtin_va_arg_pack ());
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+vprintf (__const char *__restrict __fmt, __gnuc_va_list __ap)
+{
+  return __vfprintf_chk (stdout, 2 - 1, __fmt, __ap);
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+vfprintf (FILE *__restrict __stream,
+   __const char *__restrict __fmt, __gnuc_va_list __ap)
+{
+  return __vfprintf_chk (__stream, 2 - 1, __fmt, __ap);
+}
+extern int __asprintf_chk (char **__restrict __ptr, int __flag,
+      __const char *__restrict __fmt, ...)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 3, 4))) __attribute__ ((__warn_unused_result__));
+extern int __vasprintf_chk (char **__restrict __ptr, int __flag,
+       __const char *__restrict __fmt, __gnuc_va_list __arg)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 3, 0))) __attribute__ ((__warn_unused_result__));
+extern int __dprintf_chk (int __fd, int __flag, __const char *__restrict __fmt,
+     ...) __attribute__ ((__format__ (__printf__, 3, 4)));
+extern int __vdprintf_chk (int __fd, int __flag,
+      __const char *__restrict __fmt, __gnuc_va_list __arg)
+     __attribute__ ((__format__ (__printf__, 3, 0)));
+extern int __obstack_printf_chk (struct obstack *__restrict __obstack,
+     int __flag, __const char *__restrict __format,
+     ...)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 3, 4)));
+extern int __obstack_vprintf_chk (struct obstack *__restrict __obstack,
+      int __flag,
+      __const char *__restrict __format,
+      __gnuc_va_list __args)
+     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 3, 0)));
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+__attribute__ ((__nothrow__)) asprintf (char **__restrict __ptr, __const char *__restrict __fmt, ...)
+{
+  return __asprintf_chk (__ptr, 2 - 1, __fmt,
+    __builtin_va_arg_pack ());
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+__attribute__ ((__nothrow__)) __asprintf (char **__restrict __ptr, __const char *__restrict __fmt, ...)
+{
+  return __asprintf_chk (__ptr, 2 - 1, __fmt,
+    __builtin_va_arg_pack ());
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+dprintf (int __fd, __const char *__restrict __fmt, ...)
+{
+  return __dprintf_chk (__fd, 2 - 1, __fmt,
+   __builtin_va_arg_pack ());
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+__attribute__ ((__nothrow__)) obstack_printf (struct obstack *__restrict __obstack, __const char *__restrict __fmt, ...)
+{
+  return __obstack_printf_chk (__obstack, 2 - 1, __fmt,
+          __builtin_va_arg_pack ());
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+__attribute__ ((__nothrow__)) vasprintf (char **__restrict __ptr, __const char *__restrict __fmt, __gnuc_va_list __ap)
+{
+  return __vasprintf_chk (__ptr, 2 - 1, __fmt, __ap);
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+vdprintf (int __fd, __const char *__restrict __fmt, __gnuc_va_list __ap)
+{
+  return __vdprintf_chk (__fd, 2 - 1, __fmt, __ap);
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+__attribute__ ((__nothrow__)) obstack_vprintf (struct obstack *__restrict __obstack, __const char *__restrict __fmt, __gnuc_va_list __ap)
+{
+  return __obstack_vprintf_chk (__obstack, 2 - 1, __fmt,
+    __ap);
+}
+extern char *__gets_chk (char *__str, size_t) __attribute__ ((__warn_unused_result__));
+extern char *__gets_warn (char *__str) __asm__ ("" "gets")
+     __attribute__ ((__warn_unused_result__)) __attribute__((__warning__ ("please use fgets or getline instead, gets can't " "specify buffer size")))
+                               ;
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) __attribute__ ((__warn_unused_result__)) char *
+gets (char *__str)
+{
+  if (__builtin_object_size (__str, 2 > 1) != (size_t) -1)
+    return __gets_chk (__str, __builtin_object_size (__str, 2 > 1));
+  return __gets_warn (__str);
+}
+extern char *__fgets_chk (char *__restrict __s, size_t __size, int __n,
+     FILE *__restrict __stream) __attribute__ ((__warn_unused_result__));
+extern char *__fgets_alias (char *__restrict __s, int __n, FILE *__restrict __stream) __asm__ ("" "fgets")
+                                        __attribute__ ((__warn_unused_result__));
+extern char *__fgets_chk_warn (char *__restrict __s, size_t __size, int __n, FILE *__restrict __stream) __asm__ ("" "__fgets_chk")
+     __attribute__ ((__warn_unused_result__)) __attribute__((__warning__ ("fgets called with bigger size than length " "of destination buffer")))
+                                 ;
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) __attribute__ ((__warn_unused_result__)) char *
+fgets (char *__restrict __s, int __n, FILE *__restrict __stream)
+{
+  if (__builtin_object_size (__s, 2 > 1) != (size_t) -1)
+    {
+      if (!__builtin_constant_p (__n) || __n <= 0)
+ return __fgets_chk (__s, __builtin_object_size (__s, 2 > 1), __n, __stream);
+      if ((size_t) __n > __builtin_object_size (__s, 2 > 1))
+ return __fgets_chk_warn (__s, __builtin_object_size (__s, 2 > 1), __n, __stream);
+    }
+  return __fgets_alias (__s, __n, __stream);
+}
+extern size_t __fread_chk (void *__restrict __ptr, size_t __ptrlen,
+      size_t __size, size_t __n,
+      FILE *__restrict __stream) __attribute__ ((__warn_unused_result__));
+extern size_t __fread_alias (void *__restrict __ptr, size_t __size, size_t __n, FILE *__restrict __stream) __asm__ ("" "fread")
+            __attribute__ ((__warn_unused_result__));
+extern size_t __fread_chk_warn (void *__restrict __ptr, size_t __ptrlen, size_t __size, size_t __n, FILE *__restrict __stream) __asm__ ("" "__fread_chk")
+     __attribute__ ((__warn_unused_result__)) __attribute__((__warning__ ("fread called with bigger size * nmemb than length " "of destination buffer")))
+                                 ;
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) __attribute__ ((__warn_unused_result__)) size_t
+fread (void *__restrict __ptr, size_t __size, size_t __n,
+       FILE *__restrict __stream)
+{
+  if (__builtin_object_size (__ptr, 0) != (size_t) -1)
+    {
+      if (!__builtin_constant_p (__size)
+   || !__builtin_constant_p (__n)
+   || (__size | __n) >= (((size_t) 1) << (8 * sizeof (size_t) / 2)))
+ return __fread_chk (__ptr, __builtin_object_size (__ptr, 0), __size, __n, __stream);
+      if (__size * __n > __builtin_object_size (__ptr, 0))
+ return __fread_chk_warn (__ptr, __builtin_object_size (__ptr, 0), __size, __n, __stream);
+    }
+  return __fread_alias (__ptr, __size, __n, __stream);
+}
+extern char *__fgets_unlocked_chk (char *__restrict __s, size_t __size,
+       int __n, FILE *__restrict __stream) __attribute__ ((__warn_unused_result__));
+extern char *__fgets_unlocked_alias (char *__restrict __s, int __n, FILE *__restrict __stream) __asm__ ("" "fgets_unlocked")
+                                                 __attribute__ ((__warn_unused_result__));
+extern char *__fgets_unlocked_chk_warn (char *__restrict __s, size_t __size, int __n, FILE *__restrict __stream) __asm__ ("" "__fgets_unlocked_chk")
+     __attribute__ ((__warn_unused_result__)) __attribute__((__warning__ ("fgets_unlocked called with bigger size than length " "of destination buffer")))
+                                 ;
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) __attribute__ ((__warn_unused_result__)) char *
+fgets_unlocked (char *__restrict __s, int __n, FILE *__restrict __stream)
+{
+  if (__builtin_object_size (__s, 2 > 1) != (size_t) -1)
+    {
+      if (!__builtin_constant_p (__n) || __n <= 0)
+ return __fgets_unlocked_chk (__s, __builtin_object_size (__s, 2 > 1), __n, __stream);
+      if ((size_t) __n > __builtin_object_size (__s, 2 > 1))
+ return __fgets_unlocked_chk_warn (__s, __builtin_object_size (__s, 2 > 1), __n, __stream);
+    }
+  return __fgets_unlocked_alias (__s, __n, __stream);
+}
+extern size_t __fread_unlocked_chk (void *__restrict __ptr, size_t __ptrlen,
+        size_t __size, size_t __n,
+        FILE *__restrict __stream) __attribute__ ((__warn_unused_result__));
+extern size_t __fread_unlocked_alias (void *__restrict __ptr, size_t __size, size_t __n, FILE *__restrict __stream) __asm__ ("" "fread_unlocked")
+                     __attribute__ ((__warn_unused_result__));
+extern size_t __fread_unlocked_chk_warn (void *__restrict __ptr, size_t __ptrlen, size_t __size, size_t __n, FILE *__restrict __stream) __asm__ ("" "__fread_unlocked_chk")
+     __attribute__ ((__warn_unused_result__)) __attribute__((__warning__ ("fread_unlocked called with bigger size * nmemb than " "length of destination buffer")))
+                                        ;
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) __attribute__ ((__warn_unused_result__)) size_t
+fread_unlocked (void *__restrict __ptr, size_t __size, size_t __n,
+  FILE *__restrict __stream)
+{
+  if (__builtin_object_size (__ptr, 0) != (size_t) -1)
+    {
+      if (!__builtin_constant_p (__size)
+   || !__builtin_constant_p (__n)
+   || (__size | __n) >= (((size_t) 1) << (8 * sizeof (size_t) / 2)))
+ return __fread_unlocked_chk (__ptr, __builtin_object_size (__ptr, 0), __size, __n,
+         __stream);
+      if (__size * __n > __builtin_object_size (__ptr, 0))
+ return __fread_unlocked_chk_warn (__ptr, __builtin_object_size (__ptr, 0), __size, __n,
+       __stream);
+    }
+  if (__builtin_constant_p (__size)
+      && __builtin_constant_p (__n)
+      && (__size | __n) < (((size_t) 1) << (8 * sizeof (size_t) / 2))
+      && __size * __n <= 8)
+    {
+      size_t __cnt = __size * __n;
+      char *__cptr = (char *) __ptr;
+      if (__cnt == 0)
+ return 0;
+      for (; __cnt > 0; --__cnt)
+ {
+   int __c = (__builtin_expect (((__stream)->_IO_read_ptr >= (__stream)->_IO_read_end), 0) ? __uflow (__stream) : *(unsigned char *) (__stream)->_IO_read_ptr++);
+   if (__c == (-1))
+     break;
+   *__cptr++ = __c;
+ }
+      return (__cptr - (char *) __ptr) / __size;
+    }
+  return __fread_unlocked_alias (__ptr, __size, __n, __stream);
+}
+extern void *malloc (size_t __size) __attribute__ ((__nothrow__)) __attribute__ ((__malloc__)) __attribute__ ((__warn_unused_result__));
+extern void *calloc (size_t __nmemb, size_t __size) __attribute__ ((__nothrow__))
+       __attribute__ ((__malloc__)) __attribute__ ((__warn_unused_result__));
+extern void *realloc (void *__ptr, size_t __size) __attribute__ ((__nothrow__))
+       __attribute__ ((__warn_unused_result__));
+extern void free (void *__ptr) __attribute__ ((__nothrow__));
+extern void cfree (void *__ptr) __attribute__ ((__nothrow__));
+extern void *memalign (size_t __alignment, size_t __size) __attribute__ ((__nothrow__))
+       __attribute__ ((__malloc__)) __attribute__ ((__warn_unused_result__));
+extern void *valloc (size_t __size) __attribute__ ((__nothrow__))
+       __attribute__ ((__malloc__)) __attribute__ ((__warn_unused_result__));
+extern void * pvalloc (size_t __size) __attribute__ ((__nothrow__))
+       __attribute__ ((__malloc__)) __attribute__ ((__warn_unused_result__));
+extern void *(*__morecore) (ptrdiff_t __size);
+extern void *__default_morecore (ptrdiff_t __size) __attribute__ ((__nothrow__))
+       __attribute__ ((__malloc__));
+struct mallinfo {
+  int arena;
+  int ordblks;
+  int smblks;
+  int hblks;
+  int hblkhd;
+  int usmblks;
+  int fsmblks;
+  int uordblks;
+  int fordblks;
+  int keepcost;
+};
+extern struct mallinfo mallinfo (void) __attribute__ ((__nothrow__));
+extern int mallopt (int __param, int __val) __attribute__ ((__nothrow__));
+extern int malloc_trim (size_t __pad) __attribute__ ((__nothrow__));
+extern size_t malloc_usable_size (void *__ptr) __attribute__ ((__nothrow__));
+extern void malloc_stats (void) __attribute__ ((__nothrow__));
+extern int malloc_info (int __options, FILE *__fp);
+extern void *malloc_get_state (void) __attribute__ ((__nothrow__));
+extern int malloc_set_state (void *__ptr) __attribute__ ((__nothrow__));
+extern void (*__malloc_initialize_hook) (void);
+extern void (*__free_hook) (void *__ptr, __const void *)
+                             ;
+extern void *(*__malloc_hook) (size_t __size, __const void *)
+                                  ;
+extern void *(*__realloc_hook) (void *__ptr, size_t __size, __const void *)
+                                   ;
+extern void *(*__memalign_hook) (size_t __alignment, size_t __size, __const void *)
+                                    ;
+extern void (*__after_morecore_hook) (void);
+extern void __malloc_check_init (void) __attribute__ ((__nothrow__));
+struct timespec
+  {
+    __time_t tv_sec;
+    long int tv_nsec;
+  };
+struct sched_param
+  {
+    int __sched_priority;
+  };
+extern int clone (int (*__fn) (void *__arg), void *__child_stack,
+    int __flags, void *__arg, ...) __attribute__ ((__nothrow__));
+extern int unshare (int __flags) __attribute__ ((__nothrow__));
+extern int sched_getcpu (void) __attribute__ ((__nothrow__));
+struct __sched_param
+  {
+    int __sched_priority;
+  };
+typedef unsigned long int __cpu_mask;
+typedef struct
+{
+  __cpu_mask __bits[1024 / (8 * sizeof (__cpu_mask))];
+} cpu_set_t;
+extern int __sched_cpucount (size_t __setsize, const cpu_set_t *__setp)
+  __attribute__ ((__nothrow__));
+extern cpu_set_t *__sched_cpualloc (size_t __count) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern void __sched_cpufree (cpu_set_t *__set) __attribute__ ((__nothrow__));
+extern int sched_setparam (__pid_t __pid, __const struct sched_param *__param)
+     __attribute__ ((__nothrow__));
+extern int sched_getparam (__pid_t __pid, struct sched_param *__param) __attribute__ ((__nothrow__));
+extern int sched_setscheduler (__pid_t __pid, int __policy,
+          __const struct sched_param *__param) __attribute__ ((__nothrow__));
+extern int sched_getscheduler (__pid_t __pid) __attribute__ ((__nothrow__));
+extern int sched_yield (void) __attribute__ ((__nothrow__));
+extern int sched_get_priority_max (int __algorithm) __attribute__ ((__nothrow__));
+extern int sched_get_priority_min (int __algorithm) __attribute__ ((__nothrow__));
+extern int sched_rr_get_interval (__pid_t __pid, struct timespec *__t) __attribute__ ((__nothrow__));
+extern int sched_setaffinity (__pid_t __pid, size_t __cpusetsize,
+         __const cpu_set_t *__cpuset) __attribute__ ((__nothrow__));
+extern int sched_getaffinity (__pid_t __pid, size_t __cpusetsize,
+         cpu_set_t *__cpuset) __attribute__ ((__nothrow__));
+typedef __clock_t clock_t;
+typedef __time_t time_t;
+typedef __clockid_t clockid_t;
+typedef __timer_t timer_t;
+struct tm
+{
+  int tm_sec;
+  int tm_min;
+  int tm_hour;
+  int tm_mday;
+  int tm_mon;
+  int tm_year;
+  int tm_wday;
+  int tm_yday;
+  int tm_isdst;
+  long int tm_gmtoff;
+  __const char *tm_zone;
+};
+struct itimerspec
+  {
+    struct timespec it_interval;
+    struct timespec it_value;
+  };
+struct sigevent;
+typedef __pid_t pid_t;
+extern clock_t clock (void) __attribute__ ((__nothrow__));
+extern time_t time (time_t *__timer) __attribute__ ((__nothrow__));
+extern double difftime (time_t __time1, time_t __time0)
+     __attribute__ ((__nothrow__)) __attribute__ ((__const__));
+extern time_t mktime (struct tm *__tp) __attribute__ ((__nothrow__));
+extern size_t strftime (char *__restrict __s, size_t __maxsize,
+   __const char *__restrict __format,
+   __const struct tm *__restrict __tp) __attribute__ ((__nothrow__));
+extern char *strptime (__const char *__restrict __s,
+         __const char *__restrict __fmt, struct tm *__tp)
+     __attribute__ ((__nothrow__));
+typedef struct __locale_struct
+{
+  struct locale_data *__locales[13];
+  const unsigned short int *__ctype_b;
+  const int *__ctype_tolower;
+  const int *__ctype_toupper;
+  const char *__names[13];
+} *__locale_t;
+typedef __locale_t locale_t;
+extern size_t strftime_l (char *__restrict __s, size_t __maxsize,
+     __const char *__restrict __format,
+     __const struct tm *__restrict __tp,
+     __locale_t __loc) __attribute__ ((__nothrow__));
+extern char *strptime_l (__const char *__restrict __s,
+    __const char *__restrict __fmt, struct tm *__tp,
+    __locale_t __loc) __attribute__ ((__nothrow__));
+extern struct tm *gmtime (__const time_t *__timer) __attribute__ ((__nothrow__));
+extern struct tm *localtime (__const time_t *__timer) __attribute__ ((__nothrow__));
+extern struct tm *gmtime_r (__const time_t *__restrict __timer,
+       struct tm *__restrict __tp) __attribute__ ((__nothrow__));
+extern struct tm *localtime_r (__const time_t *__restrict __timer,
+          struct tm *__restrict __tp) __attribute__ ((__nothrow__));
+extern char *asctime (__const struct tm *__tp) __attribute__ ((__nothrow__));
+extern char *ctime (__const time_t *__timer) __attribute__ ((__nothrow__));
+extern char *asctime_r (__const struct tm *__restrict __tp,
+   char *__restrict __buf) __attribute__ ((__nothrow__));
+extern char *ctime_r (__const time_t *__restrict __timer,
+        char *__restrict __buf) __attribute__ ((__nothrow__));
+extern char *__tzname[2];
+extern int __daylight;
+extern long int __timezone;
+extern char *tzname[2];
+extern void tzset (void) __attribute__ ((__nothrow__));
+extern int daylight;
+extern long int timezone;
+extern int stime (__const time_t *__when) __attribute__ ((__nothrow__));
+extern time_t timegm (struct tm *__tp) __attribute__ ((__nothrow__));
+extern time_t timelocal (struct tm *__tp) __attribute__ ((__nothrow__));
+extern int dysize (int __year) __attribute__ ((__nothrow__)) __attribute__ ((__const__));
+extern int nanosleep (__const struct timespec *__requested_time,
+        struct timespec *__remaining);
+extern int clock_getres (clockid_t __clock_id, struct timespec *__res) __attribute__ ((__nothrow__));
+extern int clock_gettime (clockid_t __clock_id, struct timespec *__tp) __attribute__ ((__nothrow__));
+extern int clock_settime (clockid_t __clock_id, __const struct timespec *__tp)
+     __attribute__ ((__nothrow__));
+extern int clock_nanosleep (clockid_t __clock_id, int __flags,
+       __const struct timespec *__req,
+       struct timespec *__rem);
+extern int clock_getcpuclockid (pid_t __pid, clockid_t *__clock_id) __attribute__ ((__nothrow__));
+extern int timer_create (clockid_t __clock_id,
+    struct sigevent *__restrict __evp,
+    timer_t *__restrict __timerid) __attribute__ ((__nothrow__));
+extern int timer_delete (timer_t __timerid) __attribute__ ((__nothrow__));
+extern int timer_settime (timer_t __timerid, int __flags,
+     __const struct itimerspec *__restrict __value,
+     struct itimerspec *__restrict __ovalue) __attribute__ ((__nothrow__));
+extern int timer_gettime (timer_t __timerid, struct itimerspec *__value)
+     __attribute__ ((__nothrow__));
+extern int timer_getoverrun (timer_t __timerid) __attribute__ ((__nothrow__));
+extern int getdate_err;
+extern struct tm *getdate (__const char *__string);
+extern int getdate_r (__const char *__restrict __string,
+        struct tm *__restrict __resbufp);
+typedef int __sig_atomic_t;
+typedef struct
+  {
+    unsigned long int __val[(1024 / (8 * sizeof (unsigned long int)))];
+  } __sigset_t;
+typedef __sigset_t sigset_t;
+typedef unsigned long int pthread_t;
+typedef union
+{
+  char __size[36];
+  long int __align;
+} pthread_attr_t;
+typedef struct __pthread_internal_slist
+{
+  struct __pthread_internal_slist *__next;
+} __pthread_slist_t;
+typedef union
+{
+  struct __pthread_mutex_s
+  {
+    int __lock;
+    unsigned int __count;
+    int __owner;
+    int __kind;
+    unsigned int __nusers;
+    __extension__ union
+    {
+      int __spins;
+      __pthread_slist_t __list;
+    };
+  } __data;
+  char __size[24];
+  long int __align;
+} pthread_mutex_t;
+typedef union
+{
+  char __size[4];
+  long int __align;
+} pthread_mutexattr_t;
+typedef union
+{
+  struct
+  {
+    int __lock;
+    unsigned int __futex;
+    __extension__ unsigned long long int __total_seq;
+    __extension__ unsigned long long int __wakeup_seq;
+    __extension__ unsigned long long int __woken_seq;
+    void *__mutex;
+    unsigned int __nwaiters;
+    unsigned int __broadcast_seq;
+  } __data;
+  char __size[48];
+  __extension__ long long int __align;
+} pthread_cond_t;
+typedef union
+{
+  char __size[4];
+  long int __align;
+} pthread_condattr_t;
+typedef unsigned int pthread_key_t;
+typedef int pthread_once_t;
+typedef union
+{
+  struct
+  {
+    int __lock;
+    unsigned int __nr_readers;
+    unsigned int __readers_wakeup;
+    unsigned int __writer_wakeup;
+    unsigned int __nr_readers_queued;
+    unsigned int __nr_writers_queued;
+    unsigned char __flags;
+    unsigned char __shared;
+    unsigned char __pad1;
+    unsigned char __pad2;
+    pthread_t __writer;
+  } __data;
+  char __size[32];
+  long int __align;
+} pthread_rwlock_t;
+typedef union
+{
+  char __size[8];
+  long int __align;
+} pthread_rwlockattr_t;
+typedef volatile int pthread_spinlock_t;
+typedef union
+{
+  char __size[20];
+  long int __align;
+} pthread_barrier_t;
+typedef union
+{
+  char __size[4];
+  int __align;
+} pthread_barrierattr_t;
+typedef struct __jmp_buf_internal_tag
+  {
+    int __regs[8];
+    void * __pc;
+    void * __gbr;
+    int __fpscr;
+    int __fpregs[4];
+  } __jmp_buf[1];
+enum
+{
+  PTHREAD_CREATE_JOINABLE,
+  PTHREAD_CREATE_DETACHED
+};
+enum
+{
+  PTHREAD_MUTEX_TIMED_NP,
+  PTHREAD_MUTEX_RECURSIVE_NP,
+  PTHREAD_MUTEX_ERRORCHECK_NP,
+  PTHREAD_MUTEX_ADAPTIVE_NP
+  ,
+  PTHREAD_MUTEX_NORMAL = PTHREAD_MUTEX_TIMED_NP,
+  PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,
+  PTHREAD_MUTEX_ERRORCHECK = PTHREAD_MUTEX_ERRORCHECK_NP,
+  PTHREAD_MUTEX_DEFAULT = PTHREAD_MUTEX_NORMAL
+  , PTHREAD_MUTEX_FAST_NP = PTHREAD_MUTEX_TIMED_NP
+};
+enum
+{
+  PTHREAD_MUTEX_STALLED,
+  PTHREAD_MUTEX_STALLED_NP = PTHREAD_MUTEX_STALLED,
+  PTHREAD_MUTEX_ROBUST,
+  PTHREAD_MUTEX_ROBUST_NP = PTHREAD_MUTEX_ROBUST
+};
+enum
+{
+  PTHREAD_PRIO_NONE,
+  PTHREAD_PRIO_INHERIT,
+  PTHREAD_PRIO_PROTECT
+};
+enum
+{
+  PTHREAD_RWLOCK_PREFER_READER_NP,
+  PTHREAD_RWLOCK_PREFER_WRITER_NP,
+  PTHREAD_RWLOCK_PREFER_WRITER_NONRECURSIVE_NP,
+  PTHREAD_RWLOCK_DEFAULT_NP = PTHREAD_RWLOCK_PREFER_READER_NP
+};
+enum
+{
+  PTHREAD_INHERIT_SCHED,
+  PTHREAD_EXPLICIT_SCHED
+};
+enum
+{
+  PTHREAD_SCOPE_SYSTEM,
+  PTHREAD_SCOPE_PROCESS
+};
+enum
+{
+  PTHREAD_PROCESS_PRIVATE,
+  PTHREAD_PROCESS_SHARED
+};
+struct _pthread_cleanup_buffer
+{
+  void (*__routine) (void *);
+  void *__arg;
+  int __canceltype;
+  struct _pthread_cleanup_buffer *__prev;
+};
+enum
+{
+  PTHREAD_CANCEL_ENABLE,
+  PTHREAD_CANCEL_DISABLE
+};
+enum
+{
+  PTHREAD_CANCEL_DEFERRED,
+  PTHREAD_CANCEL_ASYNCHRONOUS
+};
+extern int pthread_create (pthread_t *__restrict __newthread,
+      __const pthread_attr_t *__restrict __attr,
+      void *(*__start_routine) (void *),
+      void *__restrict __arg) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 3)));
+extern void pthread_exit (void *__retval) __attribute__ ((__noreturn__));
+extern int pthread_join (pthread_t __th, void **__thread_return);
+extern int pthread_tryjoin_np (pthread_t __th, void **__thread_return) __attribute__ ((__nothrow__));
+extern int pthread_timedjoin_np (pthread_t __th, void **__thread_return,
+     __const struct timespec *__abstime);
+extern int pthread_detach (pthread_t __th) __attribute__ ((__nothrow__));
+extern pthread_t pthread_self (void) __attribute__ ((__nothrow__)) __attribute__ ((__const__));
+extern int pthread_equal (pthread_t __thread1, pthread_t __thread2) __attribute__ ((__nothrow__));
+extern int pthread_attr_init (pthread_attr_t *__attr) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_attr_destroy (pthread_attr_t *__attr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_attr_getdetachstate (__const pthread_attr_t *__attr,
+     int *__detachstate)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_attr_setdetachstate (pthread_attr_t *__attr,
+     int __detachstate)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_attr_getguardsize (__const pthread_attr_t *__attr,
+          size_t *__guardsize)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_attr_setguardsize (pthread_attr_t *__attr,
+          size_t __guardsize)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_attr_getschedparam (__const pthread_attr_t *__restrict
+           __attr,
+           struct sched_param *__restrict __param)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_attr_setschedparam (pthread_attr_t *__restrict __attr,
+           __const struct sched_param *__restrict
+           __param) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_attr_getschedpolicy (__const pthread_attr_t *__restrict
+     __attr, int *__restrict __policy)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_attr_setschedpolicy (pthread_attr_t *__attr, int __policy)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_attr_getinheritsched (__const pthread_attr_t *__restrict
+      __attr, int *__restrict __inherit)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_attr_setinheritsched (pthread_attr_t *__attr,
+      int __inherit)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_attr_getscope (__const pthread_attr_t *__restrict __attr,
+      int *__restrict __scope)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_attr_setscope (pthread_attr_t *__attr, int __scope)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_attr_getstackaddr (__const pthread_attr_t *__restrict
+          __attr, void **__restrict __stackaddr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2))) __attribute__ ((__deprecated__));
+extern int pthread_attr_setstackaddr (pthread_attr_t *__attr,
+          void *__stackaddr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__deprecated__));
+extern int pthread_attr_getstacksize (__const pthread_attr_t *__restrict
+          __attr, size_t *__restrict __stacksize)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_attr_setstacksize (pthread_attr_t *__attr,
+          size_t __stacksize)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_attr_getstack (__const pthread_attr_t *__restrict __attr,
+      void **__restrict __stackaddr,
+      size_t *__restrict __stacksize)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2, 3)));
+extern int pthread_attr_setstack (pthread_attr_t *__attr, void *__stackaddr,
+      size_t __stacksize) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_attr_setaffinity_np (pthread_attr_t *__attr,
+     size_t __cpusetsize,
+     __const cpu_set_t *__cpuset)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 3)));
+extern int pthread_attr_getaffinity_np (__const pthread_attr_t *__attr,
+     size_t __cpusetsize,
+     cpu_set_t *__cpuset)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 3)));
+extern int pthread_getattr_np (pthread_t __th, pthread_attr_t *__attr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+extern int pthread_setschedparam (pthread_t __target_thread, int __policy,
+      __const struct sched_param *__param)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3)));
+extern int pthread_getschedparam (pthread_t __target_thread,
+      int *__restrict __policy,
+      struct sched_param *__restrict __param)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2, 3)));
+extern int pthread_setschedprio (pthread_t __target_thread, int __prio)
+     __attribute__ ((__nothrow__));
+extern int pthread_getconcurrency (void) __attribute__ ((__nothrow__));
+extern int pthread_setconcurrency (int __level) __attribute__ ((__nothrow__));
+extern int pthread_yield (void) __attribute__ ((__nothrow__));
+extern int pthread_setaffinity_np (pthread_t __th, size_t __cpusetsize,
+       __const cpu_set_t *__cpuset)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3)));
+extern int pthread_getaffinity_np (pthread_t __th, size_t __cpusetsize,
+       cpu_set_t *__cpuset)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3)));
+extern int pthread_once (pthread_once_t *__once_control,
+    void (*__init_routine) (void)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_setcancelstate (int __state, int *__oldstate);
+extern int pthread_setcanceltype (int __type, int *__oldtype);
+extern int pthread_cancel (pthread_t __th);
+extern void pthread_testcancel (void);
+typedef struct
+{
+  struct
+  {
+    __jmp_buf __cancel_jmp_buf;
+    int __mask_was_saved;
+  } __cancel_jmp_buf[1];
+  void *__pad[4];
+} __pthread_unwind_buf_t __attribute__ ((__aligned__));
+struct __pthread_cleanup_frame
+{
+  void (*__cancel_routine) (void *);
+  void *__cancel_arg;
+  int __do_it;
+  int __cancel_type;
+};
+extern void __pthread_register_cancel (__pthread_unwind_buf_t *__buf)
+     ;
+extern void __pthread_unregister_cancel (__pthread_unwind_buf_t *__buf)
+  ;
+extern void __pthread_register_cancel_defer (__pthread_unwind_buf_t *__buf)
+     ;
+extern void __pthread_unregister_cancel_restore (__pthread_unwind_buf_t *__buf)
+  ;
+extern void __pthread_unwind_next (__pthread_unwind_buf_t *__buf)
+     __attribute__ ((__noreturn__))
+     __attribute__ ((__weak__))
+     ;
+struct __jmp_buf_tag;
+extern int __sigsetjmp (struct __jmp_buf_tag *__env, int __savemask) __attribute__ ((__nothrow__));
+extern int pthread_mutex_init (pthread_mutex_t *__mutex,
+          __const pthread_mutexattr_t *__mutexattr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_mutex_destroy (pthread_mutex_t *__mutex)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_mutex_trylock (pthread_mutex_t *__mutex)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_mutex_lock (pthread_mutex_t *__mutex)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_mutex_timedlock (pthread_mutex_t *__restrict __mutex,
+                                    __const struct timespec *__restrict
+                                    __abstime) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_mutex_unlock (pthread_mutex_t *__mutex)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_mutex_getprioceiling (__const pthread_mutex_t *
+      __restrict __mutex,
+      int *__restrict __prioceiling)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_mutex_setprioceiling (pthread_mutex_t *__restrict __mutex,
+      int __prioceiling,
+      int *__restrict __old_ceiling)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 3)));
+extern int pthread_mutex_consistent_np (pthread_mutex_t *__mutex)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_mutex_consistent_np (pthread_mutex_t *__mutex)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_mutexattr_init (pthread_mutexattr_t *__attr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_mutexattr_destroy (pthread_mutexattr_t *__attr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_mutexattr_getpshared (__const pthread_mutexattr_t *
+      __restrict __attr,
+      int *__restrict __pshared)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_mutexattr_setpshared (pthread_mutexattr_t *__attr,
+      int __pshared)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_mutexattr_gettype (__const pthread_mutexattr_t *__restrict
+          __attr, int *__restrict __kind)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_mutexattr_settype (pthread_mutexattr_t *__attr, int __kind)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_mutexattr_getprotocol (__const pthread_mutexattr_t *
+       __restrict __attr,
+       int *__restrict __protocol)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_mutexattr_setprotocol (pthread_mutexattr_t *__attr,
+       int __protocol)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_mutexattr_getprioceiling (__const pthread_mutexattr_t *
+          __restrict __attr,
+          int *__restrict __prioceiling)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_mutexattr_setprioceiling (pthread_mutexattr_t *__attr,
+          int __prioceiling)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_mutexattr_getrobust (__const pthread_mutexattr_t *__attr,
+     int *__robustness)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_mutexattr_getrobust_np (__const pthread_mutexattr_t *__attr,
+        int *__robustness)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_mutexattr_setrobust (pthread_mutexattr_t *__attr,
+     int __robustness)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_mutexattr_setrobust_np (pthread_mutexattr_t *__attr,
+        int __robustness)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_rwlock_init (pthread_rwlock_t *__restrict __rwlock,
+    __const pthread_rwlockattr_t *__restrict
+    __attr) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_rwlock_destroy (pthread_rwlock_t *__rwlock)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_rwlock_rdlock (pthread_rwlock_t *__rwlock)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_rwlock_tryrdlock (pthread_rwlock_t *__rwlock)
+  __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_rwlock_timedrdlock (pthread_rwlock_t *__restrict __rwlock,
+           __const struct timespec *__restrict
+           __abstime) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_rwlock_wrlock (pthread_rwlock_t *__rwlock)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_rwlock_trywrlock (pthread_rwlock_t *__rwlock)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_rwlock_timedwrlock (pthread_rwlock_t *__restrict __rwlock,
+           __const struct timespec *__restrict
+           __abstime) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_rwlock_unlock (pthread_rwlock_t *__rwlock)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_rwlockattr_init (pthread_rwlockattr_t *__attr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_rwlockattr_destroy (pthread_rwlockattr_t *__attr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_rwlockattr_getpshared (__const pthread_rwlockattr_t *
+       __restrict __attr,
+       int *__restrict __pshared)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_rwlockattr_setpshared (pthread_rwlockattr_t *__attr,
+       int __pshared)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_rwlockattr_getkind_np (__const pthread_rwlockattr_t *
+       __restrict __attr,
+       int *__restrict __pref)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_rwlockattr_setkind_np (pthread_rwlockattr_t *__attr,
+       int __pref) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_cond_init (pthread_cond_t *__restrict __cond,
+         __const pthread_condattr_t *__restrict
+         __cond_attr) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_cond_destroy (pthread_cond_t *__cond)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_cond_signal (pthread_cond_t *__cond)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_cond_broadcast (pthread_cond_t *__cond)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_cond_wait (pthread_cond_t *__restrict __cond,
+         pthread_mutex_t *__restrict __mutex)
+     __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_cond_timedwait (pthread_cond_t *__restrict __cond,
+       pthread_mutex_t *__restrict __mutex,
+       __const struct timespec *__restrict
+       __abstime) __attribute__ ((__nonnull__ (1, 2, 3)));
+extern int pthread_condattr_init (pthread_condattr_t *__attr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_condattr_destroy (pthread_condattr_t *__attr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_condattr_getpshared (__const pthread_condattr_t *
+                                        __restrict __attr,
+                                        int *__restrict __pshared)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_condattr_setpshared (pthread_condattr_t *__attr,
+                                        int __pshared) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_condattr_getclock (__const pthread_condattr_t *
+          __restrict __attr,
+          __clockid_t *__restrict __clock_id)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_condattr_setclock (pthread_condattr_t *__attr,
+          __clockid_t __clock_id)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_spin_init (pthread_spinlock_t *__lock, int __pshared)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_spin_destroy (pthread_spinlock_t *__lock)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_spin_lock (pthread_spinlock_t *__lock)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_spin_trylock (pthread_spinlock_t *__lock)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_spin_unlock (pthread_spinlock_t *__lock)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_barrier_init (pthread_barrier_t *__restrict __barrier,
+     __const pthread_barrierattr_t *__restrict
+     __attr, unsigned int __count)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_barrier_destroy (pthread_barrier_t *__barrier)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_barrier_wait (pthread_barrier_t *__barrier)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_barrierattr_init (pthread_barrierattr_t *__attr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_barrierattr_destroy (pthread_barrierattr_t *__attr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_barrierattr_getpshared (__const pthread_barrierattr_t *
+        __restrict __attr,
+        int *__restrict __pshared)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int pthread_barrierattr_setpshared (pthread_barrierattr_t *__attr,
+                                           int __pshared)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_key_create (pthread_key_t *__key,
+          void (*__destr_function) (void *))
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int pthread_key_delete (pthread_key_t __key) __attribute__ ((__nothrow__));
+extern void *pthread_getspecific (pthread_key_t __key) __attribute__ ((__nothrow__));
+extern int pthread_setspecific (pthread_key_t __key,
+    __const void *__pointer) __attribute__ ((__nothrow__)) ;
+extern int pthread_getcpuclockid (pthread_t __thread_id,
+      __clockid_t *__clock_id)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+extern int pthread_atfork (void (*__prepare) (void),
+      void (*__parent) (void),
+      void (*__child) (void)) __attribute__ ((__nothrow__));
+extern __inline int
+__attribute__ ((__nothrow__)) pthread_equal (pthread_t __thread1, pthread_t __thread2)
+{
+  return __thread1 == __thread2;
+}
+typedef __u_char u_char;
+typedef __u_short u_short;
+typedef __u_int u_int;
+typedef __u_long u_long;
+typedef __quad_t quad_t;
+typedef __u_quad_t u_quad_t;
+typedef __fsid_t fsid_t;
+typedef __loff_t loff_t;
+typedef __ino_t ino_t;
+typedef __ino64_t ino64_t;
+typedef __dev_t dev_t;
+typedef __gid_t gid_t;
+typedef __mode_t mode_t;
+typedef __nlink_t nlink_t;
+typedef __uid_t uid_t;
+typedef __off_t off_t;
+typedef __off64_t off64_t;
+typedef __id_t id_t;
+typedef __ssize_t ssize_t;
+typedef __daddr_t daddr_t;
+typedef __caddr_t caddr_t;
+typedef __key_t key_t;
+typedef __useconds_t useconds_t;
+typedef __suseconds_t suseconds_t;
+typedef unsigned long int ulong;
+typedef unsigned short int ushort;
+typedef unsigned int uint;
+typedef int int8_t __attribute__ ((__mode__ (__QI__)));
+typedef int int16_t __attribute__ ((__mode__ (__HI__)));
+typedef int int32_t __attribute__ ((__mode__ (__SI__)));
+typedef int int64_t __attribute__ ((__mode__ (__DI__)));
+typedef unsigned int u_int8_t __attribute__ ((__mode__ (__QI__)));
+typedef unsigned int u_int16_t __attribute__ ((__mode__ (__HI__)));
+typedef unsigned int u_int32_t __attribute__ ((__mode__ (__SI__)));
+typedef unsigned int u_int64_t __attribute__ ((__mode__ (__DI__)));
+typedef int register_t __attribute__ ((__mode__ (__word__)));
+struct timeval
+  {
+    __time_t tv_sec;
+    __suseconds_t tv_usec;
+  };
+typedef long int __fd_mask;
+typedef struct
+  {
+    __fd_mask fds_bits[1024 / (8 * sizeof (__fd_mask))];
+  } fd_set;
+typedef __fd_mask fd_mask;
+extern int select (int __nfds, fd_set *__restrict __readfds,
+     fd_set *__restrict __writefds,
+     fd_set *__restrict __exceptfds,
+     struct timeval *__restrict __timeout);
+extern int pselect (int __nfds, fd_set *__restrict __readfds,
+      fd_set *__restrict __writefds,
+      fd_set *__restrict __exceptfds,
+      const struct timespec *__restrict __timeout,
+      const __sigset_t *__restrict __sigmask);
+__extension__
+extern unsigned int gnu_dev_major (unsigned long long int __dev)
+     __attribute__ ((__nothrow__));
+__extension__
+extern unsigned int gnu_dev_minor (unsigned long long int __dev)
+     __attribute__ ((__nothrow__));
+__extension__
+extern unsigned long long int gnu_dev_makedev (unsigned int __major,
+            unsigned int __minor)
+     __attribute__ ((__nothrow__));
+__extension__ extern __inline unsigned int
+__attribute__ ((__nothrow__)) gnu_dev_major (unsigned long long int __dev)
+{
+  return ((__dev >> 8) & 0xfff) | ((unsigned int) (__dev >> 32) & ~0xfff);
+}
+__extension__ extern __inline unsigned int
+__attribute__ ((__nothrow__)) gnu_dev_minor (unsigned long long int __dev)
+{
+  return (__dev & 0xff) | ((unsigned int) (__dev >> 12) & ~0xff);
+}
+__extension__ extern __inline unsigned long long int
+__attribute__ ((__nothrow__)) gnu_dev_makedev (unsigned int __major, unsigned int __minor)
+{
+  return ((__minor & 0xff) | ((__major & 0xfff) << 8)
+   | (((unsigned long long int) (__minor & ~0xff)) << 12)
+   | (((unsigned long long int) (__major & ~0xfff)) << 32));
+}
+typedef __blksize_t blksize_t;
+typedef __blkcnt_t blkcnt_t;
+typedef __fsblkcnt_t fsblkcnt_t;
+typedef __fsfilcnt_t fsfilcnt_t;
+typedef __blkcnt64_t blkcnt64_t;
+typedef __fsblkcnt64_t fsblkcnt64_t;
+typedef __fsfilcnt64_t fsfilcnt64_t;
+typedef union
+{
+  char __size[16];
+  long int __align;
+} sem_t;
+extern int sem_init (sem_t *__sem, int __pshared, unsigned int __value)
+     __attribute__ ((__nothrow__));
+extern int sem_destroy (sem_t *__sem) __attribute__ ((__nothrow__));
+extern sem_t *sem_open (__const char *__name, int __oflag, ...) __attribute__ ((__nothrow__));
+extern int sem_close (sem_t *__sem) __attribute__ ((__nothrow__));
+extern int sem_unlink (__const char *__name) __attribute__ ((__nothrow__));
+extern int sem_wait (sem_t *__sem);
+extern int sem_timedwait (sem_t *__restrict __sem,
+     __const struct timespec *__restrict __abstime);
+extern int sem_trywait (sem_t *__sem) __attribute__ ((__nothrow__));
+extern int sem_post (sem_t *__sem) __attribute__ ((__nothrow__));
+extern int sem_getvalue (sem_t *__restrict __sem, int *__restrict __sval)
+     __attribute__ ((__nothrow__));
+typedef CVMInt8 CVMJavaByte;
+typedef CVMInt16 CVMJavaShort;
+typedef CVMUint16 CVMJavaChar;
+typedef CVMUint8 CVMJavaBoolean;
+typedef CVMInt32 CVMJavaInt;
+typedef CVMfloat32 CVMJavaFloat;
+typedef CVMInt64 CVMJavaLong;
+typedef CVMfloat64 CVMJavaDouble;
+typedef CVMUint32 CVMBool;
+typedef struct CVMMutex CVMMutex;
+typedef struct CVMCondVar CVMCondVar;
+typedef struct CVMMicroLock CVMMicroLock;
+typedef struct CVMThreadID CVMThreadID;
+typedef struct CVMTargetGlobalState CVMTargetGlobalState;
+typedef char CVMUtf8;
+typedef struct CVMObjectHeader CVMObjectHeader;
+typedef union CVMVariousBits CVMVariousBits;
+typedef union CVMJavaVal8 CVMJavaVal8;
+typedef union CVMJavaVal16 CVMJavaVal16;
+typedef union CVMJavaVal32 CVMJavaVal32;
+typedef union CVMJavaVal64 CVMJavaVal64;
+typedef struct CVMjava_lang_Object CVMjava_lang_Object;
+typedef struct CVMSyncVector CVMSyncVector;
+typedef CVMjava_lang_Object CVMObject;
+typedef struct CVMArrayOfByte CVMArrayOfByte;
+typedef struct CVMArrayOfShort CVMArrayOfShort;
+typedef struct CVMArrayOfChar CVMArrayOfChar;
+typedef struct CVMArrayOfBoolean CVMArrayOfBoolean;
+typedef struct CVMArrayOfInt CVMArrayOfInt;
+typedef struct CVMArrayOfRef CVMArrayOfRef;
+typedef struct CVMArrayOfFloat CVMArrayOfFloat;
+typedef struct CVMArrayOfLong CVMArrayOfLong;
+typedef struct CVMArrayOfDouble CVMArrayOfDouble;
+typedef struct CVMArrayOfAnyType CVMArrayOfAnyType;
+typedef struct CVMjava_lang_ObjectICell CVMjava_lang_ObjectICell;
+typedef struct CVMObjectICell CVMObjectICell;
+typedef struct CVMArrayOfByteICell CVMArrayOfByteICell;
+typedef struct CVMArrayOfShortICell CVMArrayOfShortICell;
+typedef struct CVMArrayOfCharICell CVMArrayOfCharICell;
+typedef struct CVMArrayOfBooleanICell CVMArrayOfBooleanICell;
+typedef struct CVMArrayOfIntICell CVMArrayOfIntICell;
+typedef struct CVMArrayOfRefICell CVMArrayOfRefICell;
+typedef struct CVMArrayOfFloatICell CVMArrayOfFloatICell;
+typedef struct CVMArrayOfLongICell CVMArrayOfLongICell;
+typedef struct CVMArrayOfDoubleICell CVMArrayOfDoubleICell;
+typedef struct CVMArrayOfAnyTypeICell CVMArrayOfAnyTypeICell;
+typedef struct CVMClassBlock CVMClassBlock;
+typedef union CVMGCBitMap CVMGCBitMap;
+typedef struct CVMBigGCBitMap CVMBigGCBitMap;
+typedef struct CVMArrayInfo CVMArrayInfo;
+typedef struct CVMInterfaces CVMInterfaces;
+typedef struct CVMInterfaceTable CVMInterfaceTable;
+typedef struct CVMMethodBlock CVMMethodBlock;
+typedef struct CVMMethodBlockImmutable CVMMethodBlockImmutable;
+typedef struct CVMMethodRange CVMMethodRange;
+typedef struct CVMMethodArray CVMMethodArray;
+typedef struct CVMCheckedExceptions CVMCheckedExceptions;
+typedef struct CVMJavaMethodDescriptor CVMJavaMethodDescriptor;
+typedef struct CVMExceptionHandler CVMExceptionHandler;
+typedef struct CVMLineNumberEntry CVMLineNumberEntry;
+typedef struct CVMLocalVariableEntry CVMLocalVariableEntry;
+typedef struct CVMFieldBlock CVMFieldBlock;
+typedef struct CVMFieldRange CVMFieldRange;
+typedef struct CVMFieldArray CVMFieldArray;
+typedef struct CVMInnerClassInfo CVMInnerClassInfo;
+typedef struct CVMInnerClassesInfo CVMInnerClassesInfo;
+typedef union CVMConstantPool CVMConstantPool;
+typedef struct CVMTransitionConstantPool CVMTransitionConstantPool;
+typedef union CVMConstantPoolEntry CVMConstantPoolEntry;
+typedef struct CVMStackMapEntry CVMStackMapEntry;
+typedef struct CVMStackMaps CVMStackMaps;
+typedef CVMObjectICell CVMThreadICell;
+typedef CVMObjectICell CVMThrowableICell;
+typedef CVMObjectICell CVMStringICell;
+typedef CVMObjectICell CVMClassICell;
+typedef CVMObjectICell CVMClassLoaderICell;
+typedef CVMObject* CVMStringObject;
+typedef struct CVMExecEnv CVMExecEnv;
+typedef CVMBool CVMTryLockFunc (CVMExecEnv* ee,
+        CVMObject* obj);
+typedef CVMBool CVMLockFunc (CVMExecEnv* ee,
+        CVMObjectICell* indirectObj);
+typedef CVMBool CVMNotifyFunc (CVMExecEnv* ee,
+        CVMObjectICell* indirectObj);
+typedef CVMBool CVMNotifyAllFunc (CVMExecEnv* ee,
+        CVMObjectICell* indirectObj);
+typedef CVMBool CVMWaitFunc (CVMExecEnv* ee,
+        CVMObjectICell* indirectObj,
+        CVMJavaLong millis);
+typedef struct CVMReentrantMutex CVMReentrantMutex;
+typedef struct CVMSysMutex CVMSysMutex;
+typedef struct CVMSysMonitor CVMSysMonitor;
+typedef struct CVMProfiledMonitor CVMProfiledMonitor;
+typedef struct CVMNamedSysMonitor CVMNamedSysMonitor;
+typedef struct CVMObjMonitor CVMObjMonitor;
+typedef struct CVMOwnedMonitor CVMOwnedMonitor;
+typedef struct CVMCState CVMCState;
+typedef struct CVMTCState CVMTCState;
+typedef struct CVMLoaderCacheEntry CVMLoaderCacheEntry;
+typedef struct CVMLoaderConstraint CVMLoaderConstraint;
+typedef struct CVMSeenClass CVMSeenClass;
+typedef struct CVMClassPathEntry CVMClassPathEntry;
+typedef union CVMStackVal32 CVMStackVal32;
+typedef struct CVMStack CVMStack;
+typedef struct CVMStackChunk CVMStackChunk;
+typedef struct CVMFrame CVMFrame;
+typedef struct CVMFrameIterator CVMFrameIterator;
+typedef struct CVMLocalRootsFrame CVMLocalRootsFrame;
+typedef struct CVMFreelistFrame CVMFreelistFrame;
+typedef struct CVMInterpreterFrame CVMInterpreterFrame;
+typedef struct CVMJavaFrame CVMJavaFrame;
+typedef struct CVMTransitionFrame CVMTransitionFrame;
+typedef struct CVMStackWalkContext CVMStackWalkContext;
+typedef struct CVMGlobalState CVMGlobalState;
+typedef struct CVMGCGlobalState CVMGCGlobalState;
+typedef struct CVMOptions CVMOptions;
+typedef struct CVMGCOptions CVMGCOptions;
+typedef struct CVMJavaAssertionsOptionList CVMJavaAssertionsOptionList;
+typedef void (*CVMRefCallbackFunc)(CVMObject** refAddr, void* data);
+typedef CVMBool (*CVMRefLivenessQueryFunc)(CVMObject** refAddr, void* data);
+typedef CVMBool (*CVMObjectCallbackFunc)(CVMObject* obj, CVMClassBlock* cb,
+                                         CVMUint32 objSize, void* data);
+typedef void CVMFrameGCScannerFunc(CVMExecEnv* ee,
+       CVMFrame* thisFrame,
+       CVMStackChunk* thisChunk,
+       CVMRefCallbackFunc refCallback,
+       void* data,
+       CVMGCOptions* gcOpts);
+struct JNINativeInterface;
+typedef const struct JNINativeInterface *JNIEnv;
+typedef CVMUint32 CVMTypeID;
+typedef CVMUint16 CVMTypeIDPart;
+typedef CVMTypeID CVMMethodTypeID;
+typedef CVMTypeID CVMFieldTypeID;
+typedef CVMTypeID CVMClassTypeID;
+typedef CVMTypeIDPart CVMTypeIDNamePart;
+typedef CVMTypeIDPart CVMTypeIDTypePart;
+extern int CVMtypeidGetArrayDepthX( CVMClassTypeID );
+extern CVMClassTypeID CVMtypeidGetArrayBasetypeX( CVMClassTypeID );
+extern CVMBool
+CVMtypeidInit(CVMExecEnv *ee);
+extern void
+CVMtypeidRegisterPreloadedPackages();
+extern void
+CVMtypeidDestroy();
+extern CVMMethodTypeID
+CVMtypeidLookupMethodIDFromNameAndSig( CVMExecEnv *ee,
+      const CVMUtf8* memberName, const CVMUtf8* memberSig);
+extern CVMMethodTypeID
+CVMtypeidNewMethodIDFromNameAndSig( CVMExecEnv *ee,
+      const CVMUtf8* memberName, const CVMUtf8* memberSig);
+extern CVMMethodTypeID
+CVMtypeidCloneMethodID( CVMExecEnv *ee, CVMMethodTypeID cookie );
+extern void
+CVMtypeidDisposeMethodID( CVMExecEnv *ee, CVMMethodTypeID cookie );
+extern CVMFieldTypeID
+CVMtypeidLookupFieldIDFromNameAndSig( CVMExecEnv *ee,
+   const CVMUtf8* memberName, const CVMUtf8* memberSig);
+extern CVMFieldTypeID
+CVMtypeidNewFieldIDFromNameAndSig( CVMExecEnv *ee,
+   const CVMUtf8* memberName, const CVMUtf8* memberSig);
+extern CVMFieldTypeID
+CVMtypeidCloneFieldID( CVMExecEnv *ee, CVMFieldTypeID cookie );
+extern void
+CVMtypeidDisposeFieldID( CVMExecEnv *ee, CVMFieldTypeID cookie );
+extern CVMClassTypeID
+CVMtypeidLookupClassID( CVMExecEnv *ee, const char * name, int nameLength );
+extern CVMClassTypeID
+CVMtypeidNewClassID( CVMExecEnv *ee, const char * name, int nameLength );
+extern CVMClassTypeID
+CVMtypeidCloneClassID( CVMExecEnv *ee, CVMClassTypeID cookie );
+extern void
+CVMtypeidDisposeClassID( CVMExecEnv *ee, CVMClassTypeID cookie );
+extern CVMTypeID
+CVMtypeidLookupMembername( CVMExecEnv *ee, const char * name );
+extern CVMTypeID
+CVMtypeidNewMembername( CVMExecEnv *ee, const char * name );
+extern CVMTypeID
+CVMtypeidCloneMembername( CVMExecEnv *ee, CVMTypeID cookie );
+extern void
+CVMtypeidDisposeMembername( CVMExecEnv *ee, CVMTypeID cookie );
+extern char
+CVMtypeidGetReturnType(CVMMethodTypeID type);
+extern CVMUint16
+CVMtypeidGetArgsSize( CVMMethodTypeID methodTypeID );
+extern CVMBool
+CVMtypeidMethodIsRef(CVMMethodTypeID type);
+extern size_t
+CVMtypeidFieldTypeLength0(CVMFieldTypeID type, CVMBool isField);
+extern size_t
+CVMtypeidMethodTypeLength(CVMMethodTypeID type);
+extern size_t
+CVMtypeidMemberNameLength(CVMMethodTypeID type);
+extern size_t
+CVMtypeidClassNameLength(CVMClassTypeID type);
+extern CVMBool
+CVMtypeidMethodTypeToCString(CVMMethodTypeID type, char* buf, int bufLength);
+extern CVMBool
+CVMtypeidFieldTypeToCString(CVMFieldTypeID type, char* buf, int bufLength);
+extern CVMBool
+CVMtypeidMethodNameToCString(CVMMethodTypeID type, char* buf, int bufLength);
+extern CVMBool
+CVMtypeidFieldNameToCString(CVMFieldTypeID type, char* buf, int bufLength);
+extern CVMBool
+CVMtypeidClassNameToCString(CVMClassTypeID type, char* buf, int bufLength);
+extern char *
+CVMtypeidMethodTypeToAllocatedCString( CVMMethodTypeID type );
+extern char *
+CVMtypeidFieldTypeToAllocatedCString( CVMFieldTypeID type );
+extern char *
+CVMtypeidMethodNameToAllocatedCString( CVMMethodTypeID type );
+extern char *
+CVMtypeidFieldNameToAllocatedCString( CVMFieldTypeID type );
+extern char *
+CVMtypeidClassNameToAllocatedCString( CVMClassTypeID type );
+int CVMtypeidIncrementFieldRefcount( CVMFieldTypeID );
+int CVMtypeidDecrementFieldRefcount( CVMFieldTypeID );
+extern CVMClassTypeID
+CVMtypeidIncrementArrayDepth( CVMExecEnv *ee, CVMClassTypeID base,
+         int depthIncrement );
+extern CVMBool
+CVMtypeidIsSameClassPackage( CVMClassTypeID classname1,
+        CVMClassTypeID classname2 );
+typedef struct CVMterseSig {
+    CVMUint32 * datap;
+    int nParameters;
+} CVMterseSig;
+typedef struct CVMterseSigIterator {
+    CVMterseSig thisSig;
+    int word;
+    int syllableInWord;
+} CVMterseSigIterator;
+void
+CVMtypeidGetTerseSignature( CVMMethodTypeID tid, CVMterseSig* result );
+void
+CVMtypeidGetTerseSignatureIterator( CVMMethodTypeID tid, CVMterseSigIterator* result );
+typedef struct CVMSigIterator {
+    CVMterseSigIterator terseSig;
+    CVMTypeIDTypePart* parameterDetails;
+    CVMClassTypeID returnType;
+    CVMClassTypeID temp;
+} CVMSigIterator;
+void
+CVMtypeidGetSignatureIterator( CVMMethodTypeID tid, CVMSigIterator* result );
+extern void CVMtypeidPrintStats();
+extern void CVMtypeidPrintDiffs( CVMBool verbose );
+extern void CVMtypeidCheckTables();
+enum CVMBasicType {
+    CVM_T_ERR = 0,
+    CVM_T_CLASS = 2,
+    CVM_T_BOOLEAN = 4,
+    CVM_T_CHAR,
+    CVM_T_FLOAT,
+    CVM_T_DOUBLE,
+    CVM_T_BYTE,
+    CVM_T_SHORT,
+    CVM_T_INT,
+    CVM_T_LONG,
+    CVM_T_VOID = 17
+};
+typedef enum CVMBasicType CVMBasicType;
+extern const CVMUint32 CVMbasicTypeSizes[];
+extern const char CVMbasicTypeSignatures[];
+extern const CVMClassTypeID CVMbasicTypeID[];
+extern const CVMClassBlock* const CVMbasicTypeClassblocks[];
+extern const CVMClassBlock* const CVMbasicTypeArrayClassblocks[];
+extern const CVMClassBlock* const CVMterseTypeClassblocks[];
+extern const CVMBasicType CVMterseTypeBasicTypes[];
+extern const char CVMterseTypePrimitiveSignatures[];
+extern CVMBool CVMmicrolockInit (CVMMicroLock* m);
+extern void CVMmicrolockDestroy(CVMMicroLock* m);
+extern void CVMmicrolockLock (CVMMicroLock* m);
+extern void CVMmicrolockUnlock (CVMMicroLock* m);
+extern CVMBool CVMmutexInit (CVMMutex* m);
+extern void CVMmutexDestroy(CVMMutex* m);
+extern CVMBool CVMmutexTryLock(CVMMutex* m);
+extern void CVMmutexLock (CVMMutex* m);
+extern void CVMmutexUnlock (CVMMutex* m);
+extern void CVMmutexSetOwner(CVMThreadID *self, CVMMutex* m,
+    CVMThreadID *ti);
+extern CVMBool CVMcondvarInit (CVMCondVar *c, CVMMutex* m);
+extern void CVMcondvarDestroy(CVMCondVar *c);
+extern CVMBool CVMcondvarWait (CVMCondVar* c, CVMMutex* m,
+       CVMJavaLong millis);
+extern void CVMcondvarNotify (CVMCondVar* c);
+extern void CVMcondvarNotifyAll(CVMCondVar* c);
+typedef struct {
+    pthread_mutex_t m;
+} POSIXMutex;
+typedef struct {
+    pthread_cond_t c;
+} POSIXCondVar;
+extern CVMBool POSIXmutexInit(POSIXMutex * m);
+extern void POSIXmutexDestroy(POSIXMutex * m);
+extern CVMBool POSIXmutexTryLock(POSIXMutex * m);
+extern void POSIXmutexLock(POSIXMutex * m);
+extern void POSIXmutexUnlock(POSIXMutex * m);
+extern CVMBool POSIXcondvarInit(POSIXCondVar * c, POSIXMutex * m);
+extern void POSIXcondvarDestroy(POSIXCondVar * c);
+extern int POSIXcondvarWait(POSIXCondVar * c, POSIXMutex * m,
+ CVMJavaLong millis);
+extern void POSIXcondvarNotify(POSIXCondVar * c);
+extern void POSIXcondvarNotifyAll(POSIXCondVar * c);
+CVMBool linuxSyncInit(void);
+void linuxSyncInterruptWait(CVMThreadID *thread);
+void linuxSyncSuspend(CVMThreadID *thread);
+void linuxSyncResume(CVMThreadID *thread);
+struct CVMMutex {
+    POSIXMutex pmtx;
+};
+struct CVMCondVar {
+    POSIXCondVar pcv;
+    CVMThreadID *waiters;
+    CVMThreadID **last_p;
+};
+typedef enum {
+    CVM_CODE_MICROLOCK,
+    CVM_CONSTANTPOOL_MICROLOCK,
+    CVM_TOOLS_MICROLOCK,
+    CVM_GC_LOCKER_MICROLOCK,
+    CVM_METHOD_TRACE_MICROLOCK,
+    CVM_ACCESS_VOLATILE_MICROLOCK,
+    CVM_NUM_SYS_MICROLOCKS
+} CVMSysMicroLock;
+void
+CVMsysMicroLock(CVMExecEnv *ee, CVMSysMicroLock lock);
+void
+CVMsysMicroUnlock(CVMExecEnv *ee, CVMSysMicroLock lock);
+void
+CVMsysMicroLockAll(CVMExecEnv *ee);
+void
+CVMsysMicroUnlockAll(CVMExecEnv *ee);
+struct CVMReentrantMutex {
+    CVMExecEnv *owner;
+    CVMUint32 count;
+    CVMMutex mutex;
+};
+extern CVMBool CVMreentrantMutexInit (CVMReentrantMutex *rm,
+     CVMExecEnv *owner, CVMUint32 count);
+extern void CVMreentrantMutexDestroy(CVMReentrantMutex *rm);
+extern CVMBool CVMreentrantMutexTryLock(CVMExecEnv *ee, CVMReentrantMutex *rm);
+extern void CVMreentrantMutexLock (CVMExecEnv *ee, CVMReentrantMutex *rm);
+extern void CVMreentrantMutexUnlock (CVMExecEnv *ee, CVMReentrantMutex *rm);
+extern CVMBool CVMreentrantMutexWait (CVMExecEnv *ee, CVMReentrantMutex *rm,
+     CVMCondVar *c, CVMInt64 millis);
+extern CVMBool CVMreentrantMutexIAmOwner(CVMExecEnv *ee, CVMReentrantMutex *rm);
+struct CVMSysMutex {
+    const char *name;
+    CVMUint8 rank;
+    CVMReentrantMutex rmutex;
+    CVMSysMutex *nextOwned;
+};
+extern CVMBool CVMsysMutexInit (CVMSysMutex* m,
+         const char *name,
+         CVMUint8 rank);
+extern void CVMsysMutexDestroy(CVMSysMutex* m);
+extern CVMBool CVMsysMutexTryLock(CVMExecEnv *ee, CVMSysMutex* m);
+extern void CVMsysMutexLock (CVMExecEnv *ee, CVMSysMutex* m);
+extern void CVMsysMutexUnlock (CVMExecEnv *ee, CVMSysMutex* m);
+extern CVMBool CVMsysMutexWait (CVMExecEnv *ee, CVMSysMutex* m,
+         CVMCondVar *c, CVMInt64 millis);
+typedef enum {
+    CVM_WAIT_OK,
+    CVM_WAIT_INTERRUPTED,
+    CVM_WAIT_NOT_OWNER
+} CVMWaitStatus;
+struct CVMSysMonitor {
+    CVMReentrantMutex rmutex;
+    CVMCondVar condvar;
+};
+extern CVMBool
+CVMsysMonitorInit(CVMSysMonitor* m, CVMExecEnv *owner, CVMUint32 count);
+extern void
+CVMsysMonitorDestroy(CVMSysMonitor* m);
+extern void
+CVMsysMonitorEnter(CVMExecEnv *ee, CVMSysMonitor* m);
+extern void
+CVMsysMonitorExit(CVMExecEnv *ee, CVMSysMonitor* m);
+extern CVMBool
+CVMsysMonitorNotify(CVMExecEnv *ee, CVMSysMonitor* m);
+extern CVMBool
+CVMsysMonitorNotifyAll(CVMExecEnv *ee, CVMSysMonitor* m);
+extern CVMWaitStatus
+CVMsysMonitorWait(CVMExecEnv *ee, CVMSysMonitor* m, CVMInt64 millis);
+enum {
+    CVM_LOCKTYPE_UNKNOWN = 0,
+    CVM_LOCKTYPE_OBJ_MONITOR,
+    CVM_LOCKTYPE_NAMED_SYSMONITOR
+};
+struct CVMProfiledMonitor {
+    CVMSysMonitor _super;
+    CVMUint8 type;
+    CVMUint32 contentionCount;
+    CVMProfiledMonitor *next;
+    CVMProfiledMonitor **previousPtr;
+};
+extern CVMBool
+CVMprofiledMonitorInit(CVMProfiledMonitor *self, CVMExecEnv *owner,
+                       CVMUint32 count, CVMUint8 lockType);
+extern void
+CVMprofiledMonitorExit(CVMProfiledMonitor *self, CVMExecEnv *currentEE);
+extern CVMWaitStatus
+CVMprofiledMonitorWait(CVMProfiledMonitor *self, CVMExecEnv *currentEE,
+                       CVMInt64 millis);
+extern void
+CVMprofiledMonitorEnterUnsafe(CVMProfiledMonitor *self,
+         CVMExecEnv *currentEE, CVMBool doPost);
+extern void
+CVMprofiledMonitorEnterSafe(CVMProfiledMonitor *self, CVMExecEnv *currentEE, CVMBool doPost);
+extern void
+CVMdeleteUnreferencedMonitors(CVMExecEnv *ee,
+         CVMRefLivenessQueryFunc isLive,
+         void* isLiveData,
+         CVMRefCallbackFunc transitiveScanner,
+         void* transitiveScannerData);
+extern void
+CVMscanMonitors(CVMExecEnv *ee, CVMRefCallbackFunc refCallback, void* data);
+extern CVMBool
+CVMeeSyncInit(CVMExecEnv *ee);
+extern void
+CVMeeSyncDestroy(CVMExecEnv *ee);
+extern CVMBool
+CVMeeSyncInitGlobal(CVMExecEnv *ee, CVMGlobalState *gs);
+extern void
+CVMeeSyncDestroyGlobal(CVMExecEnv *ee, CVMGlobalState *gs);
+struct CVMObjectHeader {
+    volatile CVMClassBlock *clas;
+    volatile CVMAddr various32;
+};
+enum {
+    CVM_LOCKSTATE_LOCKED = 0,
+    CVM_LOCKSTATE_MONITOR = 1,
+    CVM_LOCKSTATE_UNLOCKED = 2
+};
+extern CVMInt32
+CVMobjectGetHashSafe(CVMExecEnv *ee, CVMObjectICell* indirectObj);
+extern CVMInt32
+CVMobjectGetHashNoSet(CVMExecEnv *ee, CVMObject* directObj);
+struct CVMjava_lang_ObjectICell { CVMjava_lang_Object * volatile ref_DONT_ACCESS_DIRECTLY; };
+struct CVMObjectICell { CVMObject * volatile ref_DONT_ACCESS_DIRECTLY; };
+enum {
+    CVM_OBJMON_OWNED_NEXT,
+    CVM_OBJMON_SCAN_NEXT,
+    CVM_OBJMON_NUM_LISTS
+};
+typedef enum {
+    CVM_OBJMON_FREE = 0,
+    CVM_OBJMON_BOUND = 1,
+    CVM_OBJMON_OWNED = 2,
+    CVM_OBJMON_BUSY = 0x4
+} CVMObjMonitorState;
+struct CVMObjMonitor {
+    CVMAddr bits;
+    CVMProfiledMonitor mon;
+    CVMUint32 magic;
+    CVMOwnedMonitor *owner;
+    CVMBool sticky;
+    CVMObject *obj;
+    CVMObjMonitorState state;
+    CVMObjMonitor *next;
+};
+extern CVMBool
+CVMobjMonitorInit(CVMExecEnv *ee, CVMObjMonitor *, CVMExecEnv *owner,
+    CVMUint32 count);
+extern void
+CVMobjMonitorDestroy(CVMObjMonitor *m);
+extern CVMObjMonitor *
+CVMobjectInflatePermanently(CVMExecEnv *ee, CVMObjectICell* indirectObj);
+typedef enum {
+    CVM_OWNEDMON_FAST = 0,
+    CVM_OWNEDMON_HEAVY = 1
+} CVMOwnedMonitorType;
+typedef enum {
+    CVM_OWNEDMON_FREE = 0,
+    CVM_OWNEDMON_OWNED = 1
+} CVMOwnedMonitorState;
+struct CVMOwnedMonitor {
+    CVMExecEnv *owner;
+    CVMOwnedMonitorType type;
+    CVMObject *object;
+    union {
+ struct {
+     CVMAddr bits;
+ } fast;
+ struct {
+     CVMObjMonitor *mon;
+ } heavy;
+    } u;
+    CVMOwnedMonitor *next;
+    CVMUint32 magic;
+    CVMOwnedMonitorState state;
+    volatile CVMAddr count;
+};
+void
+CVMsyncGCSafeAllMonitorScavenge(CVMExecEnv *ee);
+union CVMJavaVal32 {
+    CVMJavaInt i;
+    CVMJavaFloat f;
+    CVMObjectICell r;
+    CVMAddr raw;
+};
+union CVMJavaVal64 {
+    CVMJavaLong l;
+    CVMJavaDouble d;
+    CVMAddr v[2];
+};
+union CVMJavaVal16 {
+    CVMJavaShort s;
+    CVMJavaChar c;
+};
+union CVMJavaVal8 {
+    CVMJavaByte b;
+    CVMJavaBoolean z;
+};
+struct CVMjava_lang_Object {
+    volatile CVMObjectHeader hdr;
+    volatile CVMJavaVal32 fields[1];
+};
+struct CVMSyncVector {
+    CVMTryLockFunc *tryLock;
+    CVMLockFunc *lock;
+    CVMTryLockFunc *tryUnlock;
+    CVMLockFunc *unlock;
+    CVMWaitFunc *wait;
+    CVMNotifyFunc *notify;
+    CVMNotifyAllFunc *notifyAll;
+    void *dummyWord;
+};
+extern const CVMSyncVector CVMsyncKinds[];
+extern CVMTryLockFunc CVMfastTryLock, CVMfastTryUnlock;
+extern CVMBool CVMobjectLockedByCurrentThread(CVMExecEnv *ee,
+                                              CVMObjectICell *objICell);
+extern CVMBool CVMgcSafeObjectLock(CVMExecEnv *ee, CVMObjectICell *o);
+extern CVMBool CVMgcSafeObjectUnlock(CVMExecEnv *ee, CVMObjectICell *o);
+extern CVMBool CVMgcSafeObjectNotify(CVMExecEnv *ee, CVMObjectICell *o);
+extern CVMBool CVMgcSafeObjectNotifyAll(CVMExecEnv *ee, CVMObjectICell *o);
+extern CVMBool CVMgcSafeObjectWait(CVMExecEnv *ee, CVMObjectICell *o,
+       CVMInt64 millis);
+extern void CVMobjectMicroLock(CVMExecEnv *ee, CVMObject *obj);
+extern void CVMobjectMicroUnlock(CVMExecEnv *ee, CVMObject *obj);
+struct CVMArrayInfo {
+    CVMUint16 depth;
+    CVMBasicType baseType;
+    CVMClassBlock* baseCb;
+    CVMClassBlock* elementCb;
+};
+typedef CVMJavaVal32 CVMTwoJavaWords[2];
+struct CVMArrayOfByte { CVMObjectHeader hdr; CVMJavaInt length; CVMJavaByte elems[1]; };
+struct CVMArrayOfShort { CVMObjectHeader hdr; CVMJavaInt length; CVMJavaShort elems[1]; };
+struct CVMArrayOfChar { CVMObjectHeader hdr; CVMJavaInt length; CVMJavaChar elems[1]; };
+struct CVMArrayOfBoolean { CVMObjectHeader hdr; CVMJavaInt length; CVMJavaBoolean elems[1]; };
+struct CVMArrayOfInt { CVMObjectHeader hdr; CVMJavaInt length; CVMJavaInt elems[1]; };
+struct CVMArrayOfRef { CVMObjectHeader hdr; CVMJavaInt length; CVMObjectICell elems[1]; };
+struct CVMArrayOfFloat { CVMObjectHeader hdr; CVMJavaInt length; CVMJavaFloat elems[1]; };
+struct CVMArrayOfLong { CVMObjectHeader hdr; CVMJavaInt length; CVMTwoJavaWords elems[1]; };
+struct CVMArrayOfDouble { CVMObjectHeader hdr; CVMJavaInt length; CVMTwoJavaWords elems[1]; };
+struct CVMArrayOfAnyType { CVMObjectHeader hdr; CVMJavaInt length; CVMJavaVal32 elems[1]; };
+struct CVMArrayOfByteICell { CVMArrayOfByte * volatile ref_DONT_ACCESS_DIRECTLY; };
+struct CVMArrayOfShortICell { CVMArrayOfShort * volatile ref_DONT_ACCESS_DIRECTLY; };
+struct CVMArrayOfCharICell { CVMArrayOfChar * volatile ref_DONT_ACCESS_DIRECTLY; };
+struct CVMArrayOfBooleanICell { CVMArrayOfBoolean * volatile ref_DONT_ACCESS_DIRECTLY; };
+struct CVMArrayOfIntICell { CVMArrayOfInt * volatile ref_DONT_ACCESS_DIRECTLY; };
+struct CVMArrayOfRefICell { CVMArrayOfRef * volatile ref_DONT_ACCESS_DIRECTLY; };
+struct CVMArrayOfFloatICell { CVMArrayOfFloat * volatile ref_DONT_ACCESS_DIRECTLY; };
+struct CVMArrayOfLongICell { CVMArrayOfLong * volatile ref_DONT_ACCESS_DIRECTLY; };
+struct CVMArrayOfDoubleICell { CVMArrayOfDouble * volatile ref_DONT_ACCESS_DIRECTLY; };
+struct CVMArrayOfAnyTypeICell { CVMArrayOfAnyType * volatile ref_DONT_ACCESS_DIRECTLY; };
+typedef enum {
+    CVM_GC_SAFE,
+    CVM_NUM_CONSISTENT_STATES
+} CVMCStateID;
+struct CVMCState {
+    volatile CVMBool request;
+    CVMUint32 count;
+    volatile CVMBool reached;
+    CVMExecEnv *requester;
+    volatile CVMUint32 inconsistentThreadCount;
+    CVMSysMutex mutex;
+    CVMCondVar consistentCV;
+    CVMCondVar resumeCV;
+    const char *name;
+};
+struct CVMTCState {
+    volatile CVMBool isConsistent;
+    volatile CVMBool wasConsistent;
+};
+extern CVMBool CVMcsInit(CVMCState *,
+    const char *name,
+    CVMUint8 rank);
+extern void CVMcsDestroy(CVMCState *);
+extern void CVMtcsInit(CVMTCState *);
+extern void CVMtcsDestroy(CVMTCState *);
+extern void CVMcsReachConsistentState(CVMExecEnv *, CVMCStateID);
+extern void CVMcsResumeConsistentState(CVMExecEnv *, CVMCStateID);
+extern CVMBool CVMcsCheckRequest(CVMCState *);
+extern void CVMcsBecomeConsistent(CVMCState *, CVMTCState *);
+extern void CVMcsBecomeInconsistent(CVMCState *, CVMTCState *);
+extern void CVMcsRendezvous(CVMExecEnv *, CVMCState *, CVMTCState *,
+     CVMBool block);
+extern const char * const CVMcstateNames[CVM_NUM_CONSISTENT_STATES];
+typedef union {
+    CVMInt32 i;
+    CVMJavaFloat f;
+    CVMAddr v64[2];
+    void * o;
+} CVMJNIReturnValue;
+extern CVMInt32
+CVMjniInvokeNative(void * env, void * nativeCode, CVMAddr * args,
+     CVMUint32 * terseSig, CVMInt32 argsSize,
+     void * classObject,
+     CVMJNIReturnValue * returnValue);
+typedef enum {
+    CNI_VOID = 0,
+    CNI_SINGLE = 1,
+    CNI_DOUBLE = 2,
+    CNI_NEW_TRANSITION_FRAME = -1,
+    CNI_NEW_MB = -3,
+    CNI_EXCEPTION = -4
+} CNIResultCode;
+typedef CNIResultCode CNINativeMethod(CVMExecEnv* ee,
+          CVMStackVal32* arguments,
+          CVMMethodBlock** p_mb);
+typedef CVMJavaBoolean jboolean;
+typedef CVMJavaChar jchar;
+typedef CVMJavaShort jshort;
+typedef CVMJavaFloat jfloat;
+typedef CVMJavaDouble jdouble;
+typedef CVMJavaInt jint;
+typedef CVMJavaByte jbyte;
+typedef CVMJavaLong jlong;
+typedef jint jsize;
+typedef CVMObjectICell* jobject;
+typedef jobject jclass;
+typedef jobject jthrowable;
+typedef jobject jstring;
+typedef jobject jarray;
+typedef jarray jbooleanArray;
+typedef jarray jbyteArray;
+typedef jarray jcharArray;
+typedef jarray jshortArray;
+typedef jarray jintArray;
+typedef jarray jlongArray;
+typedef jarray jfloatArray;
+typedef jarray jdoubleArray;
+typedef jarray jobjectArray;
+typedef jobject jweak;
+typedef union jvalue {
+    jboolean z;
+    jbyte b;
+    jchar c;
+    jshort s;
+    jint i;
+    jlong j;
+    jfloat f;
+    jdouble d;
+    jobject l;
+} jvalue;
+typedef CVMMethodBlock* jmethodID;
+typedef CVMFieldBlock* jfieldID;
+typedef struct {
+    char *name;
+    char *signature;
+    void *fnPtr;
+} JNINativeMethod;
+struct JNIInvokeInterface;
+typedef const struct JNIInvokeInterface *JavaVM;
+struct JNINativeInterface {
+    void *reserved0;
+    void *reserved1;
+    void *reserved2;
+    void *reserved3;
+    jint ( *GetVersion)(JNIEnv *env);
+    jclass ( *DefineClass)
+      (JNIEnv *env, const char *name, jobject loader, const jbyte *buf,
+       jsize len);
+    jclass ( *FindClass)
+      (JNIEnv *env, const char *name);
+    jmethodID ( *FromReflectedMethod)
+      (JNIEnv *env, jobject method);
+    jfieldID ( *FromReflectedField)
+      (JNIEnv *env, jobject field);
+    jobject ( *ToReflectedMethod)
+      (JNIEnv *env, jclass cls, jmethodID methodID, jboolean isStatic);
+    jclass ( *GetSuperclass)
+      (JNIEnv *env, jclass sub);
+    jboolean ( *IsAssignableFrom)
+      (JNIEnv *env, jclass sub, jclass sup);
+    jobject ( *ToReflectedField)
+      (JNIEnv *env, jclass cls, jfieldID fieldID, jboolean isStatic);
+    jint ( *Throw)
+      (JNIEnv *env, jthrowable obj);
+    jint ( *ThrowNew)
+      (JNIEnv *env, jclass clazz, const char *msg);
+    jthrowable ( *ExceptionOccurred)
+      (JNIEnv *env);
+    void ( *ExceptionDescribe)
+      (JNIEnv *env);
+    void ( *ExceptionClear)
+      (JNIEnv *env);
+    void ( *FatalError)
+      (JNIEnv *env, const char *msg);
+    jint ( *PushLocalFrame)
+      (JNIEnv *env, jint capacity);
+    jobject ( *PopLocalFrame)
+      (JNIEnv *env, jobject result);
+    jobject ( *NewGlobalRef)
+      (JNIEnv *env, jobject lobj);
+    void ( *DeleteGlobalRef)
+      (JNIEnv *env, jobject gref);
+    void ( *DeleteLocalRef)
+      (JNIEnv *env, jobject obj);
+    jboolean ( *IsSameObject)
+      (JNIEnv *env, jobject obj1, jobject obj2);
+    jobject ( *NewLocalRef)
+      (JNIEnv *env, jobject ref);
+    jint ( *EnsureLocalCapacity)
+      (JNIEnv *env, jint capacity);
+    jobject ( *AllocObject)
+      (JNIEnv *env, jclass clazz);
+    jobject ( *NewObject)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, ...);
+    jobject ( *NewObjectV)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, va_list args);
+    jobject ( *NewObjectA)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, const jvalue *args);
+    jclass ( *GetObjectClass)
+      (JNIEnv *env, jobject obj);
+    jboolean ( *IsInstanceOf)
+      (JNIEnv *env, jobject obj, jclass clazz);
+    jmethodID ( *GetMethodID)
+      (JNIEnv *env, jclass clazz, const char *name, const char *sig);
+    jobject ( *CallObjectMethod)
+      (JNIEnv *env, jobject obj, jmethodID methodID, ...);
+    jobject ( *CallObjectMethodV)
+      (JNIEnv *env, jobject obj, jmethodID methodID, va_list args);
+    jobject ( *CallObjectMethodA)
+      (JNIEnv *env, jobject obj, jmethodID methodID, const jvalue * args);
+    jboolean ( *CallBooleanMethod)
+      (JNIEnv *env, jobject obj, jmethodID methodID, ...);
+    jboolean ( *CallBooleanMethodV)
+      (JNIEnv *env, jobject obj, jmethodID methodID, va_list args);
+    jboolean ( *CallBooleanMethodA)
+      (JNIEnv *env, jobject obj, jmethodID methodID, const jvalue * args);
+    jbyte ( *CallByteMethod)
+      (JNIEnv *env, jobject obj, jmethodID methodID, ...);
+    jbyte ( *CallByteMethodV)
+      (JNIEnv *env, jobject obj, jmethodID methodID, va_list args);
+    jbyte ( *CallByteMethodA)
+      (JNIEnv *env, jobject obj, jmethodID methodID, const jvalue *args);
+    jchar ( *CallCharMethod)
+      (JNIEnv *env, jobject obj, jmethodID methodID, ...);
+    jchar ( *CallCharMethodV)
+      (JNIEnv *env, jobject obj, jmethodID methodID, va_list args);
+    jchar ( *CallCharMethodA)
+      (JNIEnv *env, jobject obj, jmethodID methodID, const jvalue *args);
+    jshort ( *CallShortMethod)
+      (JNIEnv *env, jobject obj, jmethodID methodID, ...);
+    jshort ( *CallShortMethodV)
+      (JNIEnv *env, jobject obj, jmethodID methodID, va_list args);
+    jshort ( *CallShortMethodA)
+      (JNIEnv *env, jobject obj, jmethodID methodID, const jvalue *args);
+    jint ( *CallIntMethod)
+      (JNIEnv *env, jobject obj, jmethodID methodID, ...);
+    jint ( *CallIntMethodV)
+      (JNIEnv *env, jobject obj, jmethodID methodID, va_list args);
+    jint ( *CallIntMethodA)
+      (JNIEnv *env, jobject obj, jmethodID methodID, const jvalue *args);
+    jlong ( *CallLongMethod)
+      (JNIEnv *env, jobject obj, jmethodID methodID, ...);
+    jlong ( *CallLongMethodV)
+      (JNIEnv *env, jobject obj, jmethodID methodID, va_list args);
+    jlong ( *CallLongMethodA)
+      (JNIEnv *env, jobject obj, jmethodID methodID, const jvalue *args);
+    jfloat ( *CallFloatMethod)
+      (JNIEnv *env, jobject obj, jmethodID methodID, ...);
+    jfloat ( *CallFloatMethodV)
+      (JNIEnv *env, jobject obj, jmethodID methodID, va_list args);
+    jfloat ( *CallFloatMethodA)
+      (JNIEnv *env, jobject obj, jmethodID methodID, const jvalue *args);
+    jdouble ( *CallDoubleMethod)
+      (JNIEnv *env, jobject obj, jmethodID methodID, ...);
+    jdouble ( *CallDoubleMethodV)
+      (JNIEnv *env, jobject obj, jmethodID methodID, va_list args);
+    jdouble ( *CallDoubleMethodA)
+      (JNIEnv *env, jobject obj, jmethodID methodID, const jvalue *args);
+    void ( *CallVoidMethod)
+      (JNIEnv *env, jobject obj, jmethodID methodID, ...);
+    void ( *CallVoidMethodV)
+      (JNIEnv *env, jobject obj, jmethodID methodID, va_list args);
+    void ( *CallVoidMethodA)
+      (JNIEnv *env, jobject obj, jmethodID methodID, const jvalue * args);
+    jobject ( *CallNonvirtualObjectMethod)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID, ...);
+    jobject ( *CallNonvirtualObjectMethodV)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       va_list args);
+    jobject ( *CallNonvirtualObjectMethodA)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       const jvalue * args);
+    jboolean ( *CallNonvirtualBooleanMethod)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID, ...);
+    jboolean ( *CallNonvirtualBooleanMethodV)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       va_list args);
+    jboolean ( *CallNonvirtualBooleanMethodA)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       const jvalue * args);
+    jbyte ( *CallNonvirtualByteMethod)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID, ...);
+    jbyte ( *CallNonvirtualByteMethodV)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       va_list args);
+    jbyte ( *CallNonvirtualByteMethodA)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       const jvalue *args);
+    jchar ( *CallNonvirtualCharMethod)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID, ...);
+    jchar ( *CallNonvirtualCharMethodV)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       va_list args);
+    jchar ( *CallNonvirtualCharMethodA)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       const jvalue *args);
+    jshort ( *CallNonvirtualShortMethod)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID, ...);
+    jshort ( *CallNonvirtualShortMethodV)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       va_list args);
+    jshort ( *CallNonvirtualShortMethodA)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       const jvalue *args);
+    jint ( *CallNonvirtualIntMethod)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID, ...);
+    jint ( *CallNonvirtualIntMethodV)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       va_list args);
+    jint ( *CallNonvirtualIntMethodA)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       const jvalue *args);
+    jlong ( *CallNonvirtualLongMethod)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID, ...);
+    jlong ( *CallNonvirtualLongMethodV)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       va_list args);
+    jlong ( *CallNonvirtualLongMethodA)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       const jvalue *args);
+    jfloat ( *CallNonvirtualFloatMethod)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID, ...);
+    jfloat ( *CallNonvirtualFloatMethodV)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       va_list args);
+    jfloat ( *CallNonvirtualFloatMethodA)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       const jvalue *args);
+    jdouble ( *CallNonvirtualDoubleMethod)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID, ...);
+    jdouble ( *CallNonvirtualDoubleMethodV)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       va_list args);
+    jdouble ( *CallNonvirtualDoubleMethodA)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       const jvalue *args);
+    void ( *CallNonvirtualVoidMethod)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID, ...);
+    void ( *CallNonvirtualVoidMethodV)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       va_list args);
+    void ( *CallNonvirtualVoidMethodA)
+      (JNIEnv *env, jobject obj, jclass clazz, jmethodID methodID,
+       const jvalue * args);
+    jfieldID ( *GetFieldID)
+      (JNIEnv *env, jclass clazz, const char *name, const char *sig);
+    jobject ( *GetObjectField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID);
+    jboolean ( *GetBooleanField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID);
+    jbyte ( *GetByteField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID);
+    jchar ( *GetCharField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID);
+    jshort ( *GetShortField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID);
+    jint ( *GetIntField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID);
+    jlong ( *GetLongField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID);
+    jfloat ( *GetFloatField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID);
+    jdouble ( *GetDoubleField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID);
+    void ( *SetObjectField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID, jobject val);
+    void ( *SetBooleanField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID, jboolean val);
+    void ( *SetByteField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID, jbyte val);
+    void ( *SetCharField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID, jchar val);
+    void ( *SetShortField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID, jshort val);
+    void ( *SetIntField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID, jint val);
+    void ( *SetLongField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID, jlong val);
+    void ( *SetFloatField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID, jfloat val);
+    void ( *SetDoubleField)
+      (JNIEnv *env, jobject obj, jfieldID fieldID, jdouble val);
+    jmethodID ( *GetStaticMethodID)
+      (JNIEnv *env, jclass clazz, const char *name, const char *sig);
+    jobject ( *CallStaticObjectMethod)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, ...);
+    jobject ( *CallStaticObjectMethodV)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, va_list args);
+    jobject ( *CallStaticObjectMethodA)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, const jvalue *args);
+    jboolean ( *CallStaticBooleanMethod)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, ...);
+    jboolean ( *CallStaticBooleanMethodV)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, va_list args);
+    jboolean ( *CallStaticBooleanMethodA)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, const jvalue *args);
+    jbyte ( *CallStaticByteMethod)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, ...);
+    jbyte ( *CallStaticByteMethodV)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, va_list args);
+    jbyte ( *CallStaticByteMethodA)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, const jvalue *args);
+    jchar ( *CallStaticCharMethod)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, ...);
+    jchar ( *CallStaticCharMethodV)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, va_list args);
+    jchar ( *CallStaticCharMethodA)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, const jvalue *args);
+    jshort ( *CallStaticShortMethod)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, ...);
+    jshort ( *CallStaticShortMethodV)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, va_list args);
+    jshort ( *CallStaticShortMethodA)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, const jvalue *args);
+    jint ( *CallStaticIntMethod)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, ...);
+    jint ( *CallStaticIntMethodV)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, va_list args);
+    jint ( *CallStaticIntMethodA)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, const jvalue *args);
+    jlong ( *CallStaticLongMethod)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, ...);
+    jlong ( *CallStaticLongMethodV)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, va_list args);
+    jlong ( *CallStaticLongMethodA)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, const jvalue *args);
+    jfloat ( *CallStaticFloatMethod)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, ...);
+    jfloat ( *CallStaticFloatMethodV)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, va_list args);
+    jfloat ( *CallStaticFloatMethodA)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, const jvalue *args);
+    jdouble ( *CallStaticDoubleMethod)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, ...);
+    jdouble ( *CallStaticDoubleMethodV)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, va_list args);
+    jdouble ( *CallStaticDoubleMethodA)
+      (JNIEnv *env, jclass clazz, jmethodID methodID, const jvalue *args);
+    void ( *CallStaticVoidMethod)
+      (JNIEnv *env, jclass cls, jmethodID methodID, ...);
+    void ( *CallStaticVoidMethodV)
+      (JNIEnv *env, jclass cls, jmethodID methodID, va_list args);
+    void ( *CallStaticVoidMethodA)
+      (JNIEnv *env, jclass cls, jmethodID methodID, const jvalue * args);
+    jfieldID ( *GetStaticFieldID)
+      (JNIEnv *env, jclass clazz, const char *name, const char *sig);
+    jobject ( *GetStaticObjectField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID);
+    jboolean ( *GetStaticBooleanField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID);
+    jbyte ( *GetStaticByteField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID);
+    jchar ( *GetStaticCharField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID);
+    jshort ( *GetStaticShortField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID);
+    jint ( *GetStaticIntField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID);
+    jlong ( *GetStaticLongField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID);
+    jfloat ( *GetStaticFloatField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID);
+    jdouble ( *GetStaticDoubleField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID);
+    void ( *SetStaticObjectField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID, jobject value);
+    void ( *SetStaticBooleanField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID, jboolean value);
+    void ( *SetStaticByteField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID, jbyte value);
+    void ( *SetStaticCharField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID, jchar value);
+    void ( *SetStaticShortField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID, jshort value);
+    void ( *SetStaticIntField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID, jint value);
+    void ( *SetStaticLongField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID, jlong value);
+    void ( *SetStaticFloatField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID, jfloat value);
+    void ( *SetStaticDoubleField)
+      (JNIEnv *env, jclass clazz, jfieldID fieldID, jdouble value);
+    jstring ( *NewString)
+      (JNIEnv *env, const jchar *unicode, jsize len);
+    jsize ( *GetStringLength)
+      (JNIEnv *env, jstring str);
+    const jchar *( *GetStringChars)
+      (JNIEnv *env, jstring str, jboolean *isCopy);
+    void ( *ReleaseStringChars)
+      (JNIEnv *env, jstring str, const jchar *chars);
+    jstring ( *NewStringUTF)
+      (JNIEnv *env, const char *utf);
+    jsize ( *GetStringUTFLength)
+      (JNIEnv *env, jstring str);
+    const char* ( *GetStringUTFChars)
+      (JNIEnv *env, jstring str, jboolean *isCopy);
+    void ( *ReleaseStringUTFChars)
+      (JNIEnv *env, jstring str, const char* chars);
+    jsize ( *GetArrayLength)
+      (JNIEnv *env, jarray array);
+    jobjectArray ( *NewObjectArray)
+      (JNIEnv *env, jsize len, jclass clazz, jobject init);
+    jobject ( *GetObjectArrayElement)
+      (JNIEnv *env, jobjectArray array, jsize index);
+    void ( *SetObjectArrayElement)
+      (JNIEnv *env, jobjectArray array, jsize index, jobject val);
+    jbooleanArray ( *NewBooleanArray)
+      (JNIEnv *env, jsize len);
+    jbyteArray ( *NewByteArray)
+      (JNIEnv *env, jsize len);
+    jcharArray ( *NewCharArray)
+      (JNIEnv *env, jsize len);
+    jshortArray ( *NewShortArray)
+      (JNIEnv *env, jsize len);
+    jintArray ( *NewIntArray)
+      (JNIEnv *env, jsize len);
+    jlongArray ( *NewLongArray)
+      (JNIEnv *env, jsize len);
+    jfloatArray ( *NewFloatArray)
+      (JNIEnv *env, jsize len);
+    jdoubleArray ( *NewDoubleArray)
+      (JNIEnv *env, jsize len);
+    jboolean * ( *GetBooleanArrayElements)
+      (JNIEnv *env, jbooleanArray array, jboolean *isCopy);
+    jbyte * ( *GetByteArrayElements)
+      (JNIEnv *env, jbyteArray array, jboolean *isCopy);
+    jchar * ( *GetCharArrayElements)
+      (JNIEnv *env, jcharArray array, jboolean *isCopy);
+    jshort * ( *GetShortArrayElements)
+      (JNIEnv *env, jshortArray array, jboolean *isCopy);
+    jint * ( *GetIntArrayElements)
+      (JNIEnv *env, jintArray array, jboolean *isCopy);
+    jlong * ( *GetLongArrayElements)
+      (JNIEnv *env, jlongArray array, jboolean *isCopy);
+    jfloat * ( *GetFloatArrayElements)
+      (JNIEnv *env, jfloatArray array, jboolean *isCopy);
+    jdouble * ( *GetDoubleArrayElements)
+      (JNIEnv *env, jdoubleArray array, jboolean *isCopy);
+    void ( *ReleaseBooleanArrayElements)
+      (JNIEnv *env, jbooleanArray array, jboolean *elems, jint mode);
+    void ( *ReleaseByteArrayElements)
+      (JNIEnv *env, jbyteArray array, jbyte *elems, jint mode);
+    void ( *ReleaseCharArrayElements)
+      (JNIEnv *env, jcharArray array, jchar *elems, jint mode);
+    void ( *ReleaseShortArrayElements)
+      (JNIEnv *env, jshortArray array, jshort *elems, jint mode);
+    void ( *ReleaseIntArrayElements)
+      (JNIEnv *env, jintArray array, jint *elems, jint mode);
+    void ( *ReleaseLongArrayElements)
+      (JNIEnv *env, jlongArray array, jlong *elems, jint mode);
+    void ( *ReleaseFloatArrayElements)
+      (JNIEnv *env, jfloatArray array, jfloat *elems, jint mode);
+    void ( *ReleaseDoubleArrayElements)
+      (JNIEnv *env, jdoubleArray array, jdouble *elems, jint mode);
+    void ( *GetBooleanArrayRegion)
+      (JNIEnv *env, jbooleanArray array, jsize start, jsize l, jboolean *buf);
+    void ( *GetByteArrayRegion)
+      (JNIEnv *env, jbyteArray array, jsize start, jsize len, jbyte *buf);
+    void ( *GetCharArrayRegion)
+      (JNIEnv *env, jcharArray array, jsize start, jsize len, jchar *buf);
+    void ( *GetShortArrayRegion)
+      (JNIEnv *env, jshortArray array, jsize start, jsize len, jshort *buf);
+    void ( *GetIntArrayRegion)
+      (JNIEnv *env, jintArray array, jsize start, jsize len, jint *buf);
+    void ( *GetLongArrayRegion)
+      (JNIEnv *env, jlongArray array, jsize start, jsize len, jlong *buf);
+    void ( *GetFloatArrayRegion)
+      (JNIEnv *env, jfloatArray array, jsize start, jsize len, jfloat *buf);
+    void ( *GetDoubleArrayRegion)
+      (JNIEnv *env, jdoubleArray array, jsize start, jsize len, jdouble *buf);
+    void ( *SetBooleanArrayRegion)
+      (JNIEnv *env, jbooleanArray array, jsize start, jsize l,
+       const jboolean *buf);
+    void ( *SetByteArrayRegion)
+      (JNIEnv *env, jbyteArray array, jsize start, jsize len, const jbyte *buf);
+    void ( *SetCharArrayRegion)
+      (JNIEnv *env, jcharArray array, jsize start, jsize len, const jchar *buf);
+    void ( *SetShortArrayRegion)
+      (JNIEnv *env, jshortArray array, jsize start, jsize len,
+       const jshort *buf);
+    void ( *SetIntArrayRegion)
+      (JNIEnv *env, jintArray array, jsize start, jsize len, const jint *buf);
+    void ( *SetLongArrayRegion)
+      (JNIEnv *env, jlongArray array, jsize start, jsize len, const jlong *buf);
+    void ( *SetFloatArrayRegion)
+      (JNIEnv *env, jfloatArray array, jsize start, jsize len,
+       const jfloat *buf);
+    void ( *SetDoubleArrayRegion)
+      (JNIEnv *env, jdoubleArray array, jsize start, jsize len,
+       const jdouble *buf);
+    jint ( *RegisterNatives)
+      (JNIEnv *env, jclass clazz, const JNINativeMethod *methods,
+       jint nMethods);
+    jint ( *UnregisterNatives)
+      (JNIEnv *env, jclass clazz);
+    jint ( *MonitorEnter)
+      (JNIEnv *env, jobject obj);
+    jint ( *MonitorExit)
+      (JNIEnv *env, jobject obj);
+    jint ( *GetJavaVM)
+      (JNIEnv *env, JavaVM **vm);
+    void ( *GetStringRegion)
+      (JNIEnv *env, jstring str, jsize start, jsize len, jchar *buf);
+    void ( *GetStringUTFRegion)
+      (JNIEnv *env, jstring str, jsize start, jsize len, char *buf);
+    void * ( *GetPrimitiveArrayCritical)
+      (JNIEnv *env, jarray array, jboolean *isCopy);
+    void ( *ReleasePrimitiveArrayCritical)
+      (JNIEnv *env, jarray array, void *carray, jint mode);
+    const jchar * ( *GetStringCritical)
+      (JNIEnv *env, jstring string, jboolean *isCopy);
+    void ( *ReleaseStringCritical)
+      (JNIEnv *env, jstring string, const jchar *cstring);
+    jweak ( *NewWeakGlobalRef)
+       (JNIEnv *env, jobject obj);
+    void ( *DeleteWeakGlobalRef)
+       (JNIEnv *env, jweak ref);
+    jboolean ( *ExceptionCheck)
+       (JNIEnv *env);
+    jobject ( *NewDirectByteBuffer)
+       (JNIEnv* env, void* address, jlong capacity);
+    void* ( *GetDirectBufferAddress)
+       (JNIEnv* env, jobject buf);
+    jlong ( *GetDirectBufferCapacity)
+       (JNIEnv* env, jobject buf);
+};
+typedef struct JavaVMOption {
+    char *optionString;
+    void *extraInfo;
+} JavaVMOption;
+typedef struct JavaVMInitArgs {
+    jint version;
+    jint nOptions;
+    JavaVMOption *options;
+    jboolean ignoreUnrecognized;
+} JavaVMInitArgs;
+typedef struct JavaVMAttachArgs {
+    jint version;
+    char *name;
+    jobject group;
+} JavaVMAttachArgs;
+struct JNIInvokeInterface {
+    void *reserved0;
+    void *reserved1;
+    void *reserved2;
+    jint ( *DestroyJavaVM)(JavaVM *vm);
+    jint ( *AttachCurrentThread)(JavaVM *vm, void **penv, void *args);
+    jint ( *DetachCurrentThread)(JavaVM *vm);
+    jint ( *GetEnv)(JavaVM *vm, void **penv, jint version);
+    jint ( *AttachCurrentThreadAsDaemon)(JavaVM *vm, void **penv, void *args);
+};
+extern jint
+JNI_GetDefaultJavaVMInitArgs(void *args);
+extern jint
+JNI_CreateJavaVM(JavaVM **pvm, void **penv, void *args);
+extern jint
+JNI_GetCreatedJavaVMs(JavaVM **, jsize, jsize *);
+extern jint
+JNI_OnLoad(JavaVM *vm, void *reserved);
+extern void
+JNI_OnUnload(JavaVM *vm, void *reserved);
+union CVMConstantPoolEntry {
+    union {
+ struct {
+     CVMUint16 nameUtf8Idx;
+     CVMUint16 typeUtf8Idx;
+ } nameAndType;
+ struct {
+     CVMUint16 utf8Idx;
+ } clazz;
+ struct {
+     CVMUint16 utf8Idx;
+ } string;
+ CVMUtf8* utf8;
+    } intermediate;
+    union {
+ struct {
+     CVMUint16 classIdx;
+     CVMUint16 typeIDIdx;
+ } memberRef;
+ CVMMethodTypeID methodTypeID;
+ CVMFieldTypeID fieldTypeID;
+ CVMClassTypeID classTypeID;
+    } unresolved;
+    union {
+ CVMJavaVal32 val32;
+ CVMClassBlock* cb;
+ CVMFieldBlock* fb;
+ CVMMethodBlock* mb;
+ CVMStringObject* strObj;
+ CVMStringICell* strICell;
+    } resolved;
+};
+typedef CVMUint8 CVMConstantPoolEntryType;
+union CVMConstantPool {
+    CVMConstantPoolEntryType* cpTypesX;
+    CVMConstantPoolEntry entriesX[1];
+};
+struct CVMTransitionConstantPool {
+    CVMConstantPool cp;
+    CVMConstantPoolEntry entry1X;
+};
+enum CVMConstantPoolEntryTypeEnum {
+    CVM_CONSTANT_Utf8 = 1,
+    CVM_CONSTANT_Unicode = 2,
+    CVM_CONSTANT_Integer = 3,
+    CVM_CONSTANT_Float = 4,
+    CVM_CONSTANT_Long = 5,
+    CVM_CONSTANT_Double = 6,
+    CVM_CONSTANT_Class = 7,
+    CVM_CONSTANT_String = 8,
+    CVM_CONSTANT_Fieldref = 9,
+    CVM_CONSTANT_Methodref = 10,
+    CVM_CONSTANT_InterfaceMethodref = 11,
+    CVM_CONSTANT_NameAndType = 12,
+    CVM_CONSTANT_ClassTypeID = 13,
+    CVM_CONSTANT_MethodTypeID = 14,
+    CVM_CONSTANT_FieldTypeID = 15,
+    CVM_CONSTANT_ClassBlock = 19,
+    CVM_CONSTANT_FieldBlock = 20,
+    CVM_CONSTANT_MethodBlock = 21,
+    CVM_CONSTANT_StringObj = 22,
+    CVM_CONSTANT_StringICell = 23,
+    CVM_CONSTANT_Invalid = 24
+};
+typedef enum CVMConstantPoolEntryTypeEnum CVMConstantPoolEntryTypeEnum;
+extern CVMBool
+CVMprivate_cpExtractTypeIDFromUnresolvedEntry(CVMExecEnv* ee,
+           CVMClassBlock* currentCb,
+           CVMConstantPool* cp,
+           CVMUint16 cpIndex,
+           CVMTypeID* p_typeid);
+extern void
+CVMcpResolveCbEntriesWithoutClassLoading(CVMExecEnv* ee,
+                                         CVMClassBlock* cb);
+CVMBool
+CVMprivate_cpResolveEntryFromClass(CVMExecEnv* ee,
+       CVMClassBlock* currentCb,
+       CVMConstantPool* cp,
+       CVMUint16 cpIndex);
+CVMBool
+CVMprivate_cpResolveEntryWithoutClassLoading(CVMExecEnv* ee,
+          CVMClassBlock* currentCb,
+          CVMConstantPool* cp,
+          CVMUint16 cpIndex,
+          CVMTypeID* p_typeid);
+union CVMGCBitMap {
+    CVMAddr map;
+    CVMBigGCBitMap* bigmap;
+};
+struct CVMBigGCBitMap {
+    CVMUint16 maplen;
+    CVMAddr map[1];
+};
+struct CVMClassBlock {
+    CVMGCBitMap gcMapX;
+    CVMClassTypeID classNameX;
+    union {
+ CVMClassBlock* superclassCb;
+ CVMClassTypeID superclassTypeID;
+ CVMUint16 mirandaMethodCountX;
+    } superclassX;
+    union {
+ CVMConstantPool* constantpoolX;
+ CVMArrayInfo* arrayInfoX;
+    } cpX;
+    CVMInterfaces* interfacesX;
+    CVMMethodArray* methodsX;
+    CVMFieldArray* fieldsX;
+    union {
+ CVMJavaVal32* statics;
+ CVMClassBlock* freeClassLink;
+    } staticsX;
+    CVMUint16 constantpoolCountX;
+    CVMUint16 methodCountX;
+    CVMUint16 fieldCountX;
+    CVMUint16 methodTableCountX;
+    CVMUint16 accessFlagsX;
+    volatile CVMUint8 runtimeFlagsX;
+    CVMUint16 instanceSizeX;
+    CVMUint16 numStaticRefsX;
+    CVMClassICell* javaInstanceX;
+    char* theNameX;
+    CVMClassLoaderICell* classLoaderX;
+    CVMObjectICell* protectionDomainX;
+    union {
+ CVMExecEnv** eePtr;
+ CVMExecEnv* ee;
+ CVMClassBlock** classTableSlotPtr;
+    } clinitEEX;
+    CVMUint16* checkedExceptionsX;
+    char* sourceFileNameX;
+    CVMMethodBlock** methodTablePtrX;
+    CVMInnerClassesInfo* innerClassesInfoX;
+    CVMUint16 major_version;
+    CVMUint16 minor_version;
+};
+struct CVMInterfaceTable {
+    CVMClassBlock* interfaceCb;
+    union {
+ CVMUint16* methodTableIndicesX;
+ CVMClassTypeID interfaceTypeIDX;
+    } intfInfoX;
+};
+struct CVMInterfaces {
+    CVMUint16 interfaceCountX;
+    CVMUint16 implementsCountX;
+    CVMInterfaceTable itable[1];
+};
+struct CVMMethodBlockImmutable {
+    CVMMethodTypeID nameAndTypeIDX;
+    CVMUint16 methodTableIndexX;
+    CVMUint8 argsSizeX;
+    CVMUint8 methodIndexX;
+    CVMUint16 invokerAndAccessFlagsX;
+    CVMUint16 checkedExceptionsOffsetX;
+    union {
+ CVMJavaMethodDescriptor* jmd;
+ CVMUint8* nativeCode;
+ CVMAddr methodSlotIndex;
+ CVMMethodBlock* interfaceMb;
+    } codeX;
+};
+struct CVMMethodBlock {
+    CVMMethodBlockImmutable immutX;
+};
+struct CVMMethodRange {
+    CVMClassBlock* cb;
+    CVMMethodBlock mb[256];
+};
+struct CVMMethodArray {
+    CVMMethodRange ranges[1];
+};
+typedef CVMUint16 CVMCheckedException;
+struct CVMCheckedExceptions {
+    CVMUint16 numExceptions;
+    CVMCheckedException exceptions[1];
+};
+struct CVMJavaMethodDescriptor {
+    CVMUint16 maxLocalsX;
+    CVMUint16 flagsX;
+    CVMUint32 capacityX;
+    CVMUint16 exceptionTableLengthX;
+    CVMUint16 codeLengthX;
+    CVMUint16 lineNumberTableLengthX;
+    CVMUint16 localVariableTableLengthX;
+};
+struct CVMStackMapEntry {
+    CVMUint16 pc;
+    CVMUint16 state[1];
+};
+struct CVMStackMaps {
+    CVMStackMaps * next;
+    CVMStackMaps * prev;
+    CVMUint32 size;
+    CVMMethodBlock * mb;
+    CVMUint32 noGcPoints;
+    CVMStackMapEntry smEntries[1];
+};
+typedef struct CVMJavaMethodExtension {
+    CVMJavaMethodDescriptor* originalJmd;
+} CVMJavaMethodExtension;
+struct CVMExceptionHandler {
+    CVMUint16 startpc;
+    CVMUint16 endpc;
+    CVMUint16 handlerpc;
+    CVMUint16 catchtype;
+};
+struct CVMLineNumberEntry {
+    CVMUint16 startpc;
+    CVMUint16 lineNumber;
+};
+struct CVMLocalVariableEntry {
+    CVMUint16 startpc;
+    CVMUint16 length;
+    CVMUint16 index;
+    CVMTypeIDNamePart nameID;
+    CVMTypeIDTypePart typeID;
+};
+struct CVMFieldBlock {
+    CVMFieldTypeID nameAndTypeIDX;
+    CVMUint8 accessFlagsX;
+    CVMUint8 fbIndexX;
+    CVMUint16 offsetX;
+};
+struct CVMFieldRange {
+    CVMClassBlock* cb;
+    CVMFieldBlock fb[256];
+};
+struct CVMFieldArray {
+    CVMFieldRange ranges[1];
+};
+struct CVMInnerClassInfo {
+    CVMUint16 innerClassIndex;
+    CVMUint16 outerClassIndex;
+    CVMUint16 unused;
+    CVMUint16 innerClassAccessFlags;
+};
+struct CVMInnerClassesInfo {
+    CVMUint32 count;
+    CVMInnerClassInfo info[1];
+};
+enum {
+    CVM_INVOKE_JAVA_METHOD,
+    CVM_INVOKE_JAVA_SYNC_METHOD,
+    CVM_INVOKE_CNI_METHOD,
+    CVM_INVOKE_JNI_METHOD,
+    CVM_INVOKE_JNI_SYNC_METHOD,
+    CVM_INVOKE_ABSTRACT_METHOD,
+    CVM_INVOKE_NONPUBLIC_MIRANDA_METHOD,
+    CVM_INVOKE_MISSINGINTERFACE_MIRANDA_METHOD,
+    CVM_INVOKE_LAZY_JNI_METHOD,
+    CVM_NUM_INVOKER_TYPES
+};
+CVMClassBlock*
+CVMclassLookupClassWithoutLoading(CVMExecEnv* ee, CVMClassTypeID typeID,
+      CVMClassLoaderICell* loader);
+extern CVMClassBlock*
+CVMclassLookupByNameFromClass(CVMExecEnv* ee, const char* name,
+         CVMBool init, CVMClassBlock* fromClass);
+extern CVMClassBlock*
+CVMclassLookupByTypeFromClass(CVMExecEnv* ee, CVMClassTypeID typeID,
+         CVMBool init, CVMClassBlock* fromClass);
+extern CVMClassBlock*
+CVMclassLookupByNameFromClassLoader(CVMExecEnv* ee, const char* name,
+        CVMBool init,
+        CVMClassLoaderICell* loader,
+        CVMObjectICell* pd,
+        CVMBool throwError);
+extern CVMClassBlock*
+CVMclassLookupByTypeFromClassLoader(CVMExecEnv* ee, CVMClassTypeID typeID,
+        CVMBool init,
+        CVMClassLoaderICell* loader,
+        CVMObjectICell* pd,
+        CVMBool throwError);
+CVMClassBlock*
+CVMclassGetArrayOfWithNoClassCreation(CVMExecEnv* ee, CVMClassBlock* elemCb);
+extern CVMClassBlock*
+CVMclassGetArrayOf(CVMExecEnv* ee, CVMClassBlock* elemCb);
+extern CVMMethodBlock*
+CVMclassGetMethodBlock(const CVMClassBlock* cb, const CVMMethodTypeID tid,
+         CVMBool isStatic);
+CVMMethodBlock*
+CVMclassGetDeclaredMethodBlockFromTID(const CVMClassBlock* cb,
+          CVMMethodTypeID tid);
+extern CVMMethodBlock*
+CVMclassGetDeclaredMethodBlock(CVMExecEnv *ee,
+          const CVMClassBlock* cb,
+          const char *name,
+          const char *sig);
+extern CVMFieldBlock*
+CVMclassGetFieldBlock(const CVMClassBlock* cb, const CVMFieldTypeID tid,
+        CVMBool isStatic);
+extern CVMBool
+CVMclassLinkSuperClasses(CVMExecEnv* ee, CVMClassBlock* cb);
+extern CVMClassBlock*
+CVMclassLoadClass(CVMExecEnv* ee, CVMClassLoaderICell* loader,
+    const char* classname, CVMClassTypeID classTypeID);
+CVMClassICell*
+CVMclassLoadBootClass(CVMExecEnv* ee, const char* classname);
+extern CVMClassICell*
+CVMclassCreateInternalClass(CVMExecEnv* ee,
+       const CVMUint8* externalClass,
+       CVMUint32 classSize,
+       CVMClassLoaderICell* loader,
+       const char* classname,
+       const char* dirNameOrZipFileName,
+       CVMBool isRedefine);
+extern void
+CVMclassFree(CVMExecEnv* ee, CVMClassBlock* cb);
+extern void
+CVMclassFreeJavaMethods(CVMExecEnv* ee, CVMClassBlock* cb,
+   CVMBool isPreloaded);
+extern void
+CVMclassFreeLocalVariableTableFieldIDs(CVMExecEnv* ee, CVMMethodBlock* mb);
+extern void
+CVMclassDoClassUnloadingPass1(CVMExecEnv* ee,
+         CVMRefLivenessQueryFunc isLive,
+         void* isLiveData,
+         CVMRefCallbackFunc transitiveScanner,
+         void* transitiveScannerData,
+         CVMGCOptions* gcOpts);
+extern void
+CVMclassDoClassUnloadingPass2(CVMExecEnv* ee);
+extern CVMBool
+CVMclassVerify(CVMExecEnv* ee, CVMClassBlock* cb);
+enum { CVM_VERIFY_NONE = 0, CVM_VERIFY_REMOTE, CVM_VERIFY_ALL, CVM_VERIFY_UNRECOGNIZED };
+extern CVMInt32
+CVMclassVerificationSpecToEncoding(char* verifySpec);
+extern CVMBool
+CVMclassLink(CVMExecEnv* ee, CVMClassBlock* cb, CVMBool isRedefine);
+extern CVMBool
+CVMclassInit(CVMExecEnv* ee, CVMClassBlock* cb);
+extern int
+CVMclassInitNoCRecursion(CVMExecEnv* ee, CVMClassBlock* cb,
+    CVMMethodBlock **p_mb);
+extern CVMClassICell*
+CVMdefineClass(CVMExecEnv* ee, const char *name, CVMClassLoaderICell* loader,
+        const CVMUint8* buf, CVMUint32 bufLen, CVMObjectICell* pd,
+        CVMBool isRedefine);
+extern CVMClassBlock*
+CVMclassCreateMultiArrayClass(CVMExecEnv* ee, CVMClassTypeID arrayTypeId,
+         CVMClassLoaderICell* loader, CVMObjectICell* pd);
+typedef void (*CVMClassCallbackFunc)(CVMExecEnv* ee,
+         CVMClassBlock* cb,
+         void* data);
+typedef void (*CVMStackCallbackFunc)( CVMObject**, void*);
+extern void
+CVMclassIterateAllClasses(CVMExecEnv* ee,
+     CVMClassCallbackFunc callback,
+     void* data);
+extern void
+CVMclassIterateDynamicallyLoadedClasses(CVMExecEnv* ee,
+     CVMClassCallbackFunc callback,
+     void* data);
+extern void
+CVMclassTableFreeAllClasses(CVMExecEnv* ee);
+extern CVMClassBlock**
+CVMclassTableAllocateSlot(CVMExecEnv* ee);
+void
+CVMclassTableFreeSlot(CVMExecEnv* ee, CVMClassBlock** cbPtr);
+extern void
+CVMclassTableMarkUnscannedClasses(CVMExecEnv* ee,
+      CVMRefLivenessQueryFunc isLive,
+      void* isLiveData);
+extern void
+CVMclassTableIterate(CVMExecEnv* ee,
+       CVMClassCallbackFunc callback,
+       void* data);
+extern void
+CVMclassTableDump(CVMExecEnv* ee);
+extern CVMClassLoaderICell*
+CVMloaderCacheGetGlobalRootFromLoader(CVMExecEnv* ee,
+          CVMClassLoaderICell* loader);
+extern CVMBool
+CVMloaderCacheCheckPackageAccess(CVMExecEnv *ee, CVMClassLoaderICell* loader,
+     CVMClassBlock* cb, CVMObjectICell* pd);
+extern CVMClassBlock*
+CVMloaderCacheLookupWithProtectionDomain(CVMExecEnv* ee,
+      CVMClassTypeID classID,
+      CVMClassLoaderICell* loader,
+      CVMObjectICell* pd);
+extern CVMBool
+CVMloaderCacheAdd(CVMExecEnv* ee, CVMClassBlock* cb,
+    CVMClassLoaderICell* loader);
+extern void
+CVMloaderCacheMarkUnscannedClassesAndLoaders(CVMExecEnv* ee,
+           CVMRefLivenessQueryFunc isLive,
+           void* isLiveData);
+extern void
+CVMloaderCachePurgeUnscannedClassesAndLoaders(CVMExecEnv* ee);
+extern CVMBool
+CVMloaderCacheInit();
+extern void
+CVMloaderCacheDestroy(CVMExecEnv* ee);
+extern void
+CVMloaderCacheDump(CVMExecEnv* ee);
+typedef struct {
+    int index;
+    void *entry;
+} CVMLoaderCacheIterator;
+void
+CVMloaderCacheIterate(CVMExecEnv* ee, CVMLoaderCacheIterator *iter);
+CVMBool
+CVMloaderCacheIterateNext(CVMExecEnv* ee, CVMLoaderCacheIterator *iter);
+CVMObjectICell *
+CVMloaderCacheIterateGetLoader(CVMExecEnv* ee, CVMLoaderCacheIterator *iter);
+CVMClassBlock *
+CVMloaderCacheIterateGetCB(CVMExecEnv* ee, CVMLoaderCacheIterator *iter);
+CVMBool
+CVMloaderConstraintsCheckMethodSignatureLoaders(CVMExecEnv* ee,
+      CVMMethodTypeID methodID,
+      CVMClassLoaderICell* loader1,
+      CVMClassLoaderICell* loader2);
+CVMBool
+CVMloaderConstraintsCheckFieldSignatureLoaders(CVMExecEnv* ee,
+            CVMFieldTypeID fieldID,
+            CVMClassLoaderICell* loader1,
+            CVMClassLoaderICell* loader2);
+extern void
+CVMloaderConstraintsMarkUnscannedClassesAndLoaders(
+    CVMExecEnv* ee,
+    CVMRefLivenessQueryFunc isLive,
+    void* isLiveData);
+extern void
+CVMloaderConstraintsPurgeUnscannedClassesAndLoaders(CVMExecEnv* ee);
+extern void
+CVMloaderConstraintsDump(CVMExecEnv* ee);
+extern void
+CVMclassScan(CVMExecEnv* ee, CVMClassBlock* cb,
+      CVMRefCallbackFunc callback, void* data);
+extern CVMBool
+CVMclassModuleInit(CVMExecEnv* ee);
+extern void
+CVMclassModuleDestroy(CVMExecEnv* ee);
+extern CVMBool
+CVMclassBootClassPathInit(JNIEnv *env);
+extern CVMBool
+CVMclassClassPathInit(JNIEnv *env);
+extern void
+CVMclassBootClassPathDestroy(CVMExecEnv* ee);
+extern void
+CVMclassClassPathDestroy(CVMExecEnv* ee);
+extern jobject
+CVMclassFindContainer(JNIEnv *env, jobject tthis, jstring name);
+typedef struct {
+    CVMClassPathEntry* entries;
+    CVMUint16 numEntries;
+    char* pathString;
+    CVMBool initialized;
+} CVMClassPath;
+extern CVMBool
+CVMclassPathInit(JNIEnv* env, CVMClassPath* path, char* additionalPathString,
+       CVMBool doNotFailWhenPathNotFound, CVMBool initJavaSide);
+CVMClassLoaderICell*
+CVMclassGetSystemClassLoader(CVMExecEnv* ee);
+void
+CVMclassSetSystemClassLoader(CVMExecEnv* ee, jobject loader);
+CVMBool CVMclassIsValidClassBlock(CVMExecEnv *ee, CVMClassBlock *cb);
+typedef struct CVMGenSpace {
+    CVMUint32* allocPtr;
+    CVMUint32* allocBase;
+    CVMUint32* allocTop;
+} CVMGenSpace;
+typedef struct CVMGeneration {
+    CVMUint32* heapBase;
+    CVMUint32* heapTop;
+    CVMUint32* allocPtr;
+    CVMUint32* allocBase;
+    CVMUint32* allocTop;
+    CVMUint32* allocMark;
+    CVMUint32 generationNo;
+    struct CVMGeneration* nextGen;
+    struct CVMGeneration* prevGen;
+    CVMBool (*collect)(struct CVMGeneration* gen,
+     CVMExecEnv* ee,
+     CVMUint32 numBytes,
+     CVMGCOptions* gcOpts);
+    void (*scanOlderToYoungerPointers)(struct CVMGeneration* gen,
+          CVMExecEnv* ee,
+          CVMGCOptions* gcOpts,
+          CVMRefCallbackFunc callback,
+          void* callbackData);
+    CVMObject* (*promoteInto)(struct CVMGeneration* gen,
+         CVMObject* objectToPromote,
+         CVMUint32 objectSize);
+    void (*scanPromotedPointers)(struct CVMGeneration* gen,
+           CVMExecEnv* ee,
+           CVMGCOptions* gcOpts,
+           CVMRefCallbackFunc callback,
+           void* callbackData);
+    CVMGenSpace* (*getExtraSpace)(struct CVMGeneration* gen);
+    CVMUint32 (*totalMemory)(struct CVMGeneration* gen, CVMExecEnv* ee);
+    CVMUint32 (*freeMemory)(struct CVMGeneration* gen, CVMExecEnv* ee);
+} CVMGeneration;
+CVMBool
+CVMgenInGeneration(CVMGeneration *thisGen, CVMObject *ref);
+void
+CVMgenScanAllRoots(CVMGeneration* thisGen,
+     CVMExecEnv *ee, CVMGCOptions* gcOpts,
+     CVMRefCallbackFunc callback, void* data);
+void
+CVMgenBarrierObjectHeadersUpdate(CVMGeneration* gen, CVMExecEnv* ee,
+     CVMGCOptions* gcOpts,
+     CVMUint32* startRange,
+     CVMUint32* endRange);
+typedef union CVMGenSummaryTableEntry {
+    CVMUint8 offsets[4];
+    CVMUint32 intVersion;
+} CVMGenSummaryTableEntry;
+extern void
+CVMgenClearBarrierTable();
+extern void
+CVMgenBarrierPointersTraverse(CVMGeneration* gen, CVMExecEnv* ee,
+         CVMGCOptions* gcOpts,
+         CVMRefCallbackFunc callback,
+         void* callbackData);
+extern void CVMgenDumpSysInfo(CVMGCGlobalState* gc);
+struct CVMGCGlobalState {
+    CVMUint32 heapSize;
+    CVMGeneration* CVMgenGenerations[2];
+    CVMInt64 lastMajorGCTime;
+    CVMUint8* cardTable;
+    CVMUint8 volatile* cardTableVirtualBase;
+    CVMUint32 cardTableSize;
+    CVMUint8* cardTableEnd;
+    struct {
+ CVMUint32 youngGenSize;
+    } genGCAttributes;
+    CVMInt8* objectHeaderTable;
+    CVMGenSummaryTableEntry* summaryTable;
+    CVMUint32* heapBase;
+    CVMUint32* heapBaseMemoryArea;
+    CVMUint32 mappedTotalSize;
+    CVMUint32 memoryReserve;
+    CVMUint32 oldGenGrowThreshold;
+    CVMUint32 oldGenShrinkThreshold;
+    CVMUint32 oldGenLowWatermark;
+    CVMUint32 oldGenHighWatermark;
+    CVMUint32 heapMinSize;
+    CVMUint32 heapStartSize;
+    CVMUint32 heapMaxSize;
+    CVMUint32 heapCurrentSize;
+    CVMUint32 youngGenMinSize;
+    CVMUint32 youngGenStartSize;
+    CVMUint32 youngGenMaxSize;
+    CVMUint32 youngGenCurrentSize;
+    CVMUint32 oldGenMinSize;
+    CVMUint32 oldGenStartSize;
+    CVMUint32 oldGenMaxSize;
+    CVMUint32 oldGenCurrentSize;
+    CVMUint32 cardTableCurrentSize;
+    CVMUint32 objectHeaderTableCurrentSize;
+    CVMUint32 summaryTableCurrentSize;
+    CVMUint32* youngGenStart;
+    CVMUint32* oldGenStart;
+    CVMBool hasYoungGenInternedStrings;
+    CVMBool needToScanInternedStrings;
+    CVMBool hasYoungGenClassesOrLoaders;
+};
+extern void *memcpy (void *__restrict __dest,
+       __const void *__restrict __src, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern void *memmove (void *__dest, __const void *__src, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern void *memccpy (void *__restrict __dest, __const void *__restrict __src,
+        int __c, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern void *memset (void *__s, int __c, size_t __n) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int memcmp (__const void *__s1, __const void *__s2, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+extern void *memchr (__const void *__s, int __c, size_t __n)
+      __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+extern void *rawmemchr (__const void *__s, int __c)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+extern void *memrchr (__const void *__s, int __c, size_t __n)
+      __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+extern char *strcpy (char *__restrict __dest, __const char *__restrict __src)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern char *strncpy (char *__restrict __dest,
+        __const char *__restrict __src, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern char *strcat (char *__restrict __dest, __const char *__restrict __src)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern char *strncat (char *__restrict __dest, __const char *__restrict __src,
+        size_t __n) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int strcmp (__const char *__s1, __const char *__s2)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int strncmp (__const char *__s1, __const char *__s2, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int strcoll (__const char *__s1, __const char *__s2)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+extern size_t strxfrm (char *__restrict __dest,
+         __const char *__restrict __src, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+extern int strcoll_l (__const char *__s1, __const char *__s2, __locale_t __l)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2, 3)));
+extern size_t strxfrm_l (char *__dest, __const char *__src, size_t __n,
+    __locale_t __l) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2, 4)));
+extern char *strdup (__const char *__s)
+     __attribute__ ((__nothrow__)) __attribute__ ((__malloc__)) __attribute__ ((__nonnull__ (1)));
+extern char *strndup (__const char *__string, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__malloc__)) __attribute__ ((__nonnull__ (1)));
+extern char *strchr (__const char *__s, int __c)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+extern char *strrchr (__const char *__s, int __c)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+extern char *strchrnul (__const char *__s, int __c)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+extern size_t strcspn (__const char *__s, __const char *__reject)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+extern size_t strspn (__const char *__s, __const char *__accept)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+extern char *strpbrk (__const char *__s, __const char *__accept)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+extern char *strstr (__const char *__haystack, __const char *__needle)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+extern char *strtok (char *__restrict __s, __const char *__restrict __delim)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+extern char *__strtok_r (char *__restrict __s,
+    __const char *__restrict __delim,
+    char **__restrict __save_ptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2, 3)));
+extern char *strtok_r (char *__restrict __s, __const char *__restrict __delim,
+         char **__restrict __save_ptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2, 3)));
+extern char *strcasestr (__const char *__haystack, __const char *__needle)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+extern void *memmem (__const void *__haystack, size_t __haystacklen,
+       __const void *__needle, size_t __needlelen)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 3)));
+extern void *__mempcpy (void *__restrict __dest,
+   __const void *__restrict __src, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern void *mempcpy (void *__restrict __dest,
+        __const void *__restrict __src, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern size_t strlen (__const char *__s)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+extern size_t strnlen (__const char *__string, size_t __maxlen)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+extern char *strerror (int __errnum) __attribute__ ((__nothrow__));
+extern char *strerror_r (int __errnum, char *__buf, size_t __buflen)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+extern char *strerror_l (int __errnum, __locale_t __l) __attribute__ ((__nothrow__));
+extern void __bzero (void *__s, size_t __n) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern void bcopy (__const void *__src, void *__dest, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern void bzero (void *__s, size_t __n) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int bcmp (__const void *__s1, __const void *__s2, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+extern char *index (__const char *__s, int __c)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+extern char *rindex (__const char *__s, int __c)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
+extern int ffs (int __i) __attribute__ ((__nothrow__)) __attribute__ ((__const__));
+extern int ffsl (long int __l) __attribute__ ((__nothrow__)) __attribute__ ((__const__));
+__extension__ extern int ffsll (long long int __ll)
+     __attribute__ ((__nothrow__)) __attribute__ ((__const__));
+extern int strcasecmp (__const char *__s1, __const char *__s2)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int strncasecmp (__const char *__s1, __const char *__s2, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int strcasecmp_l (__const char *__s1, __const char *__s2,
+    __locale_t __loc)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2, 3)));
+extern int strncasecmp_l (__const char *__s1, __const char *__s2,
+     size_t __n, __locale_t __loc)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2, 4)));
+extern char *strsep (char **__restrict __stringp,
+       __const char *__restrict __delim)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern char *strsignal (int __sig) __attribute__ ((__nothrow__));
+extern char *__stpcpy (char *__restrict __dest, __const char *__restrict __src)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern char *stpcpy (char *__restrict __dest, __const char *__restrict __src)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern char *__stpncpy (char *__restrict __dest,
+   __const char *__restrict __src, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern char *stpncpy (char *__restrict __dest,
+        __const char *__restrict __src, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int strverscmp (__const char *__s1, __const char *__s2)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
+extern char *strfry (char *__string) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern void *memfrob (void *__s, size_t __n) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern char *basename (__const char *__filename) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+typedef struct { unsigned char __arr[2]; } __attribute__ ((__packed__)) __STRING2_COPY_ARR2;
+typedef struct { unsigned char __arr[3]; } __attribute__ ((__packed__)) __STRING2_COPY_ARR3;
+typedef struct { unsigned char __arr[4]; } __attribute__ ((__packed__)) __STRING2_COPY_ARR4;
+typedef struct { unsigned char __arr[5]; } __attribute__ ((__packed__)) __STRING2_COPY_ARR5;
+typedef struct { unsigned char __arr[6]; } __attribute__ ((__packed__)) __STRING2_COPY_ARR6;
+typedef struct { unsigned char __arr[7]; } __attribute__ ((__packed__)) __STRING2_COPY_ARR7;
+typedef struct { unsigned char __arr[8]; } __attribute__ ((__packed__)) __STRING2_COPY_ARR8;
+extern void *__rawmemchr (const void *__s, int __c);
+extern __inline size_t __strcspn_c1 (__const char *__s, int __reject);
+extern __inline size_t
+__strcspn_c1 (__const char *__s, int __reject)
+{
+  register size_t __result = 0;
+  while (__s[__result] != '\0' && __s[__result] != __reject)
+    ++__result;
+  return __result;
+}
+extern __inline size_t __strcspn_c2 (__const char *__s, int __reject1,
+         int __reject2);
+extern __inline size_t
+__strcspn_c2 (__const char *__s, int __reject1, int __reject2)
+{
+  register size_t __result = 0;
+  while (__s[__result] != '\0' && __s[__result] != __reject1
+  && __s[__result] != __reject2)
+    ++__result;
+  return __result;
+}
+extern __inline size_t __strcspn_c3 (__const char *__s, int __reject1,
+         int __reject2, int __reject3);
+extern __inline size_t
+__strcspn_c3 (__const char *__s, int __reject1, int __reject2,
+       int __reject3)
+{
+  register size_t __result = 0;
+  while (__s[__result] != '\0' && __s[__result] != __reject1
+  && __s[__result] != __reject2 && __s[__result] != __reject3)
+    ++__result;
+  return __result;
+}
+extern __inline size_t __strspn_c1 (__const char *__s, int __accept);
+extern __inline size_t
+__strspn_c1 (__const char *__s, int __accept)
+{
+  register size_t __result = 0;
+  while (__s[__result] == __accept)
+    ++__result;
+  return __result;
+}
+extern __inline size_t __strspn_c2 (__const char *__s, int __accept1,
+        int __accept2);
+extern __inline size_t
+__strspn_c2 (__const char *__s, int __accept1, int __accept2)
+{
+  register size_t __result = 0;
+  while (__s[__result] == __accept1 || __s[__result] == __accept2)
+    ++__result;
+  return __result;
+}
+extern __inline size_t __strspn_c3 (__const char *__s, int __accept1,
+        int __accept2, int __accept3);
+extern __inline size_t
+__strspn_c3 (__const char *__s, int __accept1, int __accept2, int __accept3)
+{
+  register size_t __result = 0;
+  while (__s[__result] == __accept1 || __s[__result] == __accept2
+  || __s[__result] == __accept3)
+    ++__result;
+  return __result;
+}
+extern __inline char *__strpbrk_c2 (__const char *__s, int __accept1,
+         int __accept2);
+extern __inline char *
+__strpbrk_c2 (__const char *__s, int __accept1, int __accept2)
+{
+  while (*__s != '\0' && *__s != __accept1 && *__s != __accept2)
+    ++__s;
+  return *__s == '\0' ? ((void *)0) : (char *) (size_t) __s;
+}
+extern __inline char *__strpbrk_c3 (__const char *__s, int __accept1,
+         int __accept2, int __accept3);
+extern __inline char *
+__strpbrk_c3 (__const char *__s, int __accept1, int __accept2,
+       int __accept3)
+{
+  while (*__s != '\0' && *__s != __accept1 && *__s != __accept2
+  && *__s != __accept3)
+    ++__s;
+  return *__s == '\0' ? ((void *)0) : (char *) (size_t) __s;
+}
+extern __inline char *__strtok_r_1c (char *__s, char __sep, char **__nextp);
+extern __inline char *
+__strtok_r_1c (char *__s, char __sep, char **__nextp)
+{
+  char *__result;
+  if (__s == ((void *)0))
+    __s = *__nextp;
+  while (*__s == __sep)
+    ++__s;
+  __result = ((void *)0);
+  if (*__s != '\0')
+    {
+      __result = __s++;
+      while (*__s != '\0')
+ if (*__s++ == __sep)
+   {
+     __s[-1] = '\0';
+     break;
+   }
+    }
+  *__nextp = __s;
+  return __result;
+}
+extern char *__strsep_g (char **__stringp, __const char *__delim);
+extern __inline char *__strsep_1c (char **__s, char __reject);
+extern __inline char *
+__strsep_1c (char **__s, char __reject)
+{
+  register char *__retval = *__s;
+  if (__retval != ((void *)0) && (*__s = (__extension__ (__builtin_constant_p (__reject) && !__builtin_constant_p (__retval) && (__reject) == '\0' ? (char *) __rawmemchr (__retval, __reject) : __builtin_strchr (__retval, __reject)))) != ((void *)0))
+    *(*__s)++ = '\0';
+  return __retval;
+}
+extern __inline char *__strsep_2c (char **__s, char __reject1, char __reject2);
+extern __inline char *
+__strsep_2c (char **__s, char __reject1, char __reject2)
+{
+  register char *__retval = *__s;
+  if (__retval != ((void *)0))
+    {
+      register char *__cp = __retval;
+      while (1)
+ {
+   if (*__cp == '\0')
+     {
+       __cp = ((void *)0);
+   break;
+     }
+   if (*__cp == __reject1 || *__cp == __reject2)
+     {
+       *__cp++ = '\0';
+       break;
+     }
+   ++__cp;
+ }
+      *__s = __cp;
+    }
+  return __retval;
+}
+extern __inline char *__strsep_3c (char **__s, char __reject1, char __reject2,
+       char __reject3);
+extern __inline char *
+__strsep_3c (char **__s, char __reject1, char __reject2, char __reject3)
+{
+  register char *__retval = *__s;
+  if (__retval != ((void *)0))
+    {
+      register char *__cp = __retval;
+      while (1)
+ {
+   if (*__cp == '\0')
+     {
+       __cp = ((void *)0);
+   break;
+     }
+   if (*__cp == __reject1 || *__cp == __reject2 || *__cp == __reject3)
+     {
+       *__cp++ = '\0';
+       break;
+     }
+   ++__cp;
+ }
+      *__s = __cp;
+    }
+  return __retval;
+}
+extern void *malloc (size_t __size) __attribute__ ((__nothrow__)) __attribute__ ((__malloc__)) __attribute__ ((__warn_unused_result__));
+extern void *calloc (size_t __nmemb, size_t __size)
+     __attribute__ ((__nothrow__)) __attribute__ ((__malloc__)) __attribute__ ((__warn_unused_result__));
+extern char *__strdup (__const char *__string) __attribute__ ((__nothrow__)) __attribute__ ((__malloc__));
+extern char *__strndup (__const char *__string, size_t __n)
+     __attribute__ ((__nothrow__)) __attribute__ ((__malloc__));
+extern void __warn_memset_zero_len (void) __attribute__((__warning__ ("memset used with constant zero length parameter; this could be due to transposed parameters")))
+                                                                                                   ;
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) void *
+__attribute__ ((__nothrow__)) memcpy (void *__restrict __dest, __const void *__restrict __src, size_t __len)
+{
+  return __builtin___memcpy_chk (__dest, __src, __len, __builtin_object_size (__dest, 0));
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) void *
+__attribute__ ((__nothrow__)) memmove (void *__restrict __dest, __const void *__restrict __src, size_t __len)
+{
+  return __builtin___memmove_chk (__dest, __src, __len, __builtin_object_size (__dest, 0));
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) void *
+__attribute__ ((__nothrow__)) mempcpy (void *__restrict __dest, __const void *__restrict __src, size_t __len)
+{
+  return __builtin___mempcpy_chk (__dest, __src, __len, __builtin_object_size (__dest, 0));
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) void *
+__attribute__ ((__nothrow__)) memset (void *__dest, int __ch, size_t __len)
+{
+  if (__builtin_constant_p (__len) && __len == 0)
+    {
+      __warn_memset_zero_len ();
+      return __dest;
+    }
+  return __builtin___memset_chk (__dest, __ch, __len, __builtin_object_size (__dest, 0));
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) void
+__attribute__ ((__nothrow__)) bcopy (__const void *__restrict __src, void *__restrict __dest, size_t __len)
+{
+  (void) __builtin___memmove_chk (__dest, __src, __len, __builtin_object_size (__dest, 0));
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) void
+__attribute__ ((__nothrow__)) bzero (void *__dest, size_t __len)
+{
+  (void) __builtin___memset_chk (__dest, '\0', __len, __builtin_object_size (__dest, 0));
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) char *
+__attribute__ ((__nothrow__)) strcpy (char *__restrict __dest, __const char *__restrict __src)
+{
+  return __builtin___strcpy_chk (__dest, __src, __builtin_object_size (__dest, 2 > 1));
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) char *
+__attribute__ ((__nothrow__)) stpcpy (char *__restrict __dest, __const char *__restrict __src)
+{
+  return __builtin___stpcpy_chk (__dest, __src, __builtin_object_size (__dest, 2 > 1));
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) char *
+__attribute__ ((__nothrow__)) strncpy (char *__restrict __dest, __const char *__restrict __src, size_t __len)
+{
+  return __builtin___strncpy_chk (__dest, __src, __len, __builtin_object_size (__dest, 2 > 1));
+}
+extern char *__stpncpy_chk (char *__dest, __const char *__src, size_t __n,
+       size_t __destlen) __attribute__ ((__nothrow__));
+extern char *__stpncpy_alias (char *__dest, __const char *__src, size_t __n) __asm__ ("" "stpncpy") __attribute__ ((__nothrow__))
+                                 ;
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) char *
+__attribute__ ((__nothrow__)) stpncpy (char *__dest, __const char *__src, size_t __n)
+{
+  if (__builtin_object_size (__dest, 2 > 1) != (size_t) -1
+      && (!__builtin_constant_p (__n) || __n <= __builtin_object_size (__dest, 2 > 1)))
+    return __stpncpy_chk (__dest, __src, __n, __builtin_object_size (__dest, 2 > 1));
+  return __stpncpy_alias (__dest, __src, __n);
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) char *
+__attribute__ ((__nothrow__)) strcat (char *__restrict __dest, __const char *__restrict __src)
+{
+  return __builtin___strcat_chk (__dest, __src, __builtin_object_size (__dest, 2 > 1));
+}
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) char *
+__attribute__ ((__nothrow__)) strncat (char *__restrict __dest, __const char *__restrict __src, size_t __len)
+{
+  return __builtin___strncat_chk (__dest, __src, __len, __builtin_object_size (__dest, 2 > 1));
+}
+union wait
+  {
+    int w_status;
+    struct
+      {
+ unsigned int __w_termsig:7;
+ unsigned int __w_coredump:1;
+ unsigned int __w_retcode:8;
+ unsigned int:16;
+      } __wait_terminated;
+    struct
+      {
+ unsigned int __w_stopval:8;
+ unsigned int __w_stopsig:8;
+ unsigned int:16;
+      } __wait_stopped;
+  };
+typedef union
+  {
+    union wait *__uptr;
+    int *__iptr;
+  } __WAIT_STATUS __attribute__ ((__transparent_union__));
+typedef struct
+  {
+    int quot;
+    int rem;
+  } div_t;
+typedef struct
+  {
+    long int quot;
+    long int rem;
+  } ldiv_t;
+__extension__ typedef struct
+  {
+    long long int quot;
+    long long int rem;
+  } lldiv_t;
+extern size_t __ctype_get_mb_cur_max (void) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern double atof (__const char *__nptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern int atoi (__const char *__nptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern long int atol (__const char *__nptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+__extension__ extern long long int atoll (__const char *__nptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern double strtod (__const char *__restrict __nptr,
+        char **__restrict __endptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern float strtof (__const char *__restrict __nptr,
+       char **__restrict __endptr) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern long double strtold (__const char *__restrict __nptr,
+       char **__restrict __endptr)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern long int strtol (__const char *__restrict __nptr,
+   char **__restrict __endptr, int __base)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern unsigned long int strtoul (__const char *__restrict __nptr,
+      char **__restrict __endptr, int __base)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+__extension__
+extern long long int strtoq (__const char *__restrict __nptr,
+        char **__restrict __endptr, int __base)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+__extension__
+extern unsigned long long int strtouq (__const char *__restrict __nptr,
+           char **__restrict __endptr, int __base)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+__extension__
+extern long long int strtoll (__const char *__restrict __nptr,
+         char **__restrict __endptr, int __base)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+__extension__
+extern unsigned long long int strtoull (__const char *__restrict __nptr,
+     char **__restrict __endptr, int __base)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern long int strtol_l (__const char *__restrict __nptr,
+     char **__restrict __endptr, int __base,
+     __locale_t __loc) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 4))) __attribute__ ((__warn_unused_result__));
+extern unsigned long int strtoul_l (__const char *__restrict __nptr,
+        char **__restrict __endptr,
+        int __base, __locale_t __loc)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 4))) __attribute__ ((__warn_unused_result__));
+__extension__
+extern long long int strtoll_l (__const char *__restrict __nptr,
+    char **__restrict __endptr, int __base,
+    __locale_t __loc)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 4))) __attribute__ ((__warn_unused_result__));
+__extension__
+extern unsigned long long int strtoull_l (__const char *__restrict __nptr,
+       char **__restrict __endptr,
+       int __base, __locale_t __loc)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 4))) __attribute__ ((__warn_unused_result__));
+extern double strtod_l (__const char *__restrict __nptr,
+   char **__restrict __endptr, __locale_t __loc)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 3))) __attribute__ ((__warn_unused_result__));
+extern float strtof_l (__const char *__restrict __nptr,
+         char **__restrict __endptr, __locale_t __loc)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 3))) __attribute__ ((__warn_unused_result__));
+extern long double strtold_l (__const char *__restrict __nptr,
+         char **__restrict __endptr,
+         __locale_t __loc)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 3))) __attribute__ ((__warn_unused_result__));
+extern __inline double
+__attribute__ ((__nothrow__)) atof (__const char *__nptr)
+{
+  return strtod (__nptr, (char **) ((void *)0));
+}
+extern __inline int
+__attribute__ ((__nothrow__)) atoi (__const char *__nptr)
+{
+  return (int) strtol (__nptr, (char **) ((void *)0), 10);
+}
+extern __inline long int
+__attribute__ ((__nothrow__)) atol (__const char *__nptr)
+{
+  return strtol (__nptr, (char **) ((void *)0), 10);
+}
+__extension__ extern __inline long long int
+__attribute__ ((__nothrow__)) atoll (__const char *__nptr)
+{
+  return strtoll (__nptr, (char **) ((void *)0), 10);
+}
+extern char *l64a (long int __n) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern long int a64l (__const char *__s)
+     __attribute__ ((__nothrow__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern long int random (void) __attribute__ ((__nothrow__));
+extern void srandom (unsigned int __seed) __attribute__ ((__nothrow__));
+extern char *initstate (unsigned int __seed, char *__statebuf,
+   size_t __statelen) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+extern char *setstate (char *__statebuf) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+struct random_data
+  {
+    int32_t *fptr;
+    int32_t *rptr;
+    int32_t *state;
+    int rand_type;
+    int rand_deg;
+    int rand_sep;
+    int32_t *end_ptr;
+  };
+extern int random_r (struct random_data *__restrict __buf,
+       int32_t *__restrict __result) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int srandom_r (unsigned int __seed, struct random_data *__buf)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+extern int initstate_r (unsigned int __seed, char *__restrict __statebuf,
+   size_t __statelen,
+   struct random_data *__restrict __buf)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2, 4)));
+extern int setstate_r (char *__restrict __statebuf,
+         struct random_data *__restrict __buf)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int rand (void) __attribute__ ((__nothrow__));
+extern void srand (unsigned int __seed) __attribute__ ((__nothrow__));
+extern int rand_r (unsigned int *__seed) __attribute__ ((__nothrow__));
+extern double drand48 (void) __attribute__ ((__nothrow__));
+extern double erand48 (unsigned short int __xsubi[3]) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern long int lrand48 (void) __attribute__ ((__nothrow__));
+extern long int nrand48 (unsigned short int __xsubi[3])
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern long int mrand48 (void) __attribute__ ((__nothrow__));
+extern long int jrand48 (unsigned short int __xsubi[3])
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern void srand48 (long int __seedval) __attribute__ ((__nothrow__));
+extern unsigned short int *seed48 (unsigned short int __seed16v[3])
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern void lcong48 (unsigned short int __param[7]) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+struct drand48_data
+  {
+    unsigned short int __x[3];
+    unsigned short int __old_x[3];
+    unsigned short int __c;
+    unsigned short int __init;
+    unsigned long long int __a;
+  };
+extern int drand48_r (struct drand48_data *__restrict __buffer,
+        double *__restrict __result) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int erand48_r (unsigned short int __xsubi[3],
+        struct drand48_data *__restrict __buffer,
+        double *__restrict __result) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int lrand48_r (struct drand48_data *__restrict __buffer,
+        long int *__restrict __result)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int nrand48_r (unsigned short int __xsubi[3],
+        struct drand48_data *__restrict __buffer,
+        long int *__restrict __result)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int mrand48_r (struct drand48_data *__restrict __buffer,
+        long int *__restrict __result)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int jrand48_r (unsigned short int __xsubi[3],
+        struct drand48_data *__restrict __buffer,
+        long int *__restrict __result)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int srand48_r (long int __seedval, struct drand48_data *__buffer)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+extern int seed48_r (unsigned short int __seed16v[3],
+       struct drand48_data *__buffer) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern int lcong48_r (unsigned short int __param[7],
+        struct drand48_data *__buffer)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
+extern void *realloc (void *__ptr, size_t __size)
+     __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern void free (void *__ptr) __attribute__ ((__nothrow__));
+extern void cfree (void *__ptr) __attribute__ ((__nothrow__));
+extern void *alloca (size_t __size) __attribute__ ((__nothrow__));
+extern void *valloc (size_t __size) __attribute__ ((__nothrow__)) __attribute__ ((__malloc__)) __attribute__ ((__warn_unused_result__));
+extern int posix_memalign (void **__memptr, size_t __alignment, size_t __size)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern void abort (void) __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
+extern int atexit (void (*__func) (void)) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int at_quick_exit (void (*__func) (void)) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int on_exit (void (*__func) (int __status, void *__arg), void *__arg)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern void exit (int __status) __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
+extern void quick_exit (int __status) __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
+extern void _Exit (int __status) __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
+extern char *getenv (__const char *__name) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern char *__secure_getenv (__const char *__name)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern int putenv (char *__string) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int setenv (__const char *__name, __const char *__value, int __replace)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+extern int unsetenv (__const char *__name) __attribute__ ((__nothrow__));
+extern int clearenv (void) __attribute__ ((__nothrow__));
+extern char *mktemp (char *__template) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern int mkstemp (char *__template) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern int mkstemp64 (char *__template) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern char *mkdtemp (char *__template) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern int mkostemp (char *__template, int __flags) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern int mkostemp64 (char *__template, int __flags) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern int system (__const char *__command) __attribute__ ((__warn_unused_result__));
+extern char *canonicalize_file_name (__const char *__name)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern char *realpath (__const char *__restrict __name,
+         char *__restrict __resolved) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+typedef int (*__compar_fn_t) (__const void *, __const void *);
+typedef __compar_fn_t comparison_fn_t;
+typedef int (*__compar_d_fn_t) (__const void *, __const void *, void *);
+extern void *bsearch (__const void *__key, __const void *__base,
+        size_t __nmemb, size_t __size, __compar_fn_t __compar)
+     __attribute__ ((__nonnull__ (1, 2, 5))) __attribute__ ((__warn_unused_result__));
+extern void qsort (void *__base, size_t __nmemb, size_t __size,
+     __compar_fn_t __compar) __attribute__ ((__nonnull__ (1, 4)));
+extern void qsort_r (void *__base, size_t __nmemb, size_t __size,
+       __compar_d_fn_t __compar, void *__arg)
+  __attribute__ ((__nonnull__ (1, 4)));
+extern int abs (int __x) __attribute__ ((__nothrow__)) __attribute__ ((__const__)) __attribute__ ((__warn_unused_result__));
+extern long int labs (long int __x) __attribute__ ((__nothrow__)) __attribute__ ((__const__)) __attribute__ ((__warn_unused_result__));
+__extension__ extern long long int llabs (long long int __x)
+     __attribute__ ((__nothrow__)) __attribute__ ((__const__)) __attribute__ ((__warn_unused_result__));
+extern div_t div (int __numer, int __denom)
+     __attribute__ ((__nothrow__)) __attribute__ ((__const__)) __attribute__ ((__warn_unused_result__));
+extern ldiv_t ldiv (long int __numer, long int __denom)
+     __attribute__ ((__nothrow__)) __attribute__ ((__const__)) __attribute__ ((__warn_unused_result__));
+__extension__ extern lldiv_t lldiv (long long int __numer,
+        long long int __denom)
+     __attribute__ ((__nothrow__)) __attribute__ ((__const__)) __attribute__ ((__warn_unused_result__));
+extern char *ecvt (double __value, int __ndigit, int *__restrict __decpt,
+     int *__restrict __sign) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4))) __attribute__ ((__warn_unused_result__));
+extern char *fcvt (double __value, int __ndigit, int *__restrict __decpt,
+     int *__restrict __sign) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4))) __attribute__ ((__warn_unused_result__));
+extern char *gcvt (double __value, int __ndigit, char *__buf)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3))) __attribute__ ((__warn_unused_result__));
+extern char *qecvt (long double __value, int __ndigit,
+      int *__restrict __decpt, int *__restrict __sign)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4))) __attribute__ ((__warn_unused_result__));
+extern char *qfcvt (long double __value, int __ndigit,
+      int *__restrict __decpt, int *__restrict __sign)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4))) __attribute__ ((__warn_unused_result__));
+extern char *qgcvt (long double __value, int __ndigit, char *__buf)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3))) __attribute__ ((__warn_unused_result__));
+extern int ecvt_r (double __value, int __ndigit, int *__restrict __decpt,
+     int *__restrict __sign, char *__restrict __buf,
+     size_t __len) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4, 5)));
+extern int fcvt_r (double __value, int __ndigit, int *__restrict __decpt,
+     int *__restrict __sign, char *__restrict __buf,
+     size_t __len) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4, 5)));
+extern int qecvt_r (long double __value, int __ndigit,
+      int *__restrict __decpt, int *__restrict __sign,
+      char *__restrict __buf, size_t __len)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4, 5)));
+extern int qfcvt_r (long double __value, int __ndigit,
+      int *__restrict __decpt, int *__restrict __sign,
+      char *__restrict __buf, size_t __len)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (3, 4, 5)));
+extern int mblen (__const char *__s, size_t __n) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern int mbtowc (wchar_t *__restrict __pwc,
+     __const char *__restrict __s, size_t __n) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern int wctomb (char *__s, wchar_t __wchar) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern size_t mbstowcs (wchar_t *__restrict __pwcs,
+   __const char *__restrict __s, size_t __n) __attribute__ ((__nothrow__));
+extern size_t wcstombs (char *__restrict __s,
+   __const wchar_t *__restrict __pwcs, size_t __n)
+     __attribute__ ((__nothrow__));
+extern int rpmatch (__const char *__response) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__warn_unused_result__));
+extern int getsubopt (char **__restrict __optionp,
+        char *__const *__restrict __tokens,
+        char **__restrict __valuep)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2, 3))) __attribute__ ((__warn_unused_result__));
+extern void setkey (__const char *__key) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern int posix_openpt (int __oflag) __attribute__ ((__warn_unused_result__));
+extern int grantpt (int __fd) __attribute__ ((__nothrow__));
+extern int unlockpt (int __fd) __attribute__ ((__nothrow__));
+extern char *ptsname (int __fd) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern int ptsname_r (int __fd, char *__buf, size_t __buflen)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+extern int getpt (void);
+extern int getloadavg (double __loadavg[], int __nelem)
+     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
+extern char *__realpath_chk (__const char *__restrict __name,
+        char *__restrict __resolved,
+        size_t __resolvedlen) __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern char *__realpath_alias (__const char *__restrict __name, char *__restrict __resolved) __asm__ ("" "realpath") __attribute__ ((__nothrow__))
+                                                 __attribute__ ((__warn_unused_result__));
+extern char *__realpath_chk_warn (__const char *__restrict __name, char *__restrict __resolved, size_t __resolvedlen) __asm__ ("" "__realpath_chk") __attribute__ ((__nothrow__))
+                                                __attribute__ ((__warn_unused_result__))
+     __attribute__((__warning__ ("second argument of realpath must be either NULL or at " "least PATH_MAX bytes long buffer")))
+                                      ;
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) __attribute__ ((__warn_unused_result__)) char *
+__attribute__ ((__nothrow__)) realpath (__const char *__restrict __name, char *__restrict __resolved)
+{
+  if (__builtin_object_size (__resolved, 2 > 1) != (size_t) -1)
+    {
+      return __realpath_chk (__name, __resolved, __builtin_object_size (__resolved, 2 > 1));
+    }
+  return __realpath_alias (__name, __resolved);
+}
+extern int __ptsname_r_chk (int __fd, char *__buf, size_t __buflen,
+       size_t __nreal) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (2)));
+extern int __ptsname_r_alias (int __fd, char *__buf, size_t __buflen) __asm__ ("" "ptsname_r") __attribute__ ((__nothrow__))
+     __attribute__ ((__nonnull__ (2)));
+extern int __ptsname_r_chk_warn (int __fd, char *__buf, size_t __buflen, size_t __nreal) __asm__ ("" "__ptsname_r_chk") __attribute__ ((__nothrow__))
+     __attribute__ ((__nonnull__ (2))) __attribute__((__warning__ ("ptsname_r called with buflen bigger than " "size of buf")))
+                   ;
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) int
+__attribute__ ((__nothrow__)) ptsname_r (int __fd, char *__buf, size_t __buflen)
+{
+  if (__builtin_object_size (__buf, 2 > 1) != (size_t) -1)
+    {
+      if (!__builtin_constant_p (__buflen))
+ return __ptsname_r_chk (__fd, __buf, __buflen, __builtin_object_size (__buf, 2 > 1));
+      if (__buflen > __builtin_object_size (__buf, 2 > 1))
+ return __ptsname_r_chk_warn (__fd, __buf, __buflen, __builtin_object_size (__buf, 2 > 1));
+    }
+  return __ptsname_r_alias (__fd, __buf, __buflen);
+}
+extern int __wctomb_chk (char *__s, wchar_t __wchar, size_t __buflen)
+  __attribute__ ((__nothrow__)) __attribute__ ((__warn_unused_result__));
+extern int __wctomb_alias (char *__s, wchar_t __wchar) __asm__ ("" "wctomb") __attribute__ ((__nothrow__))
+              __attribute__ ((__warn_unused_result__));
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) __attribute__ ((__warn_unused_result__)) int
+__attribute__ ((__nothrow__)) wctomb (char *__s, wchar_t __wchar)
+{
+  if (__builtin_object_size (__s, 2 > 1) != (size_t) -1 && 16 > __builtin_object_size (__s, 2 > 1))
+    return __wctomb_chk (__s, __wchar, __builtin_object_size (__s, 2 > 1));
+  return __wctomb_alias (__s, __wchar);
+}
+extern size_t __mbstowcs_chk (wchar_t *__restrict __dst,
+         __const char *__restrict __src,
+         size_t __len, size_t __dstlen) __attribute__ ((__nothrow__));
+extern size_t __mbstowcs_alias (wchar_t *__restrict __dst, __const char *__restrict __src, size_t __len) __asm__ ("" "mbstowcs") __attribute__ ((__nothrow__))
+                                  ;
+extern size_t __mbstowcs_chk_warn (wchar_t *__restrict __dst, __const char *__restrict __src, size_t __len, size_t __dstlen) __asm__ ("" "__mbstowcs_chk") __attribute__ ((__nothrow__))
+     __attribute__((__warning__ ("mbstowcs called with dst buffer smaller than len " "* sizeof (wchar_t)")))
+                        ;
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) size_t
+__attribute__ ((__nothrow__)) mbstowcs (wchar_t *__restrict __dst, __const char *__restrict __src, size_t __len)
+{
+  if (__builtin_object_size (__dst, 2 > 1) != (size_t) -1)
+    {
+      if (!__builtin_constant_p (__len))
+ return __mbstowcs_chk (__dst, __src, __len,
+          __builtin_object_size (__dst, 2 > 1) / sizeof (wchar_t));
+      if (__len > __builtin_object_size (__dst, 2 > 1) / sizeof (wchar_t))
+ return __mbstowcs_chk_warn (__dst, __src, __len,
+         __builtin_object_size (__dst, 2 > 1) / sizeof (wchar_t));
+    }
+  return __mbstowcs_alias (__dst, __src, __len);
+}
+extern size_t __wcstombs_chk (char *__restrict __dst,
+         __const wchar_t *__restrict __src,
+         size_t __len, size_t __dstlen) __attribute__ ((__nothrow__));
+extern size_t __wcstombs_alias (char *__restrict __dst, __const wchar_t *__restrict __src, size_t __len) __asm__ ("" "wcstombs") __attribute__ ((__nothrow__))
+                                  ;
+extern size_t __wcstombs_chk_warn (char *__restrict __dst, __const wchar_t *__restrict __src, size_t __len, size_t __dstlen) __asm__ ("" "__wcstombs_chk") __attribute__ ((__nothrow__))
+     __attribute__((__warning__ ("wcstombs called with dst buffer smaller than len")));
+extern __inline __attribute__ ((__always_inline__)) __attribute__ ((__artificial__)) size_t
+__attribute__ ((__nothrow__)) wcstombs (char *__restrict __dst, __const wchar_t *__restrict __src, size_t __len)
+{
+  if (__builtin_object_size (__dst, 2 > 1) != (size_t) -1)
+    {
+      if (!__builtin_constant_p (__len))
+ return __wcstombs_chk (__dst, __src, __len, __builtin_object_size (__dst, 2 > 1));
+      if (__len > __builtin_object_size (__dst, 2 > 1))
+ return __wcstombs_chk_warn (__dst, __src, __len, __builtin_object_size (__dst, 2 > 1));
+    }
+  return __wcstombs_alias (__dst, __src, __len);
+}
+enum
+{
+  _ISupper = ((0) < 8 ? ((1 << (0)) << 8) : ((1 << (0)) >> 8)),
+  _ISlower = ((1) < 8 ? ((1 << (1)) << 8) : ((1 << (1)) >> 8)),
+  _ISalpha = ((2) < 8 ? ((1 << (2)) << 8) : ((1 << (2)) >> 8)),
+  _ISdigit = ((3) < 8 ? ((1 << (3)) << 8) : ((1 << (3)) >> 8)),
+  _ISxdigit = ((4) < 8 ? ((1 << (4)) << 8) : ((1 << (4)) >> 8)),
+  _ISspace = ((5) < 8 ? ((1 << (5)) << 8) : ((1 << (5)) >> 8)),
+  _ISprint = ((6) < 8 ? ((1 << (6)) << 8) : ((1 << (6)) >> 8)),
+  _ISgraph = ((7) < 8 ? ((1 << (7)) << 8) : ((1 << (7)) >> 8)),
+  _ISblank = ((8) < 8 ? ((1 << (8)) << 8) : ((1 << (8)) >> 8)),
+  _IScntrl = ((9) < 8 ? ((1 << (9)) << 8) : ((1 << (9)) >> 8)),
+  _ISpunct = ((10) < 8 ? ((1 << (10)) << 8) : ((1 << (10)) >> 8)),
+  _ISalnum = ((11) < 8 ? ((1 << (11)) << 8) : ((1 << (11)) >> 8))
+};
+extern __const unsigned short int **__ctype_b_loc (void)
+     __attribute__ ((__nothrow__)) __attribute__ ((__const));
+extern __const __int32_t **__ctype_tolower_loc (void)
+     __attribute__ ((__nothrow__)) __attribute__ ((__const));
+extern __const __int32_t **__ctype_toupper_loc (void)
+     __attribute__ ((__nothrow__)) __attribute__ ((__const));
+extern int isalnum (int) __attribute__ ((__nothrow__));
+extern int isalpha (int) __attribute__ ((__nothrow__));
+extern int iscntrl (int) __attribute__ ((__nothrow__));
+extern int isdigit (int) __attribute__ ((__nothrow__));
+extern int islower (int) __attribute__ ((__nothrow__));
+extern int isgraph (int) __attribute__ ((__nothrow__));
+extern int isprint (int) __attribute__ ((__nothrow__));
+extern int ispunct (int) __attribute__ ((__nothrow__));
+extern int isspace (int) __attribute__ ((__nothrow__));
+extern int isupper (int) __attribute__ ((__nothrow__));
+extern int isxdigit (int) __attribute__ ((__nothrow__));
+extern int tolower (int __c) __attribute__ ((__nothrow__));
+extern int toupper (int __c) __attribute__ ((__nothrow__));
+extern int isblank (int) __attribute__ ((__nothrow__));
+extern int isctype (int __c, int __mask) __attribute__ ((__nothrow__));
+extern int isascii (int __c) __attribute__ ((__nothrow__));
+extern int toascii (int __c) __attribute__ ((__nothrow__));
+extern int _toupper (int) __attribute__ ((__nothrow__));
+extern int _tolower (int) __attribute__ ((__nothrow__));
+extern __inline int
+__attribute__ ((__nothrow__)) tolower (int __c)
+{
+  return __c >= -128 && __c < 256 ? (*__ctype_tolower_loc ())[__c] : __c;
+}
+extern __inline int
+__attribute__ ((__nothrow__)) toupper (int __c)
+{
+  return __c >= -128 && __c < 256 ? (*__ctype_toupper_loc ())[__c] : __c;
+}
+extern int isalnum_l (int, __locale_t) __attribute__ ((__nothrow__));
+extern int isalpha_l (int, __locale_t) __attribute__ ((__nothrow__));
+extern int iscntrl_l (int, __locale_t) __attribute__ ((__nothrow__));
+extern int isdigit_l (int, __locale_t) __attribute__ ((__nothrow__));
+extern int islower_l (int, __locale_t) __attribute__ ((__nothrow__));
+extern int isgraph_l (int, __locale_t) __attribute__ ((__nothrow__));
+extern int isprint_l (int, __locale_t) __attribute__ ((__nothrow__));
+extern int ispunct_l (int, __locale_t) __attribute__ ((__nothrow__));
+extern int isspace_l (int, __locale_t) __attribute__ ((__nothrow__));
+extern int isupper_l (int, __locale_t) __attribute__ ((__nothrow__));
+extern int isxdigit_l (int, __locale_t) __attribute__ ((__nothrow__));
+extern int isblank_l (int, __locale_t) __attribute__ ((__nothrow__));
+extern int __tolower_l (int __c, __locale_t __l) __attribute__ ((__nothrow__));
+extern int tolower_l (int __c, __locale_t __l) __attribute__ ((__nothrow__));
+extern int __toupper_l (int __c, __locale_t __l) __attribute__ ((__nothrow__));
+extern int toupper_l (int __c, __locale_t __l) __attribute__ ((__nothrow__));
+extern int *__errno_location (void) __attribute__ ((__nothrow__)) __attribute__ ((__const__));
+extern char *program_invocation_name, *program_invocation_short_name;
+typedef int error_t;
+extern void __assert_fail (__const char *__assertion, __const char *__file,
+      unsigned int __line, __const char *__function)
+     __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
+extern void __assert_perror_fail (int __errnum, __const char *__file,
+      unsigned int __line,
+      __const char *__function)
+     __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
+extern void __assert (const char *__assertion, const char *__file, int __line)
+     __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
+void CVMhalt(CVMInt32 status);
+void CVMsystemPanic( const char * msg );
+int CVMassertHook(const char *filename, int lineno, const char *expr);
+extern void
+CVMgcimplInitGlobalState(CVMGCGlobalState* globalState);
+extern CVMBool
+CVMgcimplInitHeap(CVMGCGlobalState* globalState,
+    CVMUint32 startBytes,
+    CVMUint32 minBytes,
+    CVMUint32 maxBytes,
+    CVMBool startIsUnspecified,
+    CVMBool minIsUnspecified,
+    CVMBool maxIsUnspecified);
+extern CVMObject*
+CVMgcimplAllocObject(CVMExecEnv* ee, CVMUint32 numBytes);
+extern CVMObject*
+CVMgcimplRetryAllocationAfterGC(CVMExecEnv* ee, CVMUint32 numBytes);
+void
+CVMgcimplDoGC(CVMExecEnv* ee, CVMUint32 numBytes);
+CVMUint32
+CVMgcimplFreeMemory(CVMExecEnv* ee);
+CVMUint32
+CVMgcimplTotalMemory(CVMExecEnv* ee);
+extern void
+CVMgcimplDestroyGlobalState(CVMGCGlobalState* globalState);
+extern CVMBool
+CVMgcimplDestroyHeap(CVMGCGlobalState* globalState);
+extern CVMInt64
+CVMgcimplTimeOfLastMajorGC();
+extern CVMBool
+CVMgcimplIterateHeap(CVMExecEnv* ee, CVMObjectCallbackFunc cback, void* data);
+void CVMgcimplDumpSysInfo();
+extern const CVMClassBlock*
+CVMpreloaderLookup(const char* className);
+const char *
+CVMpreloaderGetClassLoaderNames(CVMExecEnv *ee);
+void
+CVMpreloaderRegisterClassLoaderUnsafe(CVMExecEnv *ee, CVMInt32 index,
+    CVMClassLoaderICell *loader);
+extern CVMClassBlock*
+CVMpreloaderLookupFromType(CVMExecEnv *ee,
+    CVMClassTypeID typeID, CVMObjectICell *loader);
+extern CVMClassBlock*
+CVMpreloaderLookupPrimitiveClassFromType(CVMClassTypeID classType);
+extern void
+CVMpreloaderInit();
+extern CVMBool
+CVMpreloaderReallyInROM(CVMObject* ref);
+extern void
+CVMpreloaderInitializeStringInterning(CVMExecEnv* ee);
+extern void
+CVMpreloaderDestroy();
+extern void
+CVMpreloaderCheckROMClassInitState(CVMExecEnv* ee);
+extern CVMBool
+CVMpreloaderDisambiguateAllMethods(CVMExecEnv* ee);
+extern void
+CVMpreloaderIterateAllClasses(CVMExecEnv* ee,
+         CVMClassCallbackFunc callback,
+         void* data);
+CVMBool CVMpreloaderIsPreloadedObject(CVMObject *obj);
+CVMBool
+CVMpreloaderIteratePreloadedObjects(CVMExecEnv *ee,
+                                    CVMObjectCallbackFunc callback,
+                                    void *callbackData);
+extern const CVMClassBlock sun_misc_CVM_Classblock;
+extern const CVMClassBlock sun_misc_Launcher_Classblock;
+extern const CVMClassBlock sun_misc_Launcher_AppClassLoader_Classblock;
+extern const CVMClassBlock sun_misc_Launcher_ClassContainer_Classblock;
+extern const CVMClassBlock sun_misc_ThreadRegistry_Classblock;
+extern const CVMClassBlock java_lang_Object_Classblock;
+extern const CVMClassBlock java_lang_AssertionStatusDirectives_Classblock;
+extern const CVMClassBlock java_lang_Class_Classblock;
+extern const CVMClassBlock java_lang_ClassLoader_Classblock;
+extern const CVMClassBlock java_lang_ClassLoader_NativeLibrary_Classblock;
+extern const CVMClassBlock java_lang_Math_Classblock;
+extern const CVMClassBlock java_lang_Shutdown_Classblock;
+extern const CVMClassBlock java_lang_String_Classblock;
+extern const CVMClassBlock java_lang_Thread_Classblock;
+extern const CVMClassBlock java_lang_ThreadGroup_Classblock;
+extern const CVMClassBlock java_lang_Throwable_Classblock;
+extern const CVMClassBlock java_lang_StackTraceElement_Classblock;
+extern const CVMClassBlock java_lang_Exception_Classblock;
+extern const CVMClassBlock java_lang_Error_Classblock;
+extern const CVMClassBlock java_lang_ThreadDeath_Classblock;
+extern const CVMClassBlock java_lang_Cloneable_Classblock;
+extern const CVMClassBlock java_lang_System_Classblock;
+extern const CVMClassBlock java_io_File_Classblock;
+extern const CVMClassBlock java_io_Serializable_Classblock;
+extern const CVMClassBlock java_net_URLConnection_Classblock;
+extern const CVMClassBlock java_lang_reflect_Field_Classblock;
+extern const CVMClassBlock java_lang_reflect_Method_Classblock;
+extern const CVMClassBlock java_lang_reflect_Constructor_Classblock;
+extern const CVMClassBlock java_lang_ref_SoftReference_Classblock;
+extern const CVMClassBlock java_lang_ref_WeakReference_Classblock;
+extern const CVMClassBlock java_lang_ref_PhantomReference_Classblock;
+extern const CVMClassBlock java_lang_ref_FinalReference_Classblock;
+extern const CVMClassBlock java_lang_ref_Finalizer_Classblock;
+extern const CVMClassBlock java_lang_ref_Reference_Classblock;
+extern const CVMClassBlock java_util_jar_JarFile_Classblock;
+extern const CVMClassBlock java_util_ResourceBundle_Classblock;
+extern const CVMClassBlock java_security_AccessController_Classblock;
+extern const CVMClassBlock java_security_CodeSource_Classblock;
+extern const CVMClassBlock java_security_SecureClassLoader_Classblock;
+extern const CVMClassBlock java_lang_ClassCircularityError_Classblock;
+extern const CVMClassBlock java_lang_ClassFormatError_Classblock;
+extern const CVMClassBlock java_lang_IllegalAccessError_Classblock;
+extern const CVMClassBlock java_lang_InstantiationError_Classblock;
+extern const CVMClassBlock java_lang_LinkageError_Classblock;
+extern const CVMClassBlock java_lang_UnsupportedClassVersionError_Classblock;
+extern const CVMClassBlock java_lang_VerifyError_Classblock;
+extern const CVMClassBlock java_lang_UnsatisfiedLinkError_Classblock;
+extern const CVMClassBlock java_lang_NegativeArraySizeException_Classblock;
+extern const CVMClassBlock java_lang_NoSuchFieldException_Classblock;
+extern const CVMClassBlock java_lang_NoSuchMethodException_Classblock;
+extern const CVMClassBlock java_lang_IncompatibleClassChangeError_Classblock;
+extern const CVMClassBlock java_lang_AbstractMethodError_Classblock;
+extern const CVMClassBlock java_lang_ArithmeticException_Classblock;
+extern const CVMClassBlock java_lang_ArrayIndexOutOfBoundsException_Classblock;
+extern const CVMClassBlock java_lang_ArrayStoreException_Classblock;
+extern const CVMClassBlock java_lang_ClassCastException_Classblock;
+extern const CVMClassBlock java_lang_ClassNotFoundException_Classblock;
+extern const CVMClassBlock java_lang_CloneNotSupportedException_Classblock;
+extern const CVMClassBlock java_lang_IllegalAccessException_Classblock;
+extern const CVMClassBlock java_lang_IllegalArgumentException_Classblock;
+extern const CVMClassBlock java_lang_IllegalMonitorStateException_Classblock;
+extern const CVMClassBlock java_lang_IllegalStateException_Classblock;
+extern const CVMClassBlock java_lang_InstantiationException_Classblock;
+extern const CVMClassBlock java_lang_InternalError_Classblock;
+extern const CVMClassBlock java_lang_InterruptedException_Classblock;
+extern const CVMClassBlock java_lang_NoClassDefFoundError_Classblock;
+extern const CVMClassBlock java_lang_NoSuchFieldError_Classblock;
+extern const CVMClassBlock java_lang_NoSuchMethodError_Classblock;
+extern const CVMClassBlock java_lang_NullPointerException_Classblock;
+extern const CVMClassBlock java_lang_OutOfMemoryError_Classblock;
+extern const CVMClassBlock java_lang_StackOverflowError_Classblock;
+extern const CVMClassBlock java_lang_StringIndexOutOfBoundsException_Classblock;
+extern const CVMClassBlock java_lang_UnsupportedOperationException_Classblock;
+extern const CVMClassBlock java_io_InvalidClassException_Classblock;
+extern const CVMClassBlock java_io_IOException_Classblock;
+extern const CVMClassBlock java_lang_reflect_Method_ArgumentException_Classblock;
+extern const CVMClassBlock java_lang_reflect_Method_AccessException_Classblock;
+extern const CVMClassBlock java_lang_reflect_Constructor_ArgumentException_Classblock;
+extern const CVMClassBlock java_lang_reflect_Constructor_AccessException_Classblock;
+extern const CVMClassBlock sun_io_ConversionBufferFullException_Classblock;
+extern const CVMClassBlock sun_io_UnknownCharacterException_Classblock;
+extern const CVMClassBlock sun_io_MalformedInputException_Classblock;
+extern const CVMClassBlock manufacturedArrayOfBoolean_Classblock;
+extern const CVMClassBlock manufacturedArrayOfChar_Classblock;
+extern const CVMClassBlock manufacturedArrayOfFloat_Classblock;
+extern const CVMClassBlock manufacturedArrayOfDouble_Classblock;
+extern const CVMClassBlock manufacturedArrayOfByte_Classblock;
+extern const CVMClassBlock manufacturedArrayOfShort_Classblock;
+extern const CVMClassBlock manufacturedArrayOfInt_Classblock;
+extern const CVMClassBlock manufacturedArrayOfLong_Classblock;
+extern const CVMClassBlock manufacturedArrayOfObject_Classblock;
+extern const CVMClassBlock primitiveClass_boolean_Classblock;
+extern const CVMClassBlock primitiveClass_char_Classblock;
+extern const CVMClassBlock primitiveClass_float_Classblock;
+extern const CVMClassBlock primitiveClass_double_Classblock;
+extern const CVMClassBlock primitiveClass_byte_Classblock;
+extern const CVMClassBlock primitiveClass_short_Classblock;
+extern const CVMClassBlock primitiveClass_int_Classblock;
+extern const CVMClassBlock primitiveClass_long_Classblock;
+extern const CVMClassBlock primitiveClass_void_Classblock;
+extern const CVMClassBlock java_lang_Boolean_Classblock;
+extern const CVMClassBlock java_lang_Character_Classblock;
+extern const CVMClassBlock java_lang_Float_Classblock;
+extern const CVMClassBlock java_lang_Double_Classblock;
+extern const CVMClassBlock java_lang_Byte_Classblock;
+extern const CVMClassBlock java_lang_Short_Classblock;
+extern const CVMClassBlock java_lang_Integer_Classblock;
+extern const CVMClassBlock java_lang_Long_Classblock;
+extern CVMAddr * const CVM_staticData;
+extern CVMUint32 CVM_nStaticData;
+extern CVMAddr CVM_StaticDataMaster[];
+extern const int CVM_nROMClasses;
+extern void
+CVMweakrefInit();
+extern void
+CVMweakrefDiscover(CVMExecEnv* ee, CVMObject* weakRef);
+extern void
+CVMweakrefProcessNonStrong(CVMExecEnv* ee,
+      CVMRefLivenessQueryFunc isLive,
+      void* isLiveData,
+      CVMRefCallbackFunc transitiveScanner,
+      void* transitiveScannerData,
+      CVMGCOptions* gcOpts);
+extern void
+CVMweakrefRollbackHandling(CVMExecEnv* ee,
+      CVMGCOptions* gcOpts,
+      CVMRefCallbackFunc rootRollbackFunction,
+      void* rootRollbackData);
+void
+CVMweakrefFinalizeProcessing(CVMExecEnv* ee,
+        CVMRefLivenessQueryFunc isLive, void* isLiveData,
+        CVMRefCallbackFunc transitiveScanner,
+        void* transitiveScannerData,
+        CVMGCOptions* gcOpts);
+extern void
+CVMweakrefUpdate(CVMExecEnv* ee,
+   CVMRefCallbackFunc refUpdate, void* updateData,
+   CVMGCOptions* gcOpts);
+extern void
+CVMweakrefCleanUpForGCAbort(CVMExecEnv* ee);
+extern CVMBool CVMinitVMTargetGlobalState();
+extern void CVMdestroyVMTargetGlobalState();
+typedef struct CVMpathInfo CVMpathInfo;
+struct CVMpathInfo {
+    char *basePath;
+    char *libPath;
+    char *dllPath;
+    char *preBootclasspath;
+    char *postBootclasspath;
+};
+extern CVMBool CVMinitStaticState(CVMpathInfo *);
+extern void CVMdestroyStaticState();
+typedef struct {
+    const char *library_path;
+    const char *dll_dir;
+    const char *java_home;
+    const char *ext_dirs;
+    const char *sysclasspath;
+} CVMProperties;
+extern const CVMProperties *CVMgetProperties(void);
+struct CVMTargetGlobalState {
+    int dummy;
+    CVMThreadID *io_queue;
+};
+extern CVMBool
+linuxSegvHandlerInit(void);
+extern CVMTargetGlobalState * const CVMtargetGlobals;
+extern CNINativeMethod CNIsun_misc_CVM_setSystemClassLoader;
+extern CNINativeMethod CNIsun_misc_CVM_checkDebugFlags;
+extern CNINativeMethod CNIsun_misc_CVM_setDebugFlags;
+extern CNINativeMethod CNIsun_misc_CVM_clearDebugFlags;
+extern CNINativeMethod CNIsun_misc_CVM_restoreDebugFlags;
+extern CNINativeMethod CNIsun_misc_CVM_checkDebugJITFlags;
+extern CNINativeMethod CNIsun_misc_CVM_setDebugJITFlags;
+extern CNINativeMethod CNIsun_misc_CVM_clearDebugJITFlags;
+extern CNINativeMethod CNIsun_misc_CVM_restoreDebugJITFlags;
+extern CNINativeMethod CNIsun_misc_CVM_copyBooleanArray;
+extern CNINativeMethod CNIsun_misc_CVM_copyByteArray;
+extern CNINativeMethod CNIsun_misc_CVM_copyCharArray;
+extern CNINativeMethod CNIsun_misc_CVM_copyShortArray;
+extern CNINativeMethod CNIsun_misc_CVM_copyIntArray;
+extern CNINativeMethod CNIsun_misc_CVM_copyFloatArray;
+extern CNINativeMethod CNIsun_misc_CVM_copyLongArray;
+extern CNINativeMethod CNIsun_misc_CVM_copyDoubleArray;
+extern CNINativeMethod CNIsun_misc_CVM_copyObjectArray;
+extern CNINativeMethod CNIsun_misc_CVM_executeClinit;
+extern CNINativeMethod CNIsun_misc_CVM_freeClinit;
+extern CNINativeMethod CNIsun_misc_CVM_executeLoadSuperClasses;
+extern CNINativeMethod CNIsun_misc_CVM_disableRemoteExceptions;
+extern CNINativeMethod CNIsun_misc_CVM_enableRemoteExceptions;
+extern CNINativeMethod CNIsun_misc_CVM_throwRemoteException;
+extern CNINativeMethod CNIsun_misc_CVM_maskInterrupts;
+extern CNINativeMethod CNIsun_misc_CVM_unmaskInterrupts;
+extern CNINativeMethod CNIsun_misc_CVM_throwLocalException;
+extern CNINativeMethod CNIsun_misc_CVM_setContextArtificial;
+extern CNINativeMethod CNIsun_misc_CVM_callerCLIsMIDCLs;
+extern CNINativeMethod CNIsun_misc_CVM_isMIDPContext;
+extern CNINativeMethod CNIsun_misc_CVM_inMainLVM;
+extern CNINativeMethod CNIsun_misc_CVM_gcDumpHeapSimple;
+extern CNINativeMethod CNIsun_misc_CVM_gcDumpHeapVerbose;
+extern CNINativeMethod CNIsun_misc_CVM_gcDumpHeapStats;
+extern CNINativeMethod CNIsun_misc_CVM_trace;
+extern CNINativeMethod CNIsun_misc_CVM_setDebugEvents;
+extern CNINativeMethod CNIsun_misc_CVM_postThreadExit;
+extern CNINativeMethod CNIsun_misc_CVM_objectInflatePermanently;
+extern CNINativeMethod CNIsun_misc_CVM_setThreadNoCompilationsFlag;
+extern CNINativeMethod CNIsun_misc_CVM_getCallerClass;
+extern CNINativeMethod CNIsun_misc_CVM_isCompilerSupported;
+extern CNINativeMethod CNIsun_misc_CVM_dumpCompilerProfileData;
+extern CNINativeMethod CNIsun_misc_CVM_dumpStats;
+extern CNINativeMethod CNIsun_misc_CVM_markCodeBuffer;
+extern CNINativeMethod CNIsun_misc_CVM_initializeJITPolicy;
+extern CNINativeMethod CNIsun_misc_CVM_initializeAOTCode;
+extern CNINativeMethod CNIsun_misc_CVM_parseVerifyOptions;
+extern CNINativeMethod CNIsun_misc_CVM_parseXoptOptions;
+extern CNINativeMethod CNIsun_misc_CVM_parseXgcOptions;
+extern CNINativeMethod CNIsun_misc_CVM_parseXssOption;
+extern CNINativeMethod CNIsun_misc_CVM_parseAssertionOptions;
+extern CNINativeMethod CNIsun_misc_CVM_agentlibSupported;
+extern CNINativeMethod CNIsun_misc_CVM_agentlibInitialize;
+extern CNINativeMethod CNIsun_misc_CVM_agentlibProcess;
+extern CNINativeMethod CNIsun_misc_CVM_xrunSupported;
+extern CNINativeMethod CNIsun_misc_CVM_xrunInitialize;
+extern CNINativeMethod CNIsun_misc_CVM_xrunProcess;
+extern CNINativeMethod CNIsun_misc_CVM_xdebugSet;
+extern CNINativeMethod CNIsun_misc_CVM_simpleLockGrab;
+extern CNINativeMethod CNIsun_misc_CVM_simpleLockRelease;
+extern CNINativeMethod CNIsun_misc_CVM_getBuildOptionString;
+extern CNINativeMethod CNIsun_misc_CVM_nanoTime;
+extern CNINativeMethod CNIsun_misc_CVM_setURLConnectionDefaultUseCaches;
+extern CNINativeMethod CNIsun_misc_CVM_clearURLClassLoaderUcpField;
+void CVMconsolePrintf(const char* format, ...);
+void
+CVMdumpException(CVMExecEnv* ee);
+extern CVMInt32
+CVMcheckDebugFlags(CVMInt32 flags);
+extern CVMInt32
+CVMsetDebugFlags(CVMInt32 flags);
+extern CVMInt32
+CVMclearDebugFlags(CVMInt32 flags);
+extern CVMInt32
+CVMrestoreDebugFlags(CVMInt32 flags, CVMInt32 oldvalue);
+extern void CVMlong2String(CVMInt64, char*, char*);
+void
+CVMdumpThread(JNIEnv* env);
+void
+CVMprintThreadName(JNIEnv* env, CVMObjectICell* threadICell);
+extern char*
+CVMclassname2String(CVMClassTypeID classTypeID, char *dst, int size);
+extern CVMSize
+CVMutfLength(const char *);
+extern int
+CVMutfCountedCopyIntoCharArray(
+    const char * utf8Bytes, CVMJavaChar* unicodeChars, CVMSize unicodeLength );
+extern void
+CVMutfCopyIntoCharArray(const char* utf8Bytes, CVMJavaChar* unicodeChars);
+extern char*
+CVMutfCopyFromCharArray(const CVMJavaChar* unicodeChars,
+   char* utf8Bytes, CVMInt32 count);
+extern CVMJavaChar
+CVMutfNextUnicodeChar(const char** utf8String_p);
+size_t
+CVMformatString(char *buf, size_t bufSize, const char *format, ...);
+size_t
+CVMformatStringVaList(char *buf, size_t bufSize,
+    const char *format, va_list ap);
+extern void
+CVMnewStringUTF(CVMExecEnv* ee, CVMStringICell* resultICell,
+  const char* utf8Bytes);
+extern void
+CVMnewString(CVMExecEnv* ee, CVMStringICell* resultICell,
+      const CVMJavaChar* unicodeChars, CVMUint32 len);
+CVMBool CVMisSameClassPackage(CVMExecEnv* ee,
+         CVMClassBlock* class1, CVMClassBlock* class2);
+extern CVMClassBlock*
+CVMgcSafeClassRef2ClassBlock(CVMExecEnv* ee, CVMClassICell *clazz);
+extern CVMClassBlock *
+CVMgcUnsafeClassRef2ClassBlock(CVMExecEnv *ee, CVMClassICell *clazz);
+extern void
+CVMrandomInit();
+extern CVMInt32
+CVMrandomNext();
+CVMBool
+CVMgcSafeJavaWrap(CVMExecEnv* ee, jvalue v,
+    CVMBasicType fromType,
+    CVMObjectICell* result);
+CVMBool
+CVMgcSafeJavaUnwrap(CVMExecEnv* ee, CVMObjectICell* obj,
+      jvalue* v, CVMBasicType* toType,
+      CVMClassBlock* exceptionCb);
+CVMBool
+CVMgcUnsafeJavaUnwrap(CVMExecEnv* ee, CVMObject* obj,
+        jvalue* v, CVMBasicType* toType,
+        CVMClassBlock* exceptionCb);
+CVMBool
+CVMputProp(JNIEnv* env, jmethodID putID,
+    jobject props, const char* key, const char* val);
+CVMBool
+CVMputPropForPlatformCString(JNIEnv* env, jmethodID putID,
+        jobject props, const char* key, const char* val);
+CVMUint32 CVMpackSizeBy(CVMUint32 sizeToPack, CVMUint32 packingIncrement);
+extern CVMInt32
+CVMoptionToInt32(const char* optionString);
+typedef struct {
+    CVMUint32 numOptions;
+    char** options;
+} CVMParsedSubOptions;
+extern CVMBool
+CVMinitParsedSubOptions(CVMParsedSubOptions* subOptions,
+   const char* subOptionsString);
+extern void
+CVMdestroyParsedSubOptions(CVMParsedSubOptions *opts);
+extern const char *
+CVMgetParsedSubOption(const CVMParsedSubOptions* subOptions,
+        const char* subOptionName);
+typedef enum {
+    CVM_NULL_OPTION = 0,
+    CVM_INTEGER_OPTION,
+    CVM_BOOLEAN_OPTION,
+    CVM_PERCENT_OPTION,
+    CVM_STRING_OPTION,
+    CVM_MULTI_STRING_OPTION,
+    CVM_ENUM_OPTION
+} CVMSubOptionKindEnum;
+typedef struct {
+    const char *name;
+    CVMUint32 value;
+} CVMSubOptionEnumData;
+typedef struct {
+    const char* name;
+    const char* description;
+    CVMSubOptionKindEnum kind;
+    union {
+ struct {
+     int minValue;
+     CVMAddr maxValue;
+     CVMAddr defaultValue;
+ } intData;
+ struct {
+     int ignored1;
+     const char* helpSyntax;
+     const char* defaultValue;
+ } strData;
+ struct {
+     int numPossibleValues;
+     const char** possibleValues;
+     CVMAddr defaultValue;
+ } multiStrData;
+        struct {
+            int numPossibleValues;
+            const CVMSubOptionEnumData* possibleValues;
+            CVMAddr defaultValue;
+        } enumData;
+    } data;
+    const void* valuePtr;
+} CVMSubOptionData;
+extern CVMBool
+CVMprocessSubOptions(const CVMSubOptionData* knownSubOptions,
+       const char* optionName,
+       CVMParsedSubOptions *parsedSubOptions);
+extern void
+CVMprintSubOptionValues(const CVMSubOptionData* knownSubOptions);
+extern void
+CVMprintSubOptionsUsageString(const CVMSubOptionData* knownSubOptions);
+extern CVMBool
+CVMinitPathValues(void *propsPtr, CVMpathInfo *pathInfo,
+                  char **userBootclasspath);
+extern void CVMdestroyPathInfo(CVMpathInfo *);
+extern void
+CVMdestroyPathValues(void *propsPtr);
+extern char*
+CVMconvertJavaStringToCString(CVMExecEnv* ee, jobject stringobj);
+typedef struct CVMGCCommonGlobalState CVMGCCommonGlobalState;
+struct CVMGCCommonGlobalState {
+    CVMParsedSubOptions gcOptions;
+    CVMUint32 maxStackMapsMemorySize;
+    CVMBool doClassCleanup;
+    CVMBool stringInternedSinceLastGC;
+    CVMBool classCreatedSinceLastGC;
+    CVMBool loaderCreatedSinceLastGC;
+    CVMStackMaps *firstStackMaps;
+    CVMStackMaps *lastStackMaps;
+    CVMUint32 stackMapsTotalMemoryUsed;
+};
+struct CVMGCOptions {
+    CVMBool isUpdatingObjectPointers;
+    CVMBool discoverWeakReferences;
+    CVMBool isProfilingPass;
+};
+enum CVMGCRefType {
+    CVMGCRefType_INVALID = 0,
+    CVMGCRefType_GLOBAL_ROOT,
+    CVMGCRefType_PRELOADER_STATICS,
+    CVMGCRefType_CLASS_STATICS,
+    CVMGCRefType_LOCAL_ROOTS,
+    CVMGCRefType_UNKNOWN_STACK_FRAME,
+    CVMGCRefType_JAVA_FRAME,
+    CVMGCRefType_JNI_FRAME,
+    CVMGCRefType_TRANSITION_FRAME,
+    CVMGCRefType_OBJECT_FIELD
+};
+typedef enum CVMGCRefType CVMGCRefType;
+typedef struct CVMGCProfilingInfo CVMGCProfilingInfo;
+struct CVMGCProfilingInfo {
+    CVMGCRefType type;
+    void *data;
+    union {
+        struct {
+            CVMClassBlock *cb;
+        } clazz;
+        struct {
+            CVMExecEnv *ee;
+            CVMInt32 frameNumber;
+        } frame;
+    } u;
+};
+typedef struct CVMGCLocker CVMGCLocker;
+struct CVMGCLocker
+{
+    volatile CVMUint32 lockCount;
+    volatile CVMBool wasContended;
+};
+void CVMgcLockerInit(CVMGCLocker *self);
+void CVMgcLockerLock(CVMGCLocker *self, CVMExecEnv *current_ee);
+void CVMgcLockerUnlock(CVMGCLocker *self, CVMExecEnv *current_ee);
+extern CVMBool
+CVMgcInitHeap(CVMOptions *options);
+extern char *
+CVMgcGetGCAttributeVal(char* attrName);
+extern CVMObject*
+CVMgcAllocNewInstance(CVMExecEnv* ee, CVMClassBlock* cb);
+extern CVMObject*
+CVMgcAllocNewClassInstance(CVMExecEnv* ee, CVMClassBlock* cbOfJavaLangClass);
+extern CVMArrayOfAnyType*
+CVMgcAllocNewArray(CVMExecEnv* ee, CVMBasicType typeCode,
+     CVMClassBlock* arrayCb, CVMJavaInt len);
+extern CVMArrayOfAnyType*
+CVMgcAllocNewArrayWithInstanceSize(CVMExecEnv* ee, CVMJavaInt instanceSize,
+       CVMClassBlock* arrayCb, CVMJavaInt len);
+extern CVMJavaLong
+CVMgcFreeMemory(CVMExecEnv* ee);
+extern CVMJavaLong
+CVMgcTotalMemory(CVMExecEnv* ee);
+extern CVMBool
+CVMgcStopTheWorldAndGC(CVMExecEnv* ee, CVMUint32 numBytes);
+extern CVMBool
+CVMgcStopTheWorldAndDoAction(CVMExecEnv *ee, void *data,
+                 CVMUint32 (*preActionCallback)(CVMExecEnv *ee, void *data),
+                 CVMBool (*actionCallback)(CVMExecEnv *ee, void *data),
+                 void (*postActionCallback)(CVMExecEnv *ee, void *data,
+                                            CVMBool actionSuccess,
+                                            CVMUint32 preActionStatus),
+   void (*retryAfterActionCallback)(CVMExecEnv *ee, void *data),
+   void* retryData);
+extern void
+CVMgcStartGC(CVMExecEnv* ee);
+extern void
+CVMgcClearClassMarks(CVMExecEnv* ee, CVMGCOptions* gcOpts);
+extern void
+CVMgcEndGC(CVMExecEnv* ee);
+extern void
+CVMgcRunGC(CVMExecEnv* ee);
+extern void
+CVMnullFrameScanner(CVMFrame* frame, CVMStackChunk* chunk,
+      CVMRefCallbackFunc callback, void* data);
+extern void
+CVMgcProcessSpecialWithLivenessInfo(CVMExecEnv* ee, CVMGCOptions* gcOpts,
+        CVMRefLivenessQueryFunc isLive,
+        void* isLiveData,
+                                    CVMRefCallbackFunc transitiveScanner,
+        void* transitiveScannerData);
+void
+CVMgcProcessWeakrefWithLivenessInfo(CVMExecEnv* ee,
+    CVMGCOptions* gcOpts, CVMRefLivenessQueryFunc isLive, void* isLiveData,
+    CVMRefCallbackFunc transitiveScanner, void* transitiveScannerData);
+void
+CVMgcProcessInternedStringsWithLivenessInfo(CVMExecEnv* ee,
+    CVMGCOptions* gcOpts, CVMRefLivenessQueryFunc isLive, void* isLiveData,
+    CVMRefCallbackFunc transitiveScanner, void* transitiveScannerData);
+extern void
+CVMgcProcessSpecialWithLivenessInfoWithoutWeakRefs(
+                                    CVMExecEnv* ee, CVMGCOptions* gcOpts,
+        CVMRefLivenessQueryFunc isLive,
+        void* isLiveData,
+                                    CVMRefCallbackFunc transitiveScanner,
+        void* transitiveScannerData);
+extern void
+CVMgcScanSpecial(CVMExecEnv* ee, CVMGCOptions* gcOpts,
+   CVMRefCallbackFunc callback, void* data);
+extern void
+CVMgcScanRoots(CVMExecEnv* ee, CVMGCOptions* gcOpts,
+        CVMRefCallbackFunc callback, void* data);
+extern CVMBool
+CVMgcEnsureStackmapsForRootScans(CVMExecEnv *ee);
+extern CVMBool
+CVMgcDestroyHeap();
+extern CVMBool
+CVMgcScanObjectRange(CVMExecEnv* ee, CVMUint32* base, CVMUint32* top,
+                     CVMObjectCallbackFunc callback, void* callbackData);
+struct CVMStackWalkContext {
+    CVMFrame* frame;
+    CVMStackChunk* chunk;
+};
+extern void
+CVMstackwalkInit(CVMStack* stack, CVMStackWalkContext* c);
+extern void
+CVMstackwalkDestroy(CVMStackWalkContext* c);
+extern void
+CVMstackwalkPrev(CVMStackWalkContext* c);
+typedef union CVMSlotVal32 {
+    CVMJavaVal32 j;
+    CVMUint8* a;
+} CVMSlotVal32;
+union CVMStackVal32 {
+    CVMJavaVal32 j;
+    CVMSlotVal32 s;
+    CVMObjectICell ref;
+    CVMStackVal32* next;
+};
+struct CVMStackChunk {
+    CVMStackChunk* prev;
+    CVMStackChunk* next;
+    CVMStackVal32* end_data;
+    CVMStackVal32 data[1];
+};
+struct CVMStack {
+    CVMStackChunk* firstStackChunk;
+    CVMStackChunk* currentStackChunk;
+    CVMUint32 minStackChunkSize;
+    CVMUint32 maxStackSize;
+    CVMUint32 stackSize;
+    CVMFrame* volatile currentFrame;
+    CVMStackVal32* stackChunkStart;
+    CVMStackVal32* stackChunkEnd;
+};
+typedef enum {
+    CVM_FRAMETYPE_NONE,
+    CVM_FRAMETYPE_JAVA,
+    CVM_FRAMETYPE_TRANSITION,
+    CVM_FRAMETYPE_FREELIST,
+    CVM_FRAMETYPE_LOCALROOT,
+    CVM_FRAMETYPE_GLOBALROOT,
+    CVM_FRAMETYPE_CLASSTABLE,
+    CVM_NUM_FRAMETYPES
+} CVMFrameType;
+typedef enum {
+    CVM_FRAMEFLAG_ARTIFICIAL = 0x1,
+    CVM_FRAMEFLAG_EXCEPTION = 0x2
+} CVMFrameFlags;
+extern CVMFrameGCScannerFunc * const CVMframeScanners[CVM_NUM_FRAMETYPES];
+struct CVMFrame {
+    CVMFrame* prevX;
+    CVMUint8 type;
+    CVMUint8 flags;
+    CVMStackVal32* volatile topOfStack;
+    CVMMethodBlock* volatile mb;
+};
+struct CVMFreelistFrame {
+    CVMFrame frame;
+    CVMUint32 inUse;
+    CVMStackVal32* freeList;
+    CVMStackVal32 vals[1];
+};
+extern
+CVMStackVal32* CVMexpandStack(CVMExecEnv* ee, CVMStack* s,
+         CVMUint32 capacity,
+         CVMBool throwException,
+         CVMBool justChecking);
+extern CVMBool
+CVMensureCapacity(CVMExecEnv* ee, CVMStack* stack, int capacity);
+extern CVMBool
+CVMstackDeleteLastChunk(CVMStack *stack, CVMStackChunk *chunk);
+extern void
+CVMstackEnableReserved(CVMStack *curStack);
+extern void
+CVMstackDisableReserved(CVMStack *curStack);
+extern CVMBool
+CVMinitStack(CVMExecEnv *ee, CVMStack* s,
+      CVMUint32 initialStackSize, CVMUint32 maxStackSize,
+      CVMUint32 minStackChunkSize, CVMUint32 initialFrameCapacity,
+      CVMFrameType frameType);
+extern void
+CVMdestroyStack(CVMStack* stack);
+extern CVMBool
+CVMinitGCRootStack(CVMExecEnv *ee, CVMStack* s, CVMUint32 initialStackSize,
+     CVMUint32 maxStackSize, CVMUint32 minStackChunkSize,
+     CVMFrameType frameType);
+extern void
+CVMdestroyGCRootStack(CVMStack* stack);
+extern void
+CVMdumpStack(CVMStack* s, CVMBool verbose, CVMBool includeData,
+      CVMInt32 frameLimit);
+extern CVMStackChunk*
+CVMdumpFrame(CVMFrame* frame, CVMStackChunk* startChunk,
+      CVMBool verbose, CVMBool includeData);
+extern CVMBool
+CVMCstackCheckSize(CVMExecEnv *ee, CVMUint32 redzone, char *func_name, CVMBool exceptionThrow);
+typedef void (*CVMFrameCallbackFunc)(CVMFrame *thisFrame);
+extern void
+CVMscanStack(CVMStack* stack, CVMFrameCallbackFunc frameCallback);
+extern void
+CVMscanStackForGC(CVMStack* stack);
+typedef CVMFreelistFrame CVMJNIFrame;
+extern CVMObjectICell *
+CVMjniCreateLocalRef(CVMExecEnv *);
+extern CVMObjectICell *
+CVMjniCreateLocalRef0(CVMExecEnv *, CVMExecEnv *targetEE);
+typedef struct {
+    JNIEnv vector;
+} CVMJNIEnv;
+extern void CVMinitJNIEnv(CVMJNIEnv *);
+extern void CVMdestroyJNIEnv(CVMJNIEnv *);
+struct JNIInvokeInterface;
+typedef struct {
+    const struct JNIInvokeInterface * vector;
+    volatile CVMBool directBufferSupportInitialized;
+    volatile CVMBool directBufferSupportInitializeFailed;
+    jclass bufferClass;
+    jclass directBufferClass;
+    jclass directByteBufferClass;
+    jmethodID directByteBufferLongConstructor;
+    jmethodID directByteBufferIntConstructor;
+    jfieldID directBufferAddressLongField;
+    jfieldID directBufferAddressIntField;
+    jfieldID bufferCapacityField;
+} CVMJNIJavaVM;
+extern void
+CVMinitJNIJavaVM(CVMJNIJavaVM *);
+extern void
+CVMdestroyJNIJavaVM(CVMJNIJavaVM *);
+extern struct JNINativeInterface *
+CVMjniGetInstrumentableJNINativeInterface();
+extern jint CVMjniGetVersion(JNIEnv *env);
+extern jclass CVMjniFindClass(JNIEnv *env, const char *name);
+extern jmethodID CVMjniFromReflectedMethod(JNIEnv* env,
+         jobject method);
+extern jfieldID CVMjniFromReflectedField(JNIEnv* env, jobject field);
+extern jobject CVMjniToReflectedMethod(JNIEnv *env, jclass clazz,
+            jmethodID methodID,
+            jboolean isStatic);
+extern jboolean CVMjniIsAssignableFrom(JNIEnv* env,
+            jclass clazz1, jclass clazz2);
+extern jobject CVMjniToReflectedField(JNIEnv *env, jclass clazz,
+           jfieldID fieldID,
+           jboolean isStatic);
+extern jint CVMjniThrow(JNIEnv *env, jthrowable obj);
+extern jint CVMjniThrowNew(JNIEnv *env,
+       jclass clazz, const char *message);
+extern jthrowable CVMjniExceptionOccurred(JNIEnv *env);
+extern void CVMjniExceptionDescribe(JNIEnv *env);
+extern void CVMjniExceptionClear(JNIEnv *env);
+extern void CVMjniFatalError(JNIEnv *env, const char *msg);
+extern jint CVMjniPushLocalFrame(JNIEnv *env, jint capacity);
+extern jobject CVMjniPopLocalFrame(JNIEnv *env, jobject resultArg);
+extern jobject CVMjniNewGlobalRef(JNIEnv *env, jobject ref);
+extern void CVMjniDeleteGlobalRef(JNIEnv *env, jobject ref);
+extern void CVMjniDeleteLocalRef(JNIEnv *env, jobject obj);
+extern jboolean CVMjniIsSameObject(JNIEnv *env,
+        jobject ref1, jobject ref2);
+extern jobject CVMjniNewLocalRef(JNIEnv *env, jobject obj);
+extern jint CVMjniEnsureLocalCapacity(JNIEnv *env, jint capacity);
+extern jobject CVMjniAllocObject(JNIEnv *env, jclass clazz);
+extern jobject CVMjniNewObject(JNIEnv *env, jclass clazz,
+           jmethodID methodID, ...);
+extern jobject CVMjniNewObjectV(JNIEnv *env, jclass clazz,
+     jmethodID methodID, va_list args);
+extern jobject CVMjniNewObjectA(JNIEnv *env, jclass clazz,
+     jmethodID methodID, const jvalue *args);
+extern jclass CVMjniGetObjectClass(JNIEnv *env, jobject obj);
+extern jboolean CVMjniIsInstanceOf(JNIEnv* env, jobject obj,
+        jclass clazz);
+extern jmethodID CVMjniGetMethodID(JNIEnv *env, jclass clazz,
+        const char *name, const char *sig);
+extern jobject CVMjniCallObjectMethod(JNIEnv *env, jobject obj,
+           jmethodID methodID, ...);
+extern jobject CVMjniCallObjectMethodV(JNIEnv *env, jobject obj,
+            jmethodID methodID,
+            va_list args);
+extern jobject CVMjniCallObjectMethodA(JNIEnv *env, jobject obj,
+            jmethodID methodID,
+            const jvalue *args);
+extern jboolean CVMjniCallBooleanMethod(JNIEnv *env, jobject obj,
+      jmethodID methodID, ...);
+extern jboolean CVMjniCallBooleanMethodV(JNIEnv *env, jobject obj,
+       jmethodID methodID,
+       va_list args);
+extern jboolean CVMjniCallBooleanMethodA(JNIEnv *env, jobject obj,
+       jmethodID methodID,
+       const jvalue *args);
+extern jbyte CVMjniCallByteMethod(JNIEnv *env, jobject obj,
+       jmethodID methodID, ...);
+extern jbyte CVMjniCallByteMethodV(JNIEnv *env, jobject obj,
+        jmethodID methodID,
+        va_list args);
+extern jbyte CVMjniCallByteMethodA(JNIEnv *env, jobject obj,
+        jmethodID methodID,
+        const jvalue *args);
+extern jchar CVMjniCallCharMethod(JNIEnv *env, jobject obj,
+       jmethodID methodID, ...);
+extern jchar CVMjniCallCharMethodV(JNIEnv *env, jobject obj,
+        jmethodID methodID,
+        va_list args);
+extern jchar CVMjniCallCharMethodA(JNIEnv *env, jobject obj,
+        jmethodID methodID,
+        const jvalue *args);
+extern jshort CVMjniCallShortMethod(JNIEnv *env, jobject obj,
+         jmethodID methodID, ...);
+extern jshort CVMjniCallShortMethodV(JNIEnv *env, jobject obj,
+          jmethodID methodID,
+          va_list args);
+extern jshort CVMjniCallShortMethodA(JNIEnv *env, jobject obj,
+          jmethodID methodID,
+          const jvalue *args);
+extern jint CVMjniCallIntMethod(JNIEnv *env, jobject obj,
+     jmethodID methodID, ...);
+extern jint CVMjniCallIntMethodV(JNIEnv *env, jobject obj,
+      jmethodID methodID,
+      va_list args);
+extern jint CVMjniCallIntMethodA(JNIEnv *env, jobject obj,
+      jmethodID methodID,
+      const jvalue *args);
+extern jlong CVMjniCallLongMethod(JNIEnv *env, jobject obj,
+       jmethodID methodID, ...);
+extern jlong CVMjniCallLongMethodV(JNIEnv *env, jobject obj,
+        jmethodID methodID,
+        va_list args);
+extern jlong CVMjniCallLongMethodA(JNIEnv *env, jobject obj,
+        jmethodID methodID,
+        const jvalue *args);
+extern jfloat CVMjniCallFloatMethod(JNIEnv *env, jobject obj,
+         jmethodID methodID, ...);
+extern jfloat CVMjniCallFloatMethodV(JNIEnv *env, jobject obj,
+          jmethodID methodID,
+          va_list args);
+extern jfloat CVMjniCallFloatMethodA(JNIEnv *env, jobject obj,
+          jmethodID methodID,
+          const jvalue *args);
+extern jdouble CVMjniCallDoubleMethod(JNIEnv *env, jobject obj,
+           jmethodID methodID, ...);
+extern jdouble CVMjniCallDoubleMethodV(JNIEnv *env, jobject obj,
+            jmethodID methodID,
+            va_list args);
+extern jdouble CVMjniCallDoubleMethodA(JNIEnv *env, jobject obj,
+            jmethodID methodID,
+            const jvalue *args);
+extern void CVMjniCallVoidMethod(JNIEnv *env, jobject obj,
+      jmethodID methodID, ...);
+extern void CVMjniCallVoidMethodV(JNIEnv *env, jobject obj,
+       jmethodID methodID,
+       va_list args);
+extern void CVMjniCallVoidMethodA(JNIEnv *env, jobject obj,
+       jmethodID methodID,
+       const jvalue *args);
+extern jobject CVMjniCallNonvirtualObjectMethod(JNIEnv *env,
+       jobject obj,
+       jclass clazz,
+       jmethodID methodID,
+       ...);
+extern jobject CVMjniCallNonvirtualObjectMethodV(JNIEnv *env,
+        jobject obj,
+        jclass clazz,
+        jmethodID methodID,
+        va_list args);
+extern jobject CVMjniCallNonvirtualObjectMethodA(JNIEnv *env,
+        jobject obj,
+        jclass clazz,
+        jmethodID methodID,
+        const jvalue *args);
+extern jboolean CVMjniCallNonvirtualBooleanMethod(JNIEnv *env,
+         jobject obj,
+         jclass clazz,
+         jmethodID methodID,
+         ...);
+extern jboolean CVMjniCallNonvirtualBooleanMethodV(JNIEnv *env,
+          jobject obj,
+          jclass clazz,
+          jmethodID methodID,
+          va_list args);
+extern jboolean CVMjniCallNonvirtualBooleanMethodA(JNIEnv *env,
+          jobject obj,
+          jclass clazz,
+          jmethodID methodID,
+          const jvalue *args);
+extern jbyte CVMjniCallNonvirtualByteMethod(JNIEnv *env,
+          jobject obj,
+          jclass clazz,
+          jmethodID methodID,
+          ...);
+extern jbyte CVMjniCallNonvirtualByteMethodV(JNIEnv *env,
+           jobject obj,
+           jclass clazz,
+           jmethodID methodID,
+           va_list args);
+extern jbyte CVMjniCallNonvirtualByteMethodA(JNIEnv *env,
+           jobject obj,
+           jclass clazz,
+           jmethodID methodID,
+           const jvalue *args);
+extern jchar CVMjniCallNonvirtualCharMethod(JNIEnv *env,
+          jobject obj,
+          jclass clazz,
+          jmethodID methodID,
+          ...);
+extern jchar CVMjniCallNonvirtualCharMethodV(JNIEnv *env,
+           jobject obj,
+           jclass clazz,
+           jmethodID methodID,
+           va_list args);
+extern jchar CVMjniCallNonvirtualCharMethodA(JNIEnv *env,
+           jobject obj,
+           jclass clazz,
+           jmethodID methodID,
+           const jvalue *args);
+extern jshort CVMjniCallNonvirtualShortMethod(JNIEnv *env,
+            jobject obj,
+            jclass clazz,
+            jmethodID methodID,
+            ...);
+extern jshort CVMjniCallNonvirtualShortMethodV(JNIEnv *env,
+             jobject obj,
+             jclass clazz,
+             jmethodID methodID,
+             va_list args);
+extern jshort CVMjniCallNonvirtualShortMethodA(JNIEnv *env,
+             jobject obj,
+             jclass clazz,
+             jmethodID methodID,
+             const jvalue *args);
+extern jint CVMjniCallNonvirtualIntMethod(JNIEnv *env,
+        jobject obj,
+        jclass clazz,
+        jmethodID methodID,
+        ...);
+extern jint CVMjniCallNonvirtualIntMethodV(JNIEnv *env,
+         jobject obj,
+         jclass clazz,
+         jmethodID methodID,
+         va_list args);
+extern jint CVMjniCallNonvirtualIntMethodA(JNIEnv *env,
+         jobject obj,
+         jclass clazz,
+         jmethodID methodID,
+         const jvalue *args);
+extern jlong CVMjniCallNonvirtualLongMethod(JNIEnv *env,
+          jobject obj,
+          jclass clazz,
+          jmethodID methodID,
+          ...);
+extern jlong CVMjniCallNonvirtualLongMethodV(JNIEnv *env,
+           jobject obj,
+           jclass clazz,
+           jmethodID methodID,
+           va_list args);
+extern jlong CVMjniCallNonvirtualLongMethodA(JNIEnv *env,
+           jobject obj,
+           jclass clazz,
+           jmethodID methodID,
+           const jvalue *args);
+extern jfloat CVMjniCallNonvirtualFloatMethod(JNIEnv *env,
+            jobject obj,
+            jclass clazz,
+            jmethodID methodID,
+            ...);
+extern jfloat CVMjniCallNonvirtualFloatMethodV(JNIEnv *env,
+             jobject obj,
+             jclass clazz,
+             jmethodID methodID,
+             va_list args);
+extern jfloat CVMjniCallNonvirtualFloatMethodA(JNIEnv *env,
+             jobject obj,
+             jclass clazz,
+             jmethodID methodID,
+             const jvalue *args);
+extern jdouble CVMjniCallNonvirtualDoubleMethod(JNIEnv *env,
+       jobject obj,
+       jclass clazz,
+       jmethodID methodID,
+       ...);
+extern jdouble CVMjniCallNonvirtualDoubleMethodV(JNIEnv *env,
+        jobject obj,
+        jclass clazz,
+        jmethodID methodID,
+        va_list args);
+extern jdouble CVMjniCallNonvirtualDoubleMethodA(JNIEnv *env,
+        jobject obj,
+        jclass clazz,
+        jmethodID methodID,
+        const jvalue *args);
+extern void CVMjniCallNonvirtualVoidMethod(JNIEnv *env,
+         jobject obj,
+         jclass clazz,
+         jmethodID methodID,
+         ...);
+extern void CVMjniCallNonvirtualVoidMethodV(JNIEnv *env,
+          jobject obj,
+          jclass clazz,
+          jmethodID methodID,
+          va_list args);
+extern void CVMjniCallNonvirtualVoidMethodA(JNIEnv *env,
+          jobject obj,
+          jclass clazz,
+          jmethodID methodID,
+          const jvalue *args);
+extern jfieldID CVMjniGetFieldID(JNIEnv *env, jclass clazz,
+      const char *name, const char *sig);
+extern jobject CVMjniGetObjectField(JNIEnv* env, jobject obj,
+         jfieldID fid);
+extern jboolean CVMjniGetBooleanField(JNIEnv* env, jobject obj,
+           jfieldID fid);
+extern jbyte CVMjniGetByteField(JNIEnv* env, jobject obj,
+     jfieldID fid);
+extern jchar CVMjniGetCharField(JNIEnv* env, jobject obj,
+     jfieldID fid);
+extern jshort CVMjniGetShortField(JNIEnv* env, jobject obj,
+       jfieldID fid);
+extern jint CVMjniGetIntField(JNIEnv* env, jobject obj,
+          jfieldID fid);
+extern jlong CVMjniGetLongField(JNIEnv* env, jobject obj,
+     jfieldID fid);
+extern jfloat CVMjniGetFloatField(JNIEnv* env, jobject obj,
+       jfieldID fid);
+extern jdouble CVMjniGetDoubleField(JNIEnv* env, jobject obj,
+         jfieldID fid);
+extern void CVMjniSetObjectField(JNIEnv* env, jobject obj,
+      jfieldID fid, jobject rhs);
+extern void CVMjniSetBooleanField(JNIEnv* env, jobject obj,
+       jfieldID fid, jboolean rhs);
+extern void CVMjniSetByteField(JNIEnv* env, jobject obj,
+           jfieldID fid, jbyte rhs);
+extern void CVMjniSetCharField(JNIEnv* env, jobject obj,
+           jfieldID fid, jchar rhs);
+extern void CVMjniSetShortField(JNIEnv* env, jobject obj,
+     jfieldID fid, jshort rhs);
+extern void CVMjniSetIntField(JNIEnv* env, jobject obj,
+          jfieldID fid, jint rhs);
+extern void CVMjniSetLongField(JNIEnv* env, jobject obj,
+           jfieldID fid, jlong rhs);
+extern void CVMjniSetFloatField(JNIEnv* env, jobject obj,
+     jfieldID fid, jfloat rhs);
+extern void CVMjniSetDoubleField(JNIEnv* env, jobject obj,
+      jfieldID fid, jdouble rhs);
+extern jmethodID CVMjniGetStaticMethodID(JNIEnv *env, jclass clazz,
+       const char *name,
+       const char *sig);
+extern jobject CVMjniCallStaticObjectMethod(JNIEnv *env, jclass clazz,
+          jmethodID methodID, ...);
+extern jobject CVMjniCallStaticObjectMethodV(JNIEnv *env, jclass clazz,
+           jmethodID methodID,
+           va_list args);
+extern jobject CVMjniCallStaticObjectMethodA(JNIEnv *env, jclass clazz,
+           jmethodID methodID,
+           const jvalue *args);
+extern jboolean CVMjniCallStaticBooleanMethod(JNIEnv *env,
+            jclass clazz,
+            jmethodID methodID,
+            ...);
+extern jboolean CVMjniCallStaticBooleanMethodV(JNIEnv *env,
+             jclass clazz,
+             jmethodID methodID,
+             va_list args);
+extern jboolean CVMjniCallStaticBooleanMethodA(JNIEnv *env,
+             jclass clazz,
+             jmethodID methodID,
+             const jvalue *args);
+extern jbyte CVMjniCallStaticByteMethod(JNIEnv *env, jclass clazz,
+      jmethodID methodID, ...);
+extern jbyte CVMjniCallStaticByteMethodV(JNIEnv *env, jclass clazz,
+       jmethodID methodID,
+       va_list args);
+extern jbyte CVMjniCallStaticByteMethodA(JNIEnv *env, jclass clazz,
+       jmethodID methodID,
+       const jvalue *args);
+extern jchar CVMjniCallStaticCharMethod(JNIEnv *env, jclass clazz,
+      jmethodID methodID, ...);
+extern jchar CVMjniCallStaticCharMethodV(JNIEnv *env, jclass clazz,
+       jmethodID methodID,
+       va_list args);
+extern jchar CVMjniCallStaticCharMethodA(JNIEnv *env, jclass clazz,
+       jmethodID methodID,
+       const jvalue *args);
+extern jshort CVMjniCallStaticShortMethod(JNIEnv *env, jclass clazz,
+        jmethodID methodID, ...);
+extern jshort CVMjniCallStaticShortMethodV(JNIEnv *env, jclass clazz,
+         jmethodID methodID,
+         va_list args);
+extern jshort CVMjniCallStaticShortMethodA(JNIEnv *env, jclass clazz,
+         jmethodID methodID,
+         const jvalue *args);
+extern jint CVMjniCallStaticIntMethod(JNIEnv *env, jclass clazz,
+           jmethodID methodID, ...);
+extern jint CVMjniCallStaticIntMethodV(JNIEnv *env, jclass clazz,
+            jmethodID methodID,
+            va_list args);
+extern jint CVMjniCallStaticIntMethodA(JNIEnv *env, jclass clazz,
+            jmethodID methodID,
+            const jvalue *args);
+extern jlong CVMjniCallStaticLongMethod(JNIEnv *env, jclass clazz,
+      jmethodID methodID, ...);
+extern jlong CVMjniCallStaticLongMethodV(JNIEnv *env, jclass clazz,
+       jmethodID methodID,
+       va_list args);
+extern jlong CVMjniCallStaticLongMethodA(JNIEnv *env, jclass clazz,
+       jmethodID methodID,
+       const jvalue *args);
+extern jfloat CVMjniCallStaticFloatMethod(JNIEnv *env, jclass clazz,
+        jmethodID methodID, ...);
+extern jfloat CVMjniCallStaticFloatMethodV(JNIEnv *env, jclass clazz,
+         jmethodID methodID,
+         va_list args);
+extern jfloat CVMjniCallStaticFloatMethodA(JNIEnv *env, jclass clazz,
+         jmethodID methodID,
+         const jvalue *args);
+extern jdouble CVMjniCallStaticDoubleMethod(JNIEnv *env, jclass clazz,
+          jmethodID methodID, ...);
+extern jdouble CVMjniCallStaticDoubleMethodV(JNIEnv *env, jclass clazz,
+           jmethodID methodID,
+           va_list args);
+extern jdouble CVMjniCallStaticDoubleMethodA(JNIEnv *env, jclass clazz,
+           jmethodID methodID,
+           const jvalue *args);
+extern void CVMjniCallStaticVoidMethod(JNIEnv *env, jclass clazz,
+            jmethodID methodID, ...);
+extern void CVMjniCallStaticVoidMethodV(JNIEnv *env, jclass clazz,
+      jmethodID methodID,
+      va_list args);
+extern void CVMjniCallStaticVoidMethodA(JNIEnv *env, jclass clazz,
+      jmethodID methodID,
+      const jvalue *args);
+extern jfieldID CVMjniGetStaticFieldID(JNIEnv *env,
+            jclass clazz,
+            const char *name,
+            const char *sig);
+extern jobject CVMjniGetStaticObjectField(JNIEnv* env,
+        jclass clazz, jfieldID fid);
+extern jboolean CVMjniGetStaticBooleanField(JNIEnv* env, jclass clazz,
+          jfieldID fid);
+extern jbyte CVMjniGetStaticByteField(JNIEnv* env, jclass clazz,
+           jfieldID fid);
+extern jchar CVMjniGetStaticCharField(JNIEnv* env, jclass clazz,
+           jfieldID fid);
+extern jshort CVMjniGetStaticShortField(JNIEnv* env, jclass clazz,
+      jfieldID fid);
+extern jint CVMjniGetStaticIntField(JNIEnv* env, jclass clazz,
+         jfieldID fid);
+extern jlong CVMjniGetStaticLongField(JNIEnv* env, jclass clazz,
+           jfieldID fid);
+extern jfloat CVMjniGetStaticFloatField(JNIEnv* env, jclass clazz,
+      jfieldID fid);
+extern jdouble CVMjniGetStaticDoubleField(JNIEnv* env, jclass clazz,
+        jfieldID fid);
+extern void CVMjniSetStaticObjectField(JNIEnv* env, jclass clazz,
+            jfieldID fid, jobject rhs);
+extern void CVMjniSetStaticBooleanField(JNIEnv* env, jclass clazz,
+      jfieldID fid, jboolean rhs);
+extern void CVMjniSetStaticByteField(JNIEnv* env, jclass clazz,
+          jfieldID fid, jbyte rhs);
+extern void CVMjniSetStaticCharField(JNIEnv* env, jclass clazz,
+          jfieldID fid, jchar rhs);
+extern void CVMjniSetStaticShortField(JNIEnv* env, jclass clazz,
+           jfieldID fid, jshort rhs);
+extern void CVMjniSetStaticIntField(JNIEnv* env, jclass clazz,
+         jfieldID fid, jint rhs);
+extern void CVMjniSetStaticLongField(JNIEnv* env, jclass clazz,
+          jfieldID fid, jlong rhs);
+extern void CVMjniSetStaticFloatField(JNIEnv* env, jclass clazz,
+           jfieldID fid, jfloat rhs);
+extern void CVMjniSetStaticDoubleField(JNIEnv* env, jclass clazz,
+            jfieldID fid, jdouble rhs);
+extern jstring CVMjniNewString(JNIEnv *env, const jchar* unicodeChars,
+           jsize len);
+extern jsize CVMjniGetStringLength(JNIEnv* env, jstring string);
+extern const jchar* CVMjniGetStringChars(JNIEnv *env, jstring string,
+       jboolean *isCopy);
+extern void CVMjniReleaseStringChars(JNIEnv *env, jstring str,
+          const jchar *chars);
+extern jstring CVMjniNewStringUTF(JNIEnv* env, const char* utf8Bytes);
+extern jsize CVMjniGetStringUTFLength(JNIEnv *env, jstring string);
+extern const char* CVMjniGetStringUTFChars(JNIEnv *env,
+         jstring string,
+         jboolean *isCopy);
+extern void CVMjniReleaseStringUTFChars(JNIEnv *env, jstring str,
+      const char *chars);
+extern jsize CVMjniGetArrayLength(JNIEnv* env, jarray arrArg);
+extern jarray CVMjniNewObjectArray(JNIEnv* env, jsize length,
+        jclass elementClass,
+        jobject initialElement);
+extern jobject CVMjniGetObjectArrayElement(JNIEnv* env,
+         jarray arrArg, jsize index);
+extern void CVMjniSetObjectArrayElement(JNIEnv* env, jarray arrArg,
+      jsize index, jobject value);
+extern jbooleanArray CVMjniNewBooleanArray(JNIEnv *env, jsize length);
+extern jbyteArray CVMjniNewByteArray(JNIEnv *env, jsize length);
+extern jcharArray CVMjniNewCharArray(JNIEnv *env, jsize length);
+extern jshortArray CVMjniNewShortArray(JNIEnv *env, jsize length);
+extern jintArray CVMjniNewIntArray(JNIEnv *env, jsize length);
+extern jlongArray CVMjniNewLongArray(JNIEnv *env, jsize length);
+extern jfloatArray CVMjniNewFloatArray(JNIEnv *env, jsize length);
+extern jdoubleArray CVMjniNewDoubleArray(JNIEnv *env, jsize length);
+extern jboolean * CVMjniGetBooleanArrayElements(JNIEnv *env,
+       jbooleanArray array,
+       jboolean *isCopy);
+extern jbyte * CVMjniGetByteArrayElements(JNIEnv *env,
+        jbyteArray array,
+        jboolean *isCopy);
+extern jchar * CVMjniGetCharArrayElements(JNIEnv *env,
+        jcharArray array,
+        jboolean *isCopy);
+extern jshort * CVMjniGetShortArrayElements(JNIEnv *env,
+          jshortArray array,
+          jboolean *isCopy);
+extern jint * CVMjniGetIntArrayElements(JNIEnv *env,
+      jintArray array,
+      jboolean *isCopy);
+extern jlong * CVMjniGetLongArrayElements(JNIEnv *env,
+        jlongArray array,
+        jboolean *isCopy);
+extern jfloat * CVMjniGetFloatArrayElements(JNIEnv *env,
+          jfloatArray array,
+          jboolean *isCopy);
+extern jdouble * CVMjniGetDoubleArrayElements(JNIEnv *env,
+            jdoubleArray array,
+            jboolean *isCopy);
+extern void CVMjniReleaseBooleanArrayElements(JNIEnv *env,
+            jbooleanArray array,
+            jboolean *elems,
+            jint mode);
+extern void CVMjniReleaseByteArrayElements(JNIEnv *env,
+         jbyteArray array,
+         jbyte *elems,
+         jint mode);
+extern void CVMjniReleaseCharArrayElements(JNIEnv *env,
+         jcharArray array,
+         jchar *elems,
+         jint mode);
+extern void CVMjniReleaseShortArrayElements(JNIEnv *env,
+          jshortArray array,
+          jshort *elems,
+          jint mode);
+extern void CVMjniReleaseIntArrayElements(JNIEnv *env,
+        jintArray array,
+        jint *elems,
+        jint mode);
+extern void CVMjniReleaseLongArrayElements(JNIEnv *env,
+         jlongArray array,
+         jlong *elems,
+         jint mode);
+extern void CVMjniReleaseFloatArrayElements(JNIEnv *env,
+          jfloatArray array,
+          jfloat *elems,
+          jint mode);
+extern void CVMjniReleaseDoubleArrayElements(JNIEnv *env,
+           jdoubleArray array,
+           jdouble *elems,
+           jint mode);
+extern void CVMjniGetBooleanArrayRegion(JNIEnv *env,
+      jbooleanArray array,
+      jsize start, jsize len,
+      jboolean *buf);
+extern void CVMjniGetByteArrayRegion(JNIEnv *env,
+          jbyteArray array,
+          jsize start, jsize len,
+          jbyte *buf);
+extern void CVMjniGetCharArrayRegion(JNIEnv *env,
+          jcharArray array,
+          jsize start, jsize len,
+          jchar *buf);
+extern void CVMjniGetShortArrayRegion(JNIEnv *env,
+           jshortArray array,
+           jsize start, jsize len,
+           jshort *buf);
+extern void CVMjniGetIntArrayRegion(JNIEnv *env,
+         jintArray array,
+         jsize start, jsize len,
+         jint *buf);
+extern void CVMjniGetLongArrayRegion(JNIEnv *env,
+          jlongArray array,
+          jsize start, jsize len,
+          jlong *buf);
+extern void CVMjniGetFloatArrayRegion(JNIEnv *env,
+           jfloatArray array,
+           jsize start, jsize len,
+           jfloat *buf);
+extern void CVMjniGetDoubleArrayRegion(JNIEnv *env,
+            jdoubleArray array,
+            jsize start, jsize len,
+            jdouble *buf);
+extern void CVMjniSetBooleanArrayRegion(JNIEnv *env,
+      jbooleanArray array,
+      jsize start, jsize len,
+      const jboolean *buf);
+extern void CVMjniSetByteArrayRegion(JNIEnv *env,
+          jbyteArray array,
+          jsize start, jsize len,
+          const jbyte *buf);
+extern void CVMjniSetCharArrayRegion(JNIEnv *env,
+          jcharArray array,
+          jsize start, jsize len,
+          const jchar *buf);
+extern void CVMjniSetShortArrayRegion(JNIEnv *env,
+           jshortArray array,
+           jsize start, jsize len,
+           const jshort *buf);
+extern void CVMjniSetIntArrayRegion(JNIEnv *env,
+         jintArray array,
+         jsize start, jsize len,
+         const jint *buf);
+extern void CVMjniSetLongArrayRegion(JNIEnv *env,
+          jlongArray array,
+          jsize start, jsize len,
+          const jlong *buf);
+extern void CVMjniSetFloatArrayRegion(JNIEnv *env,
+           jfloatArray array,
+           jsize start, jsize len,
+           const jfloat *buf);
+extern void CVMjniSetDoubleArrayRegion(JNIEnv *env,
+            jdoubleArray array,
+            jsize start, jsize len,
+            const jdouble *buf);
+extern jint CVMjniRegisterNatives(JNIEnv *env, jclass clazz,
+       const JNINativeMethod *methods,
+       jint nMethods);
+extern jint CVMjniUnregisterNatives(JNIEnv *env, jclass clazz);
+extern jint CVMjniMonitorEnter(JNIEnv *env, jobject obj);
+extern jint CVMjniMonitorExit(JNIEnv *env, jobject obj);
+extern jint CVMjniGetJavaVM(JNIEnv *env, JavaVM **p_jvm);
+extern void CVMjniGetStringRegion(JNIEnv *env,
+       jstring string, jsize start,
+       jsize len, jchar *buf);
+extern void CVMjniGetStringUTFRegion(JNIEnv *env,
+          jstring string, jsize start,
+          jsize len, char *buf);
+extern void* CVMjniGetPrimitiveArrayCritical(JNIEnv *env,
+           jarray array,
+           jboolean *isCopy);
+extern void CVMjniReleasePrimitiveArrayCritical(JNIEnv *env,
+       jarray array,
+       void* buf, jint mode);
+extern const jchar* CVMjniGetStringCritical(JNIEnv *env,
+          jstring string,
+          jboolean *isCopy);
+extern void CVMjniReleaseStringCritical(JNIEnv *env, jstring str,
+      const jchar *chars);
+extern jboolean CVMjniExceptionCheck(JNIEnv *env);
+extern jobject
+CVMjniNewDirectByteBuffer(JNIEnv *env, void* address, jlong capacity);
+extern void*
+CVMjniGetDirectBufferAddress(JNIEnv *env, jobject buf);
+extern jlong
+CVMjniGetDirectBufferCapacity(JNIEnv *env, jobject buf);
+extern CVMBool CVMthreadCreate(CVMThreadID *thread,
+    CVMSize stackSize, CVMInt32 priority,
+    void (*func)(void *), void *arg);
+extern void CVMthreadYield(void);
+extern void CVMthreadSetPriority(CVMThreadID *thread, CVMInt32 prio);
+extern void CVMthreadSuspend(CVMThreadID *thread);
+extern void CVMthreadResume(CVMThreadID *thread);
+extern CVMBool CVMthreadAttach(CVMThreadID *self, CVMBool orphan);
+extern void CVMthreadDetach(CVMThreadID *self);
+extern CVMThreadID * CVMthreadSelf(void);
+extern void CVMthreadInterruptWait(CVMThreadID *thread);
+extern CVMBool CVMthreadIsInterrupted(CVMThreadID *thread,
+    CVMBool clearInterrupted);
+extern CVMBool CVMthreadStackCheck(CVMThreadID *self, CVMUint32 redZone);
+extern CVMBool POSIXthreadInitStaticState();
+extern void POSIXthreadDestroyStaticState();
+extern CVMBool POSIXthreadCreate(CVMThreadID *tid,
+    CVMSize stackSize, CVMInt32 priority,
+    void (*func)(void *), void *arg);
+extern CVMThreadID * POSIXthreadGetSelf();
+extern CVMBool POSIXthreadAttach(CVMThreadID *self, CVMBool orphan);
+extern void POSIXthreadDetach(CVMThreadID *self);
+extern void POSIXthreadSetPriority(CVMThreadID *t, CVMInt32 priority);
+extern void POSIXthreadGetPriority(CVMThreadID *t, CVMInt32 *priority);
+typedef struct CVMThreadArchData {
+    int dummy;
+} CVMThreadArchData;
+struct __jmp_buf_tag
+  {
+    __jmp_buf __jmpbuf;
+    int __mask_was_saved;
+    __sigset_t __saved_mask;
+  };
+typedef struct __jmp_buf_tag jmp_buf[1];
+extern int setjmp (jmp_buf __env) __attribute__ ((__nothrow__));
+extern int __sigsetjmp (struct __jmp_buf_tag __env[1], int __savemask) __attribute__ ((__nothrow__));
+extern int _setjmp (struct __jmp_buf_tag __env[1]) __attribute__ ((__nothrow__));
+extern void longjmp (struct __jmp_buf_tag __env[1], int __val)
+     __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
+extern void _longjmp (struct __jmp_buf_tag __env[1], int __val)
+     __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
+typedef struct __jmp_buf_tag sigjmp_buf[1];
+extern void siglongjmp (sigjmp_buf __env, int __val)
+     __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
+struct CVMThreadID {
+    pthread_t pthreadCookie;
+    void *stackTop;
+    POSIXMutex locked;
+    volatile CVMBool isSuspended;
+    volatile CVMBool isInSuspendHandler;
+    volatile CVMBool isMutexBlocked;
+    volatile CVMBool isWaitBlocked;
+    CVMBool interrupted;
+    CVMBool notified;
+    pthread_mutex_t wait_mutex;
+    pthread_cond_t wait_cv;
+    int value;
+    int fd;
+    CVMThreadArchData archData;
+    CVMThreadID *next;
+    CVMThreadID **prev_p;
+};
+extern void linuxCaptureInitialStack();
+enum {
+    JVMTI_VERSION_1 = 0x30010000,
+    JVMTI_VERSION_1_0 = 0x30010000,
+    JVMTI_VERSION_1_1 = 0x30010100,
+    JVMTI_VERSION = 0x30000000 + (1 * 0x10000) + (1 * 0x100) + 102
+};
+extern jint
+Agent_OnLoad(JavaVM *vm, char *options, void *reserved);
+extern jint
+Agent_OnAttach(JavaVM* vm, char* options, void* reserved);
+extern void
+Agent_OnUnload(JavaVM *vm);
+struct _jvmtiEnv;
+struct jvmtiInterface_1_;
+typedef const struct jvmtiInterface_1_ *jvmtiEnv;
+typedef jobject jthread;
+typedef jobject jthreadGroup;
+typedef jlong jlocation;
+struct _jrawMonitorID;
+typedef struct _jrawMonitorID *jrawMonitorID;
+typedef struct JNINativeInterface jniNativeInterface;
+enum {
+    JVMTI_THREAD_STATE_ALIVE = 0x0001,
+    JVMTI_THREAD_STATE_TERMINATED = 0x0002,
+    JVMTI_THREAD_STATE_RUNNABLE = 0x0004,
+    JVMTI_THREAD_STATE_BLOCKED_ON_MONITOR_ENTER = 0x0400,
+    JVMTI_THREAD_STATE_WAITING = 0x0080,
+    JVMTI_THREAD_STATE_WAITING_INDEFINITELY = 0x0010,
+    JVMTI_THREAD_STATE_WAITING_WITH_TIMEOUT = 0x0020,
+    JVMTI_THREAD_STATE_SLEEPING = 0x0040,
+    JVMTI_THREAD_STATE_IN_OBJECT_WAIT = 0x0100,
+    JVMTI_THREAD_STATE_PARKED = 0x0200,
+    JVMTI_THREAD_STATE_SUSPENDED = 0x100000,
+    JVMTI_THREAD_STATE_INTERRUPTED = 0x200000,
+    JVMTI_THREAD_STATE_IN_NATIVE = 0x400000,
+    JVMTI_THREAD_STATE_VENDOR_1 = 0x10000000,
+    JVMTI_THREAD_STATE_VENDOR_2 = 0x20000000,
+    JVMTI_THREAD_STATE_VENDOR_3 = 0x40000000
+};
+enum {
+    JVMTI_JAVA_LANG_THREAD_STATE_MASK = JVMTI_THREAD_STATE_TERMINATED | JVMTI_THREAD_STATE_ALIVE | JVMTI_THREAD_STATE_RUNNABLE | JVMTI_THREAD_STATE_BLOCKED_ON_MONITOR_ENTER | JVMTI_THREAD_STATE_WAITING | JVMTI_THREAD_STATE_WAITING_INDEFINITELY | JVMTI_THREAD_STATE_WAITING_WITH_TIMEOUT,
+    JVMTI_JAVA_LANG_THREAD_STATE_NEW = 0,
+    JVMTI_JAVA_LANG_THREAD_STATE_TERMINATED = JVMTI_THREAD_STATE_TERMINATED,
+    JVMTI_JAVA_LANG_THREAD_STATE_RUNNABLE = JVMTI_THREAD_STATE_ALIVE | JVMTI_THREAD_STATE_RUNNABLE,
+    JVMTI_JAVA_LANG_THREAD_STATE_BLOCKED = JVMTI_THREAD_STATE_ALIVE | JVMTI_THREAD_STATE_BLOCKED_ON_MONITOR_ENTER,
+    JVMTI_JAVA_LANG_THREAD_STATE_WAITING = JVMTI_THREAD_STATE_ALIVE | JVMTI_THREAD_STATE_WAITING | JVMTI_THREAD_STATE_WAITING_INDEFINITELY,
+    JVMTI_JAVA_LANG_THREAD_STATE_TIMED_WAITING = JVMTI_THREAD_STATE_ALIVE | JVMTI_THREAD_STATE_WAITING | JVMTI_THREAD_STATE_WAITING_WITH_TIMEOUT
+};
+enum {
+    JVMTI_THREAD_MIN_PRIORITY = 1,
+    JVMTI_THREAD_NORM_PRIORITY = 5,
+    JVMTI_THREAD_MAX_PRIORITY = 10
+};
+enum {
+    JVMTI_HEAP_FILTER_TAGGED = 0x4,
+    JVMTI_HEAP_FILTER_UNTAGGED = 0x8,
+    JVMTI_HEAP_FILTER_CLASS_TAGGED = 0x10,
+    JVMTI_HEAP_FILTER_CLASS_UNTAGGED = 0x20
+};
+enum {
+    JVMTI_VISIT_OBJECTS = 0x100,
+    JVMTI_VISIT_ABORT = 0x8000
+};
+typedef enum {
+    JVMTI_HEAP_REFERENCE_CLASS = 1,
+    JVMTI_HEAP_REFERENCE_FIELD = 2,
+    JVMTI_HEAP_REFERENCE_ARRAY_ELEMENT = 3,
+    JVMTI_HEAP_REFERENCE_CLASS_LOADER = 4,
+    JVMTI_HEAP_REFERENCE_SIGNERS = 5,
+    JVMTI_HEAP_REFERENCE_PROTECTION_DOMAIN = 6,
+    JVMTI_HEAP_REFERENCE_INTERFACE = 7,
+    JVMTI_HEAP_REFERENCE_STATIC_FIELD = 8,
+    JVMTI_HEAP_REFERENCE_CONSTANT_POOL = 9,
+    JVMTI_HEAP_REFERENCE_SUPERCLASS = 10,
+    JVMTI_HEAP_REFERENCE_JNI_GLOBAL = 21,
+    JVMTI_HEAP_REFERENCE_SYSTEM_CLASS = 22,
+    JVMTI_HEAP_REFERENCE_MONITOR = 23,
+    JVMTI_HEAP_REFERENCE_STACK_LOCAL = 24,
+    JVMTI_HEAP_REFERENCE_JNI_LOCAL = 25,
+    JVMTI_HEAP_REFERENCE_THREAD = 26,
+    JVMTI_HEAP_REFERENCE_OTHER = 27
+} jvmtiHeapReferenceKind;
+typedef enum {
+    JVMTI_PRIMITIVE_TYPE_BOOLEAN = 90,
+    JVMTI_PRIMITIVE_TYPE_BYTE = 66,
+    JVMTI_PRIMITIVE_TYPE_CHAR = 67,
+    JVMTI_PRIMITIVE_TYPE_SHORT = 83,
+    JVMTI_PRIMITIVE_TYPE_INT = 73,
+    JVMTI_PRIMITIVE_TYPE_LONG = 74,
+    JVMTI_PRIMITIVE_TYPE_FLOAT = 70,
+    JVMTI_PRIMITIVE_TYPE_DOUBLE = 68
+} jvmtiPrimitiveType;
+typedef enum {
+    JVMTI_HEAP_OBJECT_TAGGED = 1,
+    JVMTI_HEAP_OBJECT_UNTAGGED = 2,
+    JVMTI_HEAP_OBJECT_EITHER = 3
+} jvmtiHeapObjectFilter;
+typedef enum {
+    JVMTI_HEAP_ROOT_JNI_GLOBAL = 1,
+    JVMTI_HEAP_ROOT_SYSTEM_CLASS = 2,
+    JVMTI_HEAP_ROOT_MONITOR = 3,
+    JVMTI_HEAP_ROOT_STACK_LOCAL = 4,
+    JVMTI_HEAP_ROOT_JNI_LOCAL = 5,
+    JVMTI_HEAP_ROOT_THREAD = 6,
+    JVMTI_HEAP_ROOT_OTHER = 7
+} jvmtiHeapRootKind;
+typedef enum {
+    JVMTI_REFERENCE_CLASS = 1,
+    JVMTI_REFERENCE_FIELD = 2,
+    JVMTI_REFERENCE_ARRAY_ELEMENT = 3,
+    JVMTI_REFERENCE_CLASS_LOADER = 4,
+    JVMTI_REFERENCE_SIGNERS = 5,
+    JVMTI_REFERENCE_PROTECTION_DOMAIN = 6,
+    JVMTI_REFERENCE_INTERFACE = 7,
+    JVMTI_REFERENCE_STATIC_FIELD = 8,
+    JVMTI_REFERENCE_CONSTANT_POOL = 9
+} jvmtiObjectReferenceKind;
+typedef enum {
+    JVMTI_ITERATION_CONTINUE = 1,
+    JVMTI_ITERATION_IGNORE = 2,
+    JVMTI_ITERATION_ABORT = 0
+} jvmtiIterationControl;
+enum {
+    JVMTI_CLASS_STATUS_VERIFIED = 1,
+    JVMTI_CLASS_STATUS_PREPARED = 2,
+    JVMTI_CLASS_STATUS_INITIALIZED = 4,
+    JVMTI_CLASS_STATUS_ERROR = 8,
+    JVMTI_CLASS_STATUS_ARRAY = 16,
+    JVMTI_CLASS_STATUS_PRIMITIVE = 32
+};
+typedef enum {
+    JVMTI_ENABLE = 1,
+    JVMTI_DISABLE = 0
+} jvmtiEventMode;
+typedef enum {
+    JVMTI_TYPE_JBYTE = 101,
+    JVMTI_TYPE_JCHAR = 102,
+    JVMTI_TYPE_JSHORT = 103,
+    JVMTI_TYPE_JINT = 104,
+    JVMTI_TYPE_JLONG = 105,
+    JVMTI_TYPE_JFLOAT = 106,
+    JVMTI_TYPE_JDOUBLE = 107,
+    JVMTI_TYPE_JBOOLEAN = 108,
+    JVMTI_TYPE_JOBJECT = 109,
+    JVMTI_TYPE_JTHREAD = 110,
+    JVMTI_TYPE_JCLASS = 111,
+    JVMTI_TYPE_JVALUE = 112,
+    JVMTI_TYPE_JFIELDID = 113,
+    JVMTI_TYPE_JMETHODID = 114,
+    JVMTI_TYPE_CCHAR = 115,
+    JVMTI_TYPE_CVOID = 116,
+    JVMTI_TYPE_JNIENV = 117
+} jvmtiParamTypes;
+typedef enum {
+    JVMTI_KIND_IN = 91,
+    JVMTI_KIND_IN_PTR = 92,
+    JVMTI_KIND_IN_BUF = 93,
+    JVMTI_KIND_ALLOC_BUF = 94,
+    JVMTI_KIND_ALLOC_ALLOC_BUF = 95,
+    JVMTI_KIND_OUT = 96,
+    JVMTI_KIND_OUT_BUF = 97
+} jvmtiParamKind;
+typedef enum {
+    JVMTI_TIMER_USER_CPU = 30,
+    JVMTI_TIMER_TOTAL_CPU = 31,
+    JVMTI_TIMER_ELAPSED = 32
+} jvmtiTimerKind;
+typedef enum {
+    JVMTI_PHASE_ONLOAD = 1,
+    JVMTI_PHASE_PRIMORDIAL = 2,
+    JVMTI_PHASE_START = 6,
+    JVMTI_PHASE_LIVE = 4,
+    JVMTI_PHASE_DEAD = 8
+} jvmtiPhase;
+enum {
+    JVMTI_VERSION_INTERFACE_JNI = 0x00000000,
+    JVMTI_VERSION_INTERFACE_JVMTI = 0x30000000
+};
+enum {
+    JVMTI_VERSION_MASK_INTERFACE_TYPE = 0x70000000,
+    JVMTI_VERSION_MASK_MAJOR = 0x0FFF0000,
+    JVMTI_VERSION_MASK_MINOR = 0x0000FF00,
+    JVMTI_VERSION_MASK_MICRO = 0x000000FF
+};
+enum {
+    JVMTI_VERSION_SHIFT_MAJOR = 16,
+    JVMTI_VERSION_SHIFT_MINOR = 8,
+    JVMTI_VERSION_SHIFT_MICRO = 0
+};
+typedef enum {
+    JVMTI_VERBOSE_OTHER = 0,
+    JVMTI_VERBOSE_GC = 1,
+    JVMTI_VERBOSE_CLASS = 2,
+    JVMTI_VERBOSE_JNI = 4
+} jvmtiVerboseFlag;
+typedef enum {
+    JVMTI_JLOCATION_JVMBCI = 1,
+    JVMTI_JLOCATION_MACHINEPC = 2,
+    JVMTI_JLOCATION_OTHER = 0
+} jvmtiJlocationFormat;
+enum {
+    JVMTI_RESOURCE_EXHAUSTED_OOM_ERROR = 0x0001,
+    JVMTI_RESOURCE_EXHAUSTED_JAVA_HEAP = 0x0002,
+    JVMTI_RESOURCE_EXHAUSTED_THREADS = 0x0004
+};
+typedef enum {
+    JVMTI_ERROR_NONE = 0,
+    JVMTI_ERROR_INVALID_THREAD = 10,
+    JVMTI_ERROR_INVALID_THREAD_GROUP = 11,
+    JVMTI_ERROR_INVALID_PRIORITY = 12,
+    JVMTI_ERROR_THREAD_NOT_SUSPENDED = 13,
+    JVMTI_ERROR_THREAD_SUSPENDED = 14,
+    JVMTI_ERROR_THREAD_NOT_ALIVE = 15,
+    JVMTI_ERROR_INVALID_OBJECT = 20,
+    JVMTI_ERROR_INVALID_CLASS = 21,
+    JVMTI_ERROR_CLASS_NOT_PREPARED = 22,
+    JVMTI_ERROR_INVALID_METHODID = 23,
+    JVMTI_ERROR_INVALID_LOCATION = 24,
+    JVMTI_ERROR_INVALID_FIELDID = 25,
+    JVMTI_ERROR_NO_MORE_FRAMES = 31,
+    JVMTI_ERROR_OPAQUE_FRAME = 32,
+    JVMTI_ERROR_TYPE_MISMATCH = 34,
+    JVMTI_ERROR_INVALID_SLOT = 35,
+    JVMTI_ERROR_DUPLICATE = 40,
+    JVMTI_ERROR_NOT_FOUND = 41,
+    JVMTI_ERROR_INVALID_MONITOR = 50,
+    JVMTI_ERROR_NOT_MONITOR_OWNER = 51,
+    JVMTI_ERROR_INTERRUPT = 52,
+    JVMTI_ERROR_INVALID_CLASS_FORMAT = 60,
+    JVMTI_ERROR_CIRCULAR_CLASS_DEFINITION = 61,
+    JVMTI_ERROR_FAILS_VERIFICATION = 62,
+    JVMTI_ERROR_UNSUPPORTED_REDEFINITION_METHOD_ADDED = 63,
+    JVMTI_ERROR_UNSUPPORTED_REDEFINITION_SCHEMA_CHANGED = 64,
+    JVMTI_ERROR_INVALID_TYPESTATE = 65,
+    JVMTI_ERROR_UNSUPPORTED_REDEFINITION_HIERARCHY_CHANGED = 66,
+    JVMTI_ERROR_UNSUPPORTED_REDEFINITION_METHOD_DELETED = 67,
+    JVMTI_ERROR_UNSUPPORTED_VERSION = 68,
+    JVMTI_ERROR_NAMES_DONT_MATCH = 69,
+    JVMTI_ERROR_UNSUPPORTED_REDEFINITION_CLASS_MODIFIERS_CHANGED = 70,
+    JVMTI_ERROR_UNSUPPORTED_REDEFINITION_METHOD_MODIFIERS_CHANGED = 71,
+    JVMTI_ERROR_UNMODIFIABLE_CLASS = 79,
+    JVMTI_ERROR_NOT_AVAILABLE = 98,
+    JVMTI_ERROR_MUST_POSSESS_CAPABILITY = 99,
+    JVMTI_ERROR_NULL_POINTER = 100,
+    JVMTI_ERROR_ABSENT_INFORMATION = 101,
+    JVMTI_ERROR_INVALID_EVENT_TYPE = 102,
+    JVMTI_ERROR_ILLEGAL_ARGUMENT = 103,
+    JVMTI_ERROR_NATIVE_METHOD = 104,
+    JVMTI_ERROR_CLASS_LOADER_UNSUPPORTED = 106,
+    JVMTI_ERROR_OUT_OF_MEMORY = 110,
+    JVMTI_ERROR_ACCESS_DENIED = 111,
+    JVMTI_ERROR_WRONG_PHASE = 112,
+    JVMTI_ERROR_INTERNAL = 113,
+    JVMTI_ERROR_UNATTACHED_THREAD = 115,
+    JVMTI_ERROR_INVALID_ENVIRONMENT = 116,
+    JVMTI_ERROR_MAX = 116
+} jvmtiError;
+typedef enum {
+    JVMTI_MIN_EVENT_TYPE_VAL = 50,
+    JVMTI_EVENT_VM_INIT = 50,
+    JVMTI_EVENT_VM_DEATH = 51,
+    JVMTI_EVENT_THREAD_START = 52,
+    JVMTI_EVENT_THREAD_END = 53,
+    JVMTI_EVENT_CLASS_FILE_LOAD_HOOK = 54,
+    JVMTI_EVENT_CLASS_LOAD = 55,
+    JVMTI_EVENT_CLASS_PREPARE = 56,
+    JVMTI_EVENT_VM_START = 57,
+    JVMTI_EVENT_EXCEPTION = 58,
+    JVMTI_EVENT_EXCEPTION_CATCH = 59,
+    JVMTI_EVENT_SINGLE_STEP = 60,
+    JVMTI_EVENT_FRAME_POP = 61,
+    JVMTI_EVENT_BREAKPOINT = 62,
+    JVMTI_EVENT_FIELD_ACCESS = 63,
+    JVMTI_EVENT_FIELD_MODIFICATION = 64,
+    JVMTI_EVENT_METHOD_ENTRY = 65,
+    JVMTI_EVENT_METHOD_EXIT = 66,
+    JVMTI_EVENT_NATIVE_METHOD_BIND = 67,
+    JVMTI_EVENT_COMPILED_METHOD_LOAD = 68,
+    JVMTI_EVENT_COMPILED_METHOD_UNLOAD = 69,
+    JVMTI_EVENT_DYNAMIC_CODE_GENERATED = 70,
+    JVMTI_EVENT_DATA_DUMP_REQUEST = 71,
+    JVMTI_EVENT_MONITOR_WAIT = 73,
+    JVMTI_EVENT_MONITOR_WAITED = 74,
+    JVMTI_EVENT_MONITOR_CONTENDED_ENTER = 75,
+    JVMTI_EVENT_MONITOR_CONTENDED_ENTERED = 76,
+    JVMTI_EVENT_RESOURCE_EXHAUSTED = 80,
+    JVMTI_EVENT_GARBAGE_COLLECTION_START = 81,
+    JVMTI_EVENT_GARBAGE_COLLECTION_FINISH = 82,
+    JVMTI_EVENT_OBJECT_FREE = 83,
+    JVMTI_EVENT_VM_OBJECT_ALLOC = 84,
+    JVMTI_MAX_EVENT_TYPE_VAL = 84
+} jvmtiEvent;
+struct _jvmtiThreadInfo;
+typedef struct _jvmtiThreadInfo jvmtiThreadInfo;
+struct _jvmtiMonitorStackDepthInfo;
+typedef struct _jvmtiMonitorStackDepthInfo jvmtiMonitorStackDepthInfo;
+struct _jvmtiThreadGroupInfo;
+typedef struct _jvmtiThreadGroupInfo jvmtiThreadGroupInfo;
+struct _jvmtiFrameInfo;
+typedef struct _jvmtiFrameInfo jvmtiFrameInfo;
+struct _jvmtiStackInfo;
+typedef struct _jvmtiStackInfo jvmtiStackInfo;
+struct _jvmtiHeapReferenceInfoField;
+typedef struct _jvmtiHeapReferenceInfoField jvmtiHeapReferenceInfoField;
+struct _jvmtiHeapReferenceInfoArray;
+typedef struct _jvmtiHeapReferenceInfoArray jvmtiHeapReferenceInfoArray;
+struct _jvmtiHeapReferenceInfoConstantPool;
+typedef struct _jvmtiHeapReferenceInfoConstantPool jvmtiHeapReferenceInfoConstantPool;
+struct _jvmtiHeapReferenceInfoStackLocal;
+typedef struct _jvmtiHeapReferenceInfoStackLocal jvmtiHeapReferenceInfoStackLocal;
+struct _jvmtiHeapReferenceInfoJniLocal;
+typedef struct _jvmtiHeapReferenceInfoJniLocal jvmtiHeapReferenceInfoJniLocal;
+struct _jvmtiHeapReferenceInfoReserved;
+typedef struct _jvmtiHeapReferenceInfoReserved jvmtiHeapReferenceInfoReserved;
+union _jvmtiHeapReferenceInfo;
+typedef union _jvmtiHeapReferenceInfo jvmtiHeapReferenceInfo;
+struct _jvmtiHeapCallbacks;
+typedef struct _jvmtiHeapCallbacks jvmtiHeapCallbacks;
+struct _jvmtiClassDefinition;
+typedef struct _jvmtiClassDefinition jvmtiClassDefinition;
+struct _jvmtiMonitorUsage;
+typedef struct _jvmtiMonitorUsage jvmtiMonitorUsage;
+struct _jvmtiLineNumberEntry;
+typedef struct _jvmtiLineNumberEntry jvmtiLineNumberEntry;
+struct _jvmtiLocalVariableEntry;
+typedef struct _jvmtiLocalVariableEntry jvmtiLocalVariableEntry;
+struct _jvmtiParamInfo;
+typedef struct _jvmtiParamInfo jvmtiParamInfo;
+struct _jvmtiExtensionFunctionInfo;
+typedef struct _jvmtiExtensionFunctionInfo jvmtiExtensionFunctionInfo;
+struct _jvmtiExtensionEventInfo;
+typedef struct _jvmtiExtensionEventInfo jvmtiExtensionEventInfo;
+struct _jvmtiTimerInfo;
+typedef struct _jvmtiTimerInfo jvmtiTimerInfo;
+struct _jvmtiAddrLocationMap;
+typedef struct _jvmtiAddrLocationMap jvmtiAddrLocationMap;
+typedef void ( *jvmtiStartFunction)
+    (jvmtiEnv* jvmti_env, JNIEnv* jni_env, void* arg);
+typedef jint ( *jvmtiHeapIterationCallback)
+    (jlong class_tag, jlong size, jlong* tag_ptr, jint length, void* user_data);
+typedef jint ( *jvmtiHeapReferenceCallback)
+    (jvmtiHeapReferenceKind reference_kind, const jvmtiHeapReferenceInfo* reference_info, jlong class_tag, jlong referrer_class_tag, jlong size, jlong* tag_ptr, jlong* referrer_tag_ptr, jint length, void* user_data);
+typedef jint ( *jvmtiPrimitiveFieldCallback)
+    (jvmtiHeapReferenceKind kind, const jvmtiHeapReferenceInfo* info, jlong object_class_tag, jlong* object_tag_ptr, jvalue value, jvmtiPrimitiveType value_type, void* user_data);
+typedef jint ( *jvmtiArrayPrimitiveValueCallback)
+    (jlong class_tag, jlong size, jlong* tag_ptr, jint element_count, jvmtiPrimitiveType element_type, const void* elements, void* user_data);
+typedef jint ( *jvmtiStringPrimitiveValueCallback)
+    (jlong class_tag, jlong size, jlong* tag_ptr, const jchar* value, jint value_length, void* user_data);
+typedef jint ( *jvmtiReservedCallback)
+    ();
+typedef jvmtiIterationControl ( *jvmtiHeapObjectCallback)
+    (jlong class_tag, jlong size, jlong* tag_ptr, void* user_data);
+typedef jvmtiIterationControl ( *jvmtiHeapRootCallback)
+    (jvmtiHeapRootKind root_kind, jlong class_tag, jlong size, jlong* tag_ptr, void* user_data);
+typedef jvmtiIterationControl ( *jvmtiStackReferenceCallback)
+    (jvmtiHeapRootKind root_kind, jlong class_tag, jlong size, jlong* tag_ptr, jlong thread_tag, jint depth, jmethodID method, jint slot, void* user_data);
+typedef jvmtiIterationControl ( *jvmtiObjectReferenceCallback)
+    (jvmtiObjectReferenceKind reference_kind, jlong class_tag, jlong size, jlong* tag_ptr, jlong referrer_tag, jint referrer_index, void* user_data);
+typedef jvmtiError ( *jvmtiExtensionFunction)
+    (jvmtiEnv* jvmti_env, ...);
+typedef void ( *jvmtiExtensionEvent)
+    (jvmtiEnv* jvmti_env, ...);
+struct _jvmtiThreadInfo {
+    char* name;
+    jint priority;
+    jboolean is_daemon;
+    jthreadGroup thread_group;
+    jobject context_class_loader;
+};
+struct _jvmtiMonitorStackDepthInfo {
+    jobject monitor;
+    jint stack_depth;
+};
+struct _jvmtiThreadGroupInfo {
+    jthreadGroup parent;
+    char* name;
+    jint max_priority;
+    jboolean is_daemon;
+};
+struct _jvmtiFrameInfo {
+    jmethodID method;
+    jlocation location;
+};
+struct _jvmtiStackInfo {
+    jthread thread;
+    jint state;
+    jvmtiFrameInfo* frame_buffer;
+    jint frame_count;
+};
+struct _jvmtiHeapReferenceInfoField {
+    jint index;
+};
+struct _jvmtiHeapReferenceInfoArray {
+    jint index;
+};
+struct _jvmtiHeapReferenceInfoConstantPool {
+    jint index;
+};
+struct _jvmtiHeapReferenceInfoStackLocal {
+    jlong thread_tag;
+    jlong thread_id;
+    jint depth;
+    jmethodID method;
+    jlocation location;
+    jint slot;
+};
+struct _jvmtiHeapReferenceInfoJniLocal {
+    jlong thread_tag;
+    jlong thread_id;
+    jint depth;
+    jmethodID method;
+};
+struct _jvmtiHeapReferenceInfoReserved {
+    jlong reserved1;
+    jlong reserved2;
+    jlong reserved3;
+    jlong reserved4;
+    jlong reserved5;
+    jlong reserved6;
+    jlong reserved7;
+    jlong reserved8;
+};
+union _jvmtiHeapReferenceInfo {
+    jvmtiHeapReferenceInfoField field;
+    jvmtiHeapReferenceInfoArray array;
+    jvmtiHeapReferenceInfoConstantPool constant_pool;
+    jvmtiHeapReferenceInfoStackLocal stack_local;
+    jvmtiHeapReferenceInfoJniLocal jni_local;
+    jvmtiHeapReferenceInfoReserved other;
+};
+struct _jvmtiHeapCallbacks {
+    jvmtiHeapIterationCallback heap_iteration_callback;
+    jvmtiHeapReferenceCallback heap_reference_callback;
+    jvmtiPrimitiveFieldCallback primitive_field_callback;
+    jvmtiArrayPrimitiveValueCallback array_primitive_value_callback;
+    jvmtiStringPrimitiveValueCallback string_primitive_value_callback;
+    jvmtiReservedCallback reserved5;
+    jvmtiReservedCallback reserved6;
+    jvmtiReservedCallback reserved7;
+    jvmtiReservedCallback reserved8;
+    jvmtiReservedCallback reserved9;
+    jvmtiReservedCallback reserved10;
+    jvmtiReservedCallback reserved11;
+    jvmtiReservedCallback reserved12;
+    jvmtiReservedCallback reserved13;
+    jvmtiReservedCallback reserved14;
+    jvmtiReservedCallback reserved15;
+};
+struct _jvmtiClassDefinition {
+    jclass klass;
+    jint class_byte_count;
+    const unsigned char* class_bytes;
+};
+struct _jvmtiMonitorUsage {
+    jthread owner;
+    jint entry_count;
+    jint waiter_count;
+    jthread* waiters;
+    jint notify_waiter_count;
+    jthread* notify_waiters;
+};
+struct _jvmtiLineNumberEntry {
+    jlocation start_location;
+    jint line_number;
+};
+struct _jvmtiLocalVariableEntry {
+    jlocation start_location;
+    jint length;
+    char* name;
+    char* signature;
+    char* generic_signature;
+    jint slot;
+};
+struct _jvmtiParamInfo {
+    char* name;
+    jvmtiParamKind kind;
+    jvmtiParamTypes base_type;
+    jboolean null_ok;
+};
+struct _jvmtiExtensionFunctionInfo {
+    jvmtiExtensionFunction func;
+    char* id;
+    char* short_description;
+    jint param_count;
+    jvmtiParamInfo* params;
+    jint error_count;
+    jvmtiError* errors;
+};
+struct _jvmtiExtensionEventInfo {
+    jint extension_event_index;
+    char* id;
+    char* short_description;
+    jint param_count;
+    jvmtiParamInfo* params;
+};
+struct _jvmtiTimerInfo {
+    jlong max_value;
+    jboolean may_skip_forward;
+    jboolean may_skip_backward;
+    jvmtiTimerKind kind;
+    jlong reserved1;
+    jlong reserved2;
+};
+struct _jvmtiAddrLocationMap {
+    const void* start_address;
+    jlocation location;
+};
+typedef struct {
+    unsigned int can_tag_objects : 1;
+    unsigned int can_generate_field_modification_events : 1;
+    unsigned int can_generate_field_access_events : 1;
+    unsigned int can_get_bytecodes : 1;
+    unsigned int can_get_synthetic_attribute : 1;
+    unsigned int can_get_owned_monitor_info : 1;
+    unsigned int can_get_current_contended_monitor : 1;
+    unsigned int can_get_monitor_info : 1;
+    unsigned int can_pop_frame : 1;
+    unsigned int can_redefine_classes : 1;
+    unsigned int can_signal_thread : 1;
+    unsigned int can_get_source_file_name : 1;
+    unsigned int can_get_line_numbers : 1;
+    unsigned int can_get_source_debug_extension : 1;
+    unsigned int can_access_local_variables : 1;
+    unsigned int can_maintain_original_method_order : 1;
+    unsigned int can_generate_single_step_events : 1;
+    unsigned int can_generate_exception_events : 1;
+    unsigned int can_generate_frame_pop_events : 1;
+    unsigned int can_generate_breakpoint_events : 1;
+    unsigned int can_suspend : 1;
+    unsigned int can_redefine_any_class : 1;
+    unsigned int can_get_current_thread_cpu_time : 1;
+    unsigned int can_get_thread_cpu_time : 1;
+    unsigned int can_generate_method_entry_events : 1;
+    unsigned int can_generate_method_exit_events : 1;
+    unsigned int can_generate_all_class_hook_events : 1;
+    unsigned int can_generate_compiled_method_load_events : 1;
+    unsigned int can_generate_monitor_events : 1;
+    unsigned int can_generate_vm_object_alloc_events : 1;
+    unsigned int can_generate_native_method_bind_events : 1;
+    unsigned int can_generate_garbage_collection_events : 1;
+    unsigned int can_generate_object_free_events : 1;
+    unsigned int can_force_early_return : 1;
+    unsigned int can_get_owned_monitor_stack_depth_info : 1;
+    unsigned int can_get_constant_pool : 1;
+    unsigned int can_set_native_method_prefix : 1;
+    unsigned int can_retransform_classes : 1;
+    unsigned int can_retransform_any_class : 1;
+    unsigned int can_generate_resource_exhaustion_heap_events : 1;
+    unsigned int can_generate_resource_exhaustion_threads_events : 1;
+    unsigned int : 7;
+    unsigned int : 16;
+    unsigned int : 16;
+    unsigned int : 16;
+    unsigned int : 16;
+    unsigned int : 16;
+} jvmtiCapabilities;
+typedef void ( *jvmtiEventReserved)(void);
+typedef void ( *jvmtiEventBreakpoint)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jmethodID method,
+     jlocation location);
+typedef void ( *jvmtiEventClassFileLoadHook)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jclass class_being_redefined,
+     jobject loader,
+     const char* name,
+     jobject protection_domain,
+     jint class_data_len,
+     const unsigned char* class_data,
+     jint* new_class_data_len,
+     unsigned char** new_class_data);
+typedef void ( *jvmtiEventClassLoad)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jclass klass);
+typedef void ( *jvmtiEventClassPrepare)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jclass klass);
+typedef void ( *jvmtiEventCompiledMethodLoad)
+    (jvmtiEnv *jvmti_env,
+     jmethodID method,
+     jint code_size,
+     const void* code_addr,
+     jint map_length,
+     const jvmtiAddrLocationMap* map,
+     const void* compile_info);
+typedef void ( *jvmtiEventCompiledMethodUnload)
+    (jvmtiEnv *jvmti_env,
+     jmethodID method,
+     const void* code_addr);
+typedef void ( *jvmtiEventDataDumpRequest)
+    (jvmtiEnv *jvmti_env);
+typedef void ( *jvmtiEventDynamicCodeGenerated)
+    (jvmtiEnv *jvmti_env,
+     const char* name,
+     const void* address,
+     jint length);
+typedef void ( *jvmtiEventException)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jmethodID method,
+     jlocation location,
+     jobject exception,
+     jmethodID catch_method,
+     jlocation catch_location);
+typedef void ( *jvmtiEventExceptionCatch)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jmethodID method,
+     jlocation location,
+     jobject exception);
+typedef void ( *jvmtiEventFieldAccess)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jmethodID method,
+     jlocation location,
+     jclass field_klass,
+     jobject object,
+     jfieldID field);
+typedef void ( *jvmtiEventFieldModification)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jmethodID method,
+     jlocation location,
+     jclass field_klass,
+     jobject object,
+     jfieldID field,
+     char signature_type,
+     jvalue new_value);
+typedef void ( *jvmtiEventFramePop)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jmethodID method,
+     jboolean was_popped_by_exception);
+typedef void ( *jvmtiEventGarbageCollectionFinish)
+    (jvmtiEnv *jvmti_env);
+typedef void ( *jvmtiEventGarbageCollectionStart)
+    (jvmtiEnv *jvmti_env);
+typedef void ( *jvmtiEventMethodEntry)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jmethodID method);
+typedef void ( *jvmtiEventMethodExit)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jmethodID method,
+     jboolean was_popped_by_exception,
+     jvalue return_value);
+typedef void ( *jvmtiEventMonitorContendedEnter)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jobject object);
+typedef void ( *jvmtiEventMonitorContendedEntered)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jobject object);
+typedef void ( *jvmtiEventMonitorWait)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jobject object,
+     jlong timeout);
+typedef void ( *jvmtiEventMonitorWaited)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jobject object,
+     jboolean timed_out);
+typedef void ( *jvmtiEventNativeMethodBind)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jmethodID method,
+     void* address,
+     void** new_address_ptr);
+typedef void ( *jvmtiEventObjectFree)
+    (jvmtiEnv *jvmti_env,
+     jlong tag);
+typedef void ( *jvmtiEventResourceExhausted)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jint flags,
+     const void* reserved,
+     const char* description);
+typedef void ( *jvmtiEventSingleStep)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jmethodID method,
+     jlocation location);
+typedef void ( *jvmtiEventThreadEnd)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread);
+typedef void ( *jvmtiEventThreadStart)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread);
+typedef void ( *jvmtiEventVMDeath)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env);
+typedef void ( *jvmtiEventVMInit)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread);
+typedef void ( *jvmtiEventVMObjectAlloc)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env,
+     jthread thread,
+     jobject object,
+     jclass object_klass,
+     jlong size);
+typedef void ( *jvmtiEventVMStart)
+    (jvmtiEnv *jvmti_env,
+     JNIEnv* jni_env);
+typedef struct {
+    jvmtiEventVMInit VMInit;
+    jvmtiEventVMDeath VMDeath;
+    jvmtiEventThreadStart ThreadStart;
+    jvmtiEventThreadEnd ThreadEnd;
+    jvmtiEventClassFileLoadHook ClassFileLoadHook;
+    jvmtiEventClassLoad ClassLoad;
+    jvmtiEventClassPrepare ClassPrepare;
+    jvmtiEventVMStart VMStart;
+    jvmtiEventException Exception;
+    jvmtiEventExceptionCatch ExceptionCatch;
+    jvmtiEventSingleStep SingleStep;
+    jvmtiEventFramePop FramePop;
+    jvmtiEventBreakpoint Breakpoint;
+    jvmtiEventFieldAccess FieldAccess;
+    jvmtiEventFieldModification FieldModification;
+    jvmtiEventMethodEntry MethodEntry;
+    jvmtiEventMethodExit MethodExit;
+    jvmtiEventNativeMethodBind NativeMethodBind;
+    jvmtiEventCompiledMethodLoad CompiledMethodLoad;
+    jvmtiEventCompiledMethodUnload CompiledMethodUnload;
+    jvmtiEventDynamicCodeGenerated DynamicCodeGenerated;
+    jvmtiEventDataDumpRequest DataDumpRequest;
+    jvmtiEventReserved reserved72;
+    jvmtiEventMonitorWait MonitorWait;
+    jvmtiEventMonitorWaited MonitorWaited;
+    jvmtiEventMonitorContendedEnter MonitorContendedEnter;
+    jvmtiEventMonitorContendedEntered MonitorContendedEntered;
+    jvmtiEventReserved reserved77;
+    jvmtiEventReserved reserved78;
+    jvmtiEventReserved reserved79;
+    jvmtiEventResourceExhausted ResourceExhausted;
+    jvmtiEventGarbageCollectionStart GarbageCollectionStart;
+    jvmtiEventGarbageCollectionFinish GarbageCollectionFinish;
+    jvmtiEventObjectFree ObjectFree;
+    jvmtiEventVMObjectAlloc VMObjectAlloc;
+} jvmtiEventCallbacks;
+typedef struct jvmtiInterface_1_ {
+  void *reserved1;
+  jvmtiError ( *SetEventNotificationMode) (jvmtiEnv* env,
+    jvmtiEventMode mode,
+    jvmtiEvent event_type,
+    jthread event_thread,
+     ...);
+  void *reserved3;
+  jvmtiError ( *GetAllThreads) (jvmtiEnv* env,
+    jint* threads_count_ptr,
+    jthread** threads_ptr);
+  jvmtiError ( *SuspendThread) (jvmtiEnv* env,
+    jthread thread);
+  jvmtiError ( *ResumeThread) (jvmtiEnv* env,
+    jthread thread);
+  jvmtiError ( *StopThread) (jvmtiEnv* env,
+    jthread thread,
+    jobject exception);
+  jvmtiError ( *InterruptThread) (jvmtiEnv* env,
+    jthread thread);
+  jvmtiError ( *GetThreadInfo) (jvmtiEnv* env,
+    jthread thread,
+    jvmtiThreadInfo* info_ptr);
+  jvmtiError ( *GetOwnedMonitorInfo) (jvmtiEnv* env,
+    jthread thread,
+    jint* owned_monitor_count_ptr,
+    jobject** owned_monitors_ptr);
+  jvmtiError ( *GetCurrentContendedMonitor) (jvmtiEnv* env,
+    jthread thread,
+    jobject* monitor_ptr);
+  jvmtiError ( *RunAgentThread) (jvmtiEnv* env,
+    jthread thread,
+    jvmtiStartFunction proc,
+    const void* arg,
+    jint priority);
+  jvmtiError ( *GetTopThreadGroups) (jvmtiEnv* env,
+    jint* group_count_ptr,
+    jthreadGroup** groups_ptr);
+  jvmtiError ( *GetThreadGroupInfo) (jvmtiEnv* env,
+    jthreadGroup group,
+    jvmtiThreadGroupInfo* info_ptr);
+  jvmtiError ( *GetThreadGroupChildren) (jvmtiEnv* env,
+    jthreadGroup group,
+    jint* thread_count_ptr,
+    jthread** threads_ptr,
+    jint* group_count_ptr,
+    jthreadGroup** groups_ptr);
+  jvmtiError ( *GetFrameCount) (jvmtiEnv* env,
+    jthread thread,
+    jint* count_ptr);
+  jvmtiError ( *GetThreadState) (jvmtiEnv* env,
+    jthread thread,
+    jint* thread_state_ptr);
+  jvmtiError ( *GetCurrentThread) (jvmtiEnv* env,
+    jthread* thread_ptr);
+  jvmtiError ( *GetFrameLocation) (jvmtiEnv* env,
+    jthread thread,
+    jint depth,
+    jmethodID* method_ptr,
+    jlocation* location_ptr);
+  jvmtiError ( *NotifyFramePop) (jvmtiEnv* env,
+    jthread thread,
+    jint depth);
+  jvmtiError ( *GetLocalObject) (jvmtiEnv* env,
+    jthread thread,
+    jint depth,
+    jint slot,
+    jobject* value_ptr);
+  jvmtiError ( *GetLocalInt) (jvmtiEnv* env,
+    jthread thread,
+    jint depth,
+    jint slot,
+    jint* value_ptr);
+  jvmtiError ( *GetLocalLong) (jvmtiEnv* env,
+    jthread thread,
+    jint depth,
+    jint slot,
+    jlong* value_ptr);
+  jvmtiError ( *GetLocalFloat) (jvmtiEnv* env,
+    jthread thread,
+    jint depth,
+    jint slot,
+    jfloat* value_ptr);
+  jvmtiError ( *GetLocalDouble) (jvmtiEnv* env,
+    jthread thread,
+    jint depth,
+    jint slot,
+    jdouble* value_ptr);
+  jvmtiError ( *SetLocalObject) (jvmtiEnv* env,
+    jthread thread,
+    jint depth,
+    jint slot,
+    jobject value);
+  jvmtiError ( *SetLocalInt) (jvmtiEnv* env,
+    jthread thread,
+    jint depth,
+    jint slot,
+    jint value);
+  jvmtiError ( *SetLocalLong) (jvmtiEnv* env,
+    jthread thread,
+    jint depth,
+    jint slot,
+    jlong value);
+  jvmtiError ( *SetLocalFloat) (jvmtiEnv* env,
+    jthread thread,
+    jint depth,
+    jint slot,
+    jfloat value);
+  jvmtiError ( *SetLocalDouble) (jvmtiEnv* env,
+    jthread thread,
+    jint depth,
+    jint slot,
+    jdouble value);
+  jvmtiError ( *CreateRawMonitor) (jvmtiEnv* env,
+    const char* name,
+    jrawMonitorID* monitor_ptr);
+  jvmtiError ( *DestroyRawMonitor) (jvmtiEnv* env,
+    jrawMonitorID monitor);
+  jvmtiError ( *RawMonitorEnter) (jvmtiEnv* env,
+    jrawMonitorID monitor);
+  jvmtiError ( *RawMonitorExit) (jvmtiEnv* env,
+    jrawMonitorID monitor);
+  jvmtiError ( *RawMonitorWait) (jvmtiEnv* env,
+    jrawMonitorID monitor,
+    jlong millis);
+  jvmtiError ( *RawMonitorNotify) (jvmtiEnv* env,
+    jrawMonitorID monitor);
+  jvmtiError ( *RawMonitorNotifyAll) (jvmtiEnv* env,
+    jrawMonitorID monitor);
+  jvmtiError ( *SetBreakpoint) (jvmtiEnv* env,
+    jmethodID method,
+    jlocation location);
+  jvmtiError ( *ClearBreakpoint) (jvmtiEnv* env,
+    jmethodID method,
+    jlocation location);
+  void *reserved40;
+  jvmtiError ( *SetFieldAccessWatch) (jvmtiEnv* env,
+    jclass klass,
+    jfieldID field);
+  jvmtiError ( *ClearFieldAccessWatch) (jvmtiEnv* env,
+    jclass klass,
+    jfieldID field);
+  jvmtiError ( *SetFieldModificationWatch) (jvmtiEnv* env,
+    jclass klass,
+    jfieldID field);
+  jvmtiError ( *ClearFieldModificationWatch) (jvmtiEnv* env,
+    jclass klass,
+    jfieldID field);
+  jvmtiError ( *IsModifiableClass) (jvmtiEnv* env,
+    jclass klass,
+    jboolean* is_modifiable_class_ptr);
+  jvmtiError ( *Allocate) (jvmtiEnv* env,
+    jlong size,
+    unsigned char** mem_ptr);
+  jvmtiError ( *Deallocate) (jvmtiEnv* env,
+    unsigned char* mem);
+  jvmtiError ( *GetClassSignature) (jvmtiEnv* env,
+    jclass klass,
+    char** signature_ptr,
+    char** generic_ptr);
+  jvmtiError ( *GetClassStatus) (jvmtiEnv* env,
+    jclass klass,
+    jint* status_ptr);
+  jvmtiError ( *GetSourceFileName) (jvmtiEnv* env,
+    jclass klass,
+    char** source_name_ptr);
+  jvmtiError ( *GetClassModifiers) (jvmtiEnv* env,
+    jclass klass,
+    jint* modifiers_ptr);
+  jvmtiError ( *GetClassMethods) (jvmtiEnv* env,
+    jclass klass,
+    jint* method_count_ptr,
+    jmethodID** methods_ptr);
+  jvmtiError ( *GetClassFields) (jvmtiEnv* env,
+    jclass klass,
+    jint* field_count_ptr,
+    jfieldID** fields_ptr);
+  jvmtiError ( *GetImplementedInterfaces) (jvmtiEnv* env,
+    jclass klass,
+    jint* interface_count_ptr,
+    jclass** interfaces_ptr);
+  jvmtiError ( *IsInterface) (jvmtiEnv* env,
+    jclass klass,
+    jboolean* is_interface_ptr);
+  jvmtiError ( *IsArrayClass) (jvmtiEnv* env,
+    jclass klass,
+    jboolean* is_array_class_ptr);
+  jvmtiError ( *GetClassLoader) (jvmtiEnv* env,
+    jclass klass,
+    jobject* classloader_ptr);
+  jvmtiError ( *GetObjectHashCode) (jvmtiEnv* env,
+    jobject object,
+    jint* hash_code_ptr);
+  jvmtiError ( *GetObjectMonitorUsage) (jvmtiEnv* env,
+    jobject object,
+    jvmtiMonitorUsage* info_ptr);
+  jvmtiError ( *GetFieldName) (jvmtiEnv* env,
+    jclass klass,
+    jfieldID field,
+    char** name_ptr,
+    char** signature_ptr,
+    char** generic_ptr);
+  jvmtiError ( *GetFieldDeclaringClass) (jvmtiEnv* env,
+    jclass klass,
+    jfieldID field,
+    jclass* declaring_class_ptr);
+  jvmtiError ( *GetFieldModifiers) (jvmtiEnv* env,
+    jclass klass,
+    jfieldID field,
+    jint* modifiers_ptr);
+  jvmtiError ( *IsFieldSynthetic) (jvmtiEnv* env,
+    jclass klass,
+    jfieldID field,
+    jboolean* is_synthetic_ptr);
+  jvmtiError ( *GetMethodName) (jvmtiEnv* env,
+    jmethodID method,
+    char** name_ptr,
+    char** signature_ptr,
+    char** generic_ptr);
+  jvmtiError ( *GetMethodDeclaringClass) (jvmtiEnv* env,
+    jmethodID method,
+    jclass* declaring_class_ptr);
+  jvmtiError ( *GetMethodModifiers) (jvmtiEnv* env,
+    jmethodID method,
+    jint* modifiers_ptr);
+  void *reserved67;
+  jvmtiError ( *GetMaxLocals) (jvmtiEnv* env,
+    jmethodID method,
+    jint* max_ptr);
+  jvmtiError ( *GetArgumentsSize) (jvmtiEnv* env,
+    jmethodID method,
+    jint* size_ptr);
+  jvmtiError ( *GetLineNumberTable) (jvmtiEnv* env,
+    jmethodID method,
+    jint* entry_count_ptr,
+    jvmtiLineNumberEntry** table_ptr);
+  jvmtiError ( *GetMethodLocation) (jvmtiEnv* env,
+    jmethodID method,
+    jlocation* start_location_ptr,
+    jlocation* end_location_ptr);
+  jvmtiError ( *GetLocalVariableTable) (jvmtiEnv* env,
+    jmethodID method,
+    jint* entry_count_ptr,
+    jvmtiLocalVariableEntry** table_ptr);
+  jvmtiError ( *SetNativeMethodPrefix) (jvmtiEnv* env,
+    const char* prefix);
+  jvmtiError ( *SetNativeMethodPrefixes) (jvmtiEnv* env,
+    jint prefix_count,
+    char** prefixes);
+  jvmtiError ( *GetBytecodes) (jvmtiEnv* env,
+    jmethodID method,
+    jint* bytecode_count_ptr,
+    unsigned char** bytecodes_ptr);
+  jvmtiError ( *IsMethodNative) (jvmtiEnv* env,
+    jmethodID method,
+    jboolean* is_native_ptr);
+  jvmtiError ( *IsMethodSynthetic) (jvmtiEnv* env,
+    jmethodID method,
+    jboolean* is_synthetic_ptr);
+  jvmtiError ( *GetLoadedClasses) (jvmtiEnv* env,
+    jint* class_count_ptr,
+    jclass** classes_ptr);
+  jvmtiError ( *GetClassLoaderClasses) (jvmtiEnv* env,
+    jobject initiating_loader,
+    jint* class_count_ptr,
+    jclass** classes_ptr);
+  jvmtiError ( *PopFrame) (jvmtiEnv* env,
+    jthread thread);
+  jvmtiError ( *ForceEarlyReturnObject) (jvmtiEnv* env,
+    jthread thread,
+    jobject value);
+  jvmtiError ( *ForceEarlyReturnInt) (jvmtiEnv* env,
+    jthread thread,
+    jint value);
+  jvmtiError ( *ForceEarlyReturnLong) (jvmtiEnv* env,
+    jthread thread,
+    jlong value);
+  jvmtiError ( *ForceEarlyReturnFloat) (jvmtiEnv* env,
+    jthread thread,
+    jfloat value);
+  jvmtiError ( *ForceEarlyReturnDouble) (jvmtiEnv* env,
+    jthread thread,
+    jdouble value);
+  jvmtiError ( *ForceEarlyReturnVoid) (jvmtiEnv* env,
+    jthread thread);
+  jvmtiError ( *RedefineClasses) (jvmtiEnv* env,
+    jint class_count,
+    const jvmtiClassDefinition* class_definitions);
+  jvmtiError ( *GetVersionNumber) (jvmtiEnv* env,
+    jint* version_ptr);
+  jvmtiError ( *GetCapabilities) (jvmtiEnv* env,
+    jvmtiCapabilities* capabilities_ptr);
+  jvmtiError ( *GetSourceDebugExtension) (jvmtiEnv* env,
+    jclass klass,
+    char** source_debug_extension_ptr);
+  jvmtiError ( *IsMethodObsolete) (jvmtiEnv* env,
+    jmethodID method,
+    jboolean* is_obsolete_ptr);
+  jvmtiError ( *SuspendThreadList) (jvmtiEnv* env,
+    jint request_count,
+    const jthread* request_list,
+    jvmtiError* results);
+  jvmtiError ( *ResumeThreadList) (jvmtiEnv* env,
+    jint request_count,
+    const jthread* request_list,
+    jvmtiError* results);
+  void *reserved94;
+  void *reserved95;
+  void *reserved96;
+  void *reserved97;
+  void *reserved98;
+  void *reserved99;
+  jvmtiError ( *GetAllStackTraces) (jvmtiEnv* env,
+    jint max_frame_count,
+    jvmtiStackInfo** stack_info_ptr,
+    jint* thread_count_ptr);
+  jvmtiError ( *GetThreadListStackTraces) (jvmtiEnv* env,
+    jint thread_count,
+    const jthread* thread_list,
+    jint max_frame_count,
+    jvmtiStackInfo** stack_info_ptr);
+  jvmtiError ( *GetThreadLocalStorage) (jvmtiEnv* env,
+    jthread thread,
+    void** data_ptr);
+  jvmtiError ( *SetThreadLocalStorage) (jvmtiEnv* env,
+    jthread thread,
+    const void* data);
+  jvmtiError ( *GetStackTrace) (jvmtiEnv* env,
+    jthread thread,
+    jint start_depth,
+    jint max_frame_count,
+    jvmtiFrameInfo* frame_buffer,
+    jint* count_ptr);
+  void *reserved105;
+  jvmtiError ( *GetTag) (jvmtiEnv* env,
+    jobject object,
+    jlong* tag_ptr);
+  jvmtiError ( *SetTag) (jvmtiEnv* env,
+    jobject object,
+    jlong tag);
+  jvmtiError ( *ForceGarbageCollection) (jvmtiEnv* env);
+  jvmtiError ( *IterateOverObjectsReachableFromObject) (jvmtiEnv* env,
+    jobject object,
+    jvmtiObjectReferenceCallback object_reference_callback,
+    const void* user_data);
+  jvmtiError ( *IterateOverReachableObjects) (jvmtiEnv* env,
+    jvmtiHeapRootCallback heap_root_callback,
+    jvmtiStackReferenceCallback stack_ref_callback,
+    jvmtiObjectReferenceCallback object_ref_callback,
+    const void* user_data);
+  jvmtiError ( *IterateOverHeap) (jvmtiEnv* env,
+    jvmtiHeapObjectFilter object_filter,
+    jvmtiHeapObjectCallback heap_object_callback,
+    const void* user_data);
+  jvmtiError ( *IterateOverInstancesOfClass) (jvmtiEnv* env,
+    jclass klass,
+    jvmtiHeapObjectFilter object_filter,
+    jvmtiHeapObjectCallback heap_object_callback,
+    const void* user_data);
+  void *reserved113;
+  jvmtiError ( *GetObjectsWithTags) (jvmtiEnv* env,
+    jint tag_count,
+    const jlong* tags,
+    jint* count_ptr,
+    jobject** object_result_ptr,
+    jlong** tag_result_ptr);
+  jvmtiError ( *FollowReferences) (jvmtiEnv* env,
+    jint heap_filter,
+    jclass klass,
+    jobject initial_object,
+    const jvmtiHeapCallbacks* callbacks,
+    const void* user_data);
+  jvmtiError ( *IterateThroughHeap) (jvmtiEnv* env,
+    jint heap_filter,
+    jclass klass,
+    const jvmtiHeapCallbacks* callbacks,
+    const void* user_data);
+  void *reserved117;
+  void *reserved118;
+  void *reserved119;
+  jvmtiError ( *SetJNIFunctionTable) (jvmtiEnv* env,
+    const jniNativeInterface* function_table);
+  jvmtiError ( *GetJNIFunctionTable) (jvmtiEnv* env,
+    jniNativeInterface** function_table);
+  jvmtiError ( *SetEventCallbacks) (jvmtiEnv* env,
+    const jvmtiEventCallbacks* callbacks,
+    jint size_of_callbacks);
+  jvmtiError ( *GenerateEvents) (jvmtiEnv* env,
+    jvmtiEvent event_type);
+  jvmtiError ( *GetExtensionFunctions) (jvmtiEnv* env,
+    jint* extension_count_ptr,
+    jvmtiExtensionFunctionInfo** extensions);
+  jvmtiError ( *GetExtensionEvents) (jvmtiEnv* env,
+    jint* extension_count_ptr,
+    jvmtiExtensionEventInfo** extensions);
+  jvmtiError ( *SetExtensionEventCallback) (jvmtiEnv* env,
+    jint extension_event_index,
+    jvmtiExtensionEvent callback);
+  jvmtiError ( *DisposeEnvironment) (jvmtiEnv* env);
+  jvmtiError ( *GetErrorName) (jvmtiEnv* env,
+    jvmtiError error,
+    char** name_ptr);
+  jvmtiError ( *GetJLocationFormat) (jvmtiEnv* env,
+    jvmtiJlocationFormat* format_ptr);
+  jvmtiError ( *GetSystemProperties) (jvmtiEnv* env,
+    jint* count_ptr,
+    char*** property_ptr);
+  jvmtiError ( *GetSystemProperty) (jvmtiEnv* env,
+    const char* property,
+    char** value_ptr);
+  jvmtiError ( *SetSystemProperty) (jvmtiEnv* env,
+    const char* property,
+    const char* value);
+  jvmtiError ( *GetPhase) (jvmtiEnv* env,
+    jvmtiPhase* phase_ptr);
+  jvmtiError ( *GetCurrentThreadCpuTimerInfo) (jvmtiEnv* env,
+    jvmtiTimerInfo* info_ptr);
+  jvmtiError ( *GetCurrentThreadCpuTime) (jvmtiEnv* env,
+    jlong* nanos_ptr);
+  jvmtiError ( *GetThreadCpuTimerInfo) (jvmtiEnv* env,
+    jvmtiTimerInfo* info_ptr);
+  jvmtiError ( *GetThreadCpuTime) (jvmtiEnv* env,
+    jthread thread,
+    jlong* nanos_ptr);
+  jvmtiError ( *GetTimerInfo) (jvmtiEnv* env,
+    jvmtiTimerInfo* info_ptr);
+  jvmtiError ( *GetTime) (jvmtiEnv* env,
+    jlong* nanos_ptr);
+  jvmtiError ( *GetPotentialCapabilities) (jvmtiEnv* env,
+    jvmtiCapabilities* capabilities_ptr);
+  void *reserved141;
+  jvmtiError ( *AddCapabilities) (jvmtiEnv* env,
+    const jvmtiCapabilities* capabilities_ptr);
+  jvmtiError ( *RelinquishCapabilities) (jvmtiEnv* env,
+    const jvmtiCapabilities* capabilities_ptr);
+  jvmtiError ( *GetAvailableProcessors) (jvmtiEnv* env,
+    jint* processor_count_ptr);
+  jvmtiError ( *GetClassVersionNumbers) (jvmtiEnv* env,
+    jclass klass,
+    jint* minor_version_ptr,
+    jint* major_version_ptr);
+  jvmtiError ( *GetConstantPool) (jvmtiEnv* env,
+    jclass klass,
+    jint* constant_pool_count_ptr,
+    jint* constant_pool_byte_count_ptr,
+    unsigned char** constant_pool_bytes_ptr);
+  jvmtiError ( *GetEnvironmentLocalStorage) (jvmtiEnv* env,
+    void** data_ptr);
+  jvmtiError ( *SetEnvironmentLocalStorage) (jvmtiEnv* env,
+    const void* data);
+  jvmtiError ( *AddToBootstrapClassLoaderSearch) (jvmtiEnv* env,
+    const char* segment);
+  jvmtiError ( *SetVerboseFlag) (jvmtiEnv* env,
+    jvmtiVerboseFlag flag,
+    jboolean value);
+  jvmtiError ( *AddToSystemClassLoaderSearch) (jvmtiEnv* env,
+    const char* segment);
+  jvmtiError ( *RetransformClasses) (jvmtiEnv* env,
+    jint class_count,
+    const jclass* classes);
+  jvmtiError ( *GetOwnedMonitorStackDepthInfo) (jvmtiEnv* env,
+    jthread thread,
+    jint* monitor_info_count_ptr,
+    jvmtiMonitorStackDepthInfo** monitor_info_ptr);
+  jvmtiError ( *GetObjectSize) (jvmtiEnv* env,
+    jobject object,
+    jlong* size_ptr);
+} jvmtiInterface_1;
+struct _jvmtiEnv {
+    const struct jvmtiInterface_1_ *functions;
+};
+struct bkpt {
+    CVMUint8* pc;
+    CVMUint8 opcode;
+    jobject classRef;
+};
+struct fpop {
+    CVMFrame* frame;
+};
+struct fieldWatch {
+    CVMFieldBlock* fb;
+    jclass classRef;
+};
+enum {
+    JVMTI_INTERNAL_CAPABILITY_COUNT = 39
+};
+typedef struct CVMJvmtiMethodNode CVMJvmtiMethodNode;
+struct CVMJvmtiMethodNode {
+    CVMUint32 mid;
+    CVMMethodBlock *mb;
+    CVMBool isObsolete;
+    CVMConstantPool *cp;
+    CVMJvmtiMethodNode *next;
+};
+typedef struct CVMJvmtiTagNode CVMJvmtiTagNode;
+struct CVMJvmtiTagNode {
+    jlong tag;
+    jobject ref;
+    CVMJvmtiTagNode *next;
+};
+enum {
+    JVMTI_MAGIC = 0x71EE,
+    BAD_MAGIC = 0xDEAD
+};
+typedef struct CVMJvmtiEventEnabled CVMJvmtiEventEnabled;
+struct CVMJvmtiEventEnabled{
+    jlong enabledBits;
+};
+typedef struct CVMJvmtiVisitStack CVMJvmtiVisitStack;
+struct CVMJvmtiVisitStack {
+    CVMObject **stackBase;
+    CVMObject **stackPtr;
+    jvmtiEnv *env;
+    int stackSize;
+};
+typedef struct CVMJvmtiDumpContext CVMJvmtiDumpContext;
+struct CVMJvmtiDumpContext {
+    jint heapFilter;
+    jclass klass;
+    const jvmtiHeapCallbacks *callbacks;
+    const void *userData;
+    CVMExecEnv *ee;
+    JNIEnv *env;
+    CVMFrame *frame;
+    jint frameCount;
+    CVMObjectICell *icell;
+};
+typedef struct CVMJvmtiEnvEventEnable CVMJvmtiEnvEventEnable;
+struct CVMJvmtiEnvEventEnable {
+    CVMJvmtiEventEnabled eventUserEnabled;
+    CVMJvmtiEventEnabled eventCallbackEnabled;
+    CVMJvmtiEventEnabled eventEnabled;
+};
+typedef struct CVMJvmtiContext CVMJvmtiContext;
+struct CVMJvmtiContext {
+    jvmtiEnv jvmtiExternal;
+    const void *envLocalStorage;
+    jvmtiEventCallbacks eventCallbacks;
+    jboolean isValid;
+    jboolean threadEventsEnabled;
+    jint magic;
+    jint index;
+    CVMJvmtiEnvEventEnable envEventEnable;
+    jvmtiCapabilities currentCapabilities;
+    jvmtiCapabilities prohibitedCapabilities;
+    jboolean classFileLoadHookEverEnabled;
+    char** nativeMethodPrefixes;
+    int nativeMethodPrefixCount;
+};
+jvmtiError CVMjvmtiVisitStackPush(CVMObject *obj);
+CVMBool CVMjvmtiVisitStackEmpty();
+void CVMjvmtiCleanupMarked();
+void CVMjvmtiRecomputeEnabled(CVMJvmtiEnvEventEnable *);
+jlong CVMjvmtiRecomputeThreadEnabled(CVMExecEnv *ee, CVMJvmtiEnvEventEnable *);
+int CVMjvmtiDestroyContext(CVMJvmtiContext *context);
+CVMClassBlock *CVMjvmtiClassRef2ClassBlock(CVMExecEnv *ee, jclass clazz);
+CVMBool CVMjvmtiIsGCOwner();
+void CVMjvmtiSetGCOwner(CVMBool);
+typedef struct CVMJvmtiThreadNode CVMJvmtiThreadNode;
+struct CVMJvmtiThreadNode {
+    CVMObjectICell* thread;
+    jobject lastDetectedException;
+    jvmtiStartFunction startFunction;
+    const void *startFunctionArg;
+    CVMJvmtiContext *context;
+    void *jvmtiPrivateData;
+    CVMClassBlock *oldCb;
+    CVMClassBlock *redefineCb;
+    CVMBool startEventSent;
+    CVMJvmtiThreadNode *next;
+};
+typedef struct CVMJvmtiGlobals CVMJvmtiGlobals;
+struct CVMJvmtiGlobals {
+    struct {
+ int fieldAccessCount;
+ int fieldModificationCount;
+ jboolean canGetSourceDebugExtension;
+ jboolean canExamineOrDeoptAnywhere;
+ jboolean canMaintainOriginalMethodOrder;
+ jboolean canPostInterpreterEvents;
+ jboolean canHotswapOrPostBreakpoint;
+ jboolean canModifyAnyClass;
+ jboolean canWalkAnySpace;
+ jboolean canAccessLocalVariables;
+ jboolean canPostExceptions;
+ jboolean canPostBreakpoint;
+ jboolean canPostFieldAccess;
+ jboolean canPostFieldModification;
+ jboolean canPostMethodEntry;
+ jboolean canPostMethodExit;
+ jboolean canPopFrame;
+ jboolean canForceEarlyReturn;
+ jboolean shouldPostSingleStep;
+ jboolean shouldPostFieldAccess;
+ jboolean shouldPostFieldModification;
+ jboolean shouldPostClassLoad;
+ jboolean shouldPostClassPrepare;
+ jboolean shouldPostClassUnload;
+ jboolean shouldPostClassFileLoadHook;
+ jboolean shouldPostNativeMethodBind;
+ jboolean shouldPostCompiledMethodLoad;
+ jboolean shouldPostCompiledMethodUnload;
+ jboolean shouldPostDynamicCodeGenerated;
+ jboolean shouldPostMonitorContendedEnter;
+ jboolean shouldPostMonitorContendedEntered;
+ jboolean shouldPostMonitorWait;
+ jboolean shouldPostMonitorWaited;
+ jboolean shouldPostDataDump;
+ jboolean shouldPostGarbageCollectionStart;
+ jboolean shouldPostGarbageCollectionFinish;
+ jboolean shouldPostThreadLife;
+ jboolean shouldPostObjectFree;
+ jboolean shouldCleanUpHeapObjects;
+ jboolean shouldPostVmObjectAlloc;
+ jboolean hasRedefinedAClass;
+ jboolean allDependenciesAreRecorded;
+    } exports;
+    CVMBool dataDumpRequested;
+    CVMBool isEnabled;
+    CVMBool isInDebugMode;
+    CVMBool debugOptionSet;
+    CVMBool isWatchingFieldAccess;
+    CVMBool isWatchingFieldModification;
+    struct {
+ JavaVM* vm;
+ struct CVMBag* breakpoints;
+ struct CVMBag* framePops;
+ struct CVMBag* watchedFieldModifications;
+ struct CVMBag* watchedFieldAccesses;
+ volatile CVMJvmtiThreadNode *threadList;
+ CVMJvmtiContext *context;
+ jvmtiPhase currentPhase;
+ CVMJvmtiMethodNode *nodeByMB[1531];
+ jfieldID nameID;
+ jfieldID priorityID;
+ jfieldID daemonID;
+ jfieldID groupID;
+ jfieldID loaderID;
+ jfieldID tgParentID;
+ jfieldID tgNameID;
+ jfieldID tgMaxPriorityID;
+ jfieldID tgDaemonID;
+ jfieldID nthreadsID;
+ jfieldID threadsID;
+ jfieldID ngroupsID;
+ jfieldID groupsID;
+ CVMJvmtiVisitStack currentStack;
+ CVMJvmtiTagNode *romObjects[1531];
+ CVMJvmtiTagNode *objectsByRef[1531];
+    } statics;
+    struct {
+ jvmtiCapabilities always;
+ jvmtiCapabilities onload;
+ jvmtiCapabilities always_solo;
+ jvmtiCapabilities onload_solo;
+ jvmtiCapabilities always_solo_remaining;
+ jvmtiCapabilities onload_solo_remaining;
+ jvmtiCapabilities acquired;
+    } capabilities;
+};
+void CVMjvmtiSetCanGetSourceDebugExtension(jboolean on);
+void CVMjvmtiSetCanExamineOrDeoptAnywhere(jboolean on);
+void CVMjvmtiSetCanMaintainOriginalMethodOrder(jboolean on);
+void CVMjvmtiSetCanPostInterpreterEvents(jboolean on);
+void CVMjvmtiSetCanHotswapOrPostBreakpoint(jboolean on);
+void CVMjvmtiSetCanModifyAnyClass(jboolean on);
+void CVMjvmtiSetCanWalkAnySpace(jboolean on);
+void CVMjvmtiSetCanAccessLocalVariables(jboolean on);
+void CVMjvmtiSetCanPostExceptions(jboolean on);
+void CVMjvmtiSetCanPostBreakpoint(jboolean on);
+void CVMjvmtiSetCanPostFieldAccess(jboolean on);
+void CVMjvmtiSetCanPostFieldModification(jboolean on);
+void CVMjvmtiSetCanPostMethodEntry(jboolean on);
+void CVMjvmtiSetCanPostMethodExit(jboolean on);
+void CVMjvmtiSetCanPopFrame(jboolean on);
+void CVMjvmtiSetCanForceEarlyReturn(jboolean on);
+void CVMjvmtiSetShouldPostSingleStep(jboolean on);
+void CVMjvmtiSetShouldPostFieldAccess(jboolean on);
+void CVMjvmtiSetShouldPostFieldModification(jboolean on);
+void CVMjvmtiSetShouldPostClassLoad(jboolean on);
+void CVMjvmtiSetShouldPostClassPrepare(jboolean on);
+void CVMjvmtiSetShouldPostClassUnload(jboolean on);
+void CVMjvmtiSetShouldPostClassFileLoadHook(jboolean on);
+void CVMjvmtiSetShouldPostNativeMethodBind(jboolean on);
+void CVMjvmtiSetShouldPostCompiledMethodLoad(jboolean on);
+void CVMjvmtiSetShouldPostCompiledMethodUnload(jboolean on);
+void CVMjvmtiSetShouldPostDynamicCodeGenerated(jboolean on);
+void CVMjvmtiSetShouldPostMonitorContendedEnter(jboolean on);
+void CVMjvmtiSetShouldPostMonitorContendedEntered(jboolean on);
+void CVMjvmtiSetShouldPostMonitorWait(jboolean on);
+void CVMjvmtiSetShouldPostMonitorWaited(jboolean on);
+void CVMjvmtiSetShouldPostGarbageCollectionStart(jboolean on);
+void CVMjvmtiSetShouldPostGarbageCollectionFinish(jboolean on);
+void CVMjvmtiSetShouldPostDataDump(jboolean on);
+void CVMjvmtiSetShouldPostObjectFree(jboolean on);
+void CVMjvmtiSetShouldPostVmObjectAlloc(jboolean on);
+void CVMjvmtiSetShouldPostThreadLife(jboolean on);
+void CVMjvmtiSetShouldCleanUpHeapObjects(jboolean on);
+jlong CVMjvmtiGetThreadEventEnabled(CVMExecEnv *ee);
+void CVMjvmtiSetShouldPostAnyThreadEvent(CVMExecEnv *ee, jlong enabled);
+enum {
+    JVMTIVERSIONMASK = 0x70000000,
+    JVMTIVERSIONVALUE = 0x30000000,
+    JVMDIVERSIONVALUE = 0x20000000
+};
+void CVMjvmtiEnterPrimordialPhase();
+void CVMjvmtiEnterOnloadPhase();
+void CVMjvmtiEnterStartPhase();
+void CVMjvmtiEnterLivePhase();
+void CVMjvmtiEnterDeadPhase();
+jvmtiPhase CVMjvmtiGetPhase();
+jboolean CVMjvmtiCanGetSourceDebugExtension();
+jboolean CVMjvmtiCanExamineOrDeoptAnywhere();
+jboolean CVMjvmtiCanMaintainOriginalMethodOrder();
+jboolean CVMjvmtiCanPostInterpreterEvents();
+jboolean CVMjvmtiCanHotswapOrPostBreakpoint();
+jboolean CVMjvmtiCanModifyAnyClass();
+jboolean CVMjvmtiCanWalkAnySpace();
+jboolean CVMjvmtiCanAccessLocalVariables();
+jboolean CVMjvmtiCanPostExceptions();
+jboolean CVMjvmtiCanPostBreakpoint();
+jboolean CVMjvmtiCanPostFieldAccess();
+jboolean CVMjvmtiCanPostFieldModification();
+jboolean CVMjvmtiCanPostMethodEntry();
+jboolean CVMjvmtiCanPostMethodExit();
+jboolean CVMjvmtiCanPopFrame();
+jboolean CVMjvmtiCanForceEarlyReturn();
+jboolean CVMjvmtiShouldPostThreadLife();
+jboolean CVMjvmtiShouldPostSingleStep();
+jboolean CVMjvmtiShouldPostFieldAccess();
+jboolean CVMjvmtiShouldPostFieldModification();
+jboolean CVMjvmtiShouldPostClassLoad();
+jboolean CVMjvmtiShouldPostClassPrepare();
+jboolean CVMjvmtiShouldPostClassUnload();
+jboolean CVMjvmtiShouldPostClassFileLoadHook();
+jboolean CVMjvmtiShouldPostNativeMethodBind();
+jboolean CVMjvmtiShouldPostCompiledMethodLoad();
+jboolean CVMjvmtiShouldPostCompiledMethodUnload();
+jboolean CVMjvmtiShouldPostDynamicCodeGenerated();
+jboolean CVMjvmtiShouldPostMonitorContendedEnter();
+jboolean CVMjvmtiShouldPostMonitorContendedEntered();
+jboolean CVMjvmtiShouldPostMonitorWait();
+jboolean CVMjvmtiShouldPostMonitorWaited();
+jboolean CVMjvmtiShouldPostDataDump();
+jboolean CVMjvmtiShouldPostGarbageCollectionStart();
+jboolean CVMjvmtiShouldPostGarbageCollectionFinish();
+jboolean CVMjvmtiShouldPostObjectFree();
+jboolean CVMjvmtiShouldPostVmObjectAlloc();
+char** getAllNativeMethodPrefixes(int* countPtr);
+void cmsRefProcessingEpilogue();
+typedef struct AttachOperation_ {
+  char *args;
+} AttachOperation;
+typedef enum CVMJvmtiLoadKind CVMJvmtiLoadKind;
+enum CVMJvmtiLoadKind {
+  JVMTICLASSLOADKINDNORMAL = 0,
+  JVMTICLASSLOADKINDREDEFINE,
+  JVMDICLASSLOADKINDRETRANSFORM
+};
+typedef struct CVMJvmtiLockInfo CVMJvmtiLockInfo;
+struct CVMJvmtiLockInfo {
+    CVMJvmtiLockInfo *next;
+    CVMOwnedMonitor *lock;
+};
+typedef struct CVMJvmtiExecEnv CVMJvmtiExecEnv;
+struct CVMJvmtiExecEnv {
+    CVMBool debugEventsEnabled;
+    CVMBool jvmtiSingleStepping;
+    CVMBool jvmtiNeedFramePop;
+    CVMBool jvmtiNeedEarlyReturn;
+    CVMBool jvmtiDataDumpRequested;
+    CVMBool jvmtiNeedProcessing;
+    CVMJvmtiEventEnabled jvmtiUserEventEnabled;
+    CVMJvmtiEventEnabled jvmtiEventEnabled;
+    jvalue jvmtiEarlyReturnValue;
+    CVMUint32 jvmtiEarlyRetOpcode;
+    CVMJvmtiLockInfo *jvmtiLockInfoFreelist;
+    void *jvmtiProfilerData;
+};
+void CVMjvmtiPostExceptionEvent(CVMExecEnv* ee,
+    CVMUint8* pc,
+    CVMObjectICell* object);
+void CVMjvmtiPostExceptionCatchEvent(CVMExecEnv* ee,
+         CVMUint8* pc,
+         CVMObjectICell* object);
+void CVMjvmtiPostSingleStepEvent(CVMExecEnv* ee,
+     CVMUint8* pc);
+void CVMjvmtiPostFieldAccessEvent(CVMExecEnv* ee,
+      CVMObjectICell* obj,
+      CVMFieldBlock* fb);
+void CVMjvmtiPostFieldModificationEvent(CVMExecEnv* ee,
+     CVMObjectICell* obj,
+     CVMFieldBlock* fb,
+            jvalue jval);
+void CVMjvmtiPostThreadStartEvent(CVMExecEnv* ee,
+      CVMObjectICell* thread);
+void CVMjvmtiPostThreadEndEvent(CVMExecEnv* ee,
+    CVMObjectICell* thread);
+void CVMjvmtiPostFramePushEvent(CVMExecEnv* ee);
+void CVMjvmtiPostFramePopEvent(CVMExecEnv* ee, CVMBool isRef,
+          CVMBool isException, jvalue *retValue);
+void CVMjvmtiPostClassLoadEvent(CVMExecEnv* ee,
+    CVMObjectICell* clazz);
+void CVMjvmtiPostClassPrepareEvent(CVMExecEnv* ee,
+       CVMObjectICell* clazz);
+void CVMjvmtiPostClassUnloadEvent(CVMExecEnv* ee,
+      CVMObjectICell* clazz);
+void CVMjvmtiPostVmStartEvent(CVMExecEnv* ee);
+void CVMjvmtiPostVmInitEvent(CVMExecEnv* ee);
+void CVMjvmtiPostVmExitEvent(CVMExecEnv* ee);
+CVMUint8 CVMjvmtiGetBreakpointOpcode(CVMExecEnv* ee, CVMUint8* pc,
+         CVMBool notify);
+CVMBool CVMjvmtiSetBreakpointOpcode(CVMExecEnv* ee, CVMUint8* pc,
+        CVMUint8 opcode);
+void CVMjvmtiPostClassLoadHookEvent(jclass klass,
+        CVMClassLoaderICell *loader,
+        const char *className,
+        jobject protectionDomain,
+        CVMInt32 bufferLength,
+        CVMUint8 *buffer,
+        CVMInt32 *newBufferLength,
+        CVMUint8 **newBuffer);
+void CVMjvmtiPostCompiledMethodLoadEvent(CVMExecEnv *ee,
+      CVMMethodBlock *mb);
+void CVMjvmtiPostCompiledMethodUnloadEvent(CVMExecEnv *ee,
+        CVMMethodBlock* mb);
+void CVMjvmtiPostDataDumpRequest(void);
+void CVMjvmtiPostGCStartEvent(void);
+void CVMjvmtiPostGCFinishEvent(void);
+void CVMjvmtiPostStartUpEvents(CVMExecEnv *ee);
+void CVMjvmtiPostNativeMethodBind(CVMExecEnv *ee, CVMMethodBlock *mb,
+      CVMUint8 *nativeCode,
+      CVMUint8 **newNativeCode);
+void CVMjvmtiPostMonitorContendedEnterEvent(CVMExecEnv *ee,
+         CVMProfiledMonitor *pm);
+void CVMjvmtiPostMonitorContendedEnteredEvent(CVMExecEnv *ee,
+                                              CVMProfiledMonitor *pm);
+void CVMjvmtiPostMonitorWaitEvent(CVMExecEnv *ee,
+      jobject obj, jlong millis);
+void CVMjvmtiPostMonitorWaitedEvent(CVMExecEnv *ee,
+        jobject obj, CVMBool timedout);
+void CVMjvmtiPostObjectFreeEvent(CVMObject *obj);
+CVMBool CVMjvmtiDataDumpWasRequested(void);
+void CVMjvmtiResetDataDumpRequested(void);
+jint CVMjvmtiGetInterface(JavaVM *interfacesVm, void **penv);
+void CVMjvmtiInitializeGlobals(CVMJvmtiGlobals *globals);
+void CVMjvmtiDestroyGlobals(CVMJvmtiGlobals *globals);
+jvmtiError CVMjvmtiInitialize(JavaVM *vm);
+void CVMjvmtiDestroy(CVMJvmtiGlobals *globals);
+CVMJvmtiThreadNode *
+CVMjvmtiFindThread(CVMExecEnv* ee, CVMObjectICell* thread);
+CVMJvmtiThreadNode *
+CVMjvmtiInsertThread(CVMExecEnv* ee, CVMObjectICell* thread);
+jboolean CVMjvmtiRemoveThread(CVMExecEnv* ee, CVMObjectICell *thread);
+jvmtiError CVMjvmtiAllocate(jlong size, unsigned char **mem);
+jvmtiError CVMjvmtiDeallocate(unsigned char *mem);
+CVMBool CVMjvmtiClassBeingRedefined(CVMExecEnv *ee, CVMClassBlock *cb);
+CVMClassBlock *CVMjvmtiClassObject2ClassBlock(CVMExecEnv *ee, CVMObject *obj);
+void CVMjvmtiRehash(void);
+CVMUint32 CVMjvmtiUniqueID();
+void CVMjvmtiMarkAsObsolete(CVMMethodBlock *oldmb, CVMConstantPool *cp);
+CVMBool CVMjvmtiMbIsObsoleteX(CVMMethodBlock *mb);
+CVMConstantPool * CVMjvmtiMbConstantPool(CVMMethodBlock *mb);
+CVMBool CVMjvmtiCheckLockInfo(CVMExecEnv *ee);
+void CVMjvmtiAddLockInfo(CVMExecEnv *ee, CVMObjMonitor *mon,
+                                CVMOwnedMonitor *o,
+                                CVMBool okToBecomeGCSafe);
+void CVMjvmtiRemoveLockInfo(CVMExecEnv *ee, CVMObjMonitor *mon,
+                                   CVMOwnedMonitor *o);
+CVMClassBlock* CVMjvmtiGetCurrentRedefinedClass(CVMExecEnv *ee);
+void CVMjvmtiDestroyLockInfo(CVMExecEnv *ee);
+typedef enum {
+    CVM_THREAD_RUNNING = 0x0,
+    CVM_THREAD_TERMINATED = 0x2,
+    CVM_THREAD_WAITING_INDEFINITE = 0x10,
+    CVM_THREAD_WAITING_TIMEOUT = 0x20,
+    CVM_THREAD_SLEEPING = 0x40,
+    CVM_THREAD_WAITING = 0x80,
+    CVM_THREAD_OBJECT_WAIT = 0x100,
+    CVM_THREAD_BLOCKED_MONITOR_ENTER = 0x400,
+    CVM_THREAD_SUSPENDED = 0x100000,
+    CVM_THREAD_INTERRUPTED = 0x200000,
+    CVM_THREAD_IN_NATIVE = 0x400000,
+    CVM_THREAD_STACK_MUTATOR_LOCK = 0x800000
+} CVMThreadState;
+typedef enum {
+    CVM_EXCEPTION_NONE = 0,
+    CVM_EXCEPTION_TOP,
+    CVM_EXCEPTION_UNWINDING
+}CVMExceptionState;
+struct CVMExecEnv {
+    CVMTCState tcstate[CVM_NUM_CONSISTENT_STATES];
+    CVMUint8 isThrowingAnException;
+    CVMUint8 isHandlingAnException;
+    CVMUint16 remoteExceptionsDisabledCount;
+    CVMThrowableICell* localExceptionICell;
+    CVMThrowableICell* remoteExceptionICell;
+    CVMThrowableICell* currentExceptionICell;
+    union {
+ struct {
+     CVMUint8 remote;
+     CVMUint8 local;
+ } oneflag;
+ CVMUint16 bothflags;
+    } exceptionFlags;
+    CVMThreadICell* threadICell;
+    CVMObjectICell* miscICell;
+    CVMObjectICell* syncICell;
+    CVMObjectICell* finalizerRegisterICell;
+    CVMJNIEnv jniEnv;
+    CVMExecEnv **prevEEPtr;
+    CVMExecEnv *nextEE;
+    CVMStack interpreterStack;
+    CVMStack localRootsStack;
+    CVMBool cstackBufferFlag;
+    char *cstackBuffer;
+    void * nativeRunInfo;
+    CVMObjMonitor * volatile objLockCurrent;
+    CVMObjMonitor *objLocksFreeUnlocked;
+    CVMOwnedMonitor *objLocksOwned;
+    CVMOwnedMonitor *objLocksFreeOwned;
+    CVMBool threadExiting;
+    CVMOwnedMonitor *objLocksReservedOwned;
+    CVMObjMonitor *objLocksReservedUnlocked;
+    CVMThreadID threadInfo;
+    CVMThreadState threadState;
+    CVMUint32 threadID;
+    int nativeRunInfoType;
+    CVMSysMutex *sysLocks;
+    int microLock;
+    CVMBool userThread;
+    CVMObjectICell* allocationRetryICell;
+    CVMUint32 criticalCount;
+    CVMBool hasPostedExitEvents;
+    volatile CVMJvmtiExecEnv jvmtiEE;
+    CVMProfiledMonitor *blockingLockEntryMonitor;
+    CVMProfiledMonitor *blockingWaitMonitor;
+    CVMBool hasRun;
+    CVMBool interruptsMasked;
+    CVMBool maskedInterrupt;
+    CVMObjMonitor *objLocksPinned[16];
+    CVMSize objLocksPinnedCount;
+    CVMUint32 traceDepth;
+    CVMInt32 priority;
+    CVMUint32 tickCount;
+    CVMUint32 debugFlags;
+};
+typedef struct {
+    CVMThreadICell* threadICell;
+    void (*nativeFunc)(void *);
+    void* nativeFuncArg;
+    CVMBool isDaemon;
+    int started;
+    CVMMutex parentLock;
+    CVMCondVar parentCond;
+    CVMExecEnv *ee;
+    int priority;
+} CVMThreadStartInfo;
+extern CVMBool
+CVMinitExecEnv(CVMExecEnv* ee, CVMExecEnv *targetEE,
+        CVMThreadStartInfo* threadInfo);
+extern void
+CVMdestroyExecEnv(CVMExecEnv* ee);
+extern CVMBool
+CVMattachExecEnv(CVMExecEnv* ee, CVMBool orphan);
+extern void
+CVMdetachExecEnv(CVMExecEnv* ee);
+extern CVMExecEnv * CVMgetEE();
+extern void CVMaddThread(CVMExecEnv *ee, CVMBool userThread);
+extern void CVMremoveThread(CVMExecEnv *ee, CVMBool userThread);
+struct CVMInterpreterFrame {
+    CVMFrame frameX;
+    CVMUint8* pcX;
+    CVMConstantPool* cpX;
+    CVMSlotVal32* localsX;
+};
+struct CVMJavaFrame {
+    CVMInterpreterFrame frameX;
+    CVMJvmtiLockInfo *jvmtiLockInfo;
+    CVMObjectICell receiverObjX;
+    CVMStackVal32 opstackX[1];
+};
+struct CVMTransitionFrame {
+    CVMInterpreterFrame frameX;
+    CVMBool incrementPcFlagX;
+    CVMStackVal32 opstackX[1];
+};
+extern CVMInterpreterFrame *CVMDEBUGgetInterpreterFrame(CVMFrame *frame);
+extern void
+CVMgcUnsafeExecuteJavaMethod(CVMExecEnv* volatile ee, CVMMethodBlock* mb,
+        CVMBool isStatic, CVMBool isVirtual);
+extern void
+CVMgcUnsafeExecuteJavaMethodJVMTI(CVMExecEnv* volatile ee, CVMMethodBlock* mb,
+                                  CVMBool isStatic, CVMBool isVirtual);
+extern CVMUint8* CVMgcUnsafeExecuteJavaMethodQuick(CVMExecEnv* ee,
+    CVMUint8* pc, CVMStackVal32* topOfStack, CVMSlotVal32* locals,
+    CVMConstantPool* cp, CVMClassBlock** retCb);
+extern CVMInt32
+CVMpc2lineno(CVMMethodBlock *mb, CVMUint16 pc_offset);
+extern void
+CVMframe2string(CVMFrame* frame, char *buf, char* limit);
+extern void
+CVMframeIterate2string(CVMFrameIterator* frame, char *buf, char* limit);
+extern void
+CVMpc2string(CVMUint8* pc, CVMMethodBlock* mb,
+      CVMBool isTransition, CVMBool isCompiled, char *buf, char* limit);
+extern void
+CVMlineno2string(CVMInt32 lineno, CVMMethodBlock* mb,
+      CVMBool isTransition, CVMBool isCompiled, char *buf, char* limit);
+extern CVMUint8*
+CVMgcSafeFindPCForException(CVMExecEnv* ee, CVMFrameIterator* frame,
+       CVMClassBlock* exceptionClass, CVMUint8* pc);
+extern CVMFrame*
+CVMgcUnsafeHandleException(CVMExecEnv* ee, CVMFrame* frame,
+      CVMFrame* initialframe);
+extern void
+CVMsignalError(CVMExecEnv* ee, CVMClassBlock* exceptionCb,
+        const char *format, ...);
+extern void
+CVMsignalErrorVaList(CVMExecEnv* ee, CVMClassBlock* exceptionCb,
+       const char* format, va_list ap);
+extern CVMTransitionFrame*
+CVMpushTransitionFrame(CVMExecEnv* ee, CVMMethodBlock* mb);
+extern CVMBool
+CVMjavaFrameEnsureStackmaps(CVMExecEnv *ee, CVMExecEnv *frameEE,
+                            CVMFrame *frame);
+typedef struct {
+    CVMExecEnv *targetEE;
+    CVMFrame *prevFrame;
+    void *callbackData;
+} CVMInterpreterStackData;
+extern CVMStackMapEntry*
+CVMgetStackmapEntry(CVMExecEnv *frameEE, CVMFrame *frame,
+      CVMJavaMethodDescriptor *jmd, CVMStackMaps *stackmaps,
+      CVMBool *missingStackmapOK);
+CVMUint8*
+CVMfindInnermostHandlerFor(CVMJavaMethodDescriptor* jmd, CVMUint8* pc);
+CVMClassBlock* CVMgetCallerClass(CVMExecEnv* ee, int skip);
+CVMFrame*
+CVMgetCallerFrameSpecial(CVMFrame* frame, int n, CVMBool skipReflection);
+struct CVMFrameIterator {
+    CVMStack *stack;
+    CVMFrame *endFrame;
+    CVMFrame *frame;
+    CVMFrame *next;
+};
+void
+CVMframeIterateInitSpecial(CVMFrameIterator *iter, CVMStack *stack,
+      CVMFrame* firstFrame, CVMFrame *lastFrame);
+void
+CVMframeIterateInit(CVMFrameIterator *iter, CVMFrame* firstFrame);
+CVMBool
+CVMframeIterateSkipReflection(CVMFrameIterator *iter,
+    int skip, CVMBool skipReflection, CVMBool popFrame);
+CVMUint32
+CVMframeIterateCount(CVMFrameIterator *iter);
+CVMBool
+CVMframeIterateIsInlined(CVMFrameIterator *iter);
+CVMBool
+CVMframeIterateHandlesExceptions(CVMFrameIterator *iter);
+CVMBool
+CVMframeIterateCanHaveJavaCatchClause(CVMFrameIterator *iter);
+CVMFrameFlags
+CVMframeIterateGetFlags(CVMFrameIterator *iter);
+void
+CVMframeIterateSetFlags(CVMFrameIterator *iter, CVMFrameFlags flags);
+CVMFrame *
+CVMframeIterateGetFrame(CVMFrameIterator *iter);
+CVMMethodBlock *
+CVMframeIterateGetMb(CVMFrameIterator *iter);
+CVMUint8 *
+CVMframeIterateGetJavaPc(CVMFrameIterator *iter);
+void
+CVMframeIterateSetJavaPc(CVMFrameIterator *iter, CVMUint8 *pc);
+CVMStackVal32 *
+CVMframeIterateGetLocals(CVMFrameIterator *iter);
+CVMObjectICell *
+CVMframeIterateSyncObject(CVMFrameIterator *iter);
+CVMMethodBlock *
+CVMgetCallerMb(CVMFrame* frame, int skip);
+void
+CVMframeSetContextArtificial(CVMExecEnv *ee);
+extern CVMBool
+CVMisAssignable(CVMExecEnv* ee, CVMClassBlock* srcCb,
+  CVMClassBlock* dstCb);
+extern CVMBool
+CVMgcUnsafeIsInstanceOf(CVMExecEnv* ee, CVMObject* obj,
+   CVMClassBlock* cb);
+extern CVMBool
+CVMisSubclassOf(CVMExecEnv* ee, CVMClassBlock* subclasscb,
+  CVMClassBlock* cb);
+extern CVMBool
+CVMextendsClass(CVMExecEnv* ee, CVMClassBlock* subclasscb, CVMClassBlock* cb);
+extern CVMBool
+CVMimplementsInterface(CVMExecEnv* ee, CVMClassBlock* cb,
+         CVMClassBlock* interfacecb);
+CVMBool
+CVMverifyClassAccess(CVMExecEnv* ee,
+       CVMClassBlock* currentClass, CVMClassBlock* newClass,
+       CVMBool resolverAccess);
+extern CVMBool
+CVMverifyMemberAccess3(CVMExecEnv* ee,
+                       CVMClassBlock* currentClass,
+                       CVMClassBlock* resolvedClass,
+                       CVMClassBlock* memberClass,
+                       CVMUint32 access, CVMBool resolverAccess,
+                       CVMBool protectedRestriction);
+extern CVMBool
+CVMverifyMemberAccess2(CVMExecEnv* ee,
+         CVMClassBlock* currentClass,
+         CVMClassBlock* memberClass,
+         CVMUint32 access, CVMBool resolverAccess,
+         CVMBool protectedRestriction);
+CVMBool
+CVMverifyMemberAccess(CVMExecEnv* ee,
+        CVMClassBlock* currentClass,
+        CVMClassBlock* memberClass,
+        int access, CVMBool resolverAccess);
+extern CVMBool
+CVMisTrustedClassLoader(CVMExecEnv* ee, CVMClassLoaderICell* loader);
+extern void
+CVMmultiArrayAlloc(CVMExecEnv* ee,
+     CVMInt32 nDimensions,
+     CVMStackVal32* dimensions,
+     CVMClassBlock* arrayCb,
+     CVMObjectICell* resultCell);
+extern void
+CVMdisableRemoteExceptions(CVMExecEnv* ee);
+extern void
+CVMenableRemoteExceptions(CVMExecEnv* ee);
+extern CVMBool
+CVMremoteExceptionsDisabled(CVMExecEnv* ee);
+extern void
+CVMfillInStackTrace(CVMExecEnv *ee, CVMThrowableICell* objICell);
+extern void
+CVMprintStackTrace(CVMExecEnv *ee, CVMThrowableICell* throwableICell,
+     CVMObjectICell* printableICell);
+typedef enum {
+    CVM_QUICKEN_SUCCESS_OPCODE_ONLY,
+    CVM_QUICKEN_SUCCESS_OPCODE_AND_OPERANDS,
+    CVM_QUICKEN_NEED_TO_RUN_STATIC_INITIALIZERS,
+    CVM_QUICKEN_ALREADY_QUICKENED,
+    CVM_QUICKEN_ERROR
+} CVMQuickenReturnCode;
+extern CVMQuickenReturnCode
+CVMquickenOpcode(CVMExecEnv* ee, CVMUint8* pc,
+   CVMConstantPool* cp, CVMClassBlock** p_cb,
+   CVMBool clobbersCpIndex);
+extern CVMBool
+CVMisSpecialSuperCall(CVMClassBlock* currClass, CVMMethodBlock* mb);
+CVMMethodBlock*
+CVMlookupSpecialSuperMethod(CVMExecEnv* ee,
+       CVMClassBlock* currClass,
+       CVMMethodTypeID methodID);
+extern CVMBool
+CVMclassIsOKToInstantiate(CVMExecEnv *ee, CVMClassBlock *cb);
+extern CVMBool
+CVMfieldHasNotChangeStaticState(CVMExecEnv *ee, CVMFieldBlock *fb,
+                                CVMBool expectToBeStatic);
+extern CVMBool
+CVMfieldIsOKToWriteTo(CVMExecEnv *ee, CVMFieldBlock *fb,
+        CVMClassBlock *currentCb, CVMBool okToThrow);
+extern CVMBool
+CVMmethodHasNotChangeStaticState(CVMExecEnv *ee, CVMMethodBlock *mb,
+                                 CVMBool expectToBeStatic);
+extern void
+CVMinitStats();
+extern void
+CVMdumpStats();
+extern void
+CVMlocksForGCAcquire(CVMExecEnv* ee);
+extern void
+CVMlocksForGCRelease(CVMExecEnv* ee);
+extern CVMBool CVMsuspendCheckerInit();
+extern void CVMsuspendCheckerDestroy();
+extern CVMBool CVMsuspendCheckerIsOK(CVMExecEnv *ee, CVMExecEnv *targetEE);
+extern void
+CVMlocksForThreadSuspendAcquire(CVMExecEnv* ee);
+extern void
+CVMlocksForThreadSuspendRelease(CVMExecEnv* ee);
+extern void
+CVMthreadSuspendConsistentRequest(CVMExecEnv* ee);
+extern void
+CVMthreadSuspendConsistentRelease(CVMExecEnv* ee);
+typedef enum {
+    CVM_MangleMethodName_JNI_SHORT,
+    CVM_MangleMethodName_JNI_LONG,
+    CVM_MangleMethodName_CNI_SHORT
+} CVMMangleType;
+extern char*
+CVMmangleMethodName(CVMExecEnv* ee, CVMMethodBlock* mb,
+      CVMMangleType mangleType);
+extern CVMBool
+CVMlookupNativeMethodCode(CVMExecEnv* ee, CVMMethodBlock* mb);
+extern void CVMwaitForUserThreads(CVMExecEnv *ee);
+extern void CVMwaitForAllThreads(CVMExecEnv *ee);
+extern int CVMprepareToExit(void);
+extern int CVMatExit(void (*func)(void));
+extern void CVMexit(int);
+extern void CVMabort(void);
+extern CVMBool CVMsafeExit(CVMExecEnv *ee, CVMInt32 status);
+extern void
+CVMunloadApplicationclasses(CVMExecEnv* ee);
+extern void CVMtraceInit();
+extern void CVMtraceReset(CVMUint32 old, CVMUint32 nnew);
+extern void CVMtraceMethodCall(CVMExecEnv *ee,
+          CVMFrame* frame, CVMBool isJump);
+extern void CVMtraceMethodReturn(CVMExecEnv *ee, CVMFrame* frame);
+extern void CVMtraceFramelessMethodCall(CVMExecEnv *ee,
+            CVMFrame* frame, CVMMethodBlock *mb,
+     CVMBool isJump);
+extern void CVMtraceFramelessMethodReturn(CVMExecEnv *ee, CVMMethodBlock *mb,
+       CVMFrame* frame);
+CVMBool
+CVMsyncReturnHelper(CVMExecEnv *ee, CVMFrame *frame, CVMObjectICell *objICell,
+      CVMBool areturn);
+CVMUint32
+CVMregisterReturnEvent(CVMExecEnv *ee, CVMUint8* pc, CVMUint32 ret_opcode,
+         jvalue *retValue);
+CVMUint32
+CVMregisterReturnEventPC(CVMExecEnv *ee, CVMUint8* pc,
+    jvalue *retValue);
+CVMBool
+CVMinvokeJNIHelper(CVMExecEnv *ee, CVMMethodBlock *mb);
+void CVMpostThreadStartEvents(CVMExecEnv *ee);
+void CVMpostThreadExitEvents(CVMExecEnv *ee);
+void
+CVMcopyRefArrays(CVMExecEnv* ee,
+   CVMArrayOfRef* srcArr, jint src_pos,
+   CVMArrayOfRef* dstArr, jint dst_pos,
+   CVMClassBlock* dstElemCb, jint length);
+CVMBool CVMmaskInterrupts(CVMExecEnv *ee);
+void CVMunmaskInterrupts(CVMExecEnv *ee);
+typedef struct CVMPackage CVMPackage;
+struct CVMPackage {
+    char *packageName;
+    char *filename;
+    CVMPackage* next;
+};
+extern char*
+CVMpackagesGetEntry(const char* name);
+extern CVMBool
+CVMpackagesAddEntry(const char *name, const char *filename);
+extern void
+CVMpackagesDestroy();
+typedef jint ( *JVM_OnLoad_t)(JavaVM *, char *, void *);
+typedef void ( *JVM_OnUnload_t)(JavaVM *);
+typedef struct CVMXrunItem {
+    jobject shareLibRef;
+    JVM_OnUnload_t onUnloadFunc;
+} CVMXrunItem;
+typedef struct CVMXrunTable {
+    CVMInt32 elemIdx;
+    CVMInt32 elemCnt;
+    CVMXrunItem *table;
+} CVMXrunTable;
+extern CVMBool
+CVMXrunInitTable(CVMXrunTable *onUnloadTable, CVMInt32 numXrunArguments);
+extern void
+CVMXrunAppendToTable(CVMXrunTable *onUnloadTable, jobject libRef,
+       JVM_OnUnload_t fptr);
+extern void
+CVMXrunProcessTable(CVMXrunTable *onUnloadTable, JNIEnv *env, JavaVM *vm);
+extern CVMBool
+CVMXrunHandleArgument(CVMXrunTable *onUnloadTable, JNIEnv* env, char* arg);
+typedef jint ( *Agent_OnLoad_t)(JavaVM *, char *, void *);
+typedef void ( *Agent_OnUnload_t)(JavaVM *);
+typedef struct CVMAgentlibArg {
+  char *str;
+  CVMBool is_absolute;
+} CVMAgentlibArg_t;
+typedef struct CVMAgentItem {
+    void *libHandle;
+    Agent_OnUnload_t onUnloadFunc;
+} CVMAgentItem;
+typedef struct CVMAgentTable {
+    CVMInt32 elemIdx;
+    CVMInt32 elemCnt;
+    CVMAgentItem *table;
+} CVMAgentTable;
+extern CVMBool
+CVMAgentInitTable(CVMAgentTable *table, CVMInt32 numAgentArguments);
+extern void
+CVMAgentAppendToTable(CVMAgentTable *table, void *libHandle,
+        Agent_OnUnload_t fptr);
+extern void
+CVMAgentProcessTableUnload(CVMAgentTable *agentTable,
+      JNIEnv *env, JavaVM *vm);
+extern CVMBool
+CVMAgentHandleArgument(CVMAgentTable *agentTable, JNIEnv* env,
+         CVMAgentlibArg_t* arg);
+enum {
+    CVM_HEAPSTATEOBJ_INITIAL = 0,
+    CVM_HEAPSTATEOBJ_FREED
+};
+typedef struct CVMHeapStateObject CVMHeapStateObject;
+struct CVMHeapStateObject
+{
+    CVMObject *obj;
+    CVMUint32 size;
+};
+typedef struct CVMHeapState CVMHeapState;
+struct CVMHeapState
+{
+    CVMHeapState *next;
+    char *name;
+    CVMUint32 id;
+    CVMUint32 timeStamp;
+    CVMUint32 numberOfObjects;
+    CVMUint32 totalSize;
+    CVMHeapStateObject objects[1];
+};
+typedef struct CVMInspector CVMInspector;
+struct CVMInspector {
+    CVMBool keepAllObjectsAlive;
+    CVMBool hasCapturedState;
+    CVMUint32 lastHeapStateID;
+    CVMHeapState *heapStates;
+};
+void CVMinspectorGCLockerUnlock(CVMGCLocker *self, CVMExecEnv *current_ee);
+void CVMinspectorGCLockerWait(CVMGCLocker *self, CVMExecEnv *current_ee);
+extern CVMBool CVMgcIsValidObject(CVMExecEnv *ee, CVMObject *obj);
+CVMBool CVMgcDisableGC(void);
+CVMBool CVMgcEnableGC(void);
+CVMBool CVMgcIsDisabled(void);
+void CVMgcKeepAllObjectsAlive(CVMBool keepAlive);
+void CVMgcDumpObjectReferences(CVMObject *obj);
+void CVMgcDumpClassReferences(const char *clazzname);
+void CVMgcDumpClassBlocks(const char *clazzname);
+void CVMgcDumpObjectGCRoots(CVMObject *obj);
+extern void
+CVMgcDumpHeapSimple();
+extern void
+CVMgcDumpHeapVerbose();
+extern void
+CVMgcDumpHeapStats();
+enum {
+    CVM_HEAPSTATE_SORT_NONE = 0,
+    CVM_HEAPSTATE_SORT_BY_OBJ,
+    CVM_HEAPSTATE_SORT_BY_OBJCLASS
+};
+extern void
+CVMgcCaptureHeapState(const char *name);
+extern void
+CVMgcReleaseHeapState(CVMUint32 id);
+extern void
+CVMgcReleaseAllHeapState(void);
+extern void
+CVMgcListHeapStates(void);
+extern void
+CVMgcDumpHeapState(CVMUint32 id, int sortKey);
+extern void
+CVMgcCompareHeapState(CVMUint32 id1, CVMUint32 id2);
+extern void
+CVMgcHeapStateObjectMoved(CVMObject *oldObj, CVMObject *newObj);
+extern void
+CVMgcHeapStateObjectFreed(CVMObject *obj);
+extern void CVMdumpObject(CVMObject* directObj);
+extern void CVMdumpClassBlock(CVMClassBlock *cb);
+extern void CVMdumpString(CVMObject *string);
+extern void CVMdumpObjectReferences(CVMObject *obj);
+extern void CVMdumpClassReferences(const char *clazzname);
+extern void CVMdumpClassBlocks(const char *clazzname);
+extern void CVMdumpObjectGCRoots(CVMObject *obj);
+extern void CVMdumpSysInfo();
+typedef void (*pProc)(void);
+typedef struct exit_proc {
+    pProc proc;
+    struct exit_proc *next;
+} * exit_procPtr;
+typedef void (*loopProcPtr)(CVMExecEnv*, CVMMethodBlock *, CVMBool, CVMBool);
+struct CVMOptions {
+    void *vfprintfHook;
+    void *exitHook;
+    void *abortHook;
+    void *safeExitHook;
+    CVMBool timeStampEnabled;
+    const char *startHeapSizeStr;
+    const char *minHeapSizeStr;
+    const char *maxHeapSizeStr;
+    const char *nativeStackSizeStr;
+    const char *gcAttributesStr;
+    const char *optAttributesStr;
+    const char *traceFlagsStr;
+    CVMBool debugging;
+    CVMUint16 classVerificationLevel;
+    const char *bootclasspathStr;
+    const char *appclasspathStr;
+    CVMBool fullShutdownFlag;
+    CVMBool javaAssertionsUserDefault;
+    CVMBool javaAssertionsSysDefault;
+    CVMJavaAssertionsOptionList* javaAssertionsClasses;
+    CVMJavaAssertionsOptionList* javaAssertionsPackages;
+};
+struct CVMGlobalState {
+    CVMUint32** allocPtrPtr;
+    CVMUint32** allocTopPtr;
+    CVMAddr unused1;
+    CVMUint32 debugFlags;
+    CVMUint32 unused3;
+    CVMUint32 unused4;
+    CVMCState cstate[CVM_NUM_CONSISTENT_STATES];
+    CVMMutex objGlobalMicroLock;
+    CVMSysMutex globalRootsLock;
+    CVMStack globalRoots;
+    CVMSysMutex weakGlobalRootsLock;
+    CVMStack weakGlobalRoots;
+    CVMStack classGlobalRoots;
+    CVMStack classLoaderGlobalRoots;
+    CVMStack protectionDomainGlobalRoots;
+    CVMStack classTable;
+    CVMClassBlock* freeClassList;
+    CVMClassLoaderICell* freeClassLoaderList;
+    CVMSysMutex classTableLock;
+    CVMLoaderCacheEntry** loaderCache;
+    CVMLoaderConstraint** loaderConstraints;
+    CVMSysMutex loaderCacheLock;
+    CVMSysMutex heapLock;
+    CVMSysMutex nullClassLoaderLock;
+    CVMSysMutex jvmtiLock;
+    CVMSysMutex jvmtiLockInfoLock;
+    CVMTargetGlobalState target;
+    CVMUint32 maxHeapSize;
+    CVMGCLocker inspectorGCLocker;
+    CVMCondVar gcLockerCV;
+    CVMSysMutex gcLockerLock;
+    CVMGCCommonGlobalState gcCommon;
+    CVMGCGlobalState gc;
+    CVMJNIJavaVM javaVM;
+    CVMExecEnv mainEE;
+    CVMSysMutex threadLock;
+    CVMExecEnv *threadList;
+    CVMUint32 userThreadCount;
+    CVMUint32 threadCount;
+    CVMCondVar threadCountCV;
+    CVMUint32 threadIDCount;
+    CVMSysMutex syncLock;
+    CVMObjMonitor *objLocksBound;
+    CVMObjMonitor *objLocksUnbound;
+    CVMObjMonitor *objLocksFree;
+    CVMMutex sysMicroLock[CVM_NUM_SYS_MICROLOCKS];
+    CVMMethodTypeID initTid;
+    CVMMethodTypeID clinitTid;
+    CVMMethodTypeID finalizeTid;
+    CVMMethodTypeID cloneTid;
+    CVMMethodBlock *java_security_AccessController_doPrivilegedAction1;
+    CVMMethodBlock *java_security_AccessController_doPrivilegedExceptionAction1;
+    CVMMethodBlock *java_security_AccessController_doPrivilegedAction2;
+    CVMMethodBlock *java_security_AccessController_doPrivilegedExceptionAction2;
+    CVMMethodBlock* java_lang_ref_Finalizer_register;
+    CVMJavaVal32* java_lang_ref_Reference_lock;
+    CVMJavaVal32* java_lang_ref_Reference_pending;
+    CVMBool referenceWorkTODO;
+    CVMMethodBlock* java_lang_Class_runStaticInitializers;
+    CVMMethodBlock* java_lang_Class_newInstance;
+    CVMMethodBlock* java_lang_reflect_Constructor_newInstance;
+    CVMMethodBlock* java_lang_reflect_Method_invoke;
+    CVMMethodTypeID printlnTid;
+    CVMMethodBlock* java_lang_Throwable_fillInStackTrace;
+    CVMFieldBlock* java_lang_System_out;
+    CVMMethodBlock* java_lang_ClassLoader_NativeLibrary_getFromClass;
+    CVMMethodBlock* java_lang_ClassLoader_addClass;
+    CVMMethodBlock* java_lang_ClassLoader_loadClass;
+    CVMMethodBlock* java_lang_ClassLoader_findNative;
+    CVMMethodBlock* java_lang_ClassLoader_checkPackageAccess;
+    CVMMethodBlock* java_lang_ClassLoader_loadBootstrapClass;
+    CVMMethodBlock* java_lang_Class_loadSuperClasses;
+    CVMMethodBlock* java_lang_Shutdown_waitAllUserThreadsExitAndShutdown;
+    CVMMethodBlock* sun_misc_ThreadRegistry_waitAllSystemThreadsExit;
+    CVMMethodBlock* java_lang_Thread_exit;
+    CVMMethodBlock* java_lang_Thread_initMainThread;
+    CVMMethodBlock* java_lang_Thread_initAttachedThread;
+    CVMMethodBlock* java_lang_Thread_nextThreadNum;
+    CVMClassLoaderICell* systemClassLoader;
+    CVMClassPath bootClassPath;
+    CVMClassPath appClassPath;
+    CVMUint16 classVerificationLevel;
+    void* cvmDynHandle;
+    CVMMethodBlock* sun_misc_Launcher_AppClassLoader_setExtInfo;
+    CVMMethodBlock* sun_misc_Launcher_ClassContainer_init;
+    CVMMethodBlock* sun_misc_Launcher_ClassContainer_init_withClass;
+    CVMMethodBlock* sun_misc_Launcher_getFileURL;
+    CVMMethodBlock* java_io_File_init;
+    CVMMethodBlock* java_util_jar_JarFile_init;
+    CVMMethodBlock* java_security_CodeSource_init;
+    CVMMethodBlock* java_security_SecureClassLoader_getProtectionDomain;
+    CVMMethodBlock* java_lang_ClassLoader_checkCerts;
+    CVMPackage* packages[31];
+    CVMUint16 numPackages;
+    CVMJvmtiGlobals jvmti;
+    CVMSysMutex typeidLock;
+    CVMUint32 typeIDscalarSegmentSize;
+    CVMUint32 typeIDmethodTypeSegmentSize;
+    CVMUint32 typeIDmemberNameSegmentSize;
+    CVMSysMutex internLock;
+    CVMUint32 stringInternSegmentSizeIdx;
+    CVMInt32 lastRandom;
+    CVMThrowableICell* preallocatedOutOfMemoryError;
+    CVMThrowableICell* preallocatedStackOverflowError;
+    CVMParsedSubOptions parsedSubOptions;
+    struct {
+ CVMUint32 nativeStackSize;
+ CVMUint32 javaStackMinSize;
+ CVMUint32 javaStackMaxSize;
+ CVMUint32 javaStackChunkSize;
+    } config;
+    void *vfprintfHook;
+    void (*exitHook)(int);
+    void (*abortHook)();
+    void (*safeExitHook)(int);
+    CVMBool abort_entered;
+    CVMBool timeStampEnabled;
+    CVMSysMutex timestampListLock;
+    CVMInt64 firstWallclockTime;
+    CVMBool fullShutdown;
+    CVMXrunTable onUnloadTable;
+    CVMAgentTable agentTable;
+    exit_procPtr exit_procs;
+    CVMObject* discoveredSoftRefs;
+    CVMObject* discoveredWeakRefs;
+    CVMObject* discoveredFinalRefs;
+    CVMObject* discoveredPhantomRefs;
+    CVMObject* deferredWeakrefs;
+    CVMObject* deferredWeakrefsToClear;
+    CVMObject* deferredWeakrefsToAddToPending;
+    CVMBool suspendCheckerInitialized;
+    CVMThreadID suspendCheckerThreadInfo;
+    volatile CVMUint32 suspendCheckerState;
+    CVMMutex suspendCheckerLock;
+    CVMCondVar suspendCheckerCV;
+    CVMCondVar suspendCheckerAckCV;
+    CVMBool measureGC;
+    CVMInt64 totalGCTime;
+    CVMInt64 startGCTime;
+    CVMInt64 initFreeMemory;
+    CVMBool javaAssertionsUserDefault;
+    CVMBool javaAssertionsSysDefault;
+    CVMJavaAssertionsOptionList* javaAssertionsClasses;
+    CVMJavaAssertionsOptionList* javaAssertionsPackages;
+    CVMBool userHomePropSpecified;
+    CVMBool userNamePropSpecified;
+    CVMInspector inspector;
+    loopProcPtr CVMgcUnsafeExecuteJavaMethodProcPtr;
+};
+extern void
+CVMoptPrintUsage();
+extern CVMBool
+CVMoptParseXoptOptions(const char* optAttributesStr);
+extern CVMBool
+CVMoptParseXssOption(const char* optAttributesStr);
+extern void CVMdumpGlobalsSubOptionValues();
+extern CVMGlobalState CVMglobals;
+extern CVMBool
+CVMinitVMGlobalState(CVMGlobalState *, CVMOptions *options);
+extern void
+CVMdestroyVMGlobalState(CVMExecEnv *ee, CVMGlobalState *);
+extern void
+CVMglobalSysMutexesAcquire(CVMExecEnv* ee);
+extern void
+CVMglobalSysMutexesRelease(CVMExecEnv* ee);
+CVMJavaLong CVMjvm2Long(const CVMAddr location[2]);
+void CVMlong2Jvm(CVMAddr location[2], CVMJavaLong val);
+CVMJavaDouble CVMjvm2Double(const CVMAddr location[2]);
+void CVMdouble2Jvm(CVMAddr location[2], CVMJavaDouble val);
+void CVMmemCopy64(CVMUint32 *to, const CVMUint32 *from);
+extern CVMJavaDouble CVMlongBits2Double(CVMJavaLong val);
+extern CVMJavaLong CVMdouble2LongBits(CVMJavaDouble val);
+extern CVMJavaInt CVMlong2Int(CVMJavaLong val);
+extern CVMJavaFloat CVMlong2Float(CVMJavaLong val);
+extern CVMJavaDouble CVMlong2Double(CVMJavaLong val);
+extern void * CVMlong2VoidPtr(CVMJavaLong val);
+extern CVMJavaLong CVMvoidPtr2Long(void * val);
+extern CVMJavaLong CVMint2Long(CVMJavaInt val);
+extern CVMJavaLong CVMdouble2Long(CVMJavaDouble val);
+CVMJavaLong CVMlongAdd(CVMJavaLong op1, CVMJavaLong op2);
+CVMJavaLong CVMlongAnd(CVMJavaLong op1, CVMJavaLong op2);
+CVMJavaLong CVMlongDiv(CVMJavaLong op1, CVMJavaLong op2);
+CVMJavaLong CVMlongMul(CVMJavaLong op1, CVMJavaLong op2);
+CVMJavaLong CVMlongOr (CVMJavaLong op1, CVMJavaLong op2);
+CVMJavaLong CVMlongSub(CVMJavaLong op1, CVMJavaLong op2);
+CVMJavaLong CVMlongXor(CVMJavaLong op1, CVMJavaLong op2);
+CVMJavaLong CVMlongRem(CVMJavaLong op1, CVMJavaLong op2);
+CVMJavaLong CVMlongUshr(CVMJavaLong op1, CVMJavaInt op2);
+CVMJavaLong CVMlongShl (CVMJavaLong op1, CVMJavaInt op2);
+CVMJavaLong CVMlongShr (CVMJavaLong op1, CVMJavaInt op2);
+CVMJavaLong CVMlongNeg(CVMJavaLong op);
+CVMJavaLong CVMlongNot(CVMJavaLong op);
+CVMInt32 CVMlongLtz(CVMJavaLong op);
+CVMInt32 CVMlongGez(CVMJavaLong op);
+CVMInt32 CVMlongEqz(CVMJavaLong op);
+CVMInt32 CVMlongEq(CVMJavaLong op1, CVMJavaLong op2);
+CVMInt32 CVMlongNe(CVMJavaLong op1, CVMJavaLong op2);
+CVMInt32 CVMlongGe(CVMJavaLong op1, CVMJavaLong op2);
+CVMInt32 CVMlongLe(CVMJavaLong op1, CVMJavaLong op2);
+CVMInt32 CVMlongLt(CVMJavaLong op1, CVMJavaLong op2);
+CVMInt32 CVMlongGt(CVMJavaLong op1, CVMJavaLong op2);
+CVMInt32 CVMlongCompare(CVMJavaLong op1, CVMJavaLong op2);
+CVMJavaLong CVMlongConstZero();
+CVMJavaLong CVMlongConstOne();
+CVMJavaInt CVMdouble2Int(CVMJavaDouble val);
+CVMJavaFloat CVMdouble2Float(CVMJavaDouble val);
+CVMJavaDouble CVMint2Double(CVMJavaInt val);
+CVMJavaDouble CVMdoubleAdd(CVMJavaDouble op1, CVMJavaDouble op2);
+CVMJavaDouble CVMdoubleSub(CVMJavaDouble op1, CVMJavaDouble op2);
+CVMJavaDouble CVMdoubleDiv(CVMJavaDouble op1, CVMJavaDouble op2);
+CVMJavaDouble CVMdoubleMul(CVMJavaDouble op1, CVMJavaDouble op2);
+CVMJavaDouble CVMdoubleRem(CVMJavaDouble op1, CVMJavaDouble op2);
+CVMJavaDouble CVMdoubleNeg(CVMJavaDouble op);
+CVMInt32 CVMdoubleCompare(CVMJavaDouble op1, CVMJavaDouble op2,
+     CVMInt32 direction);
+CVMJavaDouble CVMdoubleConstZero();
+CVMJavaDouble CVMdoubleConstOne();
+extern CVMJavaInt double2Int(CVMJavaDouble d);
+extern CVMJavaLong double2Long(CVMJavaDouble d);
+void* memalign(size_t alignment, size_t size);
+void free(void* memalignAllocedSpace);
+CVMBool CVMmemInit();
+size_t CVMmemPageSize();
+void *CVMmemMap(size_t requestedSize, size_t *mappedSize);
+void *CVMmemUnmap(void *addr, size_t requestedSize, size_t *unmappedSize);
+void *CVMmemCommit(void *addr, size_t requestedSize, size_t *committedSize);
+void *CVMmemDecommit(void *addr, size_t requestedSize,
+       size_t *decommittedSize);
+extern const CVMObjectICell CVMID_nullICell;
+enum CVMOpcode {
+    opc_nop = 0,
+    opc_aconst_null = 1,
+    opc_iconst_m1 = 2,
+    opc_iconst_0 = 3,
+    opc_iconst_1 = 4,
+    opc_iconst_2 = 5,
+    opc_iconst_3 = 6,
+    opc_iconst_4 = 7,
+    opc_iconst_5 = 8,
+    opc_lconst_0 = 9,
+    opc_lconst_1 = 10,
+    opc_fconst_0 = 11,
+    opc_fconst_1 = 12,
+    opc_fconst_2 = 13,
+    opc_dconst_0 = 14,
+    opc_dconst_1 = 15,
+    opc_bipush = 16,
+    opc_sipush = 17,
+    opc_ldc = 18,
+    opc_ldc_w = 19,
+    opc_ldc2_w = 20,
+    opc_iload = 21,
+    opc_lload = 22,
+    opc_fload = 23,
+    opc_dload = 24,
+    opc_aload = 25,
+    opc_iload_0 = 26,
+    opc_iload_1 = 27,
+    opc_iload_2 = 28,
+    opc_iload_3 = 29,
+    opc_lload_0 = 30,
+    opc_lload_1 = 31,
+    opc_lload_2 = 32,
+    opc_lload_3 = 33,
+    opc_fload_0 = 34,
+    opc_fload_1 = 35,
+    opc_fload_2 = 36,
+    opc_fload_3 = 37,
+    opc_dload_0 = 38,
+    opc_dload_1 = 39,
+    opc_dload_2 = 40,
+    opc_dload_3 = 41,
+    opc_aload_0 = 42,
+    opc_aload_1 = 43,
+    opc_aload_2 = 44,
+    opc_aload_3 = 45,
+    opc_iaload = 46,
+    opc_laload = 47,
+    opc_faload = 48,
+    opc_daload = 49,
+    opc_aaload = 50,
+    opc_baload = 51,
+    opc_caload = 52,
+    opc_saload = 53,
+    opc_istore = 54,
+    opc_lstore = 55,
+    opc_fstore = 56,
+    opc_dstore = 57,
+    opc_astore = 58,
+    opc_istore_0 = 59,
+    opc_istore_1 = 60,
+    opc_istore_2 = 61,
+    opc_istore_3 = 62,
+    opc_lstore_0 = 63,
+    opc_lstore_1 = 64,
+    opc_lstore_2 = 65,
+    opc_lstore_3 = 66,
+    opc_fstore_0 = 67,
+    opc_fstore_1 = 68,
+    opc_fstore_2 = 69,
+    opc_fstore_3 = 70,
+    opc_dstore_0 = 71,
+    opc_dstore_1 = 72,
+    opc_dstore_2 = 73,
+    opc_dstore_3 = 74,
+    opc_astore_0 = 75,
+    opc_astore_1 = 76,
+    opc_astore_2 = 77,
+    opc_astore_3 = 78,
+    opc_iastore = 79,
+    opc_lastore = 80,
+    opc_fastore = 81,
+    opc_dastore = 82,
+    opc_aastore = 83,
+    opc_bastore = 84,
+    opc_castore = 85,
+    opc_sastore = 86,
+    opc_pop = 87,
+    opc_pop2 = 88,
+    opc_dup = 89,
+    opc_dup_x1 = 90,
+    opc_dup_x2 = 91,
+    opc_dup2 = 92,
+    opc_dup2_x1 = 93,
+    opc_dup2_x2 = 94,
+    opc_swap = 95,
+    opc_iadd = 96,
+    opc_ladd = 97,
+    opc_fadd = 98,
+    opc_dadd = 99,
+    opc_isub = 100,
+    opc_lsub = 101,
+    opc_fsub = 102,
+    opc_dsub = 103,
+    opc_imul = 104,
+    opc_lmul = 105,
+    opc_fmul = 106,
+    opc_dmul = 107,
+    opc_idiv = 108,
+    opc_ldiv = 109,
+    opc_fdiv = 110,
+    opc_ddiv = 111,
+    opc_irem = 112,
+    opc_lrem = 113,
+    opc_frem = 114,
+    opc_drem = 115,
+    opc_ineg = 116,
+    opc_lneg = 117,
+    opc_fneg = 118,
+    opc_dneg = 119,
+    opc_ishl = 120,
+    opc_lshl = 121,
+    opc_ishr = 122,
+    opc_lshr = 123,
+    opc_iushr = 124,
+    opc_lushr = 125,
+    opc_iand = 126,
+    opc_land = 127,
+    opc_ior = 128,
+    opc_lor = 129,
+    opc_ixor = 130,
+    opc_lxor = 131,
+    opc_iinc = 132,
+    opc_i2l = 133,
+    opc_i2f = 134,
+    opc_i2d = 135,
+    opc_l2i = 136,
+    opc_l2f = 137,
+    opc_l2d = 138,
+    opc_f2i = 139,
+    opc_f2l = 140,
+    opc_f2d = 141,
+    opc_d2i = 142,
+    opc_d2l = 143,
+    opc_d2f = 144,
+    opc_i2b = 145,
+    opc_i2c = 146,
+    opc_i2s = 147,
+    opc_lcmp = 148,
+    opc_fcmpl = 149,
+    opc_fcmpg = 150,
+    opc_dcmpl = 151,
+    opc_dcmpg = 152,
+    opc_ifeq = 153,
+    opc_ifne = 154,
+    opc_iflt = 155,
+    opc_ifge = 156,
+    opc_ifgt = 157,
+    opc_ifle = 158,
+    opc_if_icmpeq = 159,
+    opc_if_icmpne = 160,
+    opc_if_icmplt = 161,
+    opc_if_icmpge = 162,
+    opc_if_icmpgt = 163,
+    opc_if_icmple = 164,
+    opc_if_acmpeq = 165,
+    opc_if_acmpne = 166,
+    opc_goto = 167,
+    opc_jsr = 168,
+    opc_ret = 169,
+    opc_tableswitch = 170,
+    opc_lookupswitch = 171,
+    opc_ireturn = 172,
+    opc_lreturn = 173,
+    opc_freturn = 174,
+    opc_dreturn = 175,
+    opc_areturn = 176,
+    opc_return = 177,
+    opc_getstatic = 178,
+    opc_putstatic = 179,
+    opc_getfield = 180,
+    opc_putfield = 181,
+    opc_invokevirtual = 182,
+    opc_invokespecial = 183,
+    opc_invokestatic = 184,
+    opc_invokeinterface = 185,
+    opc_xxxunusedxxx = 186,
+    opc_new = 187,
+    opc_newarray = 188,
+    opc_anewarray = 189,
+    opc_arraylength = 190,
+    opc_athrow = 191,
+    opc_checkcast = 192,
+    opc_instanceof = 193,
+    opc_monitorenter = 194,
+    opc_monitorexit = 195,
+    opc_wide = 196,
+    opc_multianewarray = 197,
+    opc_ifnull = 198,
+    opc_ifnonnull = 199,
+    opc_goto_w = 200,
+    opc_jsr_w = 201,
+    opc_breakpoint = 202,
+    opc_aldc_ind_quick = 203,
+    opc_aldc_ind_w_quick = 204,
+    opc_invokestatic_quick = 205,
+    opc_invokestatic_checkinit_quick = 206,
+    opc_invokevirtual_quick = 207,
+    opc_getfield_quick = 208,
+    opc_agetfield_quick = 209,
+    opc_vinvokevirtual_quick = 210,
+    opc_invokevirtual_quick_w = 211,
+    opc_putfield_quick = 212,
+    opc_invokenonvirtual_quick = 213,
+    opc_invokesuper_quick = 214,
+    opc_invokeignored_quick = 215,
+    opc_getfield2_quick = 216,
+    opc_checkcast_quick = 217,
+    opc_instanceof_quick = 218,
+    opc_nonnull_quick = 219,
+    opc_putfield2_quick = 220,
+    opc_ainvokevirtual_quick = 221,
+    opc_invokevirtualobject_quick = 222,
+    opc_invokeinterface_quick = 223,
+    opc_aldc_quick = 224,
+    opc_ldc_quick = 225,
+    opc_exittransition = 226,
+    opc_dinvokevirtual_quick = 227,
+    opc_aldc_w_quick = 228,
+    opc_ldc_w_quick = 229,
+    opc_aputfield_quick = 230,
+    opc_getfield_quick_w = 231,
+    opc_ldc2_w_quick = 232,
+    opc_agetstatic_quick = 233,
+    opc_getstatic_quick = 234,
+    opc_getstatic2_quick = 235,
+    opc_aputstatic_quick = 236,
+    opc_putstatic_quick = 237,
+    opc_putstatic2_quick = 238,
+    opc_agetstatic_checkinit_quick = 239,
+    opc_getstatic_checkinit_quick = 240,
+    opc_getstatic2_checkinit_quick = 241,
+    opc_aputstatic_checkinit_quick = 242,
+    opc_putstatic_checkinit_quick = 243,
+    opc_putstatic2_checkinit_quick = 244,
+    opc_putfield_quick_w = 245,
+    opc_new_checkinit_quick = 246,
+    opc_new_quick = 247,
+    opc_anewarray_quick = 248,
+    opc_multianewarray_quick = 249,
+    opc_prefix = 250
+};
+extern const char* const CVMopnames[];
+extern const char CVMopcodeLengths[];
+extern CVMUint32 CVMopcodeGetLengthVariable(const CVMUint8* iStream);
+typedef enum CVMOpcode CVMOpcode;
+extern int
+CVMopcodeGetLengthWithBoundsCheckVariable(const unsigned char* iStream,
+       const unsigned char* iStream_end);
+typedef CVMFreelistFrame CVMGlobalRootsFrame;
+extern CVMObjectICell*
+CVMID_getGlobalRoot(CVMExecEnv* ee);
+extern CVMObjectICell*
+CVMID_getClassGlobalRoot(CVMExecEnv* ee);
+extern CVMObjectICell*
+CVMID_getClassLoaderGlobalRoot(CVMExecEnv* ee);
+extern CVMObjectICell*
+CVMID_getProtectionDomainGlobalRoot(CVMExecEnv* ee);
+extern CVMObjectICell*
+CVMID_getWeakGlobalRoot(CVMExecEnv* ee);
+extern void
+CVMID_freeGlobalRoot(CVMExecEnv* ee, CVMObjectICell* glRoot);
+extern void
+CVMID_freeClassGlobalRoot(CVMExecEnv* ee, CVMObjectICell* glRoot);
+extern void
+CVMID_freeClassLoaderGlobalRoot(CVMExecEnv* ee, CVMObjectICell* glRoot);
+extern void
+CVMID_freeProtectionDomainGlobalRoot(CVMExecEnv* ee, CVMObjectICell* glRoot);
+extern void
+CVMID_freeWeakGlobalRoot(CVMExecEnv* ee, CVMObjectICell* glRoot);
+extern CVMFrameGCScannerFunc CVMglobalrootFrameScanner;
+typedef void CVMThrowFunc(CVMExecEnv *, const char *format, ...);
+extern CVMThrowFunc CVMthrowClassCircularityError;
+extern CVMThrowFunc CVMthrowClassFormatError;
+extern CVMThrowFunc CVMthrowIllegalAccessError;
+extern CVMThrowFunc CVMthrowInstantiationError;
+extern CVMThrowFunc CVMthrowLinkageError;
+extern CVMThrowFunc CVMthrowUnsupportedClassVersionError;
+extern CVMThrowFunc CVMthrowVerifyError;
+extern CVMThrowFunc CVMthrowUnsatisfiedLinkError;
+extern CVMThrowFunc CVMthrowNegativeArraySizeException;
+extern CVMThrowFunc CVMthrowNoSuchFieldException;
+extern CVMThrowFunc CVMthrowNoSuchMethodException;
+extern CVMThrowFunc CVMthrowIncompatibleClassChangeError;
+extern CVMThrowFunc CVMthrowAbstractMethodError;
+extern CVMThrowFunc CVMthrowArithmeticException;
+extern CVMThrowFunc CVMthrowArrayIndexOutOfBoundsException;
+extern CVMThrowFunc CVMthrowArrayStoreException;
+extern CVMThrowFunc CVMthrowClassCastException;
+extern CVMThrowFunc CVMthrowClassNotFoundException;
+extern CVMThrowFunc CVMthrowCloneNotSupportedException;
+extern CVMThrowFunc CVMthrowIllegalAccessException;
+extern CVMThrowFunc CVMthrowIllegalArgumentException;
+extern CVMThrowFunc CVMthrowIllegalMonitorStateException;
+extern CVMThrowFunc CVMthrowIllegalStateException;
+extern CVMThrowFunc CVMthrowInstantiationException;
+extern CVMThrowFunc CVMthrowInternalError;
+extern CVMThrowFunc CVMthrowInterruptedException;
+extern CVMThrowFunc CVMthrowNoClassDefFoundError;
+extern CVMThrowFunc CVMthrowNoSuchFieldError;
+extern CVMThrowFunc CVMthrowNoSuchMethodError;
+extern CVMThrowFunc CVMthrowNullPointerException;
+extern CVMThrowFunc CVMthrowOutOfMemoryError;
+extern CVMThrowFunc CVMthrowStackOverflowError;
+extern CVMThrowFunc CVMthrowStringIndexOutOfBoundsException;
+extern CVMThrowFunc CVMthrowUnsupportedOperationException;
+extern CVMThrowFunc CVMthrowInvalidClassException;
+extern CVMThrowFunc CVMthrowIOException;
+extern CVMThrowFunc CVMthrowConversionBufferFullException;
+extern CVMThrowFunc CVMthrowUnknownCharacterException;
+extern CVMThrowFunc CVMthrowMalformedInputException;
+CVMJavaFloat CVMfloatAdd(CVMJavaFloat op1, CVMJavaFloat op2);
+CVMJavaFloat CVMfloatSub(CVMJavaFloat op1, CVMJavaFloat op2);
+CVMJavaFloat CVMfloatMul(CVMJavaFloat op1, CVMJavaFloat op2);
+CVMJavaFloat CVMfloatDiv(CVMJavaFloat op1, CVMJavaFloat op2);
+CVMJavaFloat CVMfloatRem(CVMJavaFloat op1, CVMJavaFloat op2);
+CVMJavaFloat CVMfloatNeg(CVMJavaFloat op);
+CVMInt32 CVMfloatCompare(CVMJavaFloat op1, CVMJavaFloat op2,
+    CVMInt32 direction);
+CVMJavaInt CVMfloat2Int(CVMJavaFloat op);
+CVMJavaDouble CVMfloat2Double(CVMJavaFloat op);
+extern CVMJavaLong CVMfloat2Long(CVMJavaFloat op);
+extern void setFPMode(void);
+extern CVMJavaInt float2Int(CVMJavaFloat d);
+extern CVMJavaLong float2Long(CVMJavaFloat d);
+CVMJavaInt CVMintAdd(CVMJavaInt op1, CVMJavaInt op2);
+CVMJavaInt CVMintSub(CVMJavaInt op1, CVMJavaInt op2);
+CVMJavaInt CVMintMul(CVMJavaInt op1, CVMJavaInt op2);
+CVMJavaInt CVMintDiv(CVMJavaInt op1, CVMJavaInt op2);
+CVMJavaInt CVMintRem(CVMJavaInt op1, CVMJavaInt op2);
+CVMJavaInt CVMintAnd(CVMJavaInt op1, CVMJavaInt op2);
+CVMJavaInt CVMintOr (CVMJavaInt op1, CVMJavaInt op2);
+CVMJavaInt CVMintXor(CVMJavaInt op1, CVMJavaInt op2);
+CVMJavaInt CVMintNeg(CVMJavaInt op);
+CVMJavaInt CVMintUshr(CVMJavaInt op, CVMJavaInt num);
+CVMJavaInt CVMintShl (CVMJavaInt op, CVMJavaInt num);
+CVMJavaInt CVMintShr (CVMJavaInt op, CVMJavaInt num);
+CVMJavaInt CVMintNeg(CVMJavaInt op);
+CVMJavaFloat CVMint2Float(CVMJavaInt val);
+CVMJavaByte CVMint2Byte(CVMJavaInt val);
+CVMJavaChar CVMint2Char(CVMJavaInt val);
+CVMJavaShort CVMint2Short(CVMJavaInt val);
+CVMUint16 CVMgetUint16(const CVMUint8 *ptr);
+CVMUint32 CVMgetUint32(const CVMUint8 *ptr);
+CVMInt16 CVMgetInt16(const CVMUint8 *ptr);
+CVMInt32 CVMgetInt32(const CVMUint8 *ptr);
+static void CVMdoubleAddHelper(CVMStackVal32* topOfStack) { CVMJavaDouble l1, l2, r; l1 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d); }); l2 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); }); r = ((l1) + (l2)); { typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d = r; }; }
+static void CVMdoubleSubHelper(CVMStackVal32* topOfStack) { CVMJavaDouble l1, l2, r; l1 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d); }); l2 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); }); r = ((l1) - (l2)); { typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d = r; }; }
+static void CVMdoubleMulHelper(CVMStackVal32* topOfStack) { CVMJavaDouble l1, l2, r; l1 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d); }); l2 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); }); r = ((l1) * (l2)); { typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d = r; }; }
+static void CVMdoubleDivHelper(CVMStackVal32* topOfStack) { CVMJavaDouble l1, l2, r; l1 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d); }); l2 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); }); r = ((l1) / (l2)); { typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d = r; }; }
+static void CVMdoubleRemHelper(CVMStackVal32* topOfStack) { CVMJavaDouble l1, l2, r; l1 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d); }); l2 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); }); r = CVMdoubleRem(l1, l2); { typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d = r; }; }
+static CVMBool CVMlongAddHelper(CVMStackVal32* topOfStack) { CVMJavaLong l1, l2, r1; l2 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }); if (0 && ((l2) == 0LL)) { return (!(1 == 1)); } l1 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }); r1 = ((l1) + (l2)); { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l = r1; }; return (1 == 1); }
+static CVMBool CVMlongSubHelper(CVMStackVal32* topOfStack) { CVMJavaLong l1, l2, r1; l2 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }); if (0 && ((l2) == 0LL)) { return (!(1 == 1)); } l1 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }); r1 = ((l1) - (l2)); { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l = r1; }; return (1 == 1); }
+static CVMBool CVMlongMulHelper(CVMStackVal32* topOfStack) { CVMJavaLong l1, l2, r1; l2 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }); if (0 && ((l2) == 0LL)) { return (!(1 == 1)); } l1 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }); r1 = ((l1) * (l2)); { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l = r1; }; return (1 == 1); }
+static CVMBool CVMlongDivHelper(CVMStackVal32* topOfStack) { CVMJavaLong l1, l2, r1; l2 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }); if (1 && ((l2) == 0LL)) { return (!(1 == 1)); } l1 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }); r1 = ((l1) / (l2)); { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l = r1; }; return (1 == 1); }
+static CVMBool CVMlongRemHelper(CVMStackVal32* topOfStack) { CVMJavaLong l1, l2, r1; l2 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }); if (1 && ((l2) == 0LL)) { return (!(1 == 1)); } l1 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }); r1 = ((l1) % (l2)); { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l = r1; }; return (1 == 1); }
+static CVMBool CVMlongAndHelper(CVMStackVal32* topOfStack) { CVMJavaLong l1, l2, r1; l2 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }); if (0 && ((l2) == 0LL)) { return (!(1 == 1)); } l1 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }); r1 = ((l1) & (l2)); { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l = r1; }; return (1 == 1); }
+static CVMBool CVMlongOrHelper(CVMStackVal32* topOfStack) { CVMJavaLong l1, l2, r1; l2 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }); if (0 && ((l2) == 0LL)) { return (!(1 == 1)); } l1 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }); r1 = ((l1) | (l2)); { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l = r1; }; return (1 == 1); }
+static CVMBool CVMlongXorHelper(CVMStackVal32* topOfStack) { CVMJavaLong l1, l2, r1; l2 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }); if (0 && ((l2) == 0LL)) { return (!(1 == 1)); } l1 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }); r1 = ((l1) ^ (l2)); { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l = r1; }; return (1 == 1); }
+static void CVMlongShlHelper(CVMStackVal32* topOfStack) { CVMJavaLong v, r; v = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-3].s).j).raw))->l); }); r = ((v) << (((((topOfStack[-1].s).j).i)) & 0x3F)); { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-3].s).j).raw))->l = r; }; }
+static void CVMlongShrHelper(CVMStackVal32* topOfStack) { CVMJavaLong v, r; v = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-3].s).j).raw))->l); }); r = ((v) >> (((((topOfStack[-1].s).j).i)) & 0x3F)); { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-3].s).j).raw))->l = r; }; }
+static void CVMlongUshrHelper(CVMStackVal32* topOfStack) { CVMJavaLong v, r; v = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-3].s).j).raw))->l); }); r = (((unsigned long long)(v)) >> (((((topOfStack[-1].s).j).i)) & 0x3F)); { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-3].s).j).raw))->l = r; }; }
+static void
+CVMlongNegHelper(CVMStackVal32* topOfStack)
+{
+    CVMJavaLong r;
+    r = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); });
+    r = (-(r));
+    { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l = r; };
+}
+static void
+CVMlongCmpHelper(CVMStackVal32* topOfStack)
+{
+    CVMJavaLong value1, value2;
+    value1 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); });
+    value2 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); });
+    (((topOfStack[-4].s).j).i) = ((((value1)) < ((value2))) ? -1 : (((value1)) > ((value2))) ? 1 : 0);
+}
+static void
+CVMdoubleNegHelper(CVMStackVal32* topOfStack)
+{
+    CVMJavaDouble r;
+    r = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); });
+    r = (-(r));
+    { typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d = r; };
+}
+static void
+CVMdoubleCmpHelper(CVMStackVal32* topOfStack, int direction)
+{
+    CVMJavaDouble value1, value2;
+    value1 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d); });
+    value2 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); });
+    (((topOfStack[-4].s).j).i) = CVMdoubleCompare(value1, value2, direction);
+}
+static void
+CVMd2lHelper(CVMStackVal32* topOfStack)
+{
+    CVMJavaDouble r1;
+    CVMJavaLong r2;
+    r1 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); });
+    r2 = double2Long((r1));
+    { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l = r2; };
+}
+static void
+CVMd2iHelper(CVMStackVal32* topOfStack)
+{
+    CVMJavaDouble r1;
+    CVMJavaInt r2;
+    r1 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); });
+    r2 = (double2Int(r1));
+    (((topOfStack[-2].s).j).i) = r2;
+}
+static void
+CVMl2dHelper(CVMStackVal32* topOfStack)
+{
+    CVMJavaLong r1;
+    CVMJavaDouble r2;
+    r1 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); });
+    r2 = ((CVMJavaDouble)(r1));
+    { typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d = r2; };
+}
+static void
+CVMi2dHelper(CVMStackVal32* topOfStack)
+{
+    CVMJavaDouble r;
+    r = ((CVMJavaDouble)((((topOfStack[-1].s).j).i)));
+    { typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-1].s).j).raw))->d = r; };
+}
+static CVMInt32
+CVMtableswitchHelper(CVMExecEnv* ee, CVMStackVal32* topOfStack, CVMUint8* pc,
+       CVMFrame* frame)
+{
+    CVMInt32* lpc = (CVMInt32*)(((CVMAddr)(pc+1) + 3) & ~3);
+    CVMInt32 key = (((topOfStack[-1].s).j).i);
+    CVMInt32 low = (CVMInt32)((*((CVMInt32*)(&lpc[1])) << 24) | ((*((CVMInt32*)(&lpc[1])) & 0xff00) << 8) | ((*((CVMInt32*)(&lpc[1])) >> 8) & 0xff00) | (*((CVMUint32*)(&lpc[1])) >> 24));
+    CVMInt32 high = (CVMInt32)((*((CVMInt32*)(&lpc[2])) << 24) | ((*((CVMInt32*)(&lpc[2])) & 0xff00) << 8) | ((*((CVMInt32*)(&lpc[2])) >> 8) & 0xff00) | (*((CVMUint32*)(&lpc[2])) >> 24));
+    CVMInt32 skip;
+    (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\ttableswitch %d [%d-%d]\n", key, low, high) : (void)0);
+    key -= low;
+    ;
+    skip = ((CVMUint32) key > high - low)
+ ? (CVMInt32)((*((CVMInt32*)(&lpc[0])) << 24) | ((*((CVMInt32*)(&lpc[0])) & 0xff00) << 8) | ((*((CVMInt32*)(&lpc[0])) >> 8) & 0xff00) | (*((CVMUint32*)(&lpc[0])) >> 24))
+ : (CVMInt32)((*((CVMInt32*)(&lpc[key + 3])) << 24) | ((*((CVMInt32*)(&lpc[key + 3])) & 0xff00) << 8) | ((*((CVMInt32*)(&lpc[key + 3])) >> 8) & 0xff00) | (*((CVMUint32*)(&lpc[key + 3])) >> 24));
+    return skip;
+}
+static CVMInt32
+CVMlookupswitchHelper(CVMExecEnv* ee, CVMStackVal32* topOfStack, CVMUint8* pc,
+        CVMFrame* frame)
+{
+    CVMInt32* lpc = (CVMInt32*)(((CVMAddr)(pc+1) + 3) & ~3);
+    CVMInt32 key = (((topOfStack[-1].s).j).i);
+    CVMInt32 skip = (CVMInt32)((*((CVMInt32*)(lpc)) << 24) | ((*((CVMInt32*)(lpc)) & 0xff00) << 8) | ((*((CVMInt32*)(lpc)) >> 8) & 0xff00) | (*((CVMUint32*)(lpc)) >> 24));
+    CVMInt32 npairs = (CVMInt32)((*((CVMInt32*)(&lpc[1])) << 24) | ((*((CVMInt32*)(&lpc[1])) & 0xff00) << 8) | ((*((CVMInt32*)(&lpc[1])) >> 8) & 0xff00) | (*((CVMUint32*)(&lpc[1])) >> 24));
+    (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tlookupswitch %d\n", key) : (void)0);
+    while (--npairs >= 0) {
+ lpc += 2;
+ if (key == (CVMInt32)((*((CVMInt32*)(lpc)) << 24) | ((*((CVMInt32*)(lpc)) & 0xff00) << 8) | ((*((CVMInt32*)(lpc)) >> 8) & 0xff00) | (*((CVMUint32*)(lpc)) >> 24))) {
+     skip = (CVMInt32)((*((CVMInt32*)(&lpc[1])) << 24) | ((*((CVMInt32*)(&lpc[1])) & 0xff00) << 8) | ((*((CVMInt32*)(&lpc[1])) >> 8) & 0xff00) | (*((CVMUint32*)(&lpc[1])) >> 24));
+     break;
+ }
+    }
+    ;
+    return skip;
+}
+static CVMBool
+CVManewarrayHelper(CVMExecEnv* ee, CVMStackVal32* topOfStack,
+     CVMClassBlock* elemCb)
+{
+    CVMJavaInt arrLen;
+    CVMArrayOfRef* directArr;
+    CVMClassBlock* arrCb;
+    arrLen = (((topOfStack[-1].s).j).i);
+    if (arrLen < 0) {
+ CVMthrowNegativeArraySizeException(ee, ((void *)0));
+ return (!(1 == 1));
+    }
+    { ((void)0); ((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe\n") : (void)0); { ((void)((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+    ,
+ 1008
+    , "!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent") || (CVMsystemPanic("CVMassertHook returned"), 0))); ((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent = (1 == 1); ; };; if ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))) { CVMcsRendezvous((ee), (&CVMglobals.cstate[(CVM_GC_SAFE)]), (&((ee))->tcstate[(CVM_GC_SAFE)]), ((!(1 == 1))));; } { arrCb = CVMclassGetArrayOf(ee, elemCb); }; ((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-unsafe\n") : (void)0); { ((void)((((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+    ,
+ 1008
+    , "((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent") || (CVMsystemPanic("CVMassertHook returned"), 0))); ((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent = (!(1 == 1)); ; };; if ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))) { CVMcsRendezvous((ee), (&CVMglobals.cstate[(CVM_GC_SAFE)]), (&((ee))->tcstate[(CVM_GC_SAFE)]), ((1 == 1)));; } }
+      ;
+    if (arrCb == ((void *)0)) {
+ return (!(1 == 1));
+    }
+    directArr = (CVMArrayOfRef*)
+ CVMgcAllocNewArray(ee, CVM_T_CLASS, arrCb, arrLen);
+    if (directArr == ((void *)0)) {
+ CVMthrowOutOfMemoryError(ee, "%C", arrCb);
+ return (!(1 == 1));
+    }
+    (((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1019, "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY = ((CVMObject*)directArr));
+    (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tanewarray_quick %C => 0x%x\n", arrCb, directArr) : (void)0);
+    return (1 == 1);
+}
+static CVMBool
+CVMnewarrayHelper(CVMExecEnv* ee, CVMStackVal32* topOfStack,
+    CVMBasicType typeCode)
+{
+    CVMJavaInt arrLen;
+    CVMArrayOfAnyType* directArr;
+    CVMClassBlock* arrCb;
+    arrLen = (((topOfStack[-1].s).j).i);
+    if (arrLen < 0) {
+ CVMthrowNegativeArraySizeException(ee, ((void *)0));
+ return (!(1 == 1));
+    }
+    arrCb = (CVMClassBlock*)CVMbasicTypeArrayClassblocks[typeCode];
+    ((void)((arrCb != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1040, "arrCb != 0") || (CVMsystemPanic("CVMassertHook returned"), 0)));
+    directArr = (CVMArrayOfAnyType*)
+ CVMgcAllocNewArray(ee, typeCode, arrCb, arrLen);
+    (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tnewarray %C.%d => 0x%x\n", arrCb, arrLen, directArr) : (void)0);
+    ((void)((directArr == ((void *)0) || ((((((((CVMClassBlock*)(((CVMAddr)((directArr)->hdr.clas)) & ~3)))->classNameX))&0xc000) != 0 ) && (((((((((CVMClassBlock*)(((CVMAddr)((directArr)->hdr.clas)) & ~3)))->classNameX))&0xc000)==0xc000)? CVMtypeidGetArrayDepthX(((((CVMClassBlock*)(((CVMAddr)((directArr)->hdr.clas)) & ~3)))->classNameX)) : (((((((CVMClassBlock*)(((CVMAddr)((directArr)->hdr.clas)) & ~3)))->classNameX))&0xc000)>>14))==1) && (((((((((CVMClassBlock*)(((CVMAddr)((directArr)->hdr.clas)) & ~3)))->classNameX))&0xc000)==0xc000)? CVMtypeidGetArrayBasetypeX(((((CVMClassBlock*)(((CVMAddr)((directArr)->hdr.clas)) & ~3)))->classNameX)) : ((((((CVMClassBlock*)(((CVMAddr)((directArr)->hdr.clas)) & ~3)))->classNameX))&0x3fff)) == CVMbasicTypeID[typeCode]))) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+    ,
+ 1052
+    , "directArr == NULL || CVMisArrayClassOfBasicType(CVMobjectGetClass(directArr), CVMbasicTypeID[typeCode])") || (CVMsystemPanic("CVMassertHook returned"), 0)))
+                                ;
+    (((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1053, "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY = ((CVMObject*)directArr));
+    if (directArr == ((void *)0)) {
+ CVMthrowOutOfMemoryError(ee, "%C", arrCb);
+  return (!(1 == 1));
+    }
+    return (1 == 1);
+}
+static CVMBool
+CVMmultianewarrayHelper(CVMExecEnv* ee, CVMClassBlock* arrCb)
+{
+    CVMInt32 nDimensions;
+    CVMInt32 dimCount;
+    CVMInt32 effectiveNDimensions;
+    CVMObjectICell* resultCell;
+    CVMStack* stack = &ee->interpreterStack;
+    CVMFrame* frame;
+    CVMStackVal32* topOfStack;
+    CVMUint8* pc;
+    frame = stack->currentFrame;;
+    topOfStack = frame->topOfStack;;
+    pc = (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX);;
+    nDimensions = pc[3];
+    effectiveNDimensions = nDimensions;
+    topOfStack -= nDimensions;
+    frame->topOfStack = topOfStack;;
+    for (dimCount = 0; dimCount < nDimensions; dimCount++) {
+ CVMInt32 dim = (((topOfStack[dimCount].s).j).i);
+ if (dim <= 0) {
+     if ((dim == 0) && (effectiveNDimensions == nDimensions)) {
+  effectiveNDimensions = dimCount + 1;
+     } else if (dim < 0) {
+  { if ((1 == 1)) { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1102, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1102, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->opstackX);; } else { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1102, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_TRANSITION)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1102, "CVMframeIsTransition(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMTransitionFrame*)(frame))->opstackX);; } };
+  CVMthrowNegativeArraySizeException(ee, ((void *)0));
+  return (!(1 == 1));
+     }
+ }
+    }
+    resultCell = ((ee)->miscICell);
+    ((void)((((resultCell)->ref_DONT_ACCESS_DIRECTLY == 0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1116, "CVMID_icellIsNull(resultCell)") || (CVMsystemPanic("CVMassertHook returned"), 0)));
+    { ((void)0); ((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe\n") : (void)0); { ((void)((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+    ,
+ 1126
+    , "!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent") || (CVMsystemPanic("CVMassertHook returned"), 0))); ((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent = (1 == 1); ; };; if ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))) { CVMcsRendezvous((ee), (&CVMglobals.cstate[(CVM_GC_SAFE)]), (&((ee))->tcstate[(CVM_GC_SAFE)]), ((!(1 == 1))));; } { CVMmultiArrayAlloc(ee, effectiveNDimensions, topOfStack, arrCb, resultCell); }; ((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-unsafe\n") : (void)0); { ((void)((((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+    ,
+ 1126
+    , "((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent") || (CVMsystemPanic("CVMassertHook returned"), 0))); ((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent = (!(1 == 1)); ; };; if ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))) { CVMcsRendezvous((ee), (&CVMglobals.cstate[(CVM_GC_SAFE)]), (&((ee))->tcstate[(CVM_GC_SAFE)]), ((1 == 1)));; } }
+      ;
+    if (((resultCell)->ref_DONT_ACCESS_DIRECTLY == 0)) {
+ { if ((1 == 1)) { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1133, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1133, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->opstackX);; } else { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1133, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_TRANSITION)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1133, "CVMframeIsTransition(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMTransitionFrame*)(frame))->opstackX);; } };
+ CVMthrowOutOfMemoryError(ee, "%C", arrCb);
+ return (!(1 == 1));
+    }
+    (((void)(((!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1138, "(!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), ((&(((topOfStack[0].s).j).r)))->ref_DONT_ACCESS_DIRECTLY = ((*(((void)(((!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1138, "(!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &((resultCell))->ref_DONT_ACCESS_DIRECTLY))));
+    (resultCell)->ref_DONT_ACCESS_DIRECTLY = 0;;
+    (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tmultianewarray_quick %C " "(dimensions = %d, effective = %d) => 0x%x\n", arrCb, nDimensions, effectiveNDimensions, ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1148, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[0].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) : (void)0)
+                                                               ;
+    return (1 == 1);
+}
+static CVMMethodBlock*
+CVMinvokeInterfaceHelper(CVMExecEnv* ee, CVMStackVal32* topOfStack,
+    CVMMethodBlock* imb )
+{
+    CVMObject* directObj;
+    CVMClassBlock* icb;
+    CVMClassBlock* ocb;
+    CVMUint32 interfaceCount;
+    CVMInterfaces* interfaces;
+    CVMInterfaceTable* itablePtr;
+    CVMUint16 methodTableIndex;
+    CVMMethodBlock* mb;
+    int guess;
+    CVMStack* stack = &ee->interpreterStack;
+    CVMFrame* frame;
+    CVMUint8* pc;
+    frame = stack->currentFrame;;
+    pc = (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX);;
+    guess = pc[4];
+    icb = (((CVMMethodRange*) ((CVMUint8 *)((imb) - ((imb)->immutX.methodIndexX)) - ((CVMAddr)(&(((CVMMethodRange *)0)->mb[0])) - (CVMAddr)(&(((CVMMethodRange *)0)->cb)))))->cb);
+    directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1175, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[0].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+    if (directObj == ((void *)0)) {
+        CVMthrowNullPointerException(ee, ((void *)0));
+ return ((void *)0);
+    }
+    ocb = ((CVMClassBlock*)(((CVMAddr)((directObj)->hdr.clas)) & ~3));
+    interfaces = ((ocb)->interfacesX);
+    interfaceCount = ((interfaces) == ((void *)0) ? 0 : (interfaces)->interfaceCountX);
+    itablePtr = ((interfaces)->itable);
+    if (guess < 0 || guess >= interfaceCount ||
+ ((itablePtr)[guess].interfaceCb) != icb) {
+ guess = interfaceCount - 1;
+ while ((guess >= 0) &&
+        (((itablePtr)[guess].interfaceCb) != icb)) {
+     guess--;
+ }
+ if (guess >= 0) {
+     ((void)((((itablePtr)[guess].interfaceCb) == icb) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+     ,
+ 1202
+     , "CVMcbInterfacecbGivenItable(itablePtr, guess) == icb") || (CVMsystemPanic("CVMassertHook returned"), 0)))
+               ;
+     if ((((ocb)->interfacesX)->itable[guess]. interfaceCb) == icb) {
+  if (!(((((((((CVMMethodRange*) ((CVMUint8 *)((frame->mb) - ((frame->mb)->immutX.methodIndexX)) - ((CVMAddr)(&(((CVMMethodRange *)0)->mb[0])) - (CVMAddr)(&(((CVMMethodRange *)0)->cb)))))->cb))->runtimeFlagsX) & 0x01) != 0))) &&
+      !((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1209, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_TRANSITION)) {
+      pc[4] = guess;
+  }
+     }
+ }
+    }
+    if (guess >= 0) {
+        methodTableIndex = (((interfaces)->itable[guess]. intfInfoX.methodTableIndicesX)[(*(((void)((((0x400 & (0x01 | 0x03 | 0x02)) ? ((((imb)->immutX.invokerAndAccessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x400) : ((((imb)->immutX.invokerAndAccessFlagsX) & 0x400) != 0)) && (((((((CVMMethodRange*) ((CVMUint8 *)((imb) - ((imb)->immutX.methodIndexX)) - ((CVMAddr)(&(((CVMMethodRange *)0)->mb[0])) - (CVMAddr)(&(((CVMMethodRange *)0)->cb)))))->cb))->accessFlagsX) & 0x200) != 0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1224, "CVMmbIs(imb, ABSTRACT) && CVMcbIs(CVMmbClassBlock(imb), INTERFACE)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(imb)->immutX.codeX.methodSlotIndex))])
+                                                      ;
+        mb = (((ocb)->methodTablePtrX)[methodTableIndex]);
+        return mb;
+    } else if (icb == ((CVMClassBlock*)(&java_lang_Object_Classblock))) {
+        methodTableIndex = ((imb)->immutX.methodTableIndexX);
+        mb = (((ocb)->methodTablePtrX)[methodTableIndex]);
+        return mb;
+    } else {
+        CVMthrowIncompatibleClassChangeError(
+     ee, "class %C does not implement interface %C", ocb, icb);
+ return ((void *)0);
+    }
+}
+static CVMBool
+CVMloadConstantHelper(CVMExecEnv *ee, CVMStackVal32* topOfStack,
+    CVMConstantPool* cp, CVMUint16 cpIndex, CVMUint8* pc)
+{
+    switch ((((cp)->cpTypesX)[cpIndex] & 0x3F)) {
+    case CVM_CONSTANT_ClassTypeID:
+    {
+ CVMBool resolved;
+ { ((void)0); ((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe\n") : (void)0); { ((void)((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+ ,
+ 1256
+ , "!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent") || (CVMsystemPanic("CVMassertHook returned"), 0))); ((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent = (1 == 1); ; };; if ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))) { CVMcsRendezvous((ee), (&CVMglobals.cstate[(CVM_GC_SAFE)]), (&((ee))->tcstate[(CVM_GC_SAFE)]), ((!(1 == 1))));; } { resolved = ((((cp)->cpTypesX) == ((void *)0) ? (1 == 1) : (((cp)->cpTypesX)[cpIndex] & 0x80) != 0) ? (1 == 1) : CVMprivate_cpResolveEntryFromClass(ee, (((CVMMethodRange*) ((CVMUint8 *)((((((ee))->interpreterStack.currentFrame)->mb)) - ((((((ee))->interpreterStack.currentFrame)->mb))->immutX.methodIndexX)) - ((CVMAddr)(&(((CVMMethodRange *)0)->mb[0])) - (CVMAddr)(&(((CVMMethodRange *)0)->cb)))))->cb), cp, cpIndex)); }; ((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-unsafe\n") : (void)0); { ((void)((((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+ ,
+ 1256
+ , "((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent") || (CVMsystemPanic("CVMassertHook returned"), 0))); ((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent = (!(1 == 1)); ; };; if ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))) { CVMcsRendezvous((ee), (&CVMglobals.cstate[(CVM_GC_SAFE)]), (&((ee))->tcstate[(CVM_GC_SAFE)]), ((1 == 1)));; } }
+   ;
+ if (!resolved) {
+     return (!(1 == 1));
+ }
+    }
+    case CVM_CONSTANT_ClassBlock: {
+ CVMClassBlock *cb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1262, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[cpIndex] & 0x3F) == CVM_CONSTANT_ClassBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1262, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, cpIndex, ClassBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[cpIndex].resolved.cb);
+ (((void)(((!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1263, "(!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), ((&(((topOfStack[0].s).j).r)))->ref_DONT_ACCESS_DIRECTLY = ((*(((void)(((!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1263, "(!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &((((cb)->javaInstanceX)))->ref_DONT_ACCESS_DIRECTLY))));
+ (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s #%d => %C\n", CVMopnames[pc[0]], cpIndex, cb) : (void)0)
+                     ;
+ return (1 == 1);
+    }
+    default:
+ return (!(1 == 1));
+    }
+}
+static CVMBool
+CVMldcHelper(CVMExecEnv *ee, CVMStackVal32* topOfStack,
+    CVMConstantPool* cp, CVMUint8* pc)
+{
+    return CVMloadConstantHelper(ee, topOfStack, cp, pc[1], pc);
+}
+static CVMBool
+CVMldc_wHelper(CVMExecEnv *ee, CVMStackVal32* topOfStack,
+    CVMConstantPool* cp, CVMUint8* pc)
+{
+    return CVMloadConstantHelper(ee, topOfStack, cp, ((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), pc);
+}
+static void
+CVMldc2_wHelper(CVMStackVal32* topOfStack, CVMConstantPool* cp, CVMUint8* pc)
+{
+    CVMJavaVal64 r;
+    ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(r.v))->l = ((fakeOutGCCStrictAliasing *)(&((cp)->entriesX[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))].resolved.val32.raw)))->l; });
+    { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l = ((fakeOutGCCStrictAliasing *)(r.v))->l; };
+}
+static CVMStackVal32*
+CVMgetfield_quick_wHelper(CVMExecEnv* ee, CVMFrame* frame,
+     CVMStackVal32* topOfStack, CVMConstantPool* cp,
+     CVMUint8* pc)
+{
+    CVMFieldBlock* fb;
+    CVMObject* directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1301, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+    if (directObj == ((void *)0)) {
+ return ((void *)0);
+    }
+    fb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1305, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))] & 0x3F) == CVM_CONSTANT_FieldBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1305, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), FieldBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))].resolved.fb);
+    ;
+    if ((( ((((fb)->nameAndTypeIDX))&0xffff) == 6) || ( ((((fb)->nameAndTypeIDX))&0xffff) == 9))) {
+        if (((0x40 & (0x01 | 0x03 | 0x02)) ? ((((fb)->accessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x40) : ((((fb)->accessFlagsX) & 0x40) != 0))) {
+            CVMsysMicroLock(ee, CVM_ACCESS_VOLATILE_MICROLOCK);
+        }
+ { CVMJavaVal32 volatile* fieldLoc_ = ((CVMJavaVal32 volatile *)(directObj) + (((fb)->offsetX))); union {CVMUint32 x;} tmp_[2]; ; tmp_[0].x = (&(fieldLoc_)->raw)[0]; tmp_[1].x = (&(fieldLoc_)->raw)[1]; { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&(&((topOfStack[-1].s).j))->raw))->l = ((fakeOutGCCStrictAliasing *)(&tmp_[0].x))->l; }; };
+        if (((0x40 & (0x01 | 0x03 | 0x02)) ? ((((fb)->accessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x40) : ((((fb)->accessFlagsX) & 0x40) != 0))) {
+            CVMsysMicroUnlock(ee, CVM_ACCESS_VOLATILE_MICROLOCK);
+        }
+ (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %O[%d](0x%X, 0x%X) ==>\n", CVMopnames[pc[0]], directObj, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), (((topOfStack[-1].s).j).i), (((topOfStack[0].s).j).i)) : (void)0)
+                                     ;
+ topOfStack++;
+    } else {
+ if (( ((((fb)->nameAndTypeIDX))&0xffff) > 10)) {
+     { CVMObject* volatile *fieldLoc_ = (CVMObject* volatile *)((CVMJavaVal32 volatile *)(directObj) + (((fb)->offsetX)));
+ ; (((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1323, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) = *fieldLoc_; };
+ } else {
+     { CVMJavaVal32 volatile* fieldLoc_ = ((CVMJavaVal32 volatile *)(directObj) + (((fb)->offsetX))); ; (((((topOfStack[-1].s).j))) = (*fieldLoc_)); }
+                       ;
+ }
+ (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %O[%d](0x%X) ==>\n", CVMopnames[pc[0]], directObj, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), (((topOfStack[-1].s).j).i)) : (void)0)
+                                                   ;
+    }
+    return topOfStack;
+}
+static CVMStackVal32*
+CVMputfield_quick_wHelper(CVMExecEnv* ee, CVMFrame* frame,
+     CVMStackVal32* topOfStack, CVMConstantPool* cp,
+     CVMUint8* pc)
+{
+    CVMObject* directObj;
+    CVMFieldBlock* fb;
+    fb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1341, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))] & 0x3F) == CVM_CONSTANT_FieldBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1341, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), FieldBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))].resolved.fb);
+    if ((( ((((fb)->nameAndTypeIDX))&0xffff) == 6) || ( ((((fb)->nameAndTypeIDX))&0xffff) == 9))) {
+ directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1343, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-3].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+ if (directObj == ((void *)0)) {
+     return ((void *)0);
+ }
+ ;
+        if (((0x40 & (0x01 | 0x03 | 0x02)) ? ((((fb)->accessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x40) : ((((fb)->accessFlagsX) & 0x40) != 0))) {
+            CVMsysMicroLock(ee, CVM_ACCESS_VOLATILE_MICROLOCK);
+        }
+ { CVMJavaVal32 volatile* fieldLoc_ = ((CVMJavaVal32 volatile *)(directObj) + (((fb)->offsetX))); union {CVMUint32 x;} tmp_[2]; ; { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&tmp_[0].x))->l = ((fakeOutGCCStrictAliasing *)(&(&((topOfStack[-2].s).j))->raw))->l; }; (&(fieldLoc_)->raw)[0] = tmp_[0].x; (&(fieldLoc_)->raw)[1] = tmp_[1].x; };
+        if (((0x40 & (0x01 | 0x03 | 0x02)) ? ((((fb)->accessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x40) : ((((fb)->accessFlagsX) & 0x40) != 0))) {
+            CVMsysMicroUnlock(ee, CVM_ACCESS_VOLATILE_MICROLOCK);
+        }
+ (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s (0x%X, 0x%X) ==> %O[%d]\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).i), (((topOfStack[0].s).j).i), directObj, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))) : (void)0)
+                                    ;
+ topOfStack -= 3;
+    } else {
+ directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1361, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+ if (directObj == ((void *)0)) {
+     return ((void *)0);
+ }
+                                     ;
+ if (( ((((fb)->nameAndTypeIDX))&0xffff) > 10)) {
+     { CVMObject* volatile *fieldLoc_ = (CVMObject* volatile *)((CVMJavaVal32 volatile *)(directObj) + (((fb)->offsetX))); ((void)(((&(CVMglobals.gc.cardTableVirtualBase[(CVMAddr)((fieldLoc_)) / (1 << 9)])) >= CVMglobals.gc.cardTable) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1368, "CARD_TABLE_SLOT_ADDRESS_FOR((fieldLoc_)) >= CVMglobals.gc.cardTable") || (CVMsystemPanic("CVMassertHook returned"), 0))); ((void)(((&(CVMglobals.gc.cardTableVirtualBase[(CVMAddr)((fieldLoc_)) / (1 << 9)])) < CVMglobals.gc.cardTable + CVMglobals.gc.cardTableSize) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1368, "CARD_TABLE_SLOT_ADDRESS_FOR((fieldLoc_)) < CVMglobals.gc.cardTable + CVMglobals.gc.cardTableSize") || (CVMsystemPanic("CVMassertHook returned"), 0))); *(&(CVMglobals.gc.cardTableVirtualBase[(CVMAddr)((fieldLoc_)) / (1 << 9)])) = 1;; *fieldLoc_ = (((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1368, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))); };
+ } else {
+     { CVMJavaVal32 volatile* fieldLoc_ = ((CVMJavaVal32 volatile *)(directObj) + (((fb)->offsetX))); ; ((*fieldLoc_) = ((((topOfStack[-1].s).j)))); };
+ }
+ (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s (0x%X) ==> %O[%d]\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).i), directObj, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))) : (void)0)
+                                                   ;
+ topOfStack -= 2;
+    }
+    return topOfStack;
+}
+static CVMBool
+CVMwideHelper(CVMExecEnv* ee, CVMSlotVal32* locals, CVMFrame* frame)
+{
+    CVMStackVal32* topOfStack;
+    CVMUint8* pc;
+    CVMUint16 reg;
+    CVMBool needRequestCheck = (!(1 == 1));
+    char trBuf[30];
+    pc = (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX);;
+    topOfStack = frame->topOfStack;;
+    reg = ((((*(CVMUint8*)((pc + 2)+(0))) << 8) | (*(CVMUint8*)((pc + 2)+(1)))));
+    ;
+    switch(pc[1]) {
+        case opc_aload:
+        case opc_iload:
+        case opc_fload:
+     (topOfStack[0].s) = locals[reg];
+     if (pc[1] == opc_iload) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tiload_w locals[%d](%d) =>\n", reg, (((topOfStack[0].s).j).i)) : (void)0); }
+                        ;
+     if (pc[1] == opc_aload) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\taload_w locals[%d](0x%x) =>\n", reg, ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1404, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[0].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) : (void)0); }
+                           ;
+     if (pc[1] == opc_fload) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tfload_w locals[%d](%f) =>\n", reg, (((topOfStack[0].s).j).f)) : (void)0); }
+                          ;
+     { pc += 4; topOfStack += 1; ; };
+     break;
+        case opc_lload:
+        case opc_dload:
+     { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l = ((fakeOutGCCStrictAliasing *)(&locals[reg].j.raw))->l; };
+     if (pc[1] == opc_lload) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tlload_w locals[%d](%s) =>\n", reg, (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); }
+                                          ;
+     if (pc[1] == opc_dload) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tdload_w locals[%d](%f) =>\n", reg, ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->d); })) : (void)0); }
+                           ;
+     { pc += 4; topOfStack += 2; ; };
+     break;
+        case opc_istore:
+        case opc_astore:
+        case opc_fstore:
+     locals[reg] = (topOfStack[-1].s);
+     if (pc[1] == opc_istore) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tistore_w %d ==> locals[%d]\n", (((topOfStack[-1].s).j).i), reg) : (void)0); }
+                            ;
+     if (pc[1] == opc_astore) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tastore_w 0x%x => locals[%d]\n", ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1426, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY))), reg) : (void)0); }
+                             ;
+     if (pc[1] == opc_fstore) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tfstore_w %f ==> locals[%d]\n", (((topOfStack[-1].s).j).f), reg) : (void)0); }
+                              ;
+     { pc += 4; topOfStack += -1; ; };
+     break;
+        case opc_lstore:
+        case opc_dstore:
+     { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&locals[reg].j.raw))->l = ((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l; };
+     if (pc[1] == opc_lstore) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tlstore_w %s => locals[%d]\n", (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf), reg) : (void)0); }
+                                            ;
+     if (pc[1] == opc_dstore) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tdstore_w %f => locals[%d]\n", ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); }), reg) : (void)0); }
+                             ;
+     { pc += 4; topOfStack += -2; ; };
+     break;
+        case opc_iinc: {
+     CVMInt16 offset = ((CVMInt16) (((*(CVMUint8*)((pc+4)+(0))) << 8) | (*(CVMUint8*)((pc+4)+(1)))));
+     locals[reg].j.i += offset;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tiinc_w locals[%d]+%d => %d\n", reg, offset, locals[reg].j.i) : (void)0)
+                              ;
+     { pc += 6; topOfStack += 0; ; };
+     break;
+ }
+        case opc_ret:
+     if (((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) {
+  needRequestCheck = (1 == 1);
+     }
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tret_w %d (%#x)\n", reg, locals[reg].a) : (void)0);
+     pc = locals[reg].a;
+     break;
+        default:
+     ((void)(((!(1 == 1))) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1458, "CVM_FALSE") || (CVMsystemPanic("CVMassertHook returned"), 0)));
+    }
+    (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+    frame->topOfStack = topOfStack;;
+    return needRequestCheck;
+}
+static void
+CVMmemCopy64Helper(CVMAddr* destination, CVMAddr* source) {
+    { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(destination))->l = ((fakeOutGCCStrictAliasing *)(source))->l; };
+}
+static CVMStackVal32*
+CVMreturn64Helper(CVMStackVal32* topOfStack, CVMFrame* frame)
+{
+    CVMJavaVal64 result;
+    { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(result.v))->l = ((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l; };
+    topOfStack = (((void)(((1 == 1)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1484, "CVMframeMaskBitsAreCorrect((frame))") || (CVMsystemPanic("CVMassertHook returned"), 0))), ((CVMFrame*)((CVMAddr)((frame)->prevX) & ~((1 << 2) - 1))))->topOfStack;;
+    { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l = ((fakeOutGCCStrictAliasing *)(result.v))->l; };
+    return topOfStack;
+}
+static const CVMUint8 CVMinvokeStaticTransitionCode[] = {
+    opc_invokestatic_quick, 0, 1, opc_exittransition
+};
+static const CVMUint8 CVMinvokeVirtualTransitionCode[] = {
+    opc_invokevirtual_quick_w, 0, 1, opc_exittransition
+};
+static const CVMUint8 CVMinvokeNonVirtualTransitionCode[] = {
+    opc_invokenonvirtual_quick, 0, 1, opc_exittransition
+};
+static const CVMUint8 CVMinvokeInterfaceTransitionCode[] = {
+    opc_invokeinterface_quick, 0, 1, 0, 0, opc_exittransition
+};
+void
+CVMgcUnsafeExecuteJavaMethod(CVMExecEnv* volatile ee,
+                        CVMMethodBlock* mb,
+                        CVMBool isStatic, CVMBool isVirtual)
+{
+    CVMFrame* frame = ((void *)0);
+    CVMFrame* initialframe = ((void *)0);
+    CVMStack* stack = &ee->interpreterStack;
+    CVMStackVal32* topOfStack = ((void *)0);
+    CVMSlotVal32* locals = ((void *)0);
+    CVMUint8* pc = ((void *)0);
+    CVMConstantPool* cp = ((void *)0);
+    CVMTransitionConstantPool transitioncp;
+    CVMClassBlock* initCb = ((void *)0);
+    char trBuf[30];
+    static const void* const opclabels_data[256] = {
+ &&opc_nop, &&opc_aconst_null, &&opc_iconst_m1, &&opc_iconst_0, &&opc_iconst_1, &&opc_iconst_2,
+ &&opc_iconst_3, &&opc_iconst_4, &&opc_iconst_5, &&opc_lconst_0, &&opc_lconst_1, &&opc_fconst_0,
+ &&opc_fconst_1, &&opc_fconst_2, &&opc_dconst_0, &&opc_dconst_1, &&opc_bipush, &&opc_sipush,
+ &&opc_ldc, &&opc_ldc_w, &&opc_ldc2_w, &&opc_iload, &&opc_lload, &&opc_fload,
+ &&opc_dload, &&opc_aload, &&opc_iload_0, &&opc_iload_1, &&opc_iload_2, &&opc_iload_3,
+ &&opc_lload_0, &&opc_lload_1, &&opc_lload_2, &&opc_lload_3, &&opc_fload_0, &&opc_fload_1,
+ &&opc_fload_2, &&opc_fload_3, &&opc_dload_0, &&opc_dload_1, &&opc_dload_2, &&opc_dload_3,
+ &&opc_aload_0, &&opc_aload_1, &&opc_aload_2, &&opc_aload_3, &&opc_iaload, &&opc_laload,
+ &&opc_faload, &&opc_daload, &&opc_aaload, &&opc_baload, &&opc_caload, &&opc_saload,
+ &&opc_istore, &&opc_lstore, &&opc_fstore, &&opc_dstore, &&opc_astore, &&opc_istore_0,
+ &&opc_istore_1, &&opc_istore_2, &&opc_istore_3, &&opc_lstore_0, &&opc_lstore_1, &&opc_lstore_2,
+ &&opc_lstore_3, &&opc_fstore_0, &&opc_fstore_1, &&opc_fstore_2, &&opc_fstore_3, &&opc_dstore_0,
+ &&opc_dstore_1, &&opc_dstore_2, &&opc_dstore_3, &&opc_astore_0, &&opc_astore_1, &&opc_astore_2,
+ &&opc_astore_3, &&opc_iastore, &&opc_lastore, &&opc_fastore, &&opc_dastore, &&opc_aastore,
+ &&opc_bastore, &&opc_castore, &&opc_sastore, &&opc_pop, &&opc_pop2, &&opc_dup,
+ &&opc_dup_x1, &&opc_dup_x2, &&opc_dup2, &&opc_dup2_x1, &&opc_dup2_x2, &&opc_swap,
+ &&opc_iadd, &&opc_ladd, &&opc_fadd, &&opc_dadd, &&opc_isub, &&opc_lsub,
+ &&opc_fsub, &&opc_dsub, &&opc_imul, &&opc_lmul, &&opc_fmul, &&opc_dmul,
+ &&opc_idiv, &&opc_ldiv, &&opc_fdiv, &&opc_ddiv, &&opc_irem, &&opc_lrem,
+ &&opc_frem, &&opc_drem, &&opc_ineg, &&opc_lneg, &&opc_fneg, &&opc_dneg,
+ &&opc_ishl, &&opc_lshl, &&opc_ishr, &&opc_lshr, &&opc_iushr, &&opc_lushr,
+ &&opc_iand, &&opc_land, &&opc_ior, &&opc_lor, &&opc_ixor, &&opc_lxor,
+ &&opc_iinc, &&opc_i2l, &&opc_i2f, &&opc_i2d, &&opc_l2i, &&opc_l2f,
+ &&opc_l2d, &&opc_f2i, &&opc_f2l, &&opc_f2d, &&opc_d2i, &&opc_d2l,
+ &&opc_d2f, &&opc_i2b, &&opc_i2c, &&opc_i2s, &&opc_lcmp, &&opc_fcmpl,
+ &&opc_fcmpg, &&opc_dcmpl, &&opc_dcmpg, &&opc_ifeq, &&opc_ifne, &&opc_iflt,
+ &&opc_ifge, &&opc_ifgt, &&opc_ifle, &&opc_if_icmpeq, &&opc_if_icmpne, &&opc_if_icmplt,
+ &&opc_if_icmpge, &&opc_if_icmpgt, &&opc_if_icmple, &&opc_if_acmpeq, &&opc_if_acmpne, &&opc_goto,
+ &&opc_jsr, &&opc_ret, &&opc_tableswitch, &&opc_lookupswitch, &&opc_ireturn, &&opc_lreturn,
+ &&opc_freturn, &&opc_dreturn, &&opc_areturn, &&opc_return, &&opc_getstatic, &&opc_putstatic,
+ &&opc_getfield, &&opc_putfield, &&opc_invokevirtual, &&opc_invokespecial, &&opc_invokestatic, &&opc_invokeinterface,
+ &&opc_xxxunusedxxx, &&opc_new, &&opc_newarray, &&opc_anewarray, &&opc_arraylength, &&opc_athrow,
+ &&opc_checkcast, &&opc_instanceof, &&opc_monitorenter, &&opc_monitorexit, &&opc_wide, &&opc_multianewarray,
+ &&opc_ifnull, &&opc_ifnonnull, &&opc_goto_w, &&opc_jsr_w, &&opc_breakpoint, &&opc_aldc_ind_quick,
+ &&opc_aldc_ind_w_quick, &&opc_invokestatic_quick, &&opc_invokestatic_checkinit_quick, &&opc_invokevirtual_quick, &&opc_getfield_quick, &&opc_agetfield_quick,
+ &&opc_vinvokevirtual_quick, &&opc_invokevirtual_quick_w, &&opc_putfield_quick, &&opc_invokenonvirtual_quick, &&opc_invokesuper_quick, &&opc_invokeignored_quick,
+ &&opc_getfield2_quick, &&opc_checkcast_quick, &&opc_instanceof_quick, &&opc_nonnull_quick, &&opc_putfield2_quick, &&opc_ainvokevirtual_quick,
+ &&opc_invokevirtualobject_quick, &&opc_invokeinterface_quick, &&opc_aldc_quick, &&opc_ldc_quick, &&opc_exittransition, &&opc_dinvokevirtual_quick,
+ &&opc_aldc_w_quick, &&opc_ldc_w_quick, &&opc_aputfield_quick, &&opc_getfield_quick_w, &&opc_ldc2_w_quick, &&opc_agetstatic_quick,
+ &&opc_getstatic_quick, &&opc_getstatic2_quick, &&opc_aputstatic_quick, &&opc_putstatic_quick, &&opc_putstatic2_quick, &&opc_agetstatic_checkinit_quick,
+ &&opc_getstatic_checkinit_quick, &&opc_getstatic2_checkinit_quick, &&opc_aputstatic_checkinit_quick, &&opc_putstatic_checkinit_quick, &&opc_putstatic2_checkinit_quick, &&opc_putfield_quick_w,
+ &&opc_new_checkinit_quick, &&opc_new_quick, &&opc_anewarray_quick, &&opc_multianewarray_quick, &&opc_prefix, &&opc_DEFAULT,
+ &&opc_DEFAULT, &&opc_DEFAULT, &&opc_DEFAULT, &&opc_DEFAULT
+    };
+    const void* const *opclabels = &opclabels_data[0];
+    if (!CVMCstackCheckSize(ee, (5976 + (3 * 1024)),
+        "CVMgcUnsafeExecuteJavaMethod", (1 == 1))) {
+ goto return_from_executejava_branch_island;
+    }
+    ((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1625, "CVMD_isgcUnsafe(ee)") || (CVMsystemPanic("CVMassertHook returned"), 0)));
+    frame = stack->currentFrame;;
+    initialframe = frame;
+new_transition:
+    ;
+    ((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1640, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_TRANSITION)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1640, "CVMframeIsTransition(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0)));
+    topOfStack = frame->topOfStack;;
+    if (isStatic) {
+ pc = (CVMUint8*)CVMinvokeStaticTransitionCode;
+    } else {
+ if ((((((((CVMMethodRange*) ((CVMUint8 *)((mb) - ((mb)->immutX.methodIndexX)) - ((CVMAddr)(&(((CVMMethodRange *)0)->mb[0])) - (CVMAddr)(&(((CVMMethodRange *)0)->cb)))))->cb))->accessFlagsX) & 0x200) != 0)) {
+     pc = (CVMUint8*)CVMinvokeInterfaceTransitionCode;
+ } else if (isVirtual && !((0x03 & (0x01 | 0x03 | 0x02)) ? ((((mb)->immutX.invokerAndAccessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x03) : ((((mb)->immutX.invokerAndAccessFlagsX) & 0x03) != 0)) &&
+     !(((((((mb)->immutX.nameAndTypeIDX))&0xffff0000) == ((CVMglobals.initTid)&0xffff0000))))) {
+     pc = (CVMUint8*)CVMinvokeVirtualTransitionCode;
+ } else {
+     pc = (CVMUint8*)CVMinvokeNonVirtualTransitionCode;
+ }
+    }
+    isVirtual = (!(1 == 1));
+    (&transitioncp)->cp.cpTypesX = ((void *)0); (&transitioncp)->entry1X.resolved.mb = mb;;
+    cp = (CVMConstantPool*)&transitioncp;
+    (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+    if ((CVMglobals.debugFlags & ((2L)))) { CVMtraceMethodCall(ee, frame, (!(1 == 1))); };
+    ((CVMglobals.debugFlags & ((4L))) != 0 ? CVMconsolePrintf ("stack=0x%x frame=0x%x locals=0x%x tos=0x%x pc=0x%x\n", stack, frame, locals, topOfStack, pc) : (void)0);;
+    {
+ const void* nextLabel;;
+ nextLabel = opclabels[pc[0]];;
+ goto *nextLabel;;
+    }
+    {
+ {
+ opc_nop: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1705, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0);
+     { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ opc_aconst_null: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1711, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     (&(((topOfStack[0].s).j).r))->ref_DONT_ACCESS_DIRECTLY = 0;;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0);
+     { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };
+     opc_iconst_m1: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1730, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; ((topOfStack[0].s).j).i = -1; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0); { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };;
+     opc_iconst_0: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1731, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; ((topOfStack[0].s).j).i = 0; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0); { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };;
+     opc_iconst_1: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1732, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; ((topOfStack[0].s).j).i = 1; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0); { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };;
+     opc_iconst_2: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1733, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; ((topOfStack[0].s).j).i = 2; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0); { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };;
+     opc_iconst_3: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1734, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; ((topOfStack[0].s).j).i = 3; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0); { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };;
+     opc_iconst_4: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1735, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; ((topOfStack[0].s).j).i = 4; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0); { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };;
+     opc_iconst_5: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1736, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; ((topOfStack[0].s).j).i = 5; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0); { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };;
+     opc_lconst_0: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1738, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l = (0LL); }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0); { pc += 1; topOfStack += 2; ; }; ; goto *nextLabel;; };;
+     opc_lconst_1: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1739, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l = (1LL); }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0); { pc += 1; topOfStack += 2; ; }; ; goto *nextLabel;; };;
+     opc_fconst_0: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1741, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; ((topOfStack[0].s).j).f = 0.0; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0); { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };;
+     opc_fconst_1: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1742, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; ((topOfStack[0].s).j).f = 1.0; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0); { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };;
+     opc_fconst_2: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1743, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; ((topOfStack[0].s).j).f = 2.0; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0); { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };;
+     opc_dconst_0: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1745, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->d = (0.0); }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0); { pc += 1; topOfStack += 2; ; }; ; goto *nextLabel;; };;
+     opc_dconst_1: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1746, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->d = (1.0); }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s\n", CVMopnames[pc[0]]) : (void)0); { pc += 1; topOfStack += 2; ; }; ; goto *nextLabel;; };;
+ opc_bipush: { const void* nextLabel; ; ((void)((2 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1749, "2 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[2]];;
+     (((topOfStack[0].s).j).i) = (CVMInt8)(pc[1]);
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tbipush %d\n", (((topOfStack[0].s).j).i)) : (void)0);
+     { pc += 2; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ opc_sipush: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1755, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+     (((topOfStack[0].s).j).i) = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))));
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tsipush %d\n", (((topOfStack[0].s).j).i)) : (void)0);
+     { pc += 3; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ opc_aload: ;
+ opc_iload: ;
+ opc_fload: { const void* nextLabel; ; ((void)((2 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1764, "2 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[2]];; {
+     CVMUint32 localNo = pc[1];
+            CVMSlotVal32 l = locals[localNo];
+     topOfStack += 1;
+     (topOfStack[-1].s) = l;
+     if (pc[0] == opc_aload) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\taload locals[%d](0x%x) =>\n", pc[1], ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1770, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) : (void)0); }
+                             ;
+     if (pc[0] == opc_iload) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tiload locals[%d](%d) =>\n", pc[1], (((topOfStack[-1].s).j).i)) : (void)0); }
+                          ;
+     if (pc[0] == opc_fload) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tfload locals[%d](%f) =>\n", pc[1], (((topOfStack[-1].s).j).f)) : (void)0); }
+                            ;
+     { pc += 2; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+        opc_lload: ;
+ opc_dload: { const void* nextLabel; ; ((void)((2 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1779, "2 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[2]];; {
+     { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l = ((fakeOutGCCStrictAliasing *)(&locals[pc[1]].j.raw))->l; };
+     if (pc[0] == opc_dload) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tdload locals[%d](%f) =>\n", pc[1], ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->d); })) : (void)0); }
+                            ;
+     if (pc[0] == opc_lload) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tlload locals[%d](%s) =>\n", pc[1], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); }
+                                           ;
+     { pc += 2; topOfStack += 2; ; }; ; goto *nextLabel;; };
+ }
+ opc_iload_0: ; opc_aload_0: ; opc_fload_0: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1810, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { CVMSlotVal32 l; pc += 1; l = locals[0]; topOfStack += 1; (topOfStack[-1].s) = l; if (pc[0] == opc_iload_0) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%d) =>\n", CVMopnames[pc[-1]], 0, (((topOfStack[-1].s).j).i)) : (void)0); }; if (pc[0] == opc_aload_0) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](0x%x) =>\n", CVMopnames[pc[-1]], 0, ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1810, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) : (void)0); }; if (pc[0] == opc_fload_0) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%f) =>\n", CVMopnames[pc[-1]], 0, (((topOfStack[-1].s).j).f)) : (void)0); }; { pc += 0; topOfStack += 0; ; }; ; goto *nextLabel;; }; };
+ opc_iload_1: ; opc_aload_1: ; opc_fload_1: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1811, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { CVMSlotVal32 l; pc += 1; l = locals[1]; topOfStack += 1; (topOfStack[-1].s) = l; if (pc[0] == opc_iload_1) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%d) =>\n", CVMopnames[pc[-1]], 1, (((topOfStack[-1].s).j).i)) : (void)0); }; if (pc[0] == opc_aload_1) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](0x%x) =>\n", CVMopnames[pc[-1]], 1, ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1811, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) : (void)0); }; if (pc[0] == opc_fload_1) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%f) =>\n", CVMopnames[pc[-1]], 1, (((topOfStack[-1].s).j).f)) : (void)0); }; { pc += 0; topOfStack += 0; ; }; ; goto *nextLabel;; }; };
+ opc_iload_2: ; opc_aload_2: ; opc_fload_2: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1812, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { CVMSlotVal32 l; pc += 1; l = locals[2]; topOfStack += 1; (topOfStack[-1].s) = l; if (pc[0] == opc_iload_2) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%d) =>\n", CVMopnames[pc[-1]], 2, (((topOfStack[-1].s).j).i)) : (void)0); }; if (pc[0] == opc_aload_2) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](0x%x) =>\n", CVMopnames[pc[-1]], 2, ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1812, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) : (void)0); }; if (pc[0] == opc_fload_2) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%f) =>\n", CVMopnames[pc[-1]], 2, (((topOfStack[-1].s).j).f)) : (void)0); }; { pc += 0; topOfStack += 0; ; }; ; goto *nextLabel;; }; };
+ opc_iload_3: ; opc_aload_3: ; opc_fload_3: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1813, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { CVMSlotVal32 l; pc += 1; l = locals[3]; topOfStack += 1; (topOfStack[-1].s) = l; if (pc[0] == opc_iload_3) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%d) =>\n", CVMopnames[pc[-1]], 3, (((topOfStack[-1].s).j).i)) : (void)0); }; if (pc[0] == opc_aload_3) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](0x%x) =>\n", CVMopnames[pc[-1]], 3, ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1813, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) : (void)0); }; if (pc[0] == opc_fload_3) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%f) =>\n", CVMopnames[pc[-1]], 3, (((topOfStack[-1].s).j).f)) : (void)0); }; { pc += 0; topOfStack += 0; ; }; ; goto *nextLabel;; }; };
+ opc_lload_0: ; opc_dload_0: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1830, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l = ((fakeOutGCCStrictAliasing *)(&locals[0].j.raw))->l; }; if (pc[0] == opc_lload_0) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%s) =>\n", CVMopnames[pc[0]], 0, (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); }; if (pc[0] == opc_dload_0) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%f) =>\n", CVMopnames[pc[0]], 0, ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->d); })) : (void)0); }; { pc += 1; topOfStack += 2; ; }; ; goto *nextLabel;; }; };
+ opc_lload_1: ; opc_dload_1: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1831, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l = ((fakeOutGCCStrictAliasing *)(&locals[1].j.raw))->l; }; if (pc[0] == opc_lload_1) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%s) =>\n", CVMopnames[pc[0]], 1, (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); }; if (pc[0] == opc_dload_1) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%f) =>\n", CVMopnames[pc[0]], 1, ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->d); })) : (void)0); }; { pc += 1; topOfStack += 2; ; }; ; goto *nextLabel;; }; };
+ opc_lload_2: ; opc_dload_2: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1832, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l = ((fakeOutGCCStrictAliasing *)(&locals[2].j.raw))->l; }; if (pc[0] == opc_lload_2) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%s) =>\n", CVMopnames[pc[0]], 2, (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); }; if (pc[0] == opc_dload_2) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%f) =>\n", CVMopnames[pc[0]], 2, ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->d); })) : (void)0); }; { pc += 1; topOfStack += 2; ; }; ; goto *nextLabel;; }; };
+ opc_lload_3: ; opc_dload_3: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1833, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l = ((fakeOutGCCStrictAliasing *)(&locals[3].j.raw))->l; }; if (pc[0] == opc_lload_3) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%s) =>\n", CVMopnames[pc[0]], 3, (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); }; if (pc[0] == opc_dload_3) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s locals[%d](%f) =>\n", CVMopnames[pc[0]], 3, ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->d); })) : (void)0); }; { pc += 1; topOfStack += 2; ; }; ; goto *nextLabel;; }; };
+        opc_iaload: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1872, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMArrayOfInt* arrObj = (CVMArrayOfInt*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1873, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-2 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; { CVMJavaInt volatile *elemLoc_ = (CVMJavaInt volatile *)(&((arrObj)->elems[(index)])); ((void)((index < ((arrObj)->length)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1873, "index < CVMD_arrayGetLength(arrObj)") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; ((((topOfStack[-2].s).j).i)) = *elemLoc_; }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %O[%d](" "%d" ") ==>\n", CVMopnames[pc[0]], arrObj, index, (((topOfStack[-1].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; };
+        opc_laload: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1874, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMJavaLong temp64; CVMArrayOfLong* arrObj = (CVMArrayOfLong*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1875, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-2 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; { CVMJavaVal32 volatile *elemLoc_ = (CVMJavaVal32 volatile *)(&((arrObj)->elems[(index)])); ; *(CVMJavaLong volatile *)&(temp64) = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)((CVMUint32*)&(elemLoc_)->raw))->l); }); }; { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l = temp64; }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %O[%d](0x%X, 0x%X) ==>\n", CVMopnames[pc[0]], arrObj, index, (((topOfStack[-2].s).j).i), (((topOfStack[-1].s).j).i)) : (void)0); { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; }; };
+        opc_faload: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1876, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMArrayOfFloat* arrObj = (CVMArrayOfFloat*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1877, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-2 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; { CVMJavaFloat volatile *elemLoc_ = (CVMJavaFloat volatile *)(&((arrObj)->elems[(index)])); ((void)((index < ((arrObj)->length)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1877, "index < CVMD_arrayGetLength(arrObj)") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; ((((topOfStack[-2].s).j).f)) = *elemLoc_; }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %O[%d](" "%f" ") ==>\n", CVMopnames[pc[0]], arrObj, index, (((topOfStack[-1].s).j).f)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; };
+        opc_daload: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1878, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMJavaDouble temp64; CVMArrayOfDouble* arrObj = (CVMArrayOfDouble*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1879, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-2 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; { CVMJavaVal32 volatile *elemLoc_ = (CVMJavaVal32 volatile *)(&((arrObj)->elems[(index)])); ; *(CVMJavaDouble volatile*)&(temp64) = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)((CVMUint32*)&(elemLoc_)->raw))->d); }); }; { typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d = temp64; }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %O[%d](0x%X, 0x%X) ==>\n", CVMopnames[pc[0]], arrObj, index, (((topOfStack[-2].s).j).i), (((topOfStack[-1].s).j).i)) : (void)0); { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; }; };
+        opc_aaload: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1880, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMArrayOfRef* arrObj = (CVMArrayOfRef*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1881, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-2 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; { CVMObject* volatile *elemLoc_ = (CVMObject* volatile *)(&((arrObj)->elems[(index)])); ((void)((index < ((arrObj)->length)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1881, "index < CVMD_arrayGetLength(arrObj)") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; (((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1881, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) = *elemLoc_; }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %O[%d](" "0x%x" ") ==>\n", CVMopnames[pc[0]], arrObj, index, ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1881, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; };
+        opc_baload: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1882, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMArrayOfByte* arrObj = (CVMArrayOfByte*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1883, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-2 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; { CVMJavaByte volatile *elemLoc_ = (CVMJavaByte volatile *)(&((arrObj)->elems[(index)])); ((void)((index < ((arrObj)->length)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1883, "index < CVMD_arrayGetLength(arrObj)") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; ((((topOfStack[-2].s).j).i)) = *elemLoc_; }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %O[%d](" "%d" ") ==>\n", CVMopnames[pc[0]], arrObj, index, (((topOfStack[-1].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; };
+        opc_caload: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1884, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMArrayOfChar* arrObj = (CVMArrayOfChar*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1885, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-2 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; { CVMJavaChar volatile *elemLoc_ = (CVMJavaChar volatile *)(&((arrObj)->elems[(index)])); ((void)((index < ((arrObj)->length)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1885, "index < CVMD_arrayGetLength(arrObj)") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; ((((topOfStack[-2].s).j).i)) = *elemLoc_; }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %O[%d](" "%d" ") ==>\n", CVMopnames[pc[0]], arrObj, index, (((topOfStack[-1].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; };
+        opc_saload: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1886, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMArrayOfShort* arrObj = (CVMArrayOfShort*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1887, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-2 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; { CVMJavaShort volatile *elemLoc_ = (CVMJavaShort volatile *)(&((arrObj)->elems[(index)])); ((void)((index < ((arrObj)->length)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1887, "index < CVMD_arrayGetLength(arrObj)") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; ((((topOfStack[-2].s).j).i)) = *elemLoc_; }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %O[%d](" "%d" ") ==>\n", CVMopnames[pc[0]], arrObj, index, (((topOfStack[-1].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; };
+ opc_istore: ;
+ opc_fstore: ;
+ opc_astore: { const void* nextLabel; ; ((void)((2 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1893, "2 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[2]];; {
+     locals[pc[1]] = (topOfStack[-1].s);
+     if (pc[0] == opc_istore) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tistore %d ==> locals[%d]\n", (((topOfStack[-1].s).j).i), pc[-1]) : (void)0); }
+                            ;
+     if (pc[0] == opc_astore) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tastore 0x%x => locals[%d]\n", ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1898, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY))), pc[-1]) : (void)0); }
+                               ;
+     if (pc[0] == opc_fstore) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tfstore %f ==> locals[%d]\n", (((topOfStack[-1].s).j).f), pc[-1]) : (void)0); }
+                              ;
+     { pc += 2; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ }
+ opc_lstore: ;
+        opc_dstore: { const void* nextLabel; ; ((void)((2 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1906, "2 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[2]];; {
+     { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&locals[pc[1]].j.raw))->l = ((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l; };
+     if (pc[0] == opc_dstore) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tdstore %f => locals[%d]\n", ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); }), pc[1]) : (void)0); }
+                              ;
+     if (pc[0] == opc_lstore) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tlstore %s => locals[%d]\n", (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf), pc[1]) : (void)0); }
+                                             ;
+     { pc += 2; topOfStack += -2; ; }; ; goto *nextLabel;; };
+ }
+ opc_istore_0: ; opc_astore_0: ; opc_fstore_0: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1933, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { locals[0] = (topOfStack[-1].s); if (pc[0] == opc_istore_0) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %d => locals[%d]\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).i), 0) : (void)0); }; if (pc[0] == opc_astore_0) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s 0x%x => locals[%d]\n", CVMopnames[pc[0]], ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1933, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY))), 0) : (void)0); }; if (pc[0] == opc_fstore_0) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %f => locals[%d]\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).f), 0) : (void)0); }; { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; };
+ opc_istore_1: ; opc_astore_1: ; opc_fstore_1: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1934, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { locals[1] = (topOfStack[-1].s); if (pc[0] == opc_istore_1) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %d => locals[%d]\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).i), 1) : (void)0); }; if (pc[0] == opc_astore_1) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s 0x%x => locals[%d]\n", CVMopnames[pc[0]], ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1934, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY))), 1) : (void)0); }; if (pc[0] == opc_fstore_1) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %f => locals[%d]\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).f), 1) : (void)0); }; { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; };
+ opc_istore_2: ; opc_astore_2: ; opc_fstore_2: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1935, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { locals[2] = (topOfStack[-1].s); if (pc[0] == opc_istore_2) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %d => locals[%d]\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).i), 2) : (void)0); }; if (pc[0] == opc_astore_2) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s 0x%x => locals[%d]\n", CVMopnames[pc[0]], ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1935, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY))), 2) : (void)0); }; if (pc[0] == opc_fstore_2) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %f => locals[%d]\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).f), 2) : (void)0); }; { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; };
+ opc_istore_3: ; opc_astore_3: ; opc_fstore_3: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1936, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { locals[3] = (topOfStack[-1].s); if (pc[0] == opc_istore_3) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %d => locals[%d]\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).i), 3) : (void)0); }; if (pc[0] == opc_astore_3) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s 0x%x => locals[%d]\n", CVMopnames[pc[0]], ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1936, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY))), 3) : (void)0); }; if (pc[0] == opc_fstore_3) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %f => locals[%d]\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).f), 3) : (void)0); }; { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; };
+ opc_lstore_0: ; opc_dstore_0: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1953, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&locals[0].j.raw))->l = ((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l; }; if (pc[0] == opc_lstore_0) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %s => locals[%d]\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf), 0) : (void)0); }; if (pc[0] == opc_dstore_0) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %f => locals[%d]\n", CVMopnames[pc[0]], ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); }), 0) : (void)0); }; { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_lstore_1: ; opc_dstore_1: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1954, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&locals[1].j.raw))->l = ((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l; }; if (pc[0] == opc_lstore_1) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %s => locals[%d]\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf), 1) : (void)0); }; if (pc[0] == opc_dstore_1) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %f => locals[%d]\n", CVMopnames[pc[0]], ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); }), 1) : (void)0); }; { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_lstore_2: ; opc_dstore_2: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1955, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&locals[2].j.raw))->l = ((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l; }; if (pc[0] == opc_lstore_2) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %s => locals[%d]\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf), 2) : (void)0); }; if (pc[0] == opc_dstore_2) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %f => locals[%d]\n", CVMopnames[pc[0]], ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); }), 2) : (void)0); }; { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_lstore_3: ; opc_dstore_3: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1956, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&locals[3].j.raw))->l = ((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l; }; if (pc[0] == opc_lstore_3) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %s => locals[%d]\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf), 3) : (void)0); }; if (pc[0] == opc_dstore_3) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %f => locals[%d]\n", CVMopnames[pc[0]], ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); }), 3) : (void)0); }; { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+        opc_bastore: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1982, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMArrayOfByte* arrObj = (CVMArrayOfByte*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1983, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-3].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-3 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; { CVMJavaByte volatile *elemLoc_ = (CVMJavaByte volatile *)(&((arrObj)->elems[(index)])); ((void)((index < ((arrObj)->length)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1983, "index < CVMD_arrayGetLength(arrObj)") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; *elemLoc_ = ((((topOfStack[-1].s).j).i)); }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s " "%d" " ==> %O[%d] ==>\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).i), arrObj, index) : (void)0); { pc += 1; topOfStack += -3; ; }; ; goto *nextLabel;; }; };
+        opc_castore: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1984, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMArrayOfChar* arrObj = (CVMArrayOfChar*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1985, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-3].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-3 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; { CVMJavaChar volatile *elemLoc_ = (CVMJavaChar volatile *)(&((arrObj)->elems[(index)])); ((void)((index < ((arrObj)->length)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1985, "index < CVMD_arrayGetLength(arrObj)") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; *elemLoc_ = ((((topOfStack[-1].s).j).i)); }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s " "%d" " ==> %O[%d] ==>\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).i), arrObj, index) : (void)0); { pc += 1; topOfStack += -3; ; }; ; goto *nextLabel;; }; };
+        opc_sastore: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1986, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMArrayOfShort* arrObj = (CVMArrayOfShort*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1987, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-3].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-3 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; { CVMJavaShort volatile *elemLoc_ = (CVMJavaShort volatile *)(&((arrObj)->elems[(index)])); ((void)((index < ((arrObj)->length)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1987, "index < CVMD_arrayGetLength(arrObj)") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; *elemLoc_ = ((((topOfStack[-1].s).j).i)); }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s " "%d" " ==> %O[%d] ==>\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).i), arrObj, index) : (void)0); { pc += 1; topOfStack += -3; ; }; ; goto *nextLabel;; }; };
+        opc_iastore: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1988, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMArrayOfInt* arrObj = (CVMArrayOfInt*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1989, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-3].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-3 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; { CVMJavaInt volatile *elemLoc_ = (CVMJavaInt volatile *)(&((arrObj)->elems[(index)])); ((void)((index < ((arrObj)->length)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1989, "index < CVMD_arrayGetLength(arrObj)") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; *elemLoc_ = ((((topOfStack[-1].s).j).i)); }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s " "%d" " ==> %O[%d] ==>\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).i), arrObj, index) : (void)0); { pc += 1; topOfStack += -3; ; }; ; goto *nextLabel;; }; };
+        opc_fastore: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1990, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMArrayOfFloat* arrObj = (CVMArrayOfFloat*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1991, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-3].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-3 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; { CVMJavaFloat volatile *elemLoc_ = (CVMJavaFloat volatile *)(&((arrObj)->elems[(index)])); ((void)((index < ((arrObj)->length)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1991, "index < CVMD_arrayGetLength(arrObj)") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; *elemLoc_ = ((((topOfStack[-1].s).j).f)); }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s " "%f" " ==> %O[%d] ==>\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).f), arrObj, index) : (void)0); { pc += 1; topOfStack += -3; ; }; ; goto *nextLabel;; }; };
+        opc_lastore: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1992, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMJavaLong temp64; CVMArrayOfLong* arrObj = (CVMArrayOfLong*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1993, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-4].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-4 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; temp64 = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }); { CVMJavaVal32 volatile *elemLoc_ = (CVMJavaVal32 volatile*)(&((arrObj)->elems[(index)])); CVMUint32 tmp_[2]; ; { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(tmp_))->l = (temp64); }; (&(elemLoc_)->raw)[0] = tmp_[0]; (&(elemLoc_)->raw)[1] = tmp_[1]; }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s (0x%X, 0x%X) ==> %O[%d]\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i), (((topOfStack[-1].s).j).i), arrObj, index) : (void)0); { pc += 1; topOfStack += -4; ; }; ; goto *nextLabel;; }; };
+        opc_dastore: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1994, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMJavaDouble temp64; CVMArrayOfDouble* arrObj = (CVMArrayOfDouble*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 1995, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-4].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-4 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; }; temp64 = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); }); { CVMJavaVal32 volatile *elemLoc_ = (CVMJavaVal32 volatile *)(&((arrObj)->elems[(index)])); CVMUint32 tmp_[2]; ; { typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(tmp_))->d = (temp64); }; (&(elemLoc_)->raw)[0] = tmp_[0]; (&(elemLoc_)->raw)[1] = tmp_[1]; }; (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s (0x%X, 0x%X) ==> %O[%d]\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i), (((topOfStack[-1].s).j).i), arrObj, index) : (void)0); { pc += 1; topOfStack += -4; ; }; ; goto *nextLabel;; }; };
+        opc_aastore: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2000, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+     CVMObject* rhsObject = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2002, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     CVMArrayOfRef* arrObj = (CVMArrayOfRef*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2003, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-3].s).j).r))->ref_DONT_ACCESS_DIRECTLY))); CVMJavaInt index = (((topOfStack[-3 + 1].s).j).i); if ((arrObj) == 0) { goto null_pointer_exception; }; if ((CVMUint32)index >= ((arrObj)->length)) { goto array_index_out_of_bounds_exception; };
+     if (rhsObject != 0) {
+  CVMClassBlock* elemType =
+      (*(((void)(((((((((CVMClassBlock*)(((CVMAddr)((arrObj)->hdr.clas)) & ~3)))->classNameX))&0xc000) != 0 )) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2007, "CVMisArrayClass(((CVMClassBlock*)(((CVMAddr)((arrObj)->hdr.clas)) & ~3)))") || (CVMsystemPanic("CVMassertHook returned"), 0))), &((((CVMClassBlock*)(((CVMAddr)((arrObj)->hdr.clas)) & ~3)))->cpX.arrayInfoX)->elementCb));
+  CVMClassBlock* rhsType = ((CVMClassBlock*)(((CVMAddr)((rhsObject)->hdr.clas)) & ~3));
+  if (rhsType != elemType) {
+      if (!CVMisAssignable(ee, rhsType, elemType)) {
+   if (!(((ee)->exceptionFlags.oneflag.local) != 0)) {
+       goto array_store_exception;
+   } else {
+       goto handle_exception;
+   }
+      }
+  }
+     }
+     { CVMObject* volatile *elemLoc_ = (CVMObject* volatile *)(&((arrObj)->elems[(index)])); ((void)((index < ((arrObj)->length)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2020, "index < CVMD_arrayGetLength(arrObj)") || (CVMsystemPanic("CVMassertHook returned"), 0))); ((void)(((&(CVMglobals.gc.cardTableVirtualBase[(CVMAddr)((elemLoc_)) / (1 << 9)])) >= CVMglobals.gc.cardTable) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2020, "CARD_TABLE_SLOT_ADDRESS_FOR((elemLoc_)) >= CVMglobals.gc.cardTable") || (CVMsystemPanic("CVMassertHook returned"), 0))); ((void)(((&(CVMglobals.gc.cardTableVirtualBase[(CVMAddr)((elemLoc_)) / (1 << 9)])) < CVMglobals.gc.cardTable + CVMglobals.gc.cardTableSize) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2020, "CARD_TABLE_SLOT_ADDRESS_FOR((elemLoc_)) < CVMglobals.gc.cardTable + CVMglobals.gc.cardTableSize") || (CVMsystemPanic("CVMassertHook returned"), 0))); *(&(CVMglobals.gc.cardTableVirtualBase[(CVMAddr)((elemLoc_)) / (1 << 9)])) = 1;; *elemLoc_ = (rhsObject); };
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s 0x%x ==> %O[%d] ==>\n", CVMopnames[pc[0]], rhsObject, arrObj, index) : (void)0)
+                                                  ;
+     { pc += 1; topOfStack += -3; ; }; ; goto *nextLabel;; };
+ }
+ opc_pop: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2028, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tpop\n") : (void)0);
+     { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ opc_pop2: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2033, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tpop2\n") : (void)0);
+     { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; };
+ opc_dup: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2037, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; {
+     CVMJavaVal32 rhs = ((topOfStack[-1].s).j);
+     topOfStack += 1;
+     pc += 1;
+     ((topOfStack[-1].s).j) = rhs;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tdup\n") : (void)0);
+     { pc += 0; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+ opc_dup_x1: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2046, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     ((topOfStack[0].s).j) = ((topOfStack[-1].s).j);
+     ((topOfStack[-1].s).j) = ((topOfStack[-2].s).j);
+     ((topOfStack[-2].s).j) = ((topOfStack[0].s).j);
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tdup_x1\n") : (void)0);
+     { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ opc_dup_x2: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2053, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     ((topOfStack[0].s).j) = ((topOfStack[-1].s).j);
+     ((topOfStack[-1].s).j) = ((topOfStack[-2].s).j);
+     ((topOfStack[-2].s).j) = ((topOfStack[-3].s).j);
+     ((topOfStack[-3].s).j) = ((topOfStack[0].s).j);
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tdup_x2\n") : (void)0);
+     { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ opc_dup2: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2061, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     ((topOfStack[0].s).j) = ((topOfStack[-2].s).j);
+     ((topOfStack[1].s).j) = ((topOfStack[-1].s).j);
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tdup2\n") : (void)0);
+     { pc += 1; topOfStack += 2; ; }; ; goto *nextLabel;; };
+ opc_dup2_x1: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2067, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     ((topOfStack[1].s).j) = ((topOfStack[-1].s).j);
+     ((topOfStack[0].s).j) = ((topOfStack[-2].s).j);
+     ((topOfStack[-1].s).j) = ((topOfStack[-3].s).j);
+     ((topOfStack[-2].s).j) = ((topOfStack[1].s).j);
+     ((topOfStack[-3].s).j) = ((topOfStack[0].s).j);
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tdup2_x1\n") : (void)0);
+     { pc += 1; topOfStack += 2; ; }; ; goto *nextLabel;; };
+ opc_dup2_x2: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2076, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     ((topOfStack[1].s).j) = ((topOfStack[-1].s).j);
+     ((topOfStack[0].s).j) = ((topOfStack[-2].s).j);
+     ((topOfStack[-1].s).j) = ((topOfStack[-3].s).j);
+     ((topOfStack[-2].s).j) = ((topOfStack[-4].s).j);
+     ((topOfStack[-3].s).j) = ((topOfStack[1].s).j);
+     ((topOfStack[-4].s).j) = ((topOfStack[0].s).j);
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tdup2_x2\n") : (void)0);
+     { pc += 1; topOfStack += 2; ; }; ; goto *nextLabel;; };
+ opc_swap: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2086, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; {
+     CVMJavaVal32 j = ((topOfStack[-1].s).j);
+     ((topOfStack[-1].s).j) = ((topOfStack[-2].s).j);
+     ((topOfStack[-2].s).j) = j;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tswap\n") : (void)0);
+     { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+ opc_iadd: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2133, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     if (0 && ((((topOfStack[-1].s).j).i) == 0)) { goto arithmetic_exception_divide_by_zero; } (((topOfStack[-2].s).j).i) = (((((topOfStack[-2].s).j).i)) + ((((topOfStack[-1].s).j).i))); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };;
+ opc_isub: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2135, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     if (0 && ((((topOfStack[-1].s).j).i) == 0)) { goto arithmetic_exception_divide_by_zero; } (((topOfStack[-2].s).j).i) = (((((topOfStack[-2].s).j).i)) - ((((topOfStack[-1].s).j).i))); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };;
+ opc_imul: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2137, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     if (0 && ((((topOfStack[-1].s).j).i) == 0)) { goto arithmetic_exception_divide_by_zero; } (((topOfStack[-2].s).j).i) = (((((topOfStack[-2].s).j).i)) * ((((topOfStack[-1].s).j).i))); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };;
+ opc_idiv: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2139, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     if (1 && ((((topOfStack[-1].s).j).i) == 0)) { goto arithmetic_exception_divide_by_zero; } (((topOfStack[-2].s).j).i) = ((((((topOfStack[-2].s).j).i)) == 0x80000000 && ((((topOfStack[-1].s).j).i)) == -1) ? (((((topOfStack[-2].s).j).i)) / 1) : (((((topOfStack[-2].s).j).i)) / ((((topOfStack[-1].s).j).i)))); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };;
+ opc_irem: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2141, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     if (1 && ((((topOfStack[-1].s).j).i) == 0)) { goto arithmetic_exception_divide_by_zero; } (((topOfStack[-2].s).j).i) = ((((((topOfStack[-2].s).j).i)) == 0x80000000 && ((((topOfStack[-1].s).j).i)) == -1) ? (((((topOfStack[-2].s).j).i)) % 1) : (((((topOfStack[-2].s).j).i)) % ((((topOfStack[-1].s).j).i)))); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };;
+ opc_iand: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2143, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     if (0 && ((((topOfStack[-1].s).j).i) == 0)) { goto arithmetic_exception_divide_by_zero; } (((topOfStack[-2].s).j).i) = (((((topOfStack[-2].s).j).i)) & ((((topOfStack[-1].s).j).i))); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };;
+ opc_ior: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2145, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     if (0 && ((((topOfStack[-1].s).j).i) == 0)) { goto arithmetic_exception_divide_by_zero; } (((topOfStack[-2].s).j).i) = (((((topOfStack[-2].s).j).i)) | ((((topOfStack[-1].s).j).i))); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };;
+ opc_ixor: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2147, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     if (0 && ((((topOfStack[-1].s).j).i) == 0)) { goto arithmetic_exception_divide_by_zero; } (((topOfStack[-2].s).j).i) = (((((topOfStack[-2].s).j).i)) ^ ((((topOfStack[-1].s).j).i))); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };;
+ opc_fadd: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2150, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     (((topOfStack[-2].s).j).f) = (((((topOfStack[-2].s).j).f)) + ((((topOfStack[-1].s).j).f))); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %f\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).f)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };;
+ opc_fsub: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2152, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     (((topOfStack[-2].s).j).f) = (((((topOfStack[-2].s).j).f)) - ((((topOfStack[-1].s).j).f))); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %f\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).f)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };;
+ opc_fmul: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2154, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     (((topOfStack[-2].s).j).f) = (((((topOfStack[-2].s).j).f)) * ((((topOfStack[-1].s).j).f))); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %f\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).f)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };;
+ opc_fdiv: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2156, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     (((topOfStack[-2].s).j).f) = (((((topOfStack[-2].s).j).f)) / ((((topOfStack[-1].s).j).f))); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %f\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).f)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };;
+ opc_frem: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2158, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     (((topOfStack[-2].s).j).f) = CVMfloatRem((((topOfStack[-2].s).j).f), (((topOfStack[-1].s).j).f)); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %f\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).f)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };;
+ opc_ladd: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2161, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMBool result = CVMlongAddHelper(topOfStack); if (0 && !result) { goto arithmetic_exception_divide_by_zero; } (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %s\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_lsub: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2163, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMBool result = CVMlongSubHelper(topOfStack); if (0 && !result) { goto arithmetic_exception_divide_by_zero; } (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %s\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_lmul: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2165, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMBool result = CVMlongMulHelper(topOfStack); if (0 && !result) { goto arithmetic_exception_divide_by_zero; } (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %s\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_ldiv: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2167, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMBool result = CVMlongDivHelper(topOfStack); if (1 && !result) { goto arithmetic_exception_divide_by_zero; } (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %s\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_lrem: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2169, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMBool result = CVMlongRemHelper(topOfStack); if (1 && !result) { goto arithmetic_exception_divide_by_zero; } (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %s\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_land: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2171, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMBool result = CVMlongAndHelper(topOfStack); if (0 && !result) { goto arithmetic_exception_divide_by_zero; } (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %s\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_lor: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2173, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMBool result = CVMlongOrHelper(topOfStack); if (0 && !result) { goto arithmetic_exception_divide_by_zero; } (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %s\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_lxor: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2175, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMBool result = CVMlongXorHelper(topOfStack); if (0 && !result) { goto arithmetic_exception_divide_by_zero; } (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %s\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_dadd: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2178, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMdoubleAddHelper(topOfStack); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %f\n", CVMopnames[pc[0]], ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d); })) : (void)0); { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_dsub: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2180, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMdoubleSubHelper(topOfStack); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %f\n", CVMopnames[pc[0]], ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d); })) : (void)0); { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_dmul: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2182, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMdoubleMulHelper(topOfStack); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %f\n", CVMopnames[pc[0]], ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d); })) : (void)0); { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_ddiv: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2184, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMdoubleDivHelper(topOfStack); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %f\n", CVMopnames[pc[0]], ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d); })) : (void)0); { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_drem: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2186, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     { CVMdoubleRemHelper(topOfStack); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %f\n", CVMopnames[pc[0]], ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-4].s).j).raw))->d); })) : (void)0); { pc += 1; topOfStack += -2; ; }; ; goto *nextLabel;; }; };
+ opc_ineg: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2191, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; {
+     (((topOfStack[-1].s).j).i) = (- (((((topOfStack[-1].s).j).i))));
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).i)) : (void)0);
+     { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+        opc_lneg: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2197, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+     CVMlongNegHelper(topOfStack);
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %s\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0)
+                                      ;
+     { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+        opc_fneg: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2205, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; {
+     (((topOfStack[-1].s).j).f) = (-((((topOfStack[-1].s).j).f)));
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %f\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).f)) : (void)0);
+     { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+        opc_dneg: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2211, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+     CVMdoubleNegHelper(topOfStack);
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %f\n", CVMopnames[pc[0]], ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); })) : (void)0);
+     { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+        opc_ishl: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2238, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; (((topOfStack[-2].s).j).i) = (((((topOfStack[-2].s).j).i)) << ((((topOfStack[-1].s).j).i) & 0x1F)); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; opc_lshl: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2238, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { CVMlongShlHelper(topOfStack); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %s\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-3].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; };
+ opc_ishr: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2239, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; (((topOfStack[-2].s).j).i) = (((((topOfStack[-2].s).j).i)) >> ((((topOfStack[-1].s).j).i) & 0x1F)); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; opc_lshr: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2239, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { CVMlongShrHelper(topOfStack); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %s\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-3].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; };
+ opc_iushr: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2240, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; (((topOfStack[-2].s).j).i) = (((unsigned int)((((topOfStack[-2].s).j).i))) >> ((((topOfStack[-1].s).j).i) & 0x1F)); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; opc_lushr: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2240, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; { CVMlongUshrHelper(topOfStack); (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %s\n", CVMopnames[pc[0]], (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-3].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; }; };
+        opc_iinc: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2244, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+ {
+     CVMUint32 localNo = pc[1];
+     CVMInt32 incr = (CVMInt8)pc[2];
+     pc += 3;
+     locals[localNo].j.i += incr;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tiinc locals[%d]+%d => %d\n", localNo, (CVMInt8)(incr), locals[localNo].j.i) : (void)0)
+                                           ;
+     { pc += 0; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+        opc_i2l: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2257, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+     CVMJavaLong r;
+     r = ((CVMJavaLong)((((topOfStack[-1].s).j).i)));
+     { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-1].s).j).raw))->l = r; };
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\ti2l => %s\n", (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-1].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0);
+            { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ }
+        opc_i2f: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2266, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+    (((topOfStack[-1].s).j).f) = ((CVMJavaFloat)(((((topOfStack[-1].s).j).i))));
+           (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\ti2f => %f\n", (((topOfStack[-1].s).j).f)) : (void)0);
+           { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+        opc_l2i: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2271, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+        CVMJavaLong r;
+     r = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); });
+     (((topOfStack[-2].s).j).i) = ((CVMJavaInt)(r));
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tl2i => %d\n", (((topOfStack[-2].s).j).i)) : (void)0);
+            { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ }
+        opc_l2f: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2280, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+        CVMJavaLong r;
+     r = ({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); });
+     (((topOfStack[-2].s).j).f) = ((CVMJavaFloat)(r));
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tl2f => %f\n", (((topOfStack[-2].s).j).f)) : (void)0);
+            { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ }
+        opc_f2i: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2289, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+            (((topOfStack[-1].s).j).i) = (float2Int((((topOfStack[-1].s).j).f)));
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tf2i => %d\n", (((topOfStack[-1].s).j).i)) : (void)0);
+            { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+        opc_f2l: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2294, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+     CVMJavaLong r;
+      r = float2Long(((((topOfStack[-1].s).j).f)));
+     { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-1].s).j).raw))->l = r; };
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tf2l => %s\n", (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-1].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0);
+            { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ }
+        opc_f2d: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2303, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+     CVMJavaDouble r;
+     r = ((CVMJavaDouble)((((topOfStack[-1].s).j).f)));
+     { typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&((topOfStack[-1].s).j).raw))->d = r; };
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tf2d => %f\n", ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-1].s).j).raw))->d); })) : (void)0);
+            { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };
+        }
+        opc_d2f: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2312, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+    {
+     CVMJavaDouble r;
+     r = ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); });
+     (((topOfStack[-2].s).j).f) = ((CVMJavaFloat)(r));
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\td2f => %f\n", (((topOfStack[-2].s).j).f)) : (void)0);
+            { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ }
+        opc_i2b: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2321, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     (((topOfStack[-1].s).j).i) = ((signed char)((((topOfStack[-1].s).j).i)));
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\ti2b => %d\n", (((topOfStack[-1].s).j).i)) : (void)0);
+            { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+        opc_i2c: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2326, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     (((topOfStack[-1].s).j).i) = (((((topOfStack[-1].s).j).i)) & (0xffff));
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\ti2c => %d\n", (((topOfStack[-1].s).j).i)) : (void)0);
+            { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+        opc_i2s: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2331, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     (((topOfStack[-1].s).j).i) = ((signed short)((((topOfStack[-1].s).j).i)));
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\ti2s => %d\n", (((topOfStack[-1].s).j).i)) : (void)0);
+            { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+        opc_lcmp: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2338, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+     CVMlongCmpHelper(topOfStack);
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-4].s).j).i)) : (void)0)
+                      ;
+     { pc += 1; topOfStack += -3; ; }; ; goto *nextLabel;; };
+ }
+        opc_fcmpl: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2346, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+     (((topOfStack[-2].s).j).i) =
+  CVMfloatCompare((((topOfStack[-2].s).j).f), (((topOfStack[-1].s).j).f), -1);
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i)) : (void)0);
+     { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ }
+        opc_fcmpg: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2354, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+     (((topOfStack[-2].s).j).i) =
+  CVMfloatCompare((((topOfStack[-2].s).j).f), (((topOfStack[-1].s).j).f), 1);
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-2].s).j).i)) : (void)0);
+     { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ }
+        opc_dcmpg: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2362, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+        {
+     CVMdoubleCmpHelper(topOfStack, 1);
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-4].s).j).i)) : (void)0);
+     { pc += 1; topOfStack += -3; ; }; ; goto *nextLabel;; };
+        }
+        opc_dcmpl: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2369, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+        {
+     CVMdoubleCmpHelper(topOfStack, -1);
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s => %d\n", CVMopnames[pc[0]], (((topOfStack[-4].s).j).i)) : (void)0);
+     { pc += 1; topOfStack += -3; ; }; ; goto *nextLabel;; };
+        }
+ opc_ifeq: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ((((topOfStack[-1].s).j).i) == 0) ? "" : "not ") : (void)0); ; if (((((topOfStack[-1].s).j).i) == 0)) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -1; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -1; ; }; ; goto *nextLabel;; }; } };
+        opc_ifne: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ((((topOfStack[-1].s).j).i) != 0) ? "" : "not ") : (void)0); ; if (((((topOfStack[-1].s).j).i) != 0)) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -1; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -1; ; }; ; goto *nextLabel;; }; } };
+ opc_iflt: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ((((topOfStack[-1].s).j).i) < 0) ? "" : "not ") : (void)0); ; if (((((topOfStack[-1].s).j).i) < 0)) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -1; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -1; ; }; ; goto *nextLabel;; }; } };
+ opc_ifge: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ((((topOfStack[-1].s).j).i) >= 0) ? "" : "not ") : (void)0); ; if (((((topOfStack[-1].s).j).i) >= 0)) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -1; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -1; ; }; ; goto *nextLabel;; }; } };
+ opc_ifgt: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ((((topOfStack[-1].s).j).i) > 0) ? "" : "not ") : (void)0); ; if (((((topOfStack[-1].s).j).i) > 0)) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -1; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -1; ; }; ; goto *nextLabel;; }; } };
+ opc_ifle: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ((((topOfStack[-1].s).j).i) <= 0) ? "" : "not ") : (void)0); ; if (((((topOfStack[-1].s).j).i) <= 0)) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -1; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -1; ; }; ; goto *nextLabel;; }; } };
+ opc_if_icmpeq: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ((((topOfStack[-2].s).j).i) == (((topOfStack[-1].s).j).i)) ? "" : "not ") : (void)0); ; if ((((topOfStack[-2].s).j).i) == (((topOfStack[-1].s).j).i)) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -2; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -2; ; }; ; goto *nextLabel;; }; } };
+        opc_if_icmpne: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ((((topOfStack[-2].s).j).i) != (((topOfStack[-1].s).j).i)) ? "" : "not ") : (void)0); ; if ((((topOfStack[-2].s).j).i) != (((topOfStack[-1].s).j).i)) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -2; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -2; ; }; ; goto *nextLabel;; }; } };
+ opc_if_icmplt: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ((((topOfStack[-2].s).j).i) < (((topOfStack[-1].s).j).i)) ? "" : "not ") : (void)0); ; if ((((topOfStack[-2].s).j).i) < (((topOfStack[-1].s).j).i)) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -2; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -2; ; }; ; goto *nextLabel;; }; } };
+ opc_if_icmpge: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ((((topOfStack[-2].s).j).i) >= (((topOfStack[-1].s).j).i)) ? "" : "not ") : (void)0); ; if ((((topOfStack[-2].s).j).i) >= (((topOfStack[-1].s).j).i)) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -2; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -2; ; }; ; goto *nextLabel;; }; } };
+ opc_if_icmpgt: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ((((topOfStack[-2].s).j).i) > (((topOfStack[-1].s).j).i)) ? "" : "not ") : (void)0); ; if ((((topOfStack[-2].s).j).i) > (((topOfStack[-1].s).j).i)) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -2; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -2; ; }; ; goto *nextLabel;; }; } };
+ opc_if_icmple: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ((((topOfStack[-2].s).j).i) <= (((topOfStack[-1].s).j).i)) ? "" : "not ") : (void)0); ; if ((((topOfStack[-2].s).j).i) <= (((topOfStack[-1].s).j).i)) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -2; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -2; ; }; ; goto *nextLabel;; }; } };
+ opc_if_acmpeq: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), (((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2441, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY))) == ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2441, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) ? "" : "not ") : (void)0); ; if (((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2441, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY))) == ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2441, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -2; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -2; ; }; ; goto *nextLabel;; }; } };
+        opc_if_acmpne: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), (((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2442, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY))) != ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2442, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) ? "" : "not ") : (void)0); ; if (((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2442, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY))) != ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2442, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -2; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -2; ; }; ; goto *nextLabel;; }; } };
+        opc_goto: ;
+ {
+     CVMInt16 skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))));
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %#x (skip=%d)\n",CVMopnames[pc[0]], pc + skip, skip) : (void)0)
+                      ;
+            ;
+            ;
+     { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+        opc_jsr: ;
+        {
+     CVMInt16 skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))));
+            ;
+     ((topOfStack[0].s).a) = pc + 3;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %#x (skip=%d)\n",CVMopnames[pc[0]], pc + skip, skip) : (void)0)
+                      ;
+     { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ }
+        opc_ret: ; {
+            ;
+     if (((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) {
+  goto handle_pending_request;
+     }
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tret %d (%#x)\n", pc[1], locals[pc[1]].a) : (void)0);
+     pc = locals[pc[1]].a;
+     { const void* nextLabel;; nextLabel = opclabels[pc[0]];; ; ; goto *nextLabel;; };
+ }
+ opc_tableswitch: ;
+ {
+     CVMInt32 skip = CVMtableswitchHelper(ee, topOfStack, pc, frame);
+     { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ }
+ opc_lookupswitch: ;
+ {
+     CVMInt32 skip = CVMlookupswitchHelper(ee, topOfStack, pc, frame);
+     { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ }
+ opc_lreturn: ;
+ opc_dreturn: ;
+        {
+            ;
+     if (((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) {
+  goto handle_pending_request;
+     }
+     topOfStack = CVMreturn64Helper(topOfStack, frame);
+     topOfStack += 2;
+     if (pc[0] == opc_dreturn) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tfreturn1 %f\n", ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); })) : (void)0); };
+     if (pc[0] == opc_lreturn) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tlreturn %s\n", (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0); }
+                                       ;
+     goto handle_return;
+        }
+ opc_return: ;
+        {
+            ;
+     if (((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) {
+  goto handle_pending_request;
+     }
+     topOfStack = (((void)(((1 == 1)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2574, "CVMframeMaskBitsAreCorrect((frame))") || (CVMsystemPanic("CVMassertHook returned"), 0))), ((CVMFrame*)((CVMAddr)((frame)->prevX) & ~((1 << 2) - 1))))->topOfStack;;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\treturn\n") : (void)0);
+     goto handle_return;
+ }
+ opc_ireturn: ;
+ opc_areturn: ;
+ opc_freturn: ;
+        {
+     CVMJavaVal32 result;
+            ;
+     if (((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) {
+  goto handle_pending_request;
+     }
+     result = ((topOfStack[-1].s).j);
+     topOfStack = (((void)(((1 == 1)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2631, "CVMframeMaskBitsAreCorrect((frame))") || (CVMsystemPanic("CVMassertHook returned"), 0))), ((CVMFrame*)((CVMAddr)((frame)->prevX) & ~((1 << 2) - 1))))->topOfStack;;
+     ((topOfStack[0].s).j) = result;
+     topOfStack++;
+     if (pc[0] == opc_ireturn) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tireturn %d\n", (((topOfStack[-1].s).j).i)) : (void)0); };
+     if (pc[0] == opc_areturn) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tareturn 0x%x\n", ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2635, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) : (void)0); };
+     if (pc[0] == opc_freturn) { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tfreturn %f\n", (((topOfStack[-1].s).j).f)) : (void)0); };
+     goto handle_return;
+        }
+    handle_return:
+ ;
+ {
+     if (((0x20 & (0x01 | 0x03 | 0x02)) ? ((((frame->mb)->immutX.invokerAndAccessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x20) : ((((frame->mb)->immutX.invokerAndAccessFlagsX) & 0x20) != 0))) {
+                CVMObjectICell *objICell = &((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2658, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2658, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->receiverObjX);
+                if (!CVMfastTryUnlock(ee, (*(((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2659, "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(objICell)->ref_DONT_ACCESS_DIRECTLY)))) {
+      ;
+      (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2662, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2662, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->opstackX);;
+      (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+      if (!CVMsyncReturnHelper(ee, frame, &(((topOfStack[-1].s).j).r),
+          pc[0] == opc_areturn))
+      {
+                        frame = stack->currentFrame;;
+   goto handle_exception;
+      }
+  }
+     }
+     ((CVMglobals.debugFlags & ((4L))) != 0 ? CVMconsolePrintf ("stack=0x%x frame=0x%x locals=0x%x tos=0x%x pc=0x%x\n", stack, frame, locals, topOfStack, pc) : (void)0);;
+     if ((CVMglobals.debugFlags & ((2L)))) { CVMtraceMethodReturn(ee, frame); };
+     { { CVMFrame* prev_ = (((frame)))->prevX; ((void)(((1 == 1)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2675, "CVMframeMaskBitsAreCorrect((((frame))))") || (CVMsystemPanic("CVMassertHook returned"), 0))); if ((((CVMAddr)(prev_) & (1 << 0)) != 0)) { CVMStackChunk* chunk_ = (((stack))->currentStackChunk); while(!(((CVMStackVal32*)((((frame)))) < (chunk_)->end_data) && ((CVMStackVal32*)((((frame)))) >= &(chunk_)->data[0]))) { chunk_ = chunk_->prev; } prev_ = ((CVMFrame*)((CVMAddr)(prev_) & ~((1 << 2) - 1))); if ((prev_ != ((void *)0)) && !(((CVMStackVal32*)(prev_->topOfStack) < (chunk_)->end_data) && ((CVMStackVal32*)(prev_->topOfStack) >= &(chunk_)->data[0]))) { chunk_ = chunk_->prev; } { { (((stack))->currentFrame) = ((prev_)); }; { CVMStackChunk * volatile *currentStackChunkPtr_; currentStackChunkPtr_ = &(((stack)))->currentStackChunk; *currentStackChunkPtr_ = chunk_; }; ((stack))->stackChunkStart = chunk_->data; ((stack))->stackChunkEnd = chunk_->end_data; { } }; } else { prev_ = ((CVMFrame*)((CVMAddr)(prev_) & ~((1 << 2) - 1))); } ((frame)) = prev_; }; ((stack))->currentFrame = ((frame)); };
+     pc = (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX);;
+     if (((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2698, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) {
+  locals = (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->localsX);
+  cp = (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->cpX);
+     }
+     pc += (*pc == opc_invokeinterface_quick ? 5 : 3);
+     ((CVMglobals.debugFlags & ((4L))) != 0 ? CVMconsolePrintf ("stack=0x%x frame=0x%x locals=0x%x tos=0x%x pc=0x%x\n", stack, frame, locals, topOfStack, pc) : (void)0);;
+     { const void* nextLabel;; nextLabel = opclabels[pc[0]];; ; ; goto *nextLabel;; };
+ }
+        opc_newarray: { const void* nextLabel; ; ((void)((2 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2726, "2 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[2]];; {
+     (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+     frame->topOfStack = topOfStack;;
+     if (!CVMnewarrayHelper(ee, topOfStack, (CVMBasicType)pc[1])) {
+  goto handle_exception;
+     }
+     { pc += 2; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+        opc_arraylength: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2741, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+     CVMArrayOfAnyType* arrObj = (CVMArrayOfAnyType*)((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2743, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     if ((arrObj) == 0) { goto null_pointer_exception; };
+     (((topOfStack[-1].s).j).i) = ((arrObj)->length);
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %O.length(%d) ==>\n", CVMopnames[pc[0]], arrObj, (((topOfStack[-1].s).j).i)) : (void)0)
+                            ;
+     { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+ opc_athrow: ; {
+     CVMObject* directObj;
+            ;
+     directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2757, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     if ((directObj) == 0) { goto null_pointer_exception; };
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tathrow => %O\n", directObj) : (void)0);
+     (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+     { ((void)((!(((ee)->exceptionFlags.oneflag.local) != 0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2761, "!CVMlocalExceptionOccurred(ee)") || (CVMsystemPanic("CVMassertHook returned"), 0))); (ee)->isThrowingAnException = (1 == 1); (((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2761, "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((ee)->localExceptionICell))->ref_DONT_ACCESS_DIRECTLY = (directObj));; ((ee)->exceptionFlags.oneflag.local) = 1; ((CVMglobals.debugFlags & ((16384L))) != 0 ? CVMconsolePrintf ("[<%d> Exception thrown: %O]\n", ee->threadID, directObj) : (void)0); if ((CVMglobals.debugFlags & ((16384L)))) { CVMdumpStack(&ee->interpreterStack, (!(1 == 1)), (!(1 == 1)), 100); } };
+     goto handle_exception;
+ }
+ opc_monitorenter: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2767, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; {
+     CVMObject* directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2768, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     if ((directObj) == 0) { goto null_pointer_exception; };
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\topc_monitorenter(%O)\n", directObj) : (void)0);
+     if (!CVMfastTryLock(ee, directObj)) {
+  (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+  frame->topOfStack = topOfStack;;
+  if (!CVMsyncKinds[((((((((*(((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2776, "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))))->hdr.various32)) & ((1 << 2) - 1)) & 0x1)].lock(ee, &(((topOfStack[-1].s).j).r))) {
+      goto out_of_memory_error;
+  }
+     }
+     { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ }
+        opc_monitorexit: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2783, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];; {
+     CVMObject* directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2784, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     if ((directObj) == 0) { goto null_pointer_exception; };
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\topc_monitorexit(%O)\n", directObj) : (void)0);
+     if (!CVMfastTryUnlock(ee, directObj)){
+  (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+  frame->topOfStack = topOfStack;;
+  if (!CVMsyncKinds[((((((((*(((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2792, "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))))->hdr.various32)) & ((1 << 2) - 1)) & 0x1)].unlock(ee, &(((topOfStack[-1].s).j).r))) {
+      goto illegal_monitor_state_exception_thread_not_owner;
+  }
+     }
+     { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ }
+ opc_ifnull: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), (!!(((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2818, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY))) == 0)) ? "" : "not ") : (void)0); ; if (!!(((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2818, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY))) == 0)) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -1; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -1; ; }; ; goto *nextLabel;; }; } };
+ opc_ifnonnull: ; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s goto +%d (%staken)\n", CVMopnames[pc[0]], ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), (!(((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2819, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY))) == 0)) ? "" : "not ") : (void)0); ; if (!(((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2819, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY))) == 0)) { int skip = ((CVMInt16) (((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))); ; { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += -1; ; }; ; goto *nextLabel;; }; } else { { const void* nextLabel;; nextLabel = opclabels[pc[3]];; if ((3) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += 3; topOfStack += -1; ; }; ; goto *nextLabel;; }; } };
+        opc_breakpoint: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2850, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); nextLabel = opclabels[pc[1]];; {
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tbreakpoint\n") : (void)0);
+     { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+ opc_aldc_ind_quick: { const void* nextLabel; ; ((void)((2 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2858, "2 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[2]];; {
+     CVMObjectICell* strICell = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2859, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[pc[1]] & 0x3F) == CVM_CONSTANT_StringICell)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2859, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, pc[1], StringICell)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[pc[1]].resolved.strICell);
+     (((void)(((!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2860, "(!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), ((&(((topOfStack[0].s).j).r)))->ref_DONT_ACCESS_DIRECTLY = ((*(((void)(((!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2860, "(!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &((strICell))->ref_DONT_ACCESS_DIRECTLY))));
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s #%d => 0x%x\n", CVMopnames[pc[0]], pc[1], (((topOfStack[0].s).j).i)) : (void)0)
+                          ;
+     { pc += 2; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ }
+        opc_aldc_quick: ;
+        opc_ldc_quick: { const void* nextLabel; ; ((void)((2 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2867, "2 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[2]];;
+     ((topOfStack[0].s).j) = ((cp)->entriesX[pc[1]].resolved.val32);
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s #%d => 0x%x\n", CVMopnames[pc[0]], pc[1], (((topOfStack[0].s).j).i)) : (void)0)
+                          ;
+     { pc += 2; topOfStack += 1; ; }; ; goto *nextLabel;; };
+        opc_checkcast_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2875, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+ {
+     CVMObject* directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2877, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     CVMClassBlock* castCb =
+  (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2879, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))] & 0x3F) == CVM_CONSTANT_ClassBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2879, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), ClassBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))].resolved.cb);
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %C\n", CVMopnames[pc[0]], castCb) : (void)0);
+     if (!CVMgcUnsafeIsInstanceOf(ee, directObj, castCb)) {
+  goto class_cast_exception;
+     }
+     { pc += 3; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+        opc_instanceof_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2889, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+ {
+     CVMObject* directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2891, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     (((topOfStack[-1].s).j).i) = (directObj != ((void *)0)) &&
+  CVMgcUnsafeIsInstanceOf(ee, directObj,
+     (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2894, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))] & 0x3F) == CVM_CONSTANT_ClassBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2894, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), ClassBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))].resolved.cb));
+     if ((((ee)->exceptionFlags.oneflag.local) != 0)) {
+  (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+  goto handle_exception;
+     }
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %C => %d\n", CVMopnames[pc[0]], (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2902, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))] & 0x3F) == CVM_CONSTANT_ClassBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2902, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), ClassBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))].resolved.cb), (((topOfStack[-1].s).j).i)) : (void)0)
+                    ;
+     { pc += 3; topOfStack += 0; ; }; ; goto *nextLabel;; };
+  }
+ opc_nonnull_quick: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2908, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tnonnull_quick\n") : (void)0);
+     if ((((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2910, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))) == 0) { goto null_pointer_exception; };
+     { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ opc_exittransition: ; {
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\texittransition\n") : (void)0);
+     if (frame == initialframe) {
+                if ((CVMglobals.debugFlags & ((2L)))) { CVMtraceMethodReturn(ee, frame); };
+  goto finish;
+     } else {
+  goto opc_exittransition_overflow;
+     }
+ }
+ opc_agetstatic_quick: ;
+ opc_getstatic_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2933, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];; {
+     CVMFieldBlock* fb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2934, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))] & 0x3F) == CVM_CONSTANT_FieldBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2934, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), FieldBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))].resolved.fb);
+     ;
+     ((topOfStack[0].s).j) = (*((void)(ee), &((((((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb))->staticsX.statics)[((fb)->offsetX)])));
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s #%d %C.%F[%d] (0x%X) ==>\n", CVMopnames[pc[0]], ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), (((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb), fb, ((fb)->offsetX), (((topOfStack[0].s).j).i)) : (void)0)
+                                    ;
+     { pc += 3; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ }
+ opc_getstatic2_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2944, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];; {
+     CVMFieldBlock* fb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2945, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))] & 0x3F) == CVM_CONSTANT_FieldBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2945, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), FieldBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))].resolved.fb);
+     ;
+            if (((0x40 & (0x01 | 0x03 | 0x02)) ? ((((fb)->accessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x40) : ((((fb)->accessFlagsX) & 0x40) != 0))) {
+                CVMsysMicroLock(ee, CVM_ACCESS_VOLATILE_MICROLOCK);
+            }
+     CVMmemCopy64Helper(&((topOfStack[0].s).j).raw,
+          &(*((void)(ee), &((((((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb))->staticsX.statics)[((fb)->offsetX)]))).raw);
+            if (((0x40 & (0x01 | 0x03 | 0x02)) ? ((((fb)->accessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x40) : ((((fb)->accessFlagsX) & 0x40) != 0))) {
+                CVMsysMicroUnlock(ee, CVM_ACCESS_VOLATILE_MICROLOCK);
+            }
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s #%d %C.%F[%d] ((0x%X,0x%X) ==>\n", CVMopnames[pc[0]], ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), (((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb), fb, ((fb)->offsetX), (((topOfStack[0].s).j).i), (((topOfStack[1].s).j).i)) : (void)0)
+                                                  ;
+     { pc += 3; topOfStack += 2; ; }; ; goto *nextLabel;; };
+ }
+ opc_aputstatic_quick: ;
+ opc_putstatic_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2963, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];; {
+     CVMFieldBlock* fb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2964, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))] & 0x3F) == CVM_CONSTANT_FieldBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2964, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), FieldBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))].resolved.fb);
+     ;
+     (*((void)(ee), &((((((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb))->staticsX.statics)[((fb)->offsetX)]))) = ((topOfStack[-1].s).j);
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s #%d (0x%X) ==> %C.%F[%d]\n", CVMopnames[pc[0]], ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), (((topOfStack[-1].s).j).i), (((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb), fb, ((fb)->offsetX)) : (void)0)
+                                               ;
+     { pc += 3; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ }
+ opc_putstatic2_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2973, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];; {
+     CVMFieldBlock* fb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2974, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))] & 0x3F) == CVM_CONSTANT_FieldBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2974, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), FieldBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))].resolved.fb);
+     ;
+            if (((0x40 & (0x01 | 0x03 | 0x02)) ? ((((fb)->accessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x40) : ((((fb)->accessFlagsX) & 0x40) != 0))) {
+                CVMsysMicroLock(ee, CVM_ACCESS_VOLATILE_MICROLOCK);
+            }
+     CVMmemCopy64Helper(&(*((void)(ee), &((((((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb))->staticsX.statics)[((fb)->offsetX)]))).raw,
+          &((topOfStack[-2].s).j).raw);
+            if (((0x40 & (0x01 | 0x03 | 0x02)) ? ((((fb)->accessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x40) : ((((fb)->accessFlagsX) & 0x40) != 0))) {
+                CVMsysMicroUnlock(ee, CVM_ACCESS_VOLATILE_MICROLOCK);
+            }
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s #%d (0x%X,0x%X) ==> %C.%F[%d]\n", CVMopnames[pc[0]], ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), (((topOfStack[-2].s).j).i), (((topOfStack[-1].s).j).i), (((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb), fb, ((fb)->offsetX)) : (void)0)
+                                               ;
+     { pc += 3; topOfStack += -2; ; }; ; goto *nextLabel;; };
+ }
+ opc_agetstatic_checkinit_quick: ;
+ opc_getstatic_checkinit_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 2997, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); nextLabel = opclabels[pc[3]];;
+ {
+     CVMFieldBlock* fb;
+     CVMClassBlock* cb;
+     fb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3001, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))] & 0x3F) == CVM_CONSTANT_FieldBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3001, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), FieldBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))].resolved.fb);
+     cb = (((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb);
+     if ((!(((CVMAddr)(*((void)(ee), ((((((cb)->runtimeFlagsX) & 0x01) != 0)) ? &((*(cb)->clinitEEX.eePtr)) : &((cb)->clinitEEX.ee)))) & 0x2) != 0) && ((CVMExecEnv*)((CVMAddr)((*((void)(ee), ((((((cb)->runtimeFlagsX) & 0x01) != 0)) ? &((*(cb)->clinitEEX.eePtr)) : &((cb)->clinitEEX.ee))))) & ~(0x1 | 0x2))) != ee)) { initCb = cb; goto init_class; } ;;
+     ;
+     ((topOfStack[0].s).j) = (*((void)(ee), &((((((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb))->staticsX.statics)[((fb)->offsetX)])));
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s #%d %C.%F[%d] (0x%X) ==>\n", CVMopnames[pc[0]], ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), cb, fb, ((fb)->offsetX), (((topOfStack[0].s).j).i)) : (void)0)
+                                    ;
+     { pc += 3; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ }
+ opc_getstatic2_checkinit_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3012, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); nextLabel = opclabels[pc[3]];;
+ {
+     CVMFieldBlock* fb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3014, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))] & 0x3F) == CVM_CONSTANT_FieldBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3014, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), FieldBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))].resolved.fb);
+     CVMClassBlock* cb = (((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb);
+     if ((!(((CVMAddr)(*((void)(ee), ((((((cb)->runtimeFlagsX) & 0x01) != 0)) ? &((*(cb)->clinitEEX.eePtr)) : &((cb)->clinitEEX.ee)))) & 0x2) != 0) && ((CVMExecEnv*)((CVMAddr)((*((void)(ee), ((((((cb)->runtimeFlagsX) & 0x01) != 0)) ? &((*(cb)->clinitEEX.eePtr)) : &((cb)->clinitEEX.ee))))) & ~(0x1 | 0x2))) != ee)) { initCb = cb; goto init_class; } ;;
+     ;
+            if (((0x40 & (0x01 | 0x03 | 0x02)) ? ((((fb)->accessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x40) : ((((fb)->accessFlagsX) & 0x40) != 0))) {
+                CVMsysMicroLock(ee, CVM_ACCESS_VOLATILE_MICROLOCK);
+            }
+     CVMmemCopy64Helper(&((topOfStack[0].s).j).raw,
+          &(*((void)(ee), &((((((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb))->staticsX.statics)[((fb)->offsetX)]))).raw);
+            if (((0x40 & (0x01 | 0x03 | 0x02)) ? ((((fb)->accessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x40) : ((((fb)->accessFlagsX) & 0x40) != 0))) {
+                CVMsysMicroUnlock(ee, CVM_ACCESS_VOLATILE_MICROLOCK);
+            }
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s #%d %C.%F[%d] ((0x%X,0x%X) ==>\n", CVMopnames[pc[0]], ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), cb, fb, ((fb)->offsetX), (((topOfStack[0].s).j).i), (((topOfStack[1].s).j).i)) : (void)0)
+                                                  ;
+     { pc += 3; topOfStack += 2; ; }; ; goto *nextLabel;; };
+ }
+ opc_aputstatic_checkinit_quick: ;
+ opc_putstatic_checkinit_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3034, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); nextLabel = opclabels[pc[3]];;
+        {
+     CVMFieldBlock* fb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3036, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))] & 0x3F) == CVM_CONSTANT_FieldBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3036, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), FieldBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))].resolved.fb);
+     CVMClassBlock* cb = (((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb);
+     if ((!(((CVMAddr)(*((void)(ee), ((((((cb)->runtimeFlagsX) & 0x01) != 0)) ? &((*(cb)->clinitEEX.eePtr)) : &((cb)->clinitEEX.ee)))) & 0x2) != 0) && ((CVMExecEnv*)((CVMAddr)((*((void)(ee), ((((((cb)->runtimeFlagsX) & 0x01) != 0)) ? &((*(cb)->clinitEEX.eePtr)) : &((cb)->clinitEEX.ee))))) & ~(0x1 | 0x2))) != ee)) { initCb = cb; goto init_class; } ;;
+     ;
+     (*((void)(ee), &((((((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb))->staticsX.statics)[((fb)->offsetX)]))) = ((topOfStack[-1].s).j);
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s #%d (0x%X) ==> %C.%F[%d]\n", CVMopnames[pc[0]], ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), (((topOfStack[-1].s).j).i), cb, fb, ((fb)->offsetX)) : (void)0)
+                              ;
+     { pc += 3; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ }
+ opc_putstatic2_checkinit_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3047, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); nextLabel = opclabels[pc[3]];;
+ {
+     CVMFieldBlock* fb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3049, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))] & 0x3F) == CVM_CONSTANT_FieldBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3049, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), FieldBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1)))))].resolved.fb);
+     CVMClassBlock* cb = (((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb);
+     if ((!(((CVMAddr)(*((void)(ee), ((((((cb)->runtimeFlagsX) & 0x01) != 0)) ? &((*(cb)->clinitEEX.eePtr)) : &((cb)->clinitEEX.ee)))) & 0x2) != 0) && ((CVMExecEnv*)((CVMAddr)((*((void)(ee), ((((((cb)->runtimeFlagsX) & 0x01) != 0)) ? &((*(cb)->clinitEEX.eePtr)) : &((cb)->clinitEEX.ee))))) & ~(0x1 | 0x2))) != ee)) { initCb = cb; goto init_class; } ;;
+     ;
+            if (((0x40 & (0x01 | 0x03 | 0x02)) ? ((((fb)->accessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x40) : ((((fb)->accessFlagsX) & 0x40) != 0))) {
+                CVMsysMicroLock(ee, CVM_ACCESS_VOLATILE_MICROLOCK);
+            }
+     CVMmemCopy64Helper(&(*((void)(ee), &((((((CVMFieldRange*) ((CVMUint8 *)((fb) - ((fb)->fbIndexX)) - ((CVMAddr)(&(((CVMFieldRange *)0)->fb[0])) - (CVMAddr)(&(((CVMFieldRange *)0)->cb)))))->cb))->staticsX.statics)[((fb)->offsetX)]))).raw,
+          &((topOfStack[-2].s).j).raw);
+            if (((0x40 & (0x01 | 0x03 | 0x02)) ? ((((fb)->accessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x40) : ((((fb)->accessFlagsX) & 0x40) != 0))) {
+                CVMsysMicroUnlock(ee, CVM_ACCESS_VOLATILE_MICROLOCK);
+            }
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s #%d (0x%X,0x%X) ==> %C.%F[%d]\n", CVMopnames[pc[0]], ((((*(CVMUint8*)((pc+1)+(0))) << 8) | (*(CVMUint8*)((pc+1)+(1))))), (((topOfStack[-2].s).j).i), (((topOfStack[-1].s).j).i), cb, fb, ((fb)->offsetX)) : (void)0)
+                              ;
+     { pc += 3; topOfStack += -2; ; }; ; goto *nextLabel;; };
+ }
+        opc_getfield_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3074, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+ {
+     CVMObject* directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3076, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     CVMUint32 slotIndex = pc[1];
+     if ((directObj) == 0) { goto null_pointer_exception; };
+     pc += 3;
+     { CVMJavaVal32 volatile* fieldLoc_ = ((CVMJavaVal32 volatile *)(directObj) + (slotIndex)); ; (((((topOfStack[-1].s).j))) = (*fieldLoc_)); };
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %O[%d](0x%X) ==>\n", CVMopnames[pc[-3]], directObj, slotIndex, (((topOfStack[-1].s).j).i)) : (void)0)
+                                          ;
+            { pc += 0; topOfStack += 0; ; }; ; goto *nextLabel;; };
+        }
+        opc_putfield_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3086, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+ {
+     CVMObject* directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3088, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     CVMUint32 slotIndex = pc[1];
+     if ((directObj) == 0) { goto null_pointer_exception; };
+     { CVMJavaVal32 volatile* fieldLoc_ = ((CVMJavaVal32 volatile *)(directObj) + (slotIndex)); ; ((*fieldLoc_) = ((((topOfStack[-1].s).j)))); };
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s (0x%X) ==> %O[%d]\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).i), directObj, slotIndex) : (void)0)
+                                          ;
+            { pc += 3; topOfStack += -2; ; }; ; goto *nextLabel;; };
+        }
+        opc_getfield2_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3097, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+ {
+     CVMObject* directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3099, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     if ((directObj) == 0) { goto null_pointer_exception; };
+     { CVMJavaVal32 volatile* fieldLoc_ = ((CVMJavaVal32 volatile *)(directObj) + (pc[1])); union {CVMUint32 x;} tmp_[2]; ; tmp_[0].x = (&(fieldLoc_)->raw)[0]; tmp_[1].x = (&(fieldLoc_)->raw)[1]; { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&(&((topOfStack[-1].s).j))->raw))->l = ((fakeOutGCCStrictAliasing *)(&tmp_[0].x))->l; }; };
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %O[%d](0x%X, 0x%X) ==>\n", CVMopnames[pc[0]], directObj, pc[1], (((topOfStack[-1].s).j).i), (((topOfStack[0].s).j).i)) : (void)0)
+                                                    ;
+            { pc += 3; topOfStack += 1; ; }; ; goto *nextLabel;; };
+        }
+        opc_putfield2_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3107, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+ {
+     CVMObject* directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3109, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-3].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     if ((directObj) == 0) { goto null_pointer_exception; };
+     { CVMJavaVal32 volatile* fieldLoc_ = ((CVMJavaVal32 volatile *)(directObj) + (pc[1])); union {CVMUint32 x;} tmp_[2]; ; { typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; ((fakeOutGCCStrictAliasing *)(&tmp_[0].x))->l = ((fakeOutGCCStrictAliasing *)(&(&((topOfStack[-2].s).j))->raw))->l; }; (&(fieldLoc_)->raw)[0] = tmp_[0].x; (&(fieldLoc_)->raw)[1] = tmp_[1].x; };
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s (0x%X, 0x%X) ==> %O[%d]\n", CVMopnames[pc[0]], (((topOfStack[-1].s).j).i), (((topOfStack[0].s).j).i), directObj, pc[1]) : (void)0)
+                                                    ;
+            { pc += 3; topOfStack += -3; ; }; ; goto *nextLabel;; };
+        }
+ opc_agetfield_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3117, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+ {
+     CVMObject* fieldObj;
+     CVMObject* directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3120, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     CVMUint32 slotIndex = pc[1];
+     if ((directObj) == 0) { goto null_pointer_exception; };
+     pc += 3;
+     { CVMObject* volatile *fieldLoc_ = (CVMObject* volatile *)((CVMJavaVal32 volatile *)(directObj) + (slotIndex)); ; (fieldObj) = *fieldLoc_; };
+     (((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3125, "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY = (fieldObj));
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %O[%d](0x%x) ==>\n", CVMopnames[pc[-3]], directObj, slotIndex, fieldObj) : (void)0)
+                                     ;
+            { pc += 0; topOfStack += 0; ; }; ; goto *nextLabel;; };
+        }
+ opc_aputfield_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3131, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+ {
+     CVMObject* directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3133, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-2].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     if ((directObj) == 0) { goto null_pointer_exception; };
+     { CVMObject* volatile *fieldLoc_ = (CVMObject* volatile *)((CVMJavaVal32 volatile *)(directObj) + (pc[1])); ((void)(((&(CVMglobals.gc.cardTableVirtualBase[(CVMAddr)((fieldLoc_)) / (1 << 9)])) >= CVMglobals.gc.cardTable) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3135, "CARD_TABLE_SLOT_ADDRESS_FOR((fieldLoc_)) >= CVMglobals.gc.cardTable") || (CVMsystemPanic("CVMassertHook returned"), 0))); ((void)(((&(CVMglobals.gc.cardTableVirtualBase[(CVMAddr)((fieldLoc_)) / (1 << 9)])) < CVMglobals.gc.cardTable + CVMglobals.gc.cardTableSize) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3135, "CARD_TABLE_SLOT_ADDRESS_FOR((fieldLoc_)) < CVMglobals.gc.cardTable + CVMglobals.gc.cardTableSize") || (CVMsystemPanic("CVMassertHook returned"), 0))); *(&(CVMglobals.gc.cardTableVirtualBase[(CVMAddr)((fieldLoc_)) / (1 << 9)])) = 1;; *fieldLoc_ = (((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3135, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)))); };
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s (0x%x) ==> %O[%d]\n", CVMopnames[pc[0]], ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3137, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY))), directObj, pc[1]) : (void)0)
+                                         ;
+            { pc += 3; topOfStack += -2; ; }; ; goto *nextLabel;; };
+        }
+ opc_new_checkinit_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3143, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); nextLabel = opclabels[pc[3]];; {
+     CVMClassBlock* newCb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3144, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))] & 0x3F) == CVM_CONSTANT_ClassBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3144, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ClassBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))].resolved.cb);
+     CVMObject* directObj;
+     if ((!(((CVMAddr)(*((void)(ee), ((((((newCb)->runtimeFlagsX) & 0x01) != 0)) ? &((*(newCb)->clinitEEX.eePtr)) : &((newCb)->clinitEEX.ee)))) & 0x2) != 0) && ((CVMExecEnv*)((CVMAddr)((*((void)(ee), ((((((newCb)->runtimeFlagsX) & 0x01) != 0)) ? &((*(newCb)->clinitEEX.eePtr)) : &((newCb)->clinitEEX.ee))))) & ~(0x1 | 0x2))) != ee)) { initCb = newCb; goto init_class; } ;;
+     frame->topOfStack = topOfStack;;
+     (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+     directObj = CVMgcAllocNewInstance(ee, newCb);
+     if (directObj == 0) {
+  goto out_of_memory_error_for_new_quick;
+     }
+     (((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3159, "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (&(((topOfStack[0].s).j).r))->ref_DONT_ACCESS_DIRECTLY = (directObj));
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\topc_new_checkinit_quick %C => 0x%x\n", newCb, directObj) : (void)0)
+                       ;
+     { pc += 3; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ }
+ opc_new_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3167, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];; {
+     CVMClassBlock* newCb;
+     CVMObject* directObj;
+     frame->topOfStack = topOfStack;;
+     (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+     newCb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3178, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))] & 0x3F) == CVM_CONSTANT_ClassBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3178, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ClassBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))].resolved.cb);
+     directObj = CVMgcAllocNewInstance(ee, newCb);
+     if (directObj == ((void *)0)) {
+  goto out_of_memory_error_for_new_quick;
+     }
+     (((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3183, "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (&(((topOfStack[0].s).j).r))->ref_DONT_ACCESS_DIRECTLY = (directObj));
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tnew_quick %C => 0x%x\n", newCb, directObj) : (void)0)
+                       ;
+     { pc += 3; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ }
+        opc_anewarray_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3191, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+ {
+     CVMClassBlock* elemCb;
+     (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+     frame->topOfStack = topOfStack;;
+     elemCb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3207, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))] & 0x3F) == CVM_CONSTANT_ClassBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3207, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ClassBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))].resolved.cb);
+     if (!CVManewarrayHelper(ee, topOfStack, elemCb)) {
+  goto handle_exception;
+     }
+     { pc += 3; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+        opc_invokeinterface_quick: ;
+ {
+     CVMMethodBlock* imb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3220, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))] & 0x3F) == CVM_CONSTANT_MethodBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3220, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), MethodBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))].resolved.mb);
+            ;
+     frame->topOfStack = topOfStack;;
+     (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+     topOfStack -= ((imb)->immutX.argsSizeX);
+     mb = CVMinvokeInterfaceHelper(ee, topOfStack, imb);
+     if (mb == ((void *)0)) {
+  goto handle_exception;
+     }
+            ;
+     goto callmethod;
+ }
+ opc_invokestatic_quick: ; {
+            ;
+     mb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3238, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))] & 0x3F) == CVM_CONSTANT_MethodBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3238, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), MethodBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))].resolved.mb);
+     frame->topOfStack = topOfStack;;
+     topOfStack -= ((mb)->immutX.argsSizeX);
+     goto callmethod;
+ }
+ opc_invokestatic_checkinit_quick: ;
+        {
+     CVMClassBlock* cb;
+     mb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3249, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))] & 0x3F) == CVM_CONSTANT_MethodBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3249, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), MethodBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))].resolved.mb);
+     cb = (((CVMMethodRange*) ((CVMUint8 *)((mb) - ((mb)->immutX.methodIndexX)) - ((CVMAddr)(&(((CVMMethodRange *)0)->mb[0])) - (CVMAddr)(&(((CVMMethodRange *)0)->cb)))))->cb);
+     if ((!(((CVMAddr)(*((void)(ee), ((((((cb)->runtimeFlagsX) & 0x01) != 0)) ? &((*(cb)->clinitEEX.eePtr)) : &((cb)->clinitEEX.ee)))) & 0x2) != 0) && ((CVMExecEnv*)((CVMAddr)((*((void)(ee), ((((((cb)->runtimeFlagsX) & 0x01) != 0)) ? &((*(cb)->clinitEEX.eePtr)) : &((cb)->clinitEEX.ee))))) & ~(0x1 | 0x2))) != ee)) { initCb = cb; goto init_class; } ;;
+     frame->topOfStack = topOfStack;;
+     topOfStack -= ((mb)->immutX.argsSizeX);
+     goto callmethod;
+ }
+ opc_invokevirtualobject_quick: ; {
+     CVMObject* directObj;
+            ;
+     frame->topOfStack = topOfStack;;
+     topOfStack -= pc[2];
+     directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3271, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[0].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     if ((directObj) == 0) { goto null_pointer_exception; };
+     mb = ((((((CVMClassBlock*)(((CVMAddr)((directObj)->hdr.clas)) & ~3)))->methodTablePtrX)[pc[1]]));
+            ;
+     goto callmethod;
+ }
+ opc_invokenonvirtual_quick: ; {
+     CVMObject* directObj;
+            ;
+     mb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3283, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))] & 0x3F) == CVM_CONSTANT_MethodBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3283, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), MethodBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))].resolved.mb);
+     frame->topOfStack = topOfStack;;
+     topOfStack -= ((mb)->immutX.argsSizeX);
+     directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3286, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[0].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     if ((directObj) == 0) { goto null_pointer_exception; };
+     goto callmethod;
+ }
+ opc_invokesuper_quick: ;
+        {
+     CVMObject* directObj;
+     CVMClassBlock* cb = (((CVMMethodRange*) ((CVMUint8 *)((frame->mb) - ((frame->mb)->immutX.methodIndexX)) - ((CVMAddr)(&(((CVMMethodRange *)0)->mb[0])) - (CVMAddr)(&(((CVMMethodRange *)0)->cb)))))->cb);
+            ;
+     mb = (((((cb)->superclassX.superclassCb))->methodTablePtrX)[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))]);
+     frame->topOfStack = topOfStack;;
+     topOfStack -= ((mb)->immutX.argsSizeX);
+     directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3301, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[0].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     if ((directObj) == 0) { goto null_pointer_exception; };
+     goto callmethod;
+ }
+        opc_invokeignored_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3311, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];; {
+     CVMObject* directObj;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tinvokeignored_quick\n") : (void)0);
+     topOfStack -= pc[1];
+     directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3315, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[0].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     if (pc[2]) {
+  if ((directObj) == 0) { goto null_pointer_exception; };
+     }
+     { pc += 3; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+ opc_invokevirtual_quick_w: ;
+        {
+     CVMObject* directObj;
+            ;
+     mb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3332, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))] & 0x3F) == CVM_CONSTANT_MethodBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3332, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), MethodBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))].resolved.mb);
+     frame->topOfStack = topOfStack;;
+     topOfStack -= ((mb)->immutX.argsSizeX);
+     directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3335, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[0].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     if ((directObj) == 0) { goto null_pointer_exception; };
+     mb = (((((CVMClassBlock*)(((CVMAddr)((directObj)->hdr.clas)) & ~3)))->methodTablePtrX)[((mb)->immutX.methodTableIndexX)])
+                                    ;
+            ;
+     goto callmethod;
+ }
+ opc_invokevirtual_quick: ;
+ opc_ainvokevirtual_quick: ;
+ opc_dinvokevirtual_quick: ;
+ opc_vinvokevirtual_quick: ;
+        {
+     CVMObject* directObj;
+            ;
+     frame->topOfStack = topOfStack;;
+     topOfStack -= pc[2];
+     directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3366, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[0].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+     if ((directObj) == 0) { goto null_pointer_exception; };
+     mb = (((((CVMClassBlock*)(((CVMAddr)((directObj)->hdr.clas)) & ~3)))->methodTablePtrX)[pc[1]]);
+            ;
+                       ;
+ }
+   callmethod:
+ ;
+ {
+     CVMFrame* prev;
+     int invokerIdx;
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %C.%M\n", CVMopnames[pc[0]], (((CVMMethodRange*) ((CVMUint8 *)((mb) - ((mb)->immutX.methodIndexX)) - ((CVMAddr)(&(((CVMMethodRange *)0)->mb[0])) - (CVMAddr)(&(((CVMMethodRange *)0)->cb)))))->cb), mb) : (void)0)
+                                                 ;
+     ((CVMglobals.debugFlags & ((4L))) != 0 ? CVMconsolePrintf ("stack=0x%x frame=0x%x locals=0x%x tos=0x%x pc=0x%x\n", stack, frame, locals, topOfStack, pc) : (void)0);;
+     (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+     prev = frame;
+    new_mb:
+     ;
+     invokerIdx = ((mb)->immutX.invokerAndAccessFlagsX >> 12);
+     if (invokerIdx < CVM_INVOKE_CNI_METHOD) {
+  CVMJavaMethodDescriptor* jmd = (*(((void)(((!((0x100 & (0x01 | 0x03 | 0x02)) ? ((((mb)->immutX.invokerAndAccessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x100) : ((((mb)->immutX.invokerAndAccessFlagsX) & 0x100) != 0)) && !((0x400 & (0x01 | 0x03 | 0x02)) ? ((((mb)->immutX.invokerAndAccessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x400) : ((((mb)->immutX.invokerAndAccessFlagsX) & 0x400) != 0)))) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3409, "CVMmbIsJava(mb)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(mb)->immutX.codeX.jmd));
+  CVMClassBlock* cb;
+  locals = &topOfStack->s;
+  { CVMFrame* cf_ = (CVMFrame*)(frame); ((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent) || (stack)->currentFrame == ((void *)0)) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+  ,
+ 3468
+  , "CVMD_isgcUnsafe(ee) || (stack)->currentFrame == NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))); if ((((CVMUint32)(((jmd)->capacityX))) <= (CVMUint32)(((stack))->stackChunkEnd - ((topOfStack))))) { (frame) = (CVMFrame*)&topOfStack[(((jmd)->maxLocalsX))]; ((frame)->prevX = (cf_)); (frame)->type = CVM_FRAMETYPE_JAVA; (frame)->mb = mb; (frame)->flags = 0; if (((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+  ,
+ 3468
+  , "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) { (((void)((((((void)((((CVMFrame*)(((frame))))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3468, "((CVMFrame*)(((frame))))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)(((frame))))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+  ,
+ 3468
+  , "CVMframeIsJava((frame))") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)((frame)))->jvmtiLockInfo = ((void *)0); }; if ((1 == 1)) { (stack)->currentFrame = (frame); } } else { CVMStackVal32* space_; space_ = CVMexpandStack(ee, stack, (((jmd)->capacityX)), (1 == 1), !(1 == 1)); if (space_ == 0) { (frame) = 0; { frame = stack->currentFrame;; locals = ((void *)0); goto handle_exception; }; } else { (cf_) = ((CVMFrame*)((CVMAddr)((cf_)) | ((1 << 0)))); (frame) = (CVMFrame*)&space_[(((jmd)->maxLocalsX))]; ((frame)->prevX = (cf_)); (frame)->type = CVM_FRAMETYPE_JAVA; (frame)->mb = mb; (frame)->flags = 0; if (((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+  ,
+ 3468
+  , "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) { (((void)((((((void)((((CVMFrame*)(((frame))))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3468, "((CVMFrame*)(((frame))))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)(((frame))))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+  ,
+ 3468
+  , "CVMframeIsJava((frame))") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)((frame)))->jvmtiLockInfo = ((void *)0); }; { (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("pushing JavaFrame caused stack expansion\n") : (void)0); locals = (CVMSlotVal32*)frame - ((jmd)->maxLocalsX); memcpy((void*)locals, (void*)topOfStack, ((mb)->immutX.argsSizeX) * sizeof(CVMSlotVal32)); }; if ((1 == 1)) { (stack)->currentFrame = (frame); } } } }
+    ;
+  prev->topOfStack = topOfStack;
+  (topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3479, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3479, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->opstackX);;
+  (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->localsX) = locals;
+  pc = ((CVMUint8*)jmd + (sizeof(CVMJavaMethodDescriptor)));
+  cb = (((CVMMethodRange*) ((CVMUint8 *)((mb) - ((mb)->immutX.methodIndexX)) - ((CVMAddr)(&(((CVMMethodRange *)0)->mb[0])) - (CVMAddr)(&(((CVMMethodRange *)0)->cb)))))->cb);
+  {
+      cp = ((cb)->cpX.constantpoolX);
+  }
+  (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->cpX) = cp;
+  (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+  if ((CVMglobals.debugFlags & ((2L)))) { CVMtraceMethodCall(ee, frame, (!(1 == 1))); };
+  ((CVMglobals.debugFlags & ((4L))) != 0 ? CVMconsolePrintf ("stack=0x%x frame=0x%x locals=0x%x tos=0x%x pc=0x%x\n", stack, frame, locals, topOfStack, pc) : (void)0);;
+  if (!((0x20 & (0x01 | 0x03 | 0x02)) ? ((((mb)->immutX.invokerAndAccessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x20) : ((((mb)->immutX.invokerAndAccessFlagsX) & 0x20) != 0))) {
+      (((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+      ,
+ 3515
+      , "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (&((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3515, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3515, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->receiverObjX))->ref_DONT_ACCESS_DIRECTLY = (((void *)0)))
+           ;
+  } else {
+      CVMObjectICell* receiverObjICell;
+      if (((0x08 & (0x01 | 0x03 | 0x02)) ? ((((mb)->immutX.invokerAndAccessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x08) : ((((mb)->immutX.invokerAndAccessFlagsX) & 0x08) != 0))) {
+   receiverObjICell = ((cb)->javaInstanceX);
+      } else {
+   receiverObjICell = &locals[0].j.r;
+      }
+      (((void)(((!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+      ,
+ 3525
+      , "(!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), ((&((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3525, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3525, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->receiverObjX)))->ref_DONT_ACCESS_DIRECTLY = ((*(((void)(((!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3525, "(!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &((receiverObjICell))->ref_DONT_ACCESS_DIRECTLY))))
+                          ;
+      receiverObjICell = &((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3527, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3527, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->receiverObjX);
+                    if (!CVMfastTryLock(
+       ee, (*(((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3531, "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(receiverObjICell)->ref_DONT_ACCESS_DIRECTLY)))) {
+                        (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+                        frame->topOfStack = topOfStack;;
+                        if (!CVMsyncKinds[((((((((*(((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3534, "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(receiverObjICell)->ref_DONT_ACCESS_DIRECTLY)))))->hdr.various32)) & ((1 << 2) - 1)) & 0x1)].lock(ee, receiverObjICell)) {
+       { { CVMFrame* prev_ = (((frame)))->prevX; ((void)(((1 == 1)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3535, "CVMframeMaskBitsAreCorrect((((frame))))") || (CVMsystemPanic("CVMassertHook returned"), 0))); if ((((CVMAddr)(prev_) & (1 << 0)) != 0)) { CVMStackChunk* chunk_ = (((stack))->currentStackChunk); while(!(((CVMStackVal32*)((((frame)))) < (chunk_)->end_data) && ((CVMStackVal32*)((((frame)))) >= &(chunk_)->data[0]))) { chunk_ = chunk_->prev; } prev_ = ((CVMFrame*)((CVMAddr)(prev_) & ~((1 << 2) - 1))); if ((prev_ != ((void *)0)) && !(((CVMStackVal32*)(prev_->topOfStack) < (chunk_)->end_data) && ((CVMStackVal32*)(prev_->topOfStack) >= &(chunk_)->data[0]))) { chunk_ = chunk_->prev; } { { (((stack))->currentFrame) = ((prev_)); }; { CVMStackChunk * volatile *currentStackChunkPtr_; currentStackChunkPtr_ = &(((stack)))->currentStackChunk; *currentStackChunkPtr_ = chunk_; }; ((stack))->stackChunkStart = chunk_->data; ((stack))->stackChunkEnd = chunk_->end_data; { } }; } else { prev_ = ((CVMFrame*)((CVMAddr)(prev_) & ~((1 << 2) - 1))); } ((frame)) = prev_; }; ((stack))->currentFrame = ((frame)); };
+       CVMthrowOutOfMemoryError(ee, ((void *)0));
+       goto handle_exception;
+   }
+                    }
+  }
+  { ((void)0); if ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))) { { (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;; frame->topOfStack = topOfStack;; }; CVMcsRendezvous((ee), (&CVMglobals.cstate[(CVM_GC_SAFE)]), (&((ee))->tcstate[(CVM_GC_SAFE)]), ((1 == 1)));; {}; } }
+        ;
+     } else if (invokerIdx < CVM_INVOKE_JNI_METHOD) {
+  CNIResultCode ret;
+  CVMMethodBlock *mb0 = mb;
+  CNINativeMethod *f = (CNINativeMethod *)(*(((void)((((0x100 & (0x01 | 0x03 | 0x02)) ? (((((mb))->immutX.invokerAndAccessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x100) : (((((mb))->immutX.invokerAndAccessFlagsX) & 0x100) != 0))) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3594, "CVMmbIs((mb), NATIVE)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(mb)->immutX.codeX.nativeCode));
+  if ((CVMglobals.debugFlags & ((2L)))) { CVMtraceFramelessMethodCall(ee, frame, mb0, (!(1 == 1))); };
+  ret = (*f)(ee, topOfStack, &mb);
+  if ((CVMglobals.debugFlags & ((2L)))) { CVMtraceFramelessMethodReturn(ee, mb0, frame); };
+  if ((int)ret >= 0) {
+                    ((void)(((int)ret <= CNI_DOUBLE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3617, "(int)ret <= CNI_DOUBLE") || (CVMsystemPanic("CVMassertHook returned"), 0)));
+      topOfStack += (int)ret;
+      pc += (*pc == opc_invokeinterface_quick ? 5 : 3);
+      { const void* nextLabel;; nextLabel = opclabels[pc[0]];; ; ; goto *nextLabel;; };
+  } else if (ret == CNI_NEW_TRANSITION_FRAME) {
+      frame->topOfStack = topOfStack;;
+      frame = stack->currentFrame;;
+      ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3635, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_TRANSITION)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3635, "CVMframeIsTransition(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMTransitionFrame*)(frame))->incrementPcFlagX) = (1 == 1);
+      isStatic = ((0x08 & (0x01 | 0x03 | 0x02)) ? ((((mb)->immutX.invokerAndAccessFlagsX) & (0x01 | 0x03 | 0x02)) == 0x08) : ((((mb)->immutX.invokerAndAccessFlagsX) & 0x08) != 0));
+      goto new_transition;
+  } else if (ret == CNI_NEW_MB) {
+      frame->topOfStack = topOfStack;;
+      frame->topOfStack += ((mb)->immutX.argsSizeX);
+      goto new_mb;
+  } else if (ret == CNI_EXCEPTION) {
+      goto handle_exception;
+  } else {
+      ((void)(((!(1 == 1))) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3684, "CVM_FALSE") || (CVMsystemPanic("CVMassertHook returned"), 0)));
+  }
+     } else if (invokerIdx < CVM_INVOKE_ABSTRACT_METHOD) {
+  if (!CVMinvokeJNIHelper(ee, mb)) {
+      goto handle_exception;
+  }
+  topOfStack = frame->topOfStack;;
+  pc += (*pc == opc_invokeinterface_quick ? 5 : 3);
+  { const void* nextLabel;; nextLabel = opclabels[pc[0]];; ; ; goto *nextLabel;; };
+     } else if (invokerIdx == CVM_INVOKE_ABSTRACT_METHOD) {
+  CVMthrowAbstractMethodError(ee, "%C.%M",
+         (((CVMMethodRange*) ((CVMUint8 *)((mb) - ((mb)->immutX.methodIndexX)) - ((CVMAddr)(&(((CVMMethodRange *)0)->mb[0])) - (CVMAddr)(&(((CVMMethodRange *)0)->cb)))))->cb), mb);
+  goto handle_exception;
+     } else if (invokerIdx == CVM_INVOKE_NONPUBLIC_MIRANDA_METHOD) {
+  CVMthrowIllegalAccessError(
+                    ee, "access non-public method %C.%M through an interface",
+      (((CVMMethodRange*) ((CVMUint8 *)((mb) - ((mb)->immutX.methodIndexX)) - ((CVMAddr)(&(((CVMMethodRange *)0)->mb[0])) - (CVMAddr)(&(((CVMMethodRange *)0)->cb)))))->cb), (*(((void)(((((mb)->immutX.invokerAndAccessFlagsX >> 12) == CVM_INVOKE_NONPUBLIC_MIRANDA_METHOD || ((mb)->immutX.invokerAndAccessFlagsX >> 12) == CVM_INVOKE_MISSINGINTERFACE_MIRANDA_METHOD)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3721, "CVMmbIsMiranda(mb)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(mb)->immutX.codeX.interfaceMb)));
+  goto handle_exception;
+     } else if (invokerIdx ==
+         CVM_INVOKE_MISSINGINTERFACE_MIRANDA_METHOD) {
+  CVMthrowAbstractMethodError(ee, "%C.%M",
+         (((CVMMethodRange*) ((CVMUint8 *)((mb) - ((mb)->immutX.methodIndexX)) - ((CVMAddr)(&(((CVMMethodRange *)0)->mb[0])) - (CVMAddr)(&(((CVMMethodRange *)0)->cb)))))->cb), mb);
+  goto handle_exception;
+     } else if (invokerIdx == CVM_INVOKE_LAZY_JNI_METHOD) {
+  CVMBool result;
+  { ((void)0); ((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe\n") : (void)0); { ((void)((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+  ,
+ 3740
+  , "!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent") || (CVMsystemPanic("CVMassertHook returned"), 0))); ((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent = (1 == 1); ; };; if ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))) { CVMcsRendezvous((ee), (&CVMglobals.cstate[(CVM_GC_SAFE)]), (&((ee))->tcstate[(CVM_GC_SAFE)]), ((!(1 == 1))));; } { result = CVMlookupNativeMethodCode(ee, mb); }; ((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-unsafe\n") : (void)0); { ((void)((((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+  ,
+ 3740
+  , "((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent") || (CVMsystemPanic("CVMassertHook returned"), 0))); ((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent = (!(1 == 1)); ; };; if ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))) { CVMcsRendezvous((ee), (&CVMglobals.cstate[(CVM_GC_SAFE)]), (&((ee))->tcstate[(CVM_GC_SAFE)]), ((1 == 1)));; } }
+    ;
+  if (!result) {
+      goto handle_exception;
+  } else {
+      goto new_mb;
+  }
+     } else {
+  CVMconsolePrintf ("Unkown method invoker: %d\n", invokerIdx);
+  ((void)(((!(1 == 1))) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3755, "CVM_FALSE") || (CVMsystemPanic("CVMassertHook returned"), 0)));
+     }
+ };
+ { const void* nextLabel;; nextLabel = opclabels[pc[0]];; ; ; goto *nextLabel;; };
+    return_from_executejava_branch_island: {
+        ;
+        pc = 0;
+        return;
+    }
+    handle_exception: {
+     ;
+     {
+  { if (((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3795, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) { (frame->topOfStack) = (
+ (((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3795, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3795, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->opstackX);; } else { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3795, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_TRANSITION)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3795, "CVMframeIsTransition(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMTransitionFrame*)(frame))->opstackX);; } };
+     }
+    handle_exception_tos_already_reset:
+     ;
+     ((void)((((ee)->exceptionFlags.bothflags != 0 && ((((ee)->exceptionFlags.oneflag.local) != 0) || ((!(1 == 1)))))) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3800, "CVMexceptionOccurred(ee)") || (CVMsystemPanic("CVMassertHook returned"), 0)));
+     frame = CVMgcUnsafeHandleException(ee, frame, initialframe);
+     if (frame == initialframe) {
+                if ((CVMglobals.debugFlags & ((2L)))) { CVMtraceMethodReturn(ee, frame); };
+  goto finish;
+     }
+     {
+  pc = (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX);;
+  (topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3846, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3846, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->opstackX);;
+  locals = (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->localsX);
+  cp = (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->cpX);
+     }
+     (((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+     ,
+ 3853
+     , "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (&(((topOfStack[0].s).j).r))->ref_DONT_ACCESS_DIRECTLY = (((*(((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3853, "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(((ee)->currentExceptionICell))->ref_DONT_ACCESS_DIRECTLY)))))
+                                   ;
+     (((void)(((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3854, "(!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((ee)->currentExceptionICell))->ref_DONT_ACCESS_DIRECTLY = (((void *)0)));;
+     topOfStack++;
+     { const void* nextLabel;; nextLabel = opclabels[pc[0]];; ; ; goto *nextLabel;; };
+ }
+    init_class:
+ ;
+ {
+            int result;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s ==> running static initializers...\n", CVMopnames[pc[0]]) : (void)0)
+                        ;
+     (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+     frame->topOfStack = topOfStack;;
+     { ((void)0); ((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe\n") : (void)0); { ((void)((!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+     ,
+ 3892
+     , "!((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent") || (CVMsystemPanic("CVMassertHook returned"), 0))); ((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent = (1 == 1); ; };; if ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))) { CVMcsRendezvous((ee), (&CVMglobals.cstate[(CVM_GC_SAFE)]), (&((ee))->tcstate[(CVM_GC_SAFE)]), ((!(1 == 1))));; } { result = CVMclassInitNoCRecursion(ee, initCb, &mb); }; ((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-unsafe\n") : (void)0); { ((void)((((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent) || CVMassertHook(
+ "../../src/share/javavm/runtime/executejava_standard.c"
+     ,
+ 3892
+     , "((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent") || (CVMsystemPanic("CVMassertHook returned"), 0))); ((&((ee))->tcstate[(CVM_GC_SAFE)]))->isConsistent = (!(1 == 1)); ; };; if ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))) { CVMcsRendezvous((ee), (&CVMglobals.cstate[(CVM_GC_SAFE)]), (&((ee))->tcstate[(CVM_GC_SAFE)]), ((1 == 1)));; } }
+       ;
+     if (result == 0) {
+  { const void* nextLabel;; nextLabel = opclabels[pc[0]];; ; ; goto *nextLabel;; };
+     } else if (result == 1) {
+  frame = stack->currentFrame;;
+  isStatic = (!(1 == 1));
+  goto new_transition;
+     } else {
+  goto handle_exception;
+     }
+        }
+    opc_exittransition_overflow:
+ ;
+        {
+     char retType;
+     CVMBool incrementPC;
+     if ((CVMglobals.debugFlags & ((2L)))) { CVMtraceMethodReturn(ee, frame); };
+     ((void)((!(((ee)->exceptionFlags.oneflag.local) != 0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3940, "!CVMlocalExceptionOccurred(ee)") || (CVMsystemPanic("CVMassertHook returned"), 0)));
+     retType =
+  CVMtypeidGetReturnType(((frame->mb)->immutX.nameAndTypeIDX));
+     if (retType == 2) {
+  topOfStack = (((void)(((1 == 1)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3957, "CVMframeMaskBitsAreCorrect((frame))") || (CVMsystemPanic("CVMassertHook returned"), 0))), ((CVMFrame*)((CVMAddr)((frame)->prevX) & ~((1 << 2) - 1))))->topOfStack;;
+     } else if ((retType == 6) ||
+         (retType == 9)) {
+  topOfStack = CVMreturn64Helper(topOfStack, frame);
+  topOfStack += 2;
+     } else {
+  CVMJavaVal32 result = ((topOfStack[-1].s).j);
+  topOfStack = (((void)(((1 == 1)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3973, "CVMframeMaskBitsAreCorrect((frame))") || (CVMsystemPanic("CVMassertHook returned"), 0))), ((CVMFrame*)((CVMAddr)((frame)->prevX) & ~((1 << 2) - 1))))->topOfStack;;
+  ((topOfStack[0].s).j) = result;
+  topOfStack++;
+     }
+     incrementPC = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3982, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_TRANSITION)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3982, "CVMframeIsTransition(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMTransitionFrame*)(frame))->incrementPcFlagX);
+     { { CVMFrame* prev_ = (((frame)))->prevX; ((void)(((1 == 1)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 3984, "CVMframeMaskBitsAreCorrect((((frame))))") || (CVMsystemPanic("CVMassertHook returned"), 0))); if ((((CVMAddr)(prev_) & (1 << 0)) != 0)) { CVMStackChunk* chunk_ = (((stack))->currentStackChunk); while(!(((CVMStackVal32*)((((frame)))) < (chunk_)->end_data) && ((CVMStackVal32*)((((frame)))) >= &(chunk_)->data[0]))) { chunk_ = chunk_->prev; } prev_ = ((CVMFrame*)((CVMAddr)(prev_) & ~((1 << 2) - 1))); if ((prev_ != ((void *)0)) && !(((CVMStackVal32*)(prev_->topOfStack) < (chunk_)->end_data) && ((CVMStackVal32*)(prev_->topOfStack) >= &(chunk_)->data[0]))) { chunk_ = chunk_->prev; } { { (((stack))->currentFrame) = ((prev_)); }; { CVMStackChunk * volatile *currentStackChunkPtr_; currentStackChunkPtr_ = &(((stack)))->currentStackChunk; *currentStackChunkPtr_ = chunk_; }; ((stack))->stackChunkStart = chunk_->data; ((stack))->stackChunkEnd = chunk_->end_data; { } }; } else { prev_ = ((CVMFrame*)((CVMAddr)(prev_) & ~((1 << 2) - 1))); } ((frame)) = prev_; }; ((stack))->currentFrame = ((frame)); };
+     pc = (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX);;
+     locals = (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->localsX);
+     cp = (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->cpX);
+     if (incrementPC) {
+  pc += (*pc == opc_invokeinterface_quick ? 5 : 3);
+  { const void* nextLabel;; nextLabel = opclabels[pc[0]];; ; ; goto *nextLabel;; };
+     } else {
+  {
+      const void* nextLabel;;
+      nextLabel = opclabels[pc[0]];;
+      ;
+      goto *nextLabel;;
+  }
+     }
+ }
+        opc_d2l: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4153, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+     CVMd2lHelper(topOfStack);
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\td2l => %s\n", (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf)) : (void)0);
+            { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+        opc_d2i: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4160, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+    {
+     CVMd2iHelper(topOfStack);
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\td2i => %d\n", (((topOfStack[-2].s).j).i)) : (void)0);
+            { pc += 1; topOfStack += -1; ; }; ; goto *nextLabel;; };
+ }
+        opc_l2d: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4167, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+     CVMl2dHelper(topOfStack);
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\tl2d => %f\n", ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-2].s).j).raw))->d); })) : (void)0);
+            { pc += 1; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+        opc_i2d: { const void* nextLabel; ; ((void)((1 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4174, "1 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[1]];;
+ {
+     CVMi2dHelper(topOfStack);
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\ti2d => %f\n", ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[-1].s).j).raw))->d); })) : (void)0);
+            { pc += 1; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ }
+        opc_goto_w: ;
+ {
+     CVMInt32 skip = ((CVMInt32) (((*(CVMUint8*)((pc + 1)+(0))) << 24) | ((*(CVMUint8*)((pc + 1)+(1))) << 16) | ((*(CVMUint8*)((pc + 1)+(2))) << 8) | (*(CVMUint8*)((pc + 1)+(3)))));
+            ;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %#x (skip=%d)\n", CVMopnames[pc[0]], pc + skip, skip) : (void)0)
+                      ;
+            ;
+     { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += 0; ; }; ; goto *nextLabel;; };
+ }
+        opc_jsr_w: ;
+        {
+     CVMInt32 skip = ((CVMInt32) (((*(CVMUint8*)((pc + 1)+(0))) << 24) | ((*(CVMUint8*)((pc + 1)+(1))) << 16) | ((*(CVMUint8*)((pc + 1)+(2))) << 8) | (*(CVMUint8*)((pc + 1)+(3)))));
+            ;
+     ((topOfStack[0].s).a) = pc + 5;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s %#x (skip=%d)\n", CVMopnames[pc[0]], pc + skip, skip) : (void)0)
+                      ;
+     { const void* nextLabel;; nextLabel = opclabels[pc[skip]];; if ((skip) <= 0 && ((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) { goto handle_pending_request; } ; ; { pc += skip; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ }
+ opc_aldc_ind_w_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4203, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];; {
+     CVMObjectICell* strICell =
+  (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4205, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))] & 0x3F) == CVM_CONSTANT_StringICell)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4205, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), StringICell)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))].resolved.strICell);
+     (((void)(((!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4206, "(!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), ((&(((topOfStack[0].s).j).r)))->ref_DONT_ACCESS_DIRECTLY = ((*(((void)(((!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4206, "(!((&(((ee)))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &((strICell))->ref_DONT_ACCESS_DIRECTLY))));
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s #%d => 0x%x\n", CVMopnames[pc[0]], pc[1], (((topOfStack[0].s).j).i)) : (void)0)
+                          ;
+     { pc += 3; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ }
+        opc_aldc_w_quick: ;
+        opc_ldc_w_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4213, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+            ((topOfStack[0].s).j) = ((cp)->entriesX[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))].resolved.val32);
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s #%d => 0x%x\n", CVMopnames[pc[0]], ((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), (((topOfStack[0].s).j).i)) : (void)0)
+                                      ;
+     { pc += 3; topOfStack += 1; ; }; ; goto *nextLabel;; };
+        opc_ldc2_w_quick: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4219, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+  {
+     CVMldc2_wHelper(topOfStack, cp, pc);
+            (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\topc_ldc2_w_quick #%d => long=%s double=%g\n", ((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), (CVMlong2String(({ typedef union { CVMJavaLong l; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->l); }), trBuf, trBuf+sizeof(trBuf)), trBuf), ({ typedef union { CVMJavaDouble d; } fakeOutGCCStrictAliasing; (((fakeOutGCCStrictAliasing *)(&((topOfStack[0].s).j).raw))->d); })) : (void)0)
+                                                                    ;
+     { pc += 3; topOfStack += 2; ; }; ; goto *nextLabel;; };
+ }
+        opc_getfield_quick_w: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4228, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+ {
+     topOfStack = CVMgetfield_quick_wHelper(ee, frame, topOfStack,
+         cp, pc);
+     if (topOfStack == ((void *)0)) {
+  goto null_pointer_exception;
+     }
+     { pc += 3; topOfStack += 0; ; }; ; goto *nextLabel;; };
+        }
+        opc_putfield_quick_w: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4238, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+ {
+     topOfStack = CVMputfield_quick_wHelper(ee, frame, topOfStack,
+         cp, pc);
+     if (topOfStack == ((void *)0)) {
+  goto null_pointer_exception;
+     }
+     { pc += 3; topOfStack += 0; ; }; ; goto *nextLabel;; };
+        }
+        opc_wide: ;
+ {
+            ;
+     (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+     frame->topOfStack = topOfStack;;
+     if (CVMwideHelper(ee, locals, frame)) {
+  if (((((void)0)), ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))))) {
+      goto handle_pending_request;
+  }
+     }
+     pc = (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX);;
+     topOfStack = frame->topOfStack;;
+     { const void* nextLabel;; nextLabel = opclabels[pc[0]];; ; ; goto *nextLabel;; };
+        }
+ opc_prefix: ;
+ {
+     goto unimplemented_opcode;
+ }
+    handle_pending_request:
+ {
+     ;
+  {
+      { ((void)0); if ((((CVMglobals.debugFlags & ((4096L))) != 0 ? CVMconsolePrintf ("gc-safe?\n") : (void)0), (((ee)->tickCount++)), (((((&CVMglobals.cstate[(CVM_GC_SAFE)]))->request))))) { { (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;; frame->topOfStack = topOfStack;; }; CVMcsRendezvous((ee), (&CVMglobals.cstate[(CVM_GC_SAFE)]), (&((ee))->tcstate[(CVM_GC_SAFE)]), ((1 == 1)));; {}; } }
+            ;
+      { const void* nextLabel;; nextLabel = opclabels[pc[0]];; ; ; goto *nextLabel;; };
+                }
+ }
+ ;
+ opc_getfield: ;
+ opc_putfield: ;
+        opc_invokevirtual: ;
+        opc_invokespecial: ;
+     goto quicken_opcode_clobber;
+ opc_getstatic: ;
+        opc_putstatic: ;
+        opc_invokestatic: ;
+ opc_invokeinterface: ;
+ opc_new: ;
+ opc_ldc2_w: ;
+ opc_anewarray: ;
+ opc_checkcast: ;
+ opc_instanceof: ;
+ opc_multianewarray: ;
+     goto quicken_opcode_noclobber;
+        opc_ldc: { const void* nextLabel; ; ((void)((2 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4337, "2 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[2]];;
+ {
+     frame->topOfStack = topOfStack;;
+     (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+     if (!CVMldcHelper(ee, topOfStack, cp, pc)) {
+  if ((((ee)->exceptionFlags.oneflag.local) != 0)) {
+      goto handle_exception;
+  }
+  goto quicken_opcode_noclobber;
+     }
+     { pc += 2; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ }
+        opc_ldc_w: { const void* nextLabel; ; ((void)((3 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4350, "3 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[3]];;
+ {
+     frame->topOfStack = topOfStack;;
+     (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+     if (!CVMldc_wHelper(ee, topOfStack, cp, pc)) {
+  if ((((ee)->exceptionFlags.oneflag.local) != 0)) {
+      goto handle_exception;
+  }
+  goto quicken_opcode_noclobber;
+     }
+     { pc += 3; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ }
+ {
+     CVMQuickenReturnCode retCode;
+     CVMClassBlock *cb;
+     CVMBool clobbersCpIndex;
+    quicken_opcode_noclobber:
+     clobbersCpIndex = (!(1 == 1));
+     goto quicken_opcode;
+    quicken_opcode_clobber:
+     clobbersCpIndex = (1 == 1);
+    quicken_opcode:
+     frame->topOfStack = topOfStack;;
+     (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+     (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("\t%s ==> quickening...\n", CVMopnames[pc[0]]) : (void)0);
+     retCode = CVMquickenOpcode(ee, pc, cp, &cb, clobbersCpIndex);
+     switch (retCode) {
+         case CVM_QUICKEN_ALREADY_QUICKENED:
+      break;
+         case CVM_QUICKEN_NEED_TO_RUN_STATIC_INITIALIZERS:
+      initCb = cb;
+      goto init_class;
+         case CVM_QUICKEN_ERROR: {
+      ((void)((((ee)->exceptionFlags.bothflags != 0 && ((((ee)->exceptionFlags.oneflag.local) != 0) || ((!(1 == 1)))))) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4396, "CVMexceptionOccurred(ee)") || (CVMsystemPanic("CVMassertHook returned"), 0)));
+      goto handle_exception;
+  }
+         default:
+      ((void)(((!(1 == 1))) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4400, "CVM_FALSE") || (CVMsystemPanic("CVMassertHook returned"), 0)));
+     }
+     {
+  const void* nextLabel;;
+  nextLabel = opclabels[pc[0]];;
+  ;
+  goto *nextLabel;;
+     }
+ }
+        opc_multianewarray_quick: { const void* nextLabel; ; ((void)((4 != 0) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4421, "4 != 0") || (CVMsystemPanic("CVMassertHook returned"), 0))); ; nextLabel = opclabels[pc[4]];;
+ {
+     CVMClassBlock* arrCb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4423, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))] & 0x3F) == CVM_CONSTANT_ClassBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4423, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ClassBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))].resolved.cb);
+     frame->topOfStack = topOfStack;;
+     (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+     if (!CVMmultianewarrayHelper(ee, arrCb)) {
+  goto handle_exception;
+     }
+     topOfStack = frame->topOfStack;;
+     { pc += 4; topOfStack += 1; ; }; ; goto *nextLabel;; };
+ }
+ opc_xxxunusedxxx: ;
+     goto unimplemented_opcode;
+ opc_DEFAULT: ;
+ unimplemented_opcode:
+     CVMconsolePrintf ("\t*** Unimplemented opcode: %d = %s\n", pc[0], CVMopnames[pc[0]])
+                               ;
+     goto finish;
+ }
+    }
+    null_pointer_exception:
+ ;
+ { (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;; { if (((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4574, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4574, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4574, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->opstackX);; } else { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4574, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_TRANSITION)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4574, "CVMframeIsTransition(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMTransitionFrame*)(frame))->opstackX);; } }; CVMthrowNullPointerException(ee, ((void *)0)); goto handle_exception_tos_already_reset; };
+    out_of_memory_error:
+ ;
+ { (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;; { if (((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4578, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4578, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4578, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->opstackX);; } else { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4578, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_TRANSITION)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4578, "CVMframeIsTransition(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMTransitionFrame*)(frame))->opstackX);; } }; CVMthrowOutOfMemoryError(ee, ((void *)0)); goto handle_exception_tos_already_reset; };
+    array_index_out_of_bounds_exception:
+ ;
+ { (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;; { if (((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4582, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4582, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4582, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->opstackX);; } else { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4582, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_TRANSITION)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4582, "CVMframeIsTransition(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMTransitionFrame*)(frame))->opstackX);; } }; CVMthrowArrayIndexOutOfBoundsException(ee, ((void *)0)); goto handle_exception_tos_already_reset; };
+    array_store_exception:
+ ;
+ { (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;; { if (((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4586, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4586, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4586, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->opstackX);; } else { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4586, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_TRANSITION)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4586, "CVMframeIsTransition(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMTransitionFrame*)(frame))->opstackX);; } }; CVMthrowArrayStoreException(ee, ((void *)0)); goto handle_exception_tos_already_reset; };
+    arithmetic_exception_divide_by_zero:
+ ;
+ { (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;; { if (((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4590, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4590, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4590, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->opstackX);; } else { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4590, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_TRANSITION)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4590, "CVMframeIsTransition(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMTransitionFrame*)(frame))->opstackX);; } }; CVMthrowArithmeticException(ee, "/ by zero"); goto handle_exception_tos_already_reset; };
+    illegal_monitor_state_exception_thread_not_owner:
+ ;
+ { (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;; { if (((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4595, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) { (frame->topOfStack) = (
+ (((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4595, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4595, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->opstackX);; } else { (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4595, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_TRANSITION)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4595, "CVMframeIsTransition(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMTransitionFrame*)(frame))->opstackX);; } }; CVMthrowIllegalMonitorStateException(ee, "current thread not owner"); goto handle_exception_tos_already_reset; };
+    out_of_memory_error_for_new_quick:
+    ;
+    {
+ CVMClassBlock* newCb = (((void)((((cp)->cpTypesX) == ((void *)0) || (((void)((((cp)->cpTypesX) != ((void *)0)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4600, "CVMcpTypes(cp) != NULL") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((cp)->cpTypesX)[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))] & 0x3F) == CVM_CONSTANT_ClassBlock)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4600, "CVMcpTypes(cp) == NULL || CVMcpTypeIs(cp, ((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1))))), ClassBlock)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (cp)->entriesX[((((*(CVMUint8*)((pc + 1)+(0))) << 8) | (*(CVMUint8*)((pc + 1)+(1)))))].resolved.cb);
+ CVMthrowOutOfMemoryError(ee, "%C", newCb);
+ goto handle_exception_tos_already_reset;
+    }
+    class_cast_exception:
+    ;
+    {
+ CVMObject* directObj = ((*(((void)(((!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4608, "(!((&((CVMgetEE()))->tcstate[(CVM_GC_SAFE)]))->isConsistent)") || (CVMsystemPanic("CVMassertHook returned"), 0))), &(&(((topOfStack[-1].s).j).r))->ref_DONT_ACCESS_DIRECTLY)));
+ CVMClassBlock* cb = ((CVMClassBlock*)(((CVMAddr)((directObj)->hdr.clas)) & ~3));
+ (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+ (frame->topOfStack) = ((((void)((((((void)((((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4611, "((CVMFrame*)((frame)))->type != CVM_FRAMETYPE_NONE") || (CVMsystemPanic("CVMassertHook returned"), 0))), (((CVMFrame*)((frame)))->type)) == CVM_FRAMETYPE_JAVA)) || CVMassertHook("../../src/share/javavm/runtime/executejava_standard.c", 4611, "CVMframeIsJava(frame)") || (CVMsystemPanic("CVMassertHook returned"), 0))), (CVMJavaFrame*)(frame))->opstackX);;
+ if (!(((ee)->exceptionFlags.oneflag.local) != 0)) {
+     CVMthrowClassCastException(ee, "%C", cb);
+ }
+ goto handle_exception_tos_already_reset;
+    }
+ finish:
+    ;
+    (((ee)->debugFlags & ((1L))) != 0 ? CVMconsolePrintf ("Exiting interpreter\n") : (void)0);
+    frame->topOfStack = topOfStack;;
+    (CVMDEBUGgetInterpreterFrame((CVMFrame *)(frame))->pcX) = pc;;
+    return;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.target/sh/fpchg1.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/fpchg1.c
--- gcc-4.7.3/gcc/testsuite/gcc.target/sh/fpchg1.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/fpchg1.c	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,24 @@
+/* { dg-do run } */
+/* { dg-options "-O1 -m4-300" } */
+
+/* Check that the fpchg instruction is not moved in a delay slot if the
+   fallthru block uses the mode.  */
+
+__attribute__ ((weak))
+void barrier(void)
+{
+}
+
+float f;
+int i;
+double d;
+
+int main()
+{
+  i = 4;
+
+  barrier();
+
+  i = (f + (i && f && d));
+  return i;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.target/sh/fpchg2.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/fpchg2.c
--- gcc-4.7.3/gcc/testsuite/gcc.target/sh/fpchg2.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/fpchg2.c	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,16 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -m4-300" } */
+
+/* Make sure that fpchg is preferred over lfd.s fpscr.  */
+/* { dg-final { scan-assembler "fpchg" } } */
+/* { dg-final { scan-assembler-not "fpscr" } } */
+
+extern float c;
+
+void
+foo(int j)
+{
+  while (j--)
+    c++;
+
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.target/sh/jump_compact_1.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/jump_compact_1.c
--- gcc-4.7.3/gcc/testsuite/gcc.target/sh/jump_compact_1.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/jump_compact_1.c	2012-04-27 08:59:21.000000000 +0200
@@ -0,0 +1,17 @@
+/* { dg-do compile { target "sh*-*-*" } } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler-not "braf"} }  */
+
+/* Check that no braf instruction is used to emit a far jump.  */
+
+int main(int argc,char **argv)
+{
+  if( argc < 2 )
+    goto label;
+
+  asm(".fill 16383,2,0x09");
+
+ label:
+  puts("after label");
+  return 0;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.target/sh/jump_compact_2.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/jump_compact_2.c
--- gcc-4.7.3/gcc/testsuite/gcc.target/sh/jump_compact_2.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/jump_compact_2.c	2013-03-20 08:38:57.000000000 +0100
@@ -0,0 +1,16 @@
+/* { dg-do run { target "sh*-*-*" } } */
+/* { dg-options "-O2" } */
+
+/* Check that a braf instruction is used to emit a medium jump.  */
+
+int main(int argc,char **argv)
+{
+  if( argc < 2 )
+    goto label;
+
+  asm(".fill 16382,2,0x09");
+
+ label:
+  puts("after label");
+  return 0;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.target/sh/mfmovd.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/mfmovd.c
--- gcc-4.7.3/gcc/testsuite/gcc.target/sh/mfmovd.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/mfmovd.c	2013-04-19 09:19:59.000000000 +0200
@@ -1,8 +1,9 @@
 /* Verify that we generate fmov.d instructions to move doubles when -mfmovd 
    option is enabled.  */
 /* { dg-do compile { target "sh*-*-*" } } */
+/* { dg-require-effective-target hard_float } */
 /* { dg-options "-mfmovd" } */
-/* { dg-skip-if "" { "sh*-*-*" } { "*" } { "-m2a" "-m2a-single" "-m4" "-m4-single" "-m4-100" "-m4-100-single" "-m4-200" "-m4-200-single" "-m4-300" "-m4-300-single" "-m4a" "-m4a-single" } }  */
+/* { dg-skip-if "" { *-*-* }  { "*-single-only" } { "" } } */
 /* { dg-final { scan-assembler "fmov.d" } } */
 
 extern double g;
@@ -13,3 +14,10 @@
   g = d;
 }
 
+extern float h;
+
+void f2 ()
+{
+  h = g;
+}
+
diff -urN gcc-4.7.3/gcc/testsuite/gcc.target/sh/muladd.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/muladd.c
--- gcc-4.7.3/gcc/testsuite/gcc.target/sh/muladd.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/muladd.c	2012-09-10 13:52:28.000000000 +0200
@@ -0,0 +1,20 @@
+/* Check that sequences of n r=r+b arecombined into r=r*nb
+   instructions.  */
+/* { dg-do compile { target "sh*-*-*" } } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler-times "shl[dl]" 1 } } */
+
+int
+plus_9(int dest_y, int dc)
+{
+  dc+= dest_y;
+  dc+= dest_y;
+  dc+= dest_y;
+  dc+= dest_y;
+  dc+= dest_y;
+  dc+= dest_y;
+  dc+= dest_y;
+  dc+= dest_y;
+
+  return dc;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.target/sh/pr32163.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/pr32163.c
--- gcc-4.7.3/gcc/testsuite/gcc.target/sh/pr32163.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/pr32163.c	2013-05-07 10:16:18.000000000 +0200
@@ -0,0 +1,25 @@
+/* PR target/32163 */
+/* { dg-do compile } */
+/* { dg-options "-O2 -fstack-protector-all" } */
+/* { dg-require-effective-target fstack_protector } */
+
+struct __graph_iterator_t
+{
+ int vertex;
+ int edge;
+};
+
+struct __graph_t
+{
+ int *edges;
+ int *first;
+
+};
+
+struct __graph_iterator_t graph_neighbors_it(struct __graph_t *g, int v)
+{
+ struct __graph_iterator_t it;
+ it.vertex = 2;
+ it.edge = g->first[v];
+ return it;
+}
diff -urN gcc-4.7.3/gcc/testsuite/gcc.target/sh/sh-trapa.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/sh-trapa.c
--- gcc-4.7.3/gcc/testsuite/gcc.target/sh/sh-trapa.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/sh-trapa.c	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,8 @@
+/* { dg-do compile { target "sh-superh-elf" } } */
+/* { dg-final { scan-assembler "trapa\t#42" } } */
+
+main()
+{
+  __builtin_trap();
+}
+
diff -urN gcc-4.7.3/gcc/testsuite/gcc.target/sh/sp-switch.c st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/sp-switch.c
--- gcc-4.7.3/gcc/testsuite/gcc.target/sh/sp-switch.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/gcc.target/sh/sp-switch.c	2013-01-15 13:48:52.000000000 +0100
@@ -0,0 +1,10 @@
+/* { dg-do compile { target "sh-*-*" } } */
+/* { dg-final { scan-assembler "mov\tr0,r15" } } */
+/* { dg-final { scan-assembler ".long\t_alt_stack" } } */
+
+void *alt_stack;
+void f() __attribute__ ((interrupt_handler, sp_switch ("alt_stack")));
+
+void f()
+{
+}
diff -urN gcc-4.7.3/gcc/testsuite/g++.dg/eh/postreload.C st40-4.7.3-13080/gcc/gcc/testsuite/g++.dg/eh/postreload.C
--- gcc-4.7.3/gcc/testsuite/g++.dg/eh/postreload.C	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/g++.dg/eh/postreload.C	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,35 @@
+// This testcase failed on sh, because stack offset to access i was shared
+// between handler and main.
+// { dg-do run }
+// { dg-options "-O2" }
+
+extern void abort (void);
+extern void exit (int);
+
+void
+bar (int *i, int *tab) __attribute__ ((weak,noinline)); 
+
+main()
+{
+  int i = 123;
+  int tab[47];
+
+  bar (&i, tab);
+
+  try
+    {
+      throw 1;
+    }
+  catch (...)
+    {
+      return 0;
+    }
+
+  abort ();
+}
+
+void
+bar (int *i, int *tab)
+{
+}
+
diff -urN gcc-4.7.3/gcc/testsuite/g++.dg/other/error27.C st40-4.7.3-13080/gcc/gcc/testsuite/g++.dg/other/error27.C
--- gcc-4.7.3/gcc/testsuite/g++.dg/other/error27.C	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/g++.dg/other/error27.C	2012-04-04 14:14:24.000000000 +0200
@@ -1,5 +1,4 @@
 // PR c++/35332
-// { dg-do compile }
 // { dg-options "-fno-finite-math-only" { target sh*-*-* } }
 
 void foo (double x, double y)
diff -urN gcc-4.7.3/gcc/testsuite/g++.dg/warn/Wstrict-aliasing-float-ref-int-obj.C st40-4.7.3-13080/gcc/gcc/testsuite/g++.dg/warn/Wstrict-aliasing-float-ref-int-obj.C
--- gcc-4.7.3/gcc/testsuite/g++.dg/warn/Wstrict-aliasing-float-ref-int-obj.C	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/g++.dg/warn/Wstrict-aliasing-float-ref-int-obj.C	2012-04-04 14:14:24.000000000 +0200
@@ -5,8 +5,8 @@
 int foo() {
   int x;
   float& q = reinterpret_cast<float&> (x);  /* { dg-message "dereferencing type-punned" "" { target *-*-* } } */
-  q = 1.0; /* { dg-warning "does break strict-aliasing" "" { xfail *-*-* } } */
+  q = 1.0; /* { dg-warning "does break strict-aliasing" "" } */
   return x;
 }
 
-/* { dg-message "initialized" "" { xfail *-*-* } 7 } */
+
diff -urN gcc-4.7.3/gcc/testsuite/go.db/dg.exp st40-4.7.3-13080/gcc/gcc/testsuite/go.db/dg.exp
--- gcc-4.7.3/gcc/testsuite/go.db/dg.exp	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/go.db/dg.exp	2012-03-28 16:58:23.000000000 +0200
@@ -0,0 +1,36 @@
+#   Copyright (C) 2009 Free Software Foundation, Inc.
+
+# This program is free software; you can redistribute it and/or modify
+# it under the terms of the GNU General Public License as published by
+# the Free Software Foundation; either version 3 of the License, or
+# (at your option) any later version.
+# 
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU General Public License for more details.
+# 
+# You should have received a copy of the GNU General Public License
+# along with GCC; see the file COPYING3.  If not see
+# <http://www.gnu.org/licenses/>.
+
+# GCC testsuite that uses the `dg.exp' driver.
+
+# Load support procs.
+load_lib go-dg.exp
+
+# If a testcase doesn't have special options, use these.
+global DEFAULT_GOCFLAGS
+if ![info exists DEFAULT_GOCFLAGS] then {
+    set DEFAULT_GOCFLAGS " -pedantic-errors"
+}
+
+# Initialize `dg'.
+dg-init
+
+# Main loop.
+go-dg-runtest [lsort \
+       [glob -nocomplain $srcdir/$subdir/*.go ] ] $DEFAULT_GOCFLAGS
+
+# All done.
+dg-finish
diff -urN gcc-4.7.3/gcc/testsuite/go.db/err-1.go st40-4.7.3-13080/gcc/gcc/testsuite/go.db/err-1.go
--- gcc-4.7.3/gcc/testsuite/go.db/err-1.go	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/go.db/err-1.go	2012-03-28 16:58:23.000000000 +0200
@@ -0,0 +1,7 @@
+// { dg-do compile }
+
+package main
+
+func main() {
+  var ret;		// { dg-error "expected type" }
+}
diff -urN gcc-4.7.3/gcc/testsuite/go.db/goto-1.go st40-4.7.3-13080/gcc/gcc/testsuite/go.db/goto-1.go
--- gcc-4.7.3/gcc/testsuite/go.db/goto-1.go	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/go.db/goto-1.go	2012-03-28 16:58:23.000000000 +0200
@@ -0,0 +1,7 @@
+// { dg-do compile }
+
+package main
+
+func main() {
+  goto lab;	// { dg-error "undefined label" }
+}
diff -urN gcc-4.7.3/gcc/testsuite/go.db/undef-1.go st40-4.7.3-13080/gcc/gcc/testsuite/go.db/undef-1.go
--- gcc-4.7.3/gcc/testsuite/go.db/undef-1.go	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/go.db/undef-1.go	2012-03-28 16:58:23.000000000 +0200
@@ -0,0 +1,7 @@
+// { dg-do compile }
+
+package main
+
+func main() {
+  sys.Exit(i)		// { dg-error "undefined" }
+}
diff -urN gcc-4.7.3/gcc/testsuite/go.dg/dg.exp st40-4.7.3-13080/gcc/gcc/testsuite/go.dg/dg.exp
--- gcc-4.7.3/gcc/testsuite/go.dg/dg.exp	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/go.dg/dg.exp	1970-01-01 01:00:00.000000000 +0100
@@ -1,36 +0,0 @@
-#   Copyright (C) 2009 Free Software Foundation, Inc.
-
-# This program is free software; you can redistribute it and/or modify
-# it under the terms of the GNU General Public License as published by
-# the Free Software Foundation; either version 3 of the License, or
-# (at your option) any later version.
-# 
-# This program is distributed in the hope that it will be useful,
-# but WITHOUT ANY WARRANTY; without even the implied warranty of
-# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
-# GNU General Public License for more details.
-# 
-# You should have received a copy of the GNU General Public License
-# along with GCC; see the file COPYING3.  If not see
-# <http://www.gnu.org/licenses/>.
-
-# GCC testsuite that uses the `dg.exp' driver.
-
-# Load support procs.
-load_lib go-dg.exp
-
-# If a testcase doesn't have special options, use these.
-global DEFAULT_GOCFLAGS
-if ![info exists DEFAULT_GOCFLAGS] then {
-    set DEFAULT_GOCFLAGS " -pedantic-errors"
-}
-
-# Initialize `dg'.
-dg-init
-
-# Main loop.
-go-dg-runtest [lsort \
-       [glob -nocomplain $srcdir/$subdir/*.go ] ] $DEFAULT_GOCFLAGS
-
-# All done.
-dg-finish
diff -urN gcc-4.7.3/gcc/testsuite/go.dg/err-1.go st40-4.7.3-13080/gcc/gcc/testsuite/go.dg/err-1.go
--- gcc-4.7.3/gcc/testsuite/go.dg/err-1.go	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/go.dg/err-1.go	1970-01-01 01:00:00.000000000 +0100
@@ -1,7 +0,0 @@
-// { dg-do compile }
-
-package main
-
-func main() {
-  var ret;		// { dg-error "expected type" }
-}
diff -urN gcc-4.7.3/gcc/testsuite/go.dg/goto-1.go st40-4.7.3-13080/gcc/gcc/testsuite/go.dg/goto-1.go
--- gcc-4.7.3/gcc/testsuite/go.dg/goto-1.go	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/go.dg/goto-1.go	1970-01-01 01:00:00.000000000 +0100
@@ -1,7 +0,0 @@
-// { dg-do compile }
-
-package main
-
-func main() {
-  goto lab;	// { dg-error "undefined label" }
-}
diff -urN gcc-4.7.3/gcc/testsuite/go.dg/undef-1.go st40-4.7.3-13080/gcc/gcc/testsuite/go.dg/undef-1.go
--- gcc-4.7.3/gcc/testsuite/go.dg/undef-1.go	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/go.dg/undef-1.go	1970-01-01 01:00:00.000000000 +0100
@@ -1,7 +0,0 @@
-// { dg-do compile }
-
-package main
-
-func main() {
-  sys.Exit(i)		// { dg-error "undefined" }
-}
diff -urN gcc-4.7.3/gcc/testsuite/lib/c-torture.exp st40-4.7.3-13080/gcc/gcc/testsuite/lib/c-torture.exp
--- gcc-4.7.3/gcc/testsuite/lib/c-torture.exp	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/testsuite/lib/c-torture.exp	2012-10-15 10:04:17.000000000 +0200
@@ -126,7 +126,8 @@
 #
 proc c-torture-execute { sources args } {
     global tmpdir tool srcdir output compiler_conditional_xfail_data
-
+    global additional_linker_flag
+    
     # Use the first source filename given as the filename under test.
     set src [lindex $sources 0]
 
@@ -135,6 +136,11 @@
     } else {
 	set additional_flags ""
     }
+
+    if { [info exists additional_linker_flag] } {
+       lappend additional_flags $additional_linker_flag
+    }
+
     # Check for alternate driver.
     if [file exists [file rootname $src].x] {
 	verbose "Using alternate driver [file rootname [file tail $src]].x" 2
diff -urN gcc-4.7.3/gcc/testsuite/lib/scanobj.exp st40-4.7.3-13080/gcc/gcc/testsuite/lib/scanobj.exp
--- gcc-4.7.3/gcc/testsuite/lib/scanobj.exp	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/lib/scanobj.exp	2012-08-23 10:22:57.000000000 +0200
@@ -0,0 +1,138 @@
+# Reset data used to avoid unecessary recompilation of same file
+proc dg-scan-obj-reset {} {
+    global saved_output_filename
+    global saved_output_datafile
+
+    if [info exists saved_output_filename] {
+        set saved_output_filename 0
+    }
+    if [info exists saved_output_datafile] {
+        set saved_output_datafile 0
+    }
+}
+
+
+# Scan a symbol in an object file.  If it is present and POSITIVE
+# is non-zero, or it is not present and POSITIVE is zero, the test
+# passes.  The ORIG_ARGS is the list of arguments provided by dg-final
+# to scan-assembler.
+# The first element in ORIG_ARGS is the regular expression to look for
+# in the file.
+# The secund element in ORIG_ARGS is the begin pattern to look for in the file.
+# The third element in ORIG_ARGS is the end pattern to look for in the file.
+# The fourth element in ORIG_ARGS, if present, is the object file.
+# The last element in ORIG_ARGS, if present, is a DejaGNU target selector.
+proc dg-scan-obj { name positive testcase orig_args } {
+    global GCC_UNDER_TEST
+    global objdump
+    global base_dir
+    global saved_output_filename
+    global saved_output_datafile
+
+    if { [llength $orig_args] >= 5 } {
+	switch [dg-process-target [lindex $orig_args 4]] {
+	    "S" { }
+	    "N" { return }
+	    "F" { setup_xfail "*-*-*" }
+	    "P" { }
+	}
+    }
+
+    # Find objdump like we find g++ in g++.exp.
+    if ![info exists objdump]  {
+        set objdump "objdump"
+        regsub "(.*)gcc$" $GCC_UNDER_TEST {\1objdump} objdump
+	set objdump [findfile $objdump $objdump \
+                [findfile $base_dir/../../../binutils/objdump \
+                     $base_dir/../../../binutils/objdump \
+                     [findfile $base_dir/../../objdump $base_dir/../../objdump \
+                          [findfile $base_dir/objdump $base_dir/objdump \
+                               [transform objdump]]]]]
+	verbose -log "objdump is $objdump"
+    }
+
+    # what is the object filename?
+    if { [llength $orig_args] >= 4 } {
+        # object file is given by the user
+        set objfile [lindex $orig_args 3]
+    } else {
+        # object file is the one from the testcase
+        set objfile "[file rootname [file tail [lindex $testcase 0]]].o"
+    }
+    set objfile [string trim $objfile]
+
+    set output_file "[glob -nocomplain $objfile]"
+    if { $output_file == "" } {
+	fail "$name $orig_args: object file does not exist"
+	return
+    }
+
+    if {[info exists saved_output_filename] &&
+        [info exists saved_output_datafile] &&
+        $saved_output_filename == $output_file} {
+        # get data from previous step
+        set output $saved_output_datafile
+    } else {
+        # get new data
+        set fd [open "| $objdump -d $output_file" r]
+        set output [read $fd]
+        close $fd
+        set saved_output_filename $output_file
+        set saved_output_datafile $output
+    }
+
+    set pattern [string trim [lindex $orig_args 0]]
+    set begin   [string trim [lindex $orig_args 1]]
+    set end     [string trim [lindex $orig_args 2]]
+
+    set match 0
+    set inside 0
+    set data [split $output "\n"]
+    foreach line $data {
+        if { $inside == "1" } {
+            # Detect pattern
+            if { [regexp $pattern $line] } {
+                set match 1
+                break
+            }
+            # Detect end
+            if { [regexp $end $line] } {
+                break
+            }
+        }
+        # Detect begin
+        if { [regexp $begin $line] } {
+            set inside 1
+        }
+    }
+
+    if { $match == $positive } {
+	pass "$testcase $name $orig_args"
+    } else {
+	fail "$testcase $name $orig_args"
+    }
+}
+
+
+# Look for a symbol in an object file, invoked via dg-final.
+# See dg-scan-obj for details.
+
+proc scan-obj { args } {
+    # This assumes that we are two frames down from dg-test, and that
+    # it still stores the filename of the testcase in a local variable "name".
+    upvar 2 name testcase
+
+    dg-scan-obj "scan-obj" 1 $testcase $args
+}
+
+
+# Check that a symbol is not present in an object file, invoked via dg-final.
+# See dg-scan-obj for details.
+
+proc scan-obj-not { args } {
+    # This assumes that we are two frames down from dg-test, and that
+    # it still stores the filename of the testcase in a local variable "name".
+    upvar 2 name testcase
+
+    dg-scan-obj "scan-obj-not" 0 $testcase $args
+}
diff -urN gcc-4.7.3/gcc/testsuite/lib/target-supports.exp st40-4.7.3-13080/gcc/gcc/testsuite/lib/target-supports.exp
--- gcc-4.7.3/gcc/testsuite/lib/target-supports.exp	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/testsuite/lib/target-supports.exp	2013-03-27 16:11:13.000000000 +0100
@@ -498,6 +498,13 @@
 	return 0
     }
 
+    # There is no profiling support on SH when running on the simu.
+    if { [istarget sh-superh-elf] } {
+	if [board_info target exists is_simulator] {
+	    return 0
+	}
+    }
+
     # uClibc does not have gcrt1.o.
     if { [check_effective_target_uclibc]
 	 && ($test_what == "-p" || $test_what == "-pg") } {
@@ -3866,6 +3873,7 @@
 	     || [istarget hppa*-*linux*]
 	     || [istarget s390*-*-*] 
 	     || [istarget powerpc*-*-*]
+	     || [istarget sh*-superh-elf]
 	     || ([istarget sparc*-*-*] && [check_effective_target_sparc_v9])
 	     || [check_effective_target_mips_llsc] } {
            set et_sync_int_long_saved 1
@@ -3895,6 +3903,7 @@
 	     || [istarget hppa*-*linux*]
 	     || [istarget s390*-*-*] 
 	     || [istarget powerpc*-*-*]
+	     || [istarget sh*-superh-elf]
 	     || ([istarget sparc*-*-*] && [check_effective_target_sparc_v9])
 	     || [check_effective_target_mips_llsc] } {
            set et_sync_char_short_saved 1
@@ -3946,6 +3955,15 @@
     }]
 }
 
+# Return true if this is a target supports complex.h
+
+proc check_effective_target_complex { } {
+    return [check_no_compiler_messages complex assembly {
+	#include <complex.h>
+	main() { complex double a; return 0; }
+    }]
+}
+
 # Return 1 if
 #   (a) an error of a few ULP is expected in string to floating-point
 #       conversion functions; and
diff -urN gcc-4.7.3/gcc/toplev.c st40-4.7.3-13080/gcc/gcc/toplev.c
--- gcc-4.7.3/gcc/toplev.c	2013-04-04 16:25:15.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/toplev.c	2013-04-15 10:26:30.000000000 +0200
@@ -619,6 +619,7 @@
       process_pending_assemble_externals ();
    }
 
+#ifndef HAVE_LTO_PLUGIN 
   /* Emit LTO marker if LTO info has been previously emitted.  This is
      used by collect2 to determine whether an object file contains IL.
      We used to emit an undefined reference here, but this produces
@@ -656,6 +657,7 @@
 #endif
         }
     }
+#endif
 
   /* Attach a special .ident directive to the end of the file to identify
      the version of GCC which compiled this code.  The format of the .ident
diff -urN gcc-4.7.3/gcc/tree.c st40-4.7.3-13080/gcc/gcc/tree.c
--- gcc-4.7.3/gcc/tree.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/tree.c	2013-03-27 16:11:13.000000000 +0100
@@ -1576,7 +1576,10 @@
 {
   switch (TREE_CODE (type))
     {
-    case INTEGER_TYPE: case ENUMERAL_TYPE: case BOOLEAN_TYPE:
+    case BOOLEAN_TYPE:
+      return boolean_true_node;
+    
+    case INTEGER_TYPE: case ENUMERAL_TYPE:
     case POINTER_TYPE: case REFERENCE_TYPE:
     case OFFSET_TYPE:
       return build_int_cst (type, 1);
@@ -1615,7 +1618,10 @@
 {
   switch (TREE_CODE (type))
     {
-    case INTEGER_TYPE: case ENUMERAL_TYPE: case BOOLEAN_TYPE:
+    case BOOLEAN_TYPE:
+      return boolean_false_node;
+    
+    case INTEGER_TYPE: case ENUMERAL_TYPE:
     case POINTER_TYPE: case REFERENCE_TYPE:
     case OFFSET_TYPE: case NULLPTR_TYPE:
       return build_int_cst (type, 0);
diff -urN gcc-4.7.3/gcc/tree-chrec.c st40-4.7.3-13080/gcc/gcc/tree-chrec.c
--- gcc-4.7.3/gcc/tree-chrec.c	2012-10-01 13:18:40.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/tree-chrec.c	2013-04-23 17:06:09.000000000 +0200
@@ -1365,6 +1365,26 @@
     res = fold_build2 (TREE_CODE (chrec), type,
 		       fold_convert (type, TREE_OPERAND (chrec, 0)),
 		       fold_convert (type, TREE_OPERAND (chrec, 1)));
+  /* Similar perform the trick that (signed char)((int)x + 2) can be
+     narrowed to (signed char)((unsigned char)x + 2). */
+  /* Similarly, (unsigned char)((int)x + 2) with x an unsigned char 
+     is simply narrowed to (unsigned char)((unsigned char)x + 2) */
+  else if (use_overflow_semantics
+           && TREE_CODE (chrec) == POLYNOMIAL_CHREC
+           && TREE_CODE (ct) == INTEGER_TYPE
+           && TREE_CODE (type) == INTEGER_TYPE
+           && TYPE_MODE (type) != TYPE_MODE (ct)
+           && TYPE_PRECISION (type) < TYPE_PRECISION (ct))
+    {
+      tree utype = unsigned_type_for (type);
+
+      res = build_polynomial_chrec (CHREC_VARIABLE (chrec),
+                                    fold_convert (utype,
+                                                  CHREC_LEFT (chrec)),
+                                    fold_convert (utype,
+                                                  CHREC_RIGHT (chrec)));
+      res = chrec_convert_1 (type, res, at_stmt, use_overflow_semantics);
+    }
   else
     res = fold_convert (type, chrec);
 
diff -urN gcc-4.7.3/gcc/tree-inline.c st40-4.7.3-13080/gcc/gcc/tree-inline.c
--- gcc-4.7.3/gcc/tree-inline.c	2013-04-04 16:25:15.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/tree-inline.c	2013-04-15 10:26:30.000000000 +0200
@@ -3852,9 +3852,9 @@
 	  /* PR 20090218-1_0.c. Body can be provided by another module. */
 	  && (reason != CIF_BODY_NOT_AVAILABLE || !flag_generate_lto))
 	{
-	  error ("inlining failed in call to always_inline %q+F: %s", fn,
-		 cgraph_inline_failed_string (reason));
-	  error ("called from here");
+	  warning (OPT_Winline, "inlining failed in call to %q+F: %s",
+		   fn, cgraph_inline_failed_string (reason));
+	  warning (OPT_Winline, "called from here");
 	}
       else if (warn_inline
 	       && DECL_DECLARED_INLINE_P (fn)
diff -urN gcc-4.7.3/gcc/tree-scalar-evolution.c st40-4.7.3-13080/gcc/gcc/tree-scalar-evolution.c
--- gcc-4.7.3/gcc/tree-scalar-evolution.c	2012-06-18 11:00:11.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/tree-scalar-evolution.c	2013-04-24 09:58:58.000000000 +0200
@@ -1632,6 +1632,7 @@
 		    tree type, tree rhs1, enum tree_code code, tree rhs2)
 {
   tree res, chrec1, chrec2;
+  gimple def;
 
   if (get_gimple_rhs_class (code) == GIMPLE_SINGLE_RHS)
     {
@@ -1714,7 +1715,31 @@
       break;
 
     CASE_CONVERT:
-      chrec1 = analyze_scalar_evolution (loop, rhs1);
+      /* In case we have a truncation of a widened operation that in
+         the truncated type has undefined overflow behavior analyze
+         the operation done in an unsigned type of the same precision
+         as the final truncation.  We cannot derive a scalar evolution
+         for the widened operation but for the truncated result.  */
+      if (TREE_CODE (type) == INTEGER_TYPE
+          && TREE_CODE (TREE_TYPE (rhs1)) == INTEGER_TYPE
+          && TYPE_PRECISION (type) < TYPE_PRECISION (TREE_TYPE (rhs1))
+	  && TYPE_MODE (type) != TYPE_MODE (TREE_TYPE (rhs1))
+          && TREE_CODE (rhs1) == SSA_NAME
+          && (def = SSA_NAME_DEF_STMT (rhs1))
+          && is_gimple_assign (def)
+          && TREE_CODE_CLASS (gimple_assign_rhs_code (def)) == tcc_binary
+          && TREE_CODE (gimple_assign_rhs2 (def)) == INTEGER_CST)
+        {
+          /* type might already be unsigned, in that case type and utype 
+	     are the same : (unsigned char)((unsigned char)x + 2) */
+	  tree utype = unsigned_type_for (type);
+          chrec1 = interpret_rhs_expr (loop, at_stmt, utype,
+                                       gimple_assign_rhs1 (def),
+                                       gimple_assign_rhs_code (def),
+                                       gimple_assign_rhs2 (def));
+        }
+      else
+        chrec1 = analyze_scalar_evolution (loop, rhs1);
       res = chrec_convert (type, chrec1, at_stmt);
       break;
 
diff -urN gcc-4.7.3/gcc/tree-ssa-ccp.c st40-4.7.3-13080/gcc/gcc/tree-ssa-ccp.c
--- gcc-4.7.3/gcc/tree-ssa-ccp.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/tree-ssa-ccp.c	2013-03-27 16:11:13.000000000 +0100
@@ -3,6 +3,7 @@
    2010, 2011, 2012, 2013 Free Software Foundation, Inc.
    Adapted from original RTL SSA-CCP by Daniel Berlin <dberlin@dberlin.org>
    Adapted to GIMPLE trees by Diego Novillo <dnovillo@redhat.com>
+   Copyright (c) 2010 STMicroelectronics.
 
 This file is part of GCC.
 
@@ -385,6 +386,9 @@
   if (!HONOR_NANS (mode)
       && REAL_VALUE_ISNAN (d))
     {
+      if (warn_non_finite_math)
+	warning (OPT_Wnon_finite_math,
+		 "non-finite operation %E not honored", val->value);
       val->lattice_val = UNDEFINED;
       val->value = NULL;
       return;
diff -urN gcc-4.7.3/gcc/tree-ssa-math-opts.c st40-4.7.3-13080/gcc/gcc/tree-ssa-math-opts.c
--- gcc-4.7.3/gcc/tree-ssa-math-opts.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/tree-ssa-math-opts.c	2013-03-27 16:11:13.000000000 +0100
@@ -1420,7 +1420,8 @@
 		CASE_FLT_FN (BUILT_IN_SIN):
 		CASE_FLT_FN (BUILT_IN_CEXPI):
 		  /* Make sure we have either sincos or cexp.  */
-		  if (!TARGET_HAS_SINCOS && !TARGET_C99_FUNCTIONS)
+		  if (!TARGET_HAS_SINCOS && !TARGET_C99_FUNCTIONS
+		      && flag_cse_sincos)
 		    break;
 
 		  arg = gimple_call_arg (stmt, 0);
diff -urN gcc-4.7.3/gcc/tree-ssa-tail-merge.c st40-4.7.3-13080/gcc/gcc/tree-ssa-tail-merge.c
--- gcc-4.7.3/gcc/tree-ssa-tail-merge.c	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/gcc/tree-ssa-tail-merge.c	2013-03-27 16:11:13.000000000 +0100
@@ -1437,6 +1437,8 @@
     bb2->frequency = BB_FREQ_MAX;
   bb1->frequency = 0;
 
+  bb2->count += bb1->count;
+
   /* Do updates that use bb1, before deleting bb1.  */
   release_last_vdef (bb1);
   same_succ_flush_bb (bb1);
diff -urN gcc-4.7.3/gcc/varasm.c st40-4.7.3-13080/gcc/gcc/varasm.c
--- gcc-4.7.3/gcc/varasm.c	2012-06-18 11:00:11.000000000 +0200
+++ st40-4.7.3-13080/gcc/gcc/varasm.c	2012-06-18 16:10:36.000000000 +0200
@@ -1645,14 +1645,14 @@
      Note that we still need to align to DECL_ALIGN, as above,
      because ASM_OUTPUT_MAX_SKIP_ALIGN might not do any alignment at all.  */
   if (! DECL_USER_ALIGN (decl)
-      && align_functions_log > align
+      && ASM_ALIGN_FUNCTION_LOG (decl) > align
       && optimize_function_for_speed_p (cfun))
     {
 #ifdef ASM_OUTPUT_MAX_SKIP_ALIGN
       ASM_OUTPUT_MAX_SKIP_ALIGN (asm_out_file,
 				 align_functions_log, align_functions - 1);
 #else
-      ASM_OUTPUT_ALIGN (asm_out_file, align_functions_log);
+      ASM_OUTPUT_ALIGN (asm_out_file, ASM_ALIGN_FUNCTION_LOG (decl));
 #endif
     }
 
diff -urN gcc-4.7.3/include/ChangeLog.STM st40-4.7.3-13080/gcc/include/ChangeLog.STM
--- gcc-4.7.3/include/ChangeLog.STM	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/include/ChangeLog.STM	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,3 @@
+2006-03-27  Andrew Stubbs  <andrew.stubbs@st.com>
+
+	* libiberty.h: Add support for cygpath.c.
diff -urN gcc-4.7.3/include/libiberty.h st40-4.7.3-13080/gcc/include/libiberty.h
--- gcc-4.7.3/include/libiberty.h	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/include/libiberty.h	2012-04-04 14:14:24.000000000 +0200
@@ -678,9 +678,21 @@
    (char *) memcpy (libiberty_nptr, libiberty_optr, libiberty_len))
 #endif
 
+#ifdef __MINGW32__
+/* Reassign the pointer PATH without freeing anything.  */
+extern char *cygpath (const char *path);
+#define CYGPATH(path) do {path = cygpath (path);} while(0)
+
+/* Reassign the pointer PATH and free the previous content.  */
+extern void cygpath_replace (char **path);
+#else
+/* If these were properly empty statements then there might be warnings
+   which would kill a -Werror build.  */
+#define CYGPATH(path) do {} while (0)
+#endif
+
 #ifdef __cplusplus
 }
 #endif
 
-
 #endif /* ! defined (LIBIBERTY_H) */
diff -urN gcc-4.7.3/libcpp/ChangeLog.STM st40-4.7.3-13080/gcc/libcpp/ChangeLog.STM
--- gcc-4.7.3/libcpp/ChangeLog.STM	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libcpp/ChangeLog.STM	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,12 @@
+2009-06-10  Antony King  <antony.king@st.com>
+
+	* mkdeps.c (deps_write): Use ISALPHA instead of isalpha.
+	(deps_phony_targets): Likewise.
+
+2007-08-14  Andrew Stubbs  <andrew.stubbs@st.com>
+
+	* mkdeps.c (deps_write): Convert paths to Cygwin format on MinGW,
+	if GCC_CYGWIN_DEPS environment variable is set.
+	(deps_phony_targets): Likewise.
+
+
diff -urN gcc-4.7.3/libcpp/mkdeps.c st40-4.7.3-13080/gcc/libcpp/mkdeps.c
--- gcc-4.7.3/libcpp/mkdeps.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libcpp/mkdeps.c	2012-04-04 14:14:24.000000000 +0200
@@ -321,6 +321,17 @@
 	      column++;
 	    }
 	}
+#ifdef __MINGW32__
+      if (getenv ("GCC_CYGWIN_DEPS") != NULL
+	  && ISALPHA (d->targetv[i][0])
+	  && d->targetv[i][1] == ':')
+	{
+	  fputs ("/cygdrive/", fp);
+	  fputc (d->targetv[i][0], fp);
+	  fputs (d->targetv[i]+2, fp);
+	}
+      else
+#endif
       fputs (d->targetv[i], fp);
     }
 
@@ -341,6 +352,17 @@
 	  putc (' ', fp);
 	  column++;
 	}
+#ifdef __MINGW32__
+      if (getenv ("GCC_CYGWIN_DEPS") != NULL
+	  && ISALPHA (d->depv[i][0])
+	  && d->depv[i][1] == ':')
+	{
+	  fputs ("/cygdrive/", fp);
+	  fputc (d->depv[i][0], fp);
+	  fputs (d->depv[i]+2, fp);
+	}
+      else
+#endif
       fputs (d->depv[i], fp);
     }
   putc ('\n', fp);
@@ -354,6 +376,17 @@
   for (i = 1; i < d->ndeps; i++)
     {
       putc ('\n', fp);
+#ifdef __MINGW32__
+      if (getenv ("GCC_CYGWIN_DEPS") != NULL
+	  && ISALPHA (d->depv[i][0])
+	  && d->depv[i][1] == ':')
+	{
+	  fputs ("/cygdrive/", fp);
+	  fputc (d->depv[i][0], fp);
+	  fputs (d->depv[i]+2, fp);
+	}
+      else
+#endif
       fputs (d->depv[i], fp);
       putc (':', fp);
       putc ('\n', fp);
diff -urN gcc-4.7.3/libgcc/ChangeLog.STM st40-4.7.3-13080/gcc/libgcc/ChangeLog.STM
--- gcc-4.7.3/libgcc/ChangeLog.STM	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/ChangeLog.STM	2013-07-24 10:08:04.000000000 +0200
@@ -0,0 +1,34 @@
+2012-11-28  Laurent Alfonsi  <laurent.alfonsi@st.com>
+
+        * config/sh/lib1funcs.S (movmem): Add local labels for pc-relative
+        operations.
+
+2013-04-30  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/ieee-754-sf.S: Move here
+	Don't include insn-constants.h
+	* config/sh/ieee-754-ff.S: Likewise.
+
+2013-02-12  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/supervisor-atomic.S: New file.
+	* config/sh/supervisor-sync.S: Rename.
+	* config/sh/t-superh (LIB2ADD): Add supervisor-sync.S
+
+2012-11-13  Christian Bruel  <christian.bruel@st.com>
+
+	* config/sh/lib1funcs.S (movmem): Remove strmem aliases.
+
+2012-04-04  Antony King  <antony.king@st.com>
+	Christian Bruel  <christian.bruel@st.com>
+
+	* gthr-generic.c (__generic_gxx_mutex_destroy): New function.
+	(__generic_gxx_recursive_mutex_destroy): Likewise.
+	* gthr-generic.h (__generic_gxx_mutex_destroy): Declare.
+	(__generic_gxx_recursive_mutex_destroy): Likewise.
+
+2009-07-27  Christian Bruel  <christian.bruel@st.com>
+
+        * config.host (extra_parts): Set for sh*-*-linux.
+	(tmake_file): Add t-extra for sh*-*-linux.
+	* config/sh/t-extra: New file to build optimized libgcc objects.
diff -urN gcc-4.7.3/libgcc/config/sh/crt1.S st40-4.7.3-13080/gcc/libgcc/config/sh/crt1.S
--- gcc-4.7.3/libgcc/config/sh/crt1.S	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/crt1.S	2012-04-10 14:48:43.000000000 +0200
@@ -2,6 +2,8 @@
    Free Software Foundation, Inc.
    This file was pretty much copied from newlib.
 
+   Copyright (c) 2006  STMicroelectronics.
+
 This file is part of GCC.
 
 GCC is free software; you can redistribute it and/or modify it
@@ -34,7 +36,7 @@
 /* Label at the highest stack address where the stack grows from */
 __timer_stack:
 #endif /* MMU_SUPPORT */
-	
+
 	/* ;----------------------------------------
 	Normal newlib crt1.S */
 
@@ -421,7 +423,7 @@
 #endif /* MMU_SUPPORT */
 
 	pt/l	.Lzero_bss_loop, tr0
-	pt/l	_init, tr5
+	pt/l	__init, tr5
 	pt/l	___setup_argv_and_call_main, tr6
 	pt/l	_exit, tr7
 
@@ -453,7 +455,7 @@
 
 	! arrange for exit to call fini
 	pt/l	_atexit, tr1
-	LOAD_ADDR (_fini, r2)
+	LOAD_ADDR (__fini, r2)
 	blink	tr1, r18
 
 	! call init
@@ -851,9 +853,9 @@
 atexit_k:
 	.long	_atexit
 init_k:
-	.long	_init
+	.long	__init
 fini_k:
-	.long	_fini
+	.long	__fini
 #ifdef VBR_SETUP
 old_vbr_k:
 	.long	old_vbr
@@ -1169,201 +1171,5 @@
 handler_exit_k:
 	.long _exit
 	.align 2
-! Simulated compile of trap handler.
-	.section	.debug_abbrev,"",@progbits
-.Ldebug_abbrev0:
-	.section	.debug_info,"",@progbits
-.Ldebug_info0:
-	.section	.debug_line,"",@progbits
-.Ldebug_line0:
-	.text
-.Ltext0:
-	.align 5
-	.type	__superh_trap_handler,@function
-__superh_trap_handler:
-.LFB1:
-	mov.l	r14,@-r15
-.LCFI0:
-	add	#-4,r15
-.LCFI1:
-	mov	r15,r14
-.LCFI2:
-	mov.l	r4,@r14
-	lds	r1, pr
-	add	#4,r14
-	mov	r14,r15
-	mov.l	@r15+,r14
-	rts	
-	nop
-.LFE1:
-.Lfe1:
-	.size	__superh_trap_handler,.Lfe1-__superh_trap_handler
-	.section	.debug_frame,"",@progbits
-.Lframe0:
-	.ualong	.LECIE0-.LSCIE0
-.LSCIE0:
-	.ualong	0xffffffff
-	.byte	0x1
-	.string	""
-	.uleb128 0x1
-	.sleb128 -4
-	.byte	0x11
-	.byte	0xc
-	.uleb128 0xf
-	.uleb128 0x0
-	.align 2
-.LECIE0:
-.LSFDE0:
-	.ualong	.LEFDE0-.LASFDE0
-.LASFDE0:
-	.ualong	.Lframe0
-	.ualong	.LFB1
-	.ualong	.LFE1-.LFB1
-	.byte	0x4
-	.ualong	.LCFI0-.LFB1
-	.byte	0xe
-	.uleb128 0x4
-	.byte	0x4
-	.ualong	.LCFI1-.LCFI0
-	.byte	0xe
-	.uleb128 0x8
-	.byte	0x8e
-	.uleb128 0x1
-	.byte	0x4
-	.ualong	.LCFI2-.LCFI1
-	.byte	0xd
-	.uleb128 0xe
-	.align 2
-.LEFDE0:
-	.text
-.Letext0:
-	.section	.debug_info
-	.ualong	0xb3
-	.uaword	0x2
-	.ualong	.Ldebug_abbrev0
-	.byte	0x4
-	.uleb128 0x1
-	.ualong	.Ldebug_line0
-	.ualong	.Letext0
-	.ualong	.Ltext0
-	.string	"trap_handler.c"
-	.string	"xxxxxxxxxxxxxxxxxxxxxxxxxxxx"
-	.string	"GNU C 3.2 20020529 (experimental)"
-	.byte	0x1
-	.uleb128 0x2
-	.ualong	0xa6
-	.byte	0x1
-	.string	"_superh_trap_handler"
-	.byte	0x1
-	.byte	0x2
-	.byte	0x1
-	.ualong	.LFB1
-	.ualong	.LFE1
-	.byte	0x1
-	.byte	0x5e
-	.uleb128 0x3
-	.string	"trap_reason"
-	.byte	0x1
-	.byte	0x1
-	.ualong	0xa6
-	.byte	0x2
-	.byte	0x91
-	.sleb128 0
-	.byte	0x0
-	.uleb128 0x4
-	.string	"unsigned int"
-	.byte	0x4
-	.byte	0x7
-	.byte	0x0
-	.section	.debug_abbrev
-	.uleb128 0x1
-	.uleb128 0x11
-	.byte	0x1
-	.uleb128 0x10
-	.uleb128 0x6
-	.uleb128 0x12
-	.uleb128 0x1
-	.uleb128 0x11
-	.uleb128 0x1
-	.uleb128 0x3
-	.uleb128 0x8
-	.uleb128 0x1b
-	.uleb128 0x8
-	.uleb128 0x25
-	.uleb128 0x8
-	.uleb128 0x13
-	.uleb128 0xb
-	.byte	0x0
-	.byte	0x0
-	.uleb128 0x2
-	.uleb128 0x2e
-	.byte	0x1
-	.uleb128 0x1
-	.uleb128 0x13
-	.uleb128 0x3f
-	.uleb128 0xc
-	.uleb128 0x3
-	.uleb128 0x8
-	.uleb128 0x3a
-	.uleb128 0xb
-	.uleb128 0x3b
-	.uleb128 0xb
-	.uleb128 0x27
-	.uleb128 0xc
-	.uleb128 0x11
-	.uleb128 0x1
-	.uleb128 0x12
-	.uleb128 0x1
-	.uleb128 0x40
-	.uleb128 0xa
-	.byte	0x0
-	.byte	0x0
-	.uleb128 0x3
-	.uleb128 0x5
-	.byte	0x0
-	.uleb128 0x3
-	.uleb128 0x8
-	.uleb128 0x3a
-	.uleb128 0xb
-	.uleb128 0x3b
-	.uleb128 0xb
-	.uleb128 0x49
-	.uleb128 0x13
-	.uleb128 0x2
-	.uleb128 0xa
-	.byte	0x0
-	.byte	0x0
-	.uleb128 0x4
-	.uleb128 0x24
-	.byte	0x0
-	.uleb128 0x3
-	.uleb128 0x8
-	.uleb128 0xb
-	.uleb128 0xb
-	.uleb128 0x3e
-	.uleb128 0xb
-	.byte	0x0
-	.byte	0x0
-	.byte	0x0
-	.section	.debug_pubnames,"",@progbits
-	.ualong	0x27
-	.uaword	0x2
-	.ualong	.Ldebug_info0
-	.ualong	0xb7
-	.ualong	0x67
-	.string	"_superh_trap_handler"
-	.ualong	0x0
-	.section	.debug_aranges,"",@progbits
-	.ualong	0x1c
-	.uaword	0x2
-	.ualong	.Ldebug_info0
-	.byte	0x4
-	.byte	0x0
-	.uaword	0x0
-	.uaword	0x0
-	.ualong	.Ltext0
-	.ualong	.Letext0-.Ltext0
-	.ualong	0x0
-	.ualong	0x0
 #endif /* VBR_SETUP */
 #endif /* ! __SH5__ */
diff -urN gcc-4.7.3/libgcc/config/sh/crti.S st40-4.7.3-13080/gcc/libgcc/config/sh/crti.S
--- gcc-4.7.3/libgcc/config/sh/crti.S	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/crti.S	2012-04-10 14:48:43.000000000 +0200
@@ -44,8 +44,8 @@
 #else
 	.p2align 1
 #endif
-	.global	 _init
-_init:
+	.global	 __init
+__init:
 #if __SHMEDIA__
 	addi	r15, -16, r15
 	st.q	r15, 8, r14
@@ -89,8 +89,8 @@
 #else
 	.p2align 1
 #endif
-	.global  _fini
-_fini:	
+	.global  __fini
+__fini:
 #if __SHMEDIA__
 	addi	r15, -16, r15
 	st.q	r15, 8, r14
diff -urN gcc-4.7.3/libgcc/config/sh/crtn.S st40-4.7.3-13080/gcc/libgcc/config/sh/crtn.S
--- gcc-4.7.3/libgcc/config/sh/crtn.S	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/crtn.S	2012-04-04 14:14:24.000000000 +0200
@@ -39,9 +39,15 @@
 	rts
 	add	#8,r15
 #else
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif	
 	mov	r14,r15
 	lds.l	@r15+,pr
 	mov.l	@r15+,r14
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	nop
+#endif		
 	rts
 #ifdef __ELF__
 	mov.l	@r15+,r12
@@ -65,9 +71,15 @@
 	rts
 	add	#8,r15
 #else
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif		
 	mov	r14,r15
 	lds.l	@r15+,pr
 	mov.l	@r15+,r14
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	nop
+#endif			
 	rts
 #ifdef __ELF__
 	mov.l	@r15+,r12
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/adddf3.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/adddf3.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/adddf3.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/adddf3.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,799 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+! Routine for adding two double numbers
+
+! Author: Rakesh Kumar
+! SH1 Support by Joern Rennecke
+! Sticky Bit handling : Joern Rennecke
+
+! Arguments: r4-r5, r6-r7
+! Result: r0-r1
+
+! The value in r4-r5 is referred to as op1
+! and that in r6-r7 is referred to as op2
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+        .align 5
+	.global	GLOBAL (subdf3)
+	FUNC (GLOBAL (subdf3))
+        .global GLOBAL (adddf3)
+	FUNC (GLOBAL (adddf3))
+
+GLOBAL (subdf3):
+#ifdef __LITTLE_ENDIAN__
+	mov	r4,r1
+	mov	r6,r2
+
+	mov	r5,r4
+	mov	r7,r6
+
+	mov	r1,r5
+	mov	r2,r7
+#endif
+	mov.l	.L_sign,r2
+	bra	.L_adddf3_1
+	xor	r2,r6
+
+GLOBAL (adddf3):
+#ifdef	__LITTLE_ENDIAN__
+	mov	r4,r1
+	mov	r6,r2
+
+	mov	r5,r4
+	mov	r7,r6
+
+	mov	r1,r5
+	mov	r2,r7
+#endif
+	
+.L_adddf3_1:
+	mov.l	r8,@-r15
+	mov	r4,r1
+
+	mov.l 	.L_inf,r2
+	mov	r6,r3
+
+	mov.l	r9,@-r15
+	and	r2,r1		!Exponent of op1 in r1
+
+	mov.l	r10,@-r15
+	and	r2,r3		!Exponent of op2 in r3
+
+	! Check for Nan or Infinity
+	mov.l	.L_sign,r9
+	cmp/eq	r2,r1
+
+	mov	r9,r10
+	bt	.L_thread_inv_exp_op1
+
+	mov	r9,r0
+	cmp/eq	r2,r3
+! op1 has a valid exponent. We need not check it again.
+! Return op2 straight away.
+	and	r4,r9		!r9 has sign bit for op1
+	bt	.L_ret_op2
+
+	! Check for -ve zero
+	cmp/eq	r4,r0
+	and	r6,r10		!r10 has sign bit for op2
+
+	bt	.L_op1_nzero
+
+	cmp/eq	r6,r0
+	bt	.L_op2_nzero
+
+! Check for zero
+.L_non_zero:
+	tst	r4,r4
+	bt	.L_op1_zero
+
+	! op1 is not zero, check op2 for zero
+	tst	r6,r6
+	bt	.L_op2_zero
+
+! r1 and r3 has masked out exponents, r9 and r10 has signs
+.L_add:
+	mov.l	.L_high_mant,r8
+	mov	#-20,r2
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r2,r1		! r1 now has exponent for op1 in its lower bits
+#else
+	SHLR20 (r1)
+#endif
+	and	r8,r6	! Higher bits of mantissa of op2
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r2,r3		! r3 has exponent for op2 in its lower bits
+#else
+	SHLR20 (r3)
+#endif
+	and	r8,r4	! Higher bits of mantissa of op1
+
+	mov.l	.L_21bit,r8
+
+	tst	r1,r1
+	bt	.L_norm_op1
+
+	! Set the 21st bit.
+	or	r8,r4
+	tst	r3,r3
+
+	bt	.L_norm_op2
+	or	r8,r6
+
+! Check for negative mantissas. Make them positive by negation
+! r9 and r10 have signs of op1 and op2 respectively
+.L_neg_mant:
+	tst	r9,r9
+	bf	.L_neg_op1
+
+	tst	r10,r10
+	bf	.L_neg_op2
+
+.L_add_1:
+	cmp/ge	r1,r3
+
+	mov	r1,r0
+	bt	.L_op2_exp_greater
+
+	sub	r3,r0
+	! If exponent difference is greater than 54, the resultant exponent
+	! won't be changed. Return op1 straight away.
+	mov	#54,r2
+	cmp/gt	r2,r0
+
+	bt	.L_pack_op1
+
+	mov	r1,r3
+	clrt
+
+	cmp/eq	#0,r0
+	bt	.L_add_mant
+
+	! Shift left the first operand and apply rest of shifts to second operand.
+	mov	#0,r2
+	shll	r5
+
+	rotcl	r4
+
+	add	#-1,r3
+	dt	r0
+
+	bt	.L_add_mant
+	dt	r0
+
+	bt	LOCAL(got_guard)
+	dt	r0
+
+	bt	LOCAL(got_sticky)
+
+! Shift the mantissa part of op2 so that both exponents are equal
+.L_shfrac_op2:
+	shar	r6
+	or	r7,r2	! sticky bit
+
+	rotcr	r7
+	dt	r0
+
+	bf	.L_shfrac_op2
+
+	shlr	r2
+
+	subc	r2,r2	! spread sticky bit across r2
+LOCAL(got_sticky):
+	shar	r6
+
+	rotcr	r7
+
+	rotcr	r2
+LOCAL(got_guard):
+	shar	r6
+
+	rotcr	r7
+
+	rotcr	r2
+
+
+! Add the psotive mantissas and check for overflow by checking the
+! MSB of the resultant. In case of overflow, negate the result.
+.L_add_mant:
+	clrt
+	addc	r7,r5
+
+	mov	#0,r10	! Assume resultant to be positive
+	addc	r6,r4
+
+	cmp/pz	r4
+
+	bt	.L_mant_ptv
+	negc	r2,r2
+
+	negc	r5,r5
+
+	mov.l	.L_sign,r10 ! The assumption was wrong, result is negative
+	negc	r4,r4
+
+! 23rd bit in the high part of mantissa could be set.
+! In this case, right shift the mantissa.
+.L_mant_ptv:
+	mov.l	.L_23bit,r0
+
+	tst	r4,r0
+	bt	.L_mant_ptv_0
+
+	shlr	r4
+	rotcr	r5
+
+	add	#1,r3
+	bra	.L_mant_ptv_1
+	rotcr	r2
+
+.L_mant_ptv_0:
+	mov.l	.L_22bit,r0
+	tst	r4,r0
+
+	bt	.L_norm_mant
+
+.L_mant_ptv_1:
+	! 22 bit of resultant mantissa is set. Shift right the mantissa
+	! and add 1 to exponent
+	add	#1,r3
+	shlr	r4
+	rotcr	r5
+	! The mantissa is already normalized. We don't need to
+	! spend any effort. Branch to epilogue. 
+	bra	.L_epil
+	rotcr	r2
+
+! Normalize operands
+.L_norm_op1:
+	shll	r5
+
+	rotcl	r4
+	add	#-1,r1
+
+	tst	r4,r8
+	bt	.L_norm_op1
+
+	tst	r3,r3
+	SL(bf,	.L_neg_mant,
+	 add	#1,r1)
+
+.L_norm_op2:
+	shll	r7
+
+	rotcl	r6
+	add	#-1,r3
+
+	tst	r6,r8
+	bt	.L_norm_op2
+
+	bra	.L_neg_mant
+	add	#1,r3
+
+! Negate the mantissa of op1
+.L_neg_op1:
+	clrt
+	negc	r5,r5
+
+	negc	r4,r4
+	tst	r10,r10
+
+	bt	.L_add_1
+
+! Negate the mantissa of op2
+.L_neg_op2:
+	clrt
+	negc	r7,r7
+
+	bra	.L_add_1
+	negc	r6,r6
+
+! Thread the jump to .L_inv_exp_op1
+.L_thread_inv_exp_op1:
+	bra	.L_inv_exp_op1
+	nop
+
+.L_ret_op2:
+	mov.l	@r15+,r10
+#ifdef	__LITTLE_ENDIAN__
+	mov	r6,r1
+#else
+	mov	r6,r0
+#endif
+
+	mov.l	@r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r7,r0
+#else
+	mov	r7,r1
+#endif
+
+	rts
+	mov.l	@r15+,r8
+
+.L_op1_nzero:
+	tst	r5,r5
+	bt	.L_ret_op2
+
+	! op1 is not zero. Check op2 for negative zero
+	cmp/eq	r6,r0
+	bf	.L_non_zero	! both op1 and op2 are not -0
+
+.L_op2_nzero:
+	tst	r7,r7
+	bf	.L_non_zero
+
+	mov.l	@r15+,r10
+#ifdef	__LITTLE_ENDIAN__
+	mov	r4,r1
+#else
+	mov	r4,r0	! op2 is -0, return op1
+#endif
+
+	mov.l	@r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r5,r0
+#else
+	mov	r5,r1
+#endif
+
+	rts
+	mov.l	@r15+,r8
+
+! High bit of op1 is known to be zero.
+! Check low bit. r2 contains 0x00000000
+.L_op1_zero:
+	tst	r5,r5
+	bt	.L_ret_op2
+
+	! op1 is not zero. Check high bit of op2
+	tst	r6,r6
+	bf	.L_add	! both op1 and op2 are not zero
+
+! op1 is not zero. High bit of op2 is known to be zero.
+! Check low bit of op2. r2 contains 0x00000000
+.L_op2_zero:
+	tst	r7,r7
+	bf	.L_add
+
+	mov.l	@r15+,r10
+#ifdef	__LITTLE_ENDIAN__
+	mov	r4,r1
+#else
+	mov	r4,r0	! op2 is zero, return op1
+#endif
+
+	mov.l	@r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r5,r0
+#else
+	mov	r5,r1
+#endif
+
+	rts
+	mov.l	@r15+,r8
+
+! exp (op1) is smaller or equal to exp (op2)
+! The logic of same operations is present in .L_add. Kindly refer it for
+! comments
+.L_op2_exp_greater:
+	mov	r3,r0
+	sub	r1,r0
+
+	mov	#54,r2
+	cmp/gt	r2,r0
+
+	bt	.L_pack_op2
+
+	cmp/eq	#0,r0
+	bt	.L_add_mant
+
+	mov	#0,r2
+	shll	r7
+	rotcl	r6
+	add	#-1,r0
+	add	#-1,r3
+
+	cmp/eq	#0,r0
+	bt	.L_add_mant
+.L_shfrac_op1:	
+        add     #-1,r0
+        shar    r4
+
+	rotcr	r5
+	rotcr	r2
+
+        cmp/eq  #0,r0
+        bf      .L_shfrac_op1
+
+	bra	.L_add_mant
+	nop
+
+! Return the value in op1
+.L_ret_op1:
+        mov.l   @r15+,r10
+#ifdef	__LITTLE_ENDIAN__
+	mov	r4,r1
+#else
+        mov     r4,r0
+#endif
+
+        mov.l   @r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r5,r0
+#else
+        mov     r5,r1
+#endif
+
+        rts
+        mov.l   @r15+,r8
+
+! r1 has exp, r9 has sign, r4 and r5 mantissa
+.L_pack_op1:
+	mov.l	.L_high_mant,r7
+	mov	r4,r0
+
+	tst	r9,r9
+	bt	.L_pack_op1_1
+
+	clrt
+	negc	r5,r5
+	negc	r0,r0
+
+.L_pack_op1_1:
+	and	r7,r0
+	mov	r1,r3
+
+	mov	#20,r2
+	mov	r5,r1
+
+	mov.l	@r15+,r10
+	or	r9,r0
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r2,r3
+#else
+	SHLL20 (r3)
+#endif
+	mov.l	@r15+,r9
+
+	or	r3,r0
+#ifdef	__LITTLE_ENDIAN__
+	mov	r0,r2
+	mov	r1,r0
+	mov	r2,r1
+#endif
+	rts
+	mov.l	@r15+,r8
+
+!r2 has exp, r10 has sign, r6 and r7 mantissa
+.L_pack_op2:
+	mov.l	.L_high_mant,r9
+	mov	r6,r0
+
+	tst	r10,r10
+	bt	.L_pack_op2_1
+
+	clrt
+	negc	r7,r7
+	negc	r0,r0
+
+.L_pack_op2_1:
+	and	r9,r0
+	mov	r7,r1
+
+	mov	#20,r2
+	or	r10,r0
+
+	mov.l	@r15+,r10
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r2,r3
+#else
+	SHLL20 (r3)
+#endif
+
+	mov.l	@r15+,r9
+
+	or	r3,r0
+#ifdef	__LITTLE_ENDIAN__
+	mov	r0,r2
+	mov	r1,r0
+	mov	r2,r1
+#endif
+	rts
+	mov.l	@r15+,r8
+
+! Normalize the mantissa by setting its 21 bit in high part
+.L_norm_mant:
+	mov.l	.L_21bit,r0
+
+	tst	r4,r0
+	bf	.L_epil
+
+	tst	r4,r4
+	bf	.L_shift_till_1
+
+	tst	r5,r5
+	bf	.L_shift_till_1
+
+	! Mantissa is zero, return 0
+	mov.l	@r15+,r10
+	mov	#0,r0
+
+	mov.l	@r15+,r9
+	mov.l	@r15+,r8
+
+	rts
+	mov	#0,r1
+
+! A loop for making the 21st bit 1 in high part of resultant mantissa
+! It is already ensured that 1 bit is present in the mantissa
+.L_shift_till_1:
+	clrt
+	shll	r5
+
+	rotcl	r4
+	add	#-1,r3
+
+	tst	r4,r0
+	bt	.L_shift_till_1
+
+! Return the result. Mantissa is in r4-r5. Exponent is in r3
+! Sign bit in r10
+.L_epil:
+	cmp/pl	r3
+
+	bf	.L_denorm
+	mov.l	LOCAL(x7fffffff),r0
+
+	mov	r5,r1
+	shlr	r1
+
+	mov	#0,r1
+	addc	r0,r2
+
+! Check extra MSB here
+	mov.l	.L_22bit,r9
+	addc	r1,r5	! round to even
+
+	addc	r1,r4
+	tst	r9,r4
+
+	bf	.L_epil_1
+
+.L_epil_0:
+	mov.l	.L_21bit,r1
+
+	not	r1,r1
+	and	r1,r4
+
+	mov	r4,r0
+	or	r10,r0
+
+	mov.l	@r15+,r10
+	mov	#20,r2
+
+	mov.l	@r15+,r9
+	mov	r5,r1
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r2,r3
+#else
+	SHLL20 (r3)
+#endif
+	or	r3,r0
+
+#ifdef	__LITTLE_ENDIAN__
+	mov	r0,r2
+	mov	r1,r0
+	mov	r2,r1
+#endif
+	rts
+	mov.l	@r15+,r8
+
+.L_epil_1:
+	shlr	r4
+	add	#1,r3
+	bra	.L_epil_0
+	rotcr	r5
+
+.L_denorm:
+	add	#-1,r3
+.L_denorm_1:
+	tst	r3,r3
+	bt	.L_denorm_2
+
+	shlr	r4
+	rotcr	r5
+
+	movt	r1
+	bra	.L_denorm_1
+	add	#1,r3
+
+.L_denorm_2:
+	clrt
+	mov	#0,r2
+	addc	r1,r5
+
+	addc	r2,r4
+	mov	r4,r0
+
+	or	r10,r0
+	mov.l	@r15+,r10
+
+	mov	r5,r1
+
+	mov.l	@r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r0,r2
+	mov	r1,r0
+	mov	r2,r1
+#endif
+	rts
+	mov.l	@r15+,r8
+
+! op1 is known to be positive infinity, and op2 is Inf. The sign
+! of op2 is not known. Return the appropriate value
+.L_op1_pinf_op2_inf:
+	mov.l	.L_sign,r0
+	tst	r6,r0
+
+	bt	.L_ret_op2_1
+
+	! op2 is negative infinity. Inf - Inf is being performed
+	mov.l	.L_inf,r0
+	mov.l	@r15+,r10
+	mov.l	@r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r0,r1
+#endif
+	mov.l	@r15+,r8
+
+	rts
+#ifdef	__LITTLE_ENDIAN__
+	mov	#1,r0
+#else
+	mov	#1,r1	! Any value here will return Nan
+#endif
+	
+.L_ret_op1_1:
+        mov.l   @r15+,r10
+#ifdef	__LITTLE_ENDIAN__
+	mov	r4,r1
+#else
+        mov     r4,r0
+#endif
+
+        mov.l   @r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r5,r0
+#else
+        mov     r5,r1
+#endif
+
+        rts
+        mov.l   @r15+,r8
+
+.L_ret_op2_1:
+	mov.l	@r15+,r10
+#ifdef	__LITTLE_ENDIAN__
+	mov	r6,r1
+#else
+	mov	r6,r0
+#endif
+
+	mov.l	@r15+,r9
+#ifdef	__LITTLE_ENDIAN__
+	mov	r7,r0
+#else
+	mov	r7,r1
+#endif
+
+	rts
+	mov.l	@r15+,r8
+
+! op1 is negative infinity. Check op2 for infinity or Nan
+.L_op1_ninf:
+	cmp/eq	r2,r3
+	bf	.L_ret_op1_1	! op2 is neither Nan nor Inf
+
+	mov.l	@r15+,r9
+	div0s	r4,r6		! different signs -> NaN
+	mov	r4,DBLRH
+	or	r6,DBLRH
+	mov.l	@r15+,r8
+	SL(bf, 0f,
+	 mov	r5,DBLRL)
+	mov	#-1,DBLRH	! return NaN.
+0:	rts
+	or	r7,DBLRL
+
+!r1 contains exponent for op1, r3 contains exponent for op2
+!r2 has .L_inf (+ve Inf)
+!op1 has invalid exponent. Either it contains Nan or Inf
+.L_inv_exp_op1:
+	! Check if a is Nan
+	cmp/pl	r5
+	bt	.L_ret_op1_1
+
+	mov.l	.L_high_mant,r0
+	and	r4,r0
+
+	cmp/pl	r0
+	bt	.L_ret_op1_1
+
+	! op1 is not Nan. It is infinity. Check the sign of it.
+	! If op2 is Nan, return op2
+	cmp/pz	r4
+
+	bf	.L_op1_ninf
+
+	! op2 is +ve infinity here
+	cmp/eq	r2,r3
+	bf	.L_ret_op1_1	! op2 is neither Nan nor Inf
+
+	! r2 is free now
+	mov.l	.L_high_mant,r0
+	tst	r6,r0		! op2 also has invalid exponent
+
+	bf	.L_ret_op2_1	! op2 is Infinity, and op1 is +Infinity
+
+	tst	r7,r7
+	bt	.L_op1_pinf_op2_inf	! op2 is Infinity, and op1 is +Infinity
+	!op2 is not infinity, It is Nan
+	bf	.L_ret_op2_1
+
+	.align 2	
+.L_high_mant:
+	.long 0x000FFFFF
+
+.L_21bits:
+	.long 0x001FFFFF
+
+.L_22bit:
+	.long 0x00200000
+
+.L_23bit:
+	.long 0x00400000
+
+.L_21bit:
+	.long 0x00100000
+
+.L_sign:
+	.long 0x80000000
+
+.L_inf:
+	.long 0x7ff00000
+
+LOCAL(x7fffffff): .long 0x7fffffff
+
+ENDFUNC (GLOBAL (subdf3))
+ENDFUNC (GLOBAL (adddf3))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/addsf3.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/addsf3.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/addsf3.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/addsf3.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,535 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+! Add floating point numbers in r4, r5.
+
+! Author: Rakesh Kumar
+
+! Arguments are in r4, r5 and result in r0
+
+! Entry points: ___subsf3, ___addsf3
+
+! r4 and r5 are referred as op1 and op2
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+	.align 5
+        .global GLOBAL (subsf3)
+	.global	GLOBAL (addsf3)
+	FUNC (GLOBAL (subsf3))
+	FUNC (GLOBAL (addsf3))
+
+GLOBAL (subsf3):
+        mov.l   .L_sign_bit,r1
+        xor     r1,r5
+
+GLOBAL (addsf3):
+	mov.l	r8,@-r15
+	mov	r4,r3
+
+	mov.l	.L_pinf,r2
+	mov	#0,r8
+
+	and	r2,r3 ! op1's exponent.
+	mov	r5,r6
+
+	! Check NaN or Infinity
+	and	r2,r6 ! op2's exponent.
+	cmp/eq	r2,r3
+
+	! go if op1 is NaN or INF. 
+	mov.l	.L_sign_bit,r0
+	SL(bt,	.L_inv_op1,
+	 mov	#-23,r1)
+	
+	! Go if op2 is NaN/INF.
+	cmp/eq	r2,r6
+	mov	r0,r7
+	bt	.L_ret_op2
+
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLR23 (r3)
+#else
+	shld	r1,r3
+#endif
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLR23 (r6)
+#else
+	shld	r1,r6
+#endif
+
+	! Check for negative zero
+	cmp/eq	r0,r5
+
+	mov	r5,r1
+	SL(bt,	.L_ret_op1,
+	 and	r7,r1)
+
+	cmp/eq	r0,r4
+	bt	.L_ret_op2
+
+	! if op1 is zero return op2
+	tst	r4,r4
+	bt	.L_ret_op2
+
+	! Equal numbers with opposite sign
+	mov	r4,r2
+	xor	r5,r2
+
+	cmp/eq	r0,r2
+	bt	.L_ret_zero
+
+	! if op2 is zero return op1
+	mov.l	.L_mask_fra,r2
+	tst	r5,r5
+
+	! Extract the mantissa
+	mov	r4,r0
+	SL(bt,	.L_ret_op1,
+	 and	r2,r5)
+
+	and	r2,r4
+
+	mov.l	.L_imp_bit,r2
+	and	r7,r0	! sign bit of op1
+
+	! Check for denormals
+	tst	r3,r3
+	bt	.L_norm_op1
+
+	! Attach the implicit bit
+	or	r2,r4
+	tst	r6,r6
+
+	bt	.L_norm_op2
+
+	or	r2,r5
+	tst	r0,r0
+
+	! operands are +ve or -ve??
+	bt	.L_ptv_op1
+
+	neg	r4,r4
+
+.L_ptv_op1:
+	tst	r1,r1
+	bt	.L_ptv_op2
+
+	neg	r5,r5
+
+! Test exponents for equality
+.L_ptv_op2:
+	cmp/eq	r3,r6
+	bt	.L_exp_eq
+
+! Make exponents of two arguments equal
+.L_exp_ne:
+	! r0, r1 contain sign bits.
+	! r4, r5 contain mantissas.
+	! r3, r6 contain exponents.
+	! r2, r7 scratch.
+
+	! Calculate result exponent.
+	mov	r6,r2
+	sub	r3,r2	! e2 - e1
+
+	cmp/pl	r2
+	mov	#23,r7
+
+	! e2 - e1 is -ve
+	bf	.L_exp_ne_1
+
+	mov	r6,r3 ! Result exp.
+	cmp/gt	r7,r2 ! e2-e1 > 23
+
+	mov	#1,r7
+	bt	.L_pack_op2_0
+
+	! Align the mantissa
+.L_loop_ne:
+	shar	r4
+
+	rotcr	r8
+	cmp/eq	r7,r2
+
+	add	#-1,r2
+	bf	.L_loop_ne
+
+	bt	.L_exp_eq
+
+! Exponent difference is too high.
+! Return op2 after placing pieces in proper place
+.L_pack_op2_0:
+	! If op1 is -ve
+	tst	r1,r1
+	bt	.L_pack_op2
+
+	neg	r5,r5
+
+! r6 has exponent
+! r5 has mantissa, r1 has sign
+.L_pack_op2:
+	mov.l	.L_nimp_bit,r2
+	mov	#23,r3
+
+	mov	r1,r0
+	
+	and	r2,r5
+	mov.l	@r15+,r8
+
+	or	r5,r0
+
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLL23 (r6)
+#else
+	shld	r3,r6
+#endif
+        rts
+	or	r6,r0
+
+! return op1. It is NAN or INF or op2 is zero.
+.L_ret_op1:
+	mov	r4,r0
+
+	rts
+	mov.l	@r15+,r8
+
+! return zero
+.L_ret_zero:
+	mov	#0,r0
+
+	rts
+	mov.l	@r15+,r8
+
+! return op2. It is NaN or INF or op1 is zero.
+.L_ret_op2:
+	mov	r5,r0
+
+	rts
+	mov.l	@r15+,r8
+
+! op2 is denormal. Normalize it.
+.L_norm_op2:
+	shll	r5
+	add	#-1,r6
+
+	tst	r2,r5
+	bt	.L_norm_op2
+
+	! Check sign
+	tst	r1,r1
+	bt	.L_norm_op2_2
+
+	neg	r5,r5
+
+.L_norm_op2_2:
+	add	#1,r6
+	cmp/eq	r3,r6
+
+	bf	.L_exp_ne
+	bt	.L_exp_eq
+
+! Normalize op1
+.L_norm_op1:
+	shll	r4
+	add	#-1,r3
+
+	tst	r2,r4
+	bt	.L_norm_op1
+
+	! Check sign
+	tst	r0,r0
+	bt	.L_norm_op1_1
+
+	neg	r4,r4
+
+.L_norm_op1_1:
+	! Adjust biasing
+	add	#1,r3
+
+	! Check op2 for denormalized value
+	tst	r6,r6
+	bt	.L_norm_op2
+
+	mov.l	.L_imp_bit,r2
+
+	tst	r1,r1	! Check sign
+	or	r2,r5	! Attach 24th bit
+
+	bt	.L_norm_op1_2
+
+	neg	r5,r5
+
+.L_norm_op1_2:
+	cmp/eq	r3,r6
+
+	bt	.L_exp_eq
+	bf	.L_exp_ne
+
+! op1 is NaN or Inf
+.L_inv_op1:
+	! Return op1 if it is NAN. 
+	! r2 is infinity
+	cmp/gt	r2,r4
+	bt	.L_ret_op1
+
+	! op1 is +/- INF
+	! If op2 is same return now.
+	cmp/eq	r4,r5
+	bt	.L_ret_op1
+
+	! return op2 if it is NAN
+	cmp/gt	r2,r5
+	bt	.L_ret_op2
+
+	! Check if op2 is inf
+	cmp/eq	r2,r6
+	bf	.L_ret_op1
+	
+	! Both op1 and op2 are infinities 
+	!of opp signs, or there is -NAN. Return a NAN.
+	mov.l	@r15+,r8
+	rts
+	mov	#-1,r0
+
+! Make unequal exponents equal.
+.L_exp_ne_1:
+	mov	#-25,r7
+	cmp/gt	r2,r7 ! -23 > e2 - e1
+
+	add	#1,r2
+	bf	.L_exp_ne_2
+
+	tst	r0,r0
+	bt	.L_pack_op1
+
+.L_pack_op1_0:
+	bra	.L_pack_op1
+	neg	r4,r4
+
+! Accumulate the shifted bits in r8
+.L_exp_ne_2:
+	! Shift with rounding
+	shar	r5
+	rotcr	r8
+
+	tst	r2,r2
+
+	add	#1,r2
+	bf	.L_exp_ne_2
+
+! Exponents of op1 and op2 are equal (or made so)
+! The mantissas are in r4-r5 and remaining bits in r8
+.L_exp_eq:
+	add	r5,r4 ! Add fractions.
+	mov.l	.L_sign_bit,r2
+
+	! Check for negative result
+	mov	#0,r0
+	tst	r2,r4
+
+	mov.l	.L_255,r5
+	bt	.L_post_add
+
+	negc	r8,r8
+	negc	r4,r4
+	or	r2,r0
+
+.L_post_add:
+	! Check for extra MSB
+	mov.l	.L_chk_25,r2
+
+	tst	r2,r4
+	bt	.L_imp_check
+
+	shar 	r4
+	rotcr	r8
+
+	add	#1,r3
+	cmp/ge	r5,r3
+
+	! Return Inf if exp > 254
+	bt	.L_ret_inf
+
+! Check for implicit (24th) bit in result
+.L_imp_check:
+        mov.l	.L_imp_bit,r2
+	tst	r2,r4
+
+	bf	.L_pack_op1
+
+! Result needs left shift
+.L_lft_shft:
+	shll	r8
+	rotcl	r4
+
+	add	#-1,r3
+	tst	r2,r4
+
+	bt	.L_lft_shft
+	
+! Pack the result after rounding
+.L_pack_op1:
+	! See if denormalized result is possible 
+	mov.l	.L_chk_25,r5
+	cmp/pl	r3
+
+	bf	.L_denorm_res
+
+	! Are there any bits shifted previously?
+	tst	r8,r8
+	bt	.L_pack_1
+
+	! Round
+	shll	r8
+	movt	r6
+
+	add	r6,r4
+
+	! If we are halfway between two numbers,
+	! round towards LSB = 0
+	tst	r8,r8
+
+	bf	.L_pack_1
+
+	shlr	r4
+	shll	r4
+
+.L_pack_1:
+	! Adjust extra MSB generated after rounding
+	tst	r4,r5
+	mov.l	.L_255,r2
+
+	bt	.L_pack_2
+	shar	r4
+
+	add	#1,r3 
+	cmp/ge	r2,r3	! Check for exp overflow
+
+	bt	.L_ret_inf
+	
+! Pack it finally
+.L_pack_2:
+	! Do not store implicit bit
+	mov.l	.L_nimp_bit,r2
+	mov	#23,r1
+
+	and	r2,r4
+
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLL23 (r3)
+#else
+	shld	r1,r3
+#endif
+	mov.l	@r15+,r8
+
+	or	r4,r0
+        rts
+	or	r3,r0
+
+! Return infinity
+.L_ret_inf:
+	mov.l	.L_pinf,r2
+
+	mov.l	@r15+,r8
+	rts
+	or	r2,r0
+
+! Result must be denormalized
+.L_denorm_res:
+	mov	#0,r2
+	
+! Denormalizing loop with rounding
+.L_den_1:
+	shar	r4
+	movt	r6
+
+	tst	r3,r3
+	bt	.L_den_2
+
+	! Increment the exponent
+	add	#1,r3
+
+	tst	r6,r6
+	bt	.L_den_0
+
+	! Count number of ON bits shifted
+	add	#1,r2
+
+.L_den_0:
+	bra	.L_den_1
+	nop
+
+! Apply rounding
+.L_den_2:
+	cmp/eq	r6,r1
+	bf	.L_den_3
+
+	add	r6,r4
+	mov	#1,r1
+
+	! If halfway between two numbers,
+	! round towards LSB = 0
+	cmp/eq	r2,r1
+	bf	.L_den_3
+
+	shar	r4
+	shll	r4
+
+.L_den_3:
+
+	mov.l	@r15+,r8
+	rts
+	or	r4,r0
+	
+	.align 2
+.L_imp_bit:
+        .long   0x00800000
+
+.L_nimp_bit:
+	.long	0xFF7FFFFF
+
+.L_mask_fra:
+        .long   0x007FFFFF
+
+.L_pinf:
+        .long   0x7F800000
+
+.L_sign_bit:
+	.long	0x80000000
+
+.L_bit_25:
+	.long	0x01000000
+
+.L_chk_25:
+        .long   0x7F000000
+
+.L_255:
+	.long	0x000000FF
+
+ENDFUNC (GLOBAL (addsf3))
+ENDFUNC (GLOBAL (subsf3))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/divdf3.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/divdf3.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/divdf3.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/divdf3.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,598 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+!division of two double precision floating point numbers
+!Author:Aanchal Khanna
+!
+!Entry:
+!r4,r5:dividend
+!
+!r6,r7:divisor
+!
+!Exit:
+!r0,r1:quotient
+
+!Notes: dividend is passed in regs r4 and r5 and divisor is passed in regs 
+!r6 and r7, quotient is returned in regs r0 and r1. dividend is referred as op1
+!and divisor as op2.
+!
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+	.align	5
+	.global	GLOBAL (divdf3)
+	FUNC (GLOBAL (divdf3))
+
+GLOBAL (divdf3):
+
+#ifdef  __LITTLE_ENDIAN__
+	mov	r4,r1
+	mov	r5,r4
+	mov	r1,r5
+
+        mov     r6,r1
+        mov     r7,r6
+        mov     r1,r7
+#endif
+	mov	r4,r2
+	mov.l	.L_inf,r1
+
+	and	r1,r2
+	mov.l   r8,@-r15
+
+	cmp/eq	r1,r2
+	mov     r6,r8
+
+	bt	.L_a_inv
+	and	r1,r8
+
+	cmp/eq	r1,r8
+	mov.l	.L_high_mant,r3
+
+	bf	.L_chk_zero
+	and	r6,r3
+
+	mov.l   .L_mask_sign,r8	
+	cmp/pl	r7
+
+	mov	r8,r0
+	bt	.L_ret_b	!op2=NaN,return op2
+
+	and	r4,r8
+	cmp/pl	r3
+
+	and	r6,r0
+	bt	.L_ret_b	!op2=NaN,return op2
+
+	xor     r8,r0           !op1=normal no,op2=Inf, return Zero
+	mov     #0,r1
+	
+#ifdef __LITTLE_ENDIAN__
+	mov	r0,r2
+	mov	r1,r0
+	mov	r2,r1
+#endif
+	rts
+	mov.l   @r15+,r8
+
+.L_ret_b:
+	mov	r7,r1
+	mov     r6,r0
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+
+	rts
+	mov.l   @r15+,r8
+
+.L_a_inv:
+	!chk if op1 is Inf or NaN
+	mov.l   .L_high_mant,r2
+	cmp/pl  r5
+
+	and	r4,r2
+	bt	.L_ret_a
+
+	and	r1,r8		!r1 contains infinity
+	cmp/pl	r2
+
+	bt	.L_ret_a
+	cmp/eq	r1,r8
+
+	mov	r1,DBLRH
+	add	DBLRH,DBLRH
+	bf	0f
+	mov	#-1,DBLRH	! Inf/Inf, return NaN.
+0:	div0s	r4,r6
+	mov.l   @r15+,r8	
+	rts
+	rotcr	DBLRH
+
+.L_ret_a:
+	!return op1
+	mov	r5,r1
+	mov	r4,r0
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+        mov.l   @r15+,r8
+
+.L_chk_zero:
+	!chk if op1=0
+	mov.l   .L_mask_sign,r0
+        mov     r4,r3
+
+        and     r0,r3
+        shll    r4
+
+        and     r6,r0
+        shlr    r4
+
+        xor     r3,r0
+        shll    r6
+
+	shlr	r6
+	tst	r4,r4
+
+
+	bf      .L_op1_not_zero	
+	tst	r5,r5
+	
+        bf      .L_op1_not_zero
+	tst	r7,r7
+
+	mov.l   @r15+,r8
+	bf	.L_ret_zero
+
+	tst	r6,r6
+	bf	.L_ret_zero
+
+	rts
+	mov     #-1,DBLRH       !op1=op2=0, return NaN
+	
+.L_ret_zero:
+	!return zero
+	mov	r0,r1
+	rts
+#ifdef __LITTLE__ENDIAN
+	mov	#0,r0
+#else
+	mov	#0,r1		!op1=0,op2=normal no,return zero
+#endif
+
+.L_norm_b:
+	!normalize op2
+        shll    r7
+        mov.l   .L_imp_bit,r3
+
+        rotcl   r6
+        tst     r3,r6
+
+        add     #-1,r8
+        bt      .L_norm_b
+
+        bra     .L_divide
+        add     #1,r8
+
+.L_op1_not_zero:
+	!op1!=0, chk if op2=0
+	tst	r7,r7	
+	mov	r1,r3
+	
+	mov	#0,r1
+	bf	.L_normal_nos
+
+	tst	r6,r6
+	bf      .L_normal_nos
+
+	mov.l   @r15+,r8
+	or	r3,r0
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+
+	rts
+	nop
+
+.L_normal_nos:
+	!op1 and op2 are normal nos
+	tst	r2,r2
+	mov	#-20,r1
+
+! The subsequent branch is for the upper compare
+! Shifting will not alter the result, for the
+! macro is declared with care.
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld    r1,r2
+#else
+	SHLR20 (r2)
+#endif
+	bt	.L_norm_a	!normalize dividend
+	
+.L_chk_b:
+	mov.l	r9,@-r15
+	tst	r8,r8
+
+        mov.l   .L_high_mant,r9
+
+! The subsequent branch is for the upper compare
+! Shifting will not alter the result, for the
+! macro is declared with care.
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r1,r8
+#else
+        SHLR20 (r8)
+#endif
+				! T set -> normalize divisor
+	SL(bt,	.L_norm_b,
+	 and	r9,r4)
+
+.L_divide:
+	mov.l   .L_2047,r1
+	sub	r8,r2
+
+	mov.l	.L_1023,r8
+	and	r9,r6
+
+	!resultant exponent
+	add	r8,r2
+	!chk the exponent for overflow
+	cmp/ge	r1,r2
+	
+	mov.l	.L_imp_bit,r1
+	bt	.L_overflow
+	
+	mov	#0,r8
+	or	r1,r4
+	
+	or      r1,r6	
+	mov	#-24,r3
+
+	!chk if the divisor is 1(mantissa only)
+	cmp/eq	r8,r7
+	bf	.L_div2
+
+	cmp/eq	 r6,r1
+	bt	.L_den_one
+
+.L_div2:
+	!divide the mantissas
+	shll8	r4
+	mov	r5,r9
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r3,r9
+#else
+        SHLR24 (r9)
+#endif
+	shll8	r6
+
+	or	r9,r4
+	shll8   r5
+
+	mov	r7,r9
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r3,r9
+#else
+        SHLR24 (r9)
+#endif
+	mov	r8,r3
+	shll8	r7
+
+	or	r9,r6	
+	cmp/gt	r4,r6
+
+	mov	r3,r9
+	bt	.L_shift
+
+	cmp/eq	r4,r6
+	bf	.L_loop
+
+	cmp/gt	r5,r7
+	bf	.L_loop
+
+.L_shift:
+	add	#-1,r2
+	shll	r5
+	rotcl	r4
+
+.L_loop:
+	!actual division loop
+	cmp/gt	r6,r4
+	bt	.L_subtract
+
+	cmp/eq	r6,r4
+	bf	.L_skip
+
+	cmp/ge	r7,r5
+	bf	.L_skip
+
+.L_subtract:
+	clrt
+	subc	r7,r5
+	
+	or	r1,r8
+	subc	r6,r4
+
+.L_skip:
+	shlr	r1
+	shll	r5
+
+	rotcl	r4
+	cmp/eq	r1,r3
+
+	bf	.L_loop
+	mov.l	.L_imp_bit,r1
+
+	!chk if the divison was for the higher word of the quotient
+	tst	r1,r9
+	bf	.L_chk_exp
+
+	mov	r8,r9
+	mov.l   .L_mask_sign,r1
+
+	!divide for the lower word of the quotient
+	bra	.L_loop
+	mov	r3,r8
+
+.L_chk_exp:
+	!chk if the result needs to be denormalized
+	cmp/gt	r2,r3
+	bf	.L_round
+	mov     #-53,r7
+
+.L_underflow:
+	!denormalize the result
+	add	#1,r2
+	cmp/gt	r2,r7
+
+	or      r4,r5           !remainder
+	add	#-2,r2
+
+	mov	#32,r4
+	bt      .L_return_zero
+
+	add	r2,r4
+	cmp/ge	r3,r4
+
+	mov	r2,r7
+	mov	r3,r1
+
+	mov     #-54,r2
+	bt	.L_denorm
+	mov	#-32,r7
+
+.L_denorm:
+	shlr	r8
+	rotcr	r1
+
+	shll	r8
+	add     #1,r7
+
+	shlr	r9
+	rotcr	r8
+
+	cmp/eq	r3,r7
+	bf	.L_denorm
+
+	mov	r4,r7
+	cmp/eq	r2,r4
+
+	bt	.L_break
+	mov     r3,r6
+
+	cmp/gt	r7,r3
+	bf	.L_break
+
+	mov	r2,r4
+	mov	r1,r6
+
+	mov	r3,r1
+	bt	.L_denorm
+
+.L_break:
+	mov     #0,r2
+
+	cmp/gt	r1,r2
+
+	addc	r2,r8
+	mov.l   .L_comp_1,r4
+
+	addc	r3,r9		
+	or	r9,r0
+
+	cmp/eq	r5,r3
+	bf	.L_return	
+
+	cmp/eq	r3,r6
+	mov.l	.L_mask_sign,r7
+
+	bf	.L_return
+	cmp/eq	r7,r1
+
+	bf	.L_return
+	and	r4,r8
+
+.L_return:
+	mov.l	@r15+,r9
+	mov     r8,r1
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	mov.l   @r15+,r8
+
+.L_norm_a:
+        !normalize op1
+        shll    r5
+        mov.l   .L_imp_bit,r3
+
+        rotcl   r4
+        tst     r3,r4
+
+        add     #-1,r2
+        bt      .L_norm_a
+
+        bra     .L_chk_b
+        add     #1,r2
+
+.L_overflow:
+	!overflow, return inf
+	mov.l   .L_inf,r2
+#ifdef __LITTLE_ENDIAN__
+	or	r2,r1	
+	mov	#0,r0
+#else
+	or	r2,r0
+	mov	#0,r1
+#endif
+        mov.l   @r15+,r9
+        rts
+        mov.l   @r15+,r8
+
+.L_den_one:
+	!denominator=1, result=numerator
+        mov     r4,r9
+        mov   	#-53,r7
+
+	cmp/ge	r2,r8
+	mov	r8,r4
+
+	mov	r5,r8
+	mov	r4,r3
+
+	!chk the exponent for underflow
+	SL(bt,	.L_underflow,
+	 mov     r4,r5)
+
+	mov.l	.L_high_mant,r7
+        bra     .L_pack
+	mov     #20,r6
+
+.L_return_zero:
+	!return zero
+	mov	r3,r1
+	mov.l	@r15+,r9
+
+	rts
+	mov.l   @r15+,r8
+
+.L_round:
+	!apply rounding
+	cmp/eq	r4,r6
+	bt	.L_lower
+
+	clrt
+	subc    r6,r4
+
+	bra     .L_rounding
+	mov	r4,r6
+	
+.L_lower:
+	clrt
+	subc	r7,r5
+	mov	r5,r6
+	
+.L_rounding:
+	!apply rounding
+	mov.l   .L_invert,r1
+	mov	r3,r4
+
+	movt	r3
+	clrt
+	
+	not	r3,r3
+	and	r1,r3	
+
+	addc	r3,r8
+	mov.l   .L_high_mant,r7
+
+	addc	r4,r9
+	cmp/eq	r4,r6
+
+	mov.l   .L_comp_1,r3
+	SL (bf,	.L_pack,
+	 mov     #20,r6)
+	and	r3,r8
+
+.L_pack:
+	!pack the result, r2=exponent,r0=sign,r8=lower mantissa, r9=higher mantissa
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld    r6,r2
+#else
+        SHLL20 (r2)
+#endif
+	and	r7,r9
+
+	or	r2,r0
+	mov	r8,r1
+
+	or      r9,r0
+	mov.l	@r15+,r9
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	mov.l	@r15+,r8
+
+	.align	2
+
+.L_mask_sign:
+	.long	0x80000000
+.L_high_mant:
+	.long	0x000fffff
+.L_inf:
+	.long	0x7ff00000
+.L_1023:
+	.long	1023
+.L_2047:
+	.long	2047
+.L_imp_bit:
+	.long	0x00100000	
+.L_comp_1:
+	.long	0xfffffffe
+.L_invert:
+	.long	0x00000001
+
+ENDFUNC (GLOBAL (divdf3))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/divsf3.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/divsf3.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/divsf3.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/divsf3.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,404 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+!divides two single precision floating point 
+
+! Author: Aanchal Khanna
+
+! Arguments: Dividend is in r4, divisor in r5
+! Result: r0
+
+! r4 and r5 are referred as op1 and op2 resp.
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+	.align	5
+	.global	GLOBAL (divsf3)
+	FUNC (GLOBAL (divsf3))
+
+GLOBAL (divsf3):
+	mov.l	.L_mask_sign,r1
+	mov	r4,r3
+
+	xor	r5,r3
+	shll	r4
+
+	shlr	r4
+	mov.l	.L_inf,r2
+
+	and	r3,r1		!r1=resultant sign
+	mov	r4,r6
+
+	shll	r5
+	mov	#0,r0		
+
+	shlr	r5
+	and	r2,r6
+
+	cmp/eq	r2,r6
+	mov	r5,r7
+
+	and     r2,r7
+	bt	.L_op1_inv
+
+	cmp/eq	r2,r7
+	mov	#-23,r3
+
+	bt	.L_op2_inv
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLR23 (r6)
+	SHLR23 (r7)
+#else
+	shld	r3,r6
+	shld	r3,r7
+#endif
+
+	cmp/eq	r0,r4
+
+	bt	.L_op1_zero		!dividend=0
+	cmp/eq	r0,r6
+
+	mov.l   .L_imp_bit,r3
+	bt	.L_norm_op1		!normalize dividend
+.L_chk_op2:
+	cmp/eq	r0,r5
+	bt	.L_op2_zero		!divisor=0
+
+	cmp/eq	r0,r7
+	bt	.L_norm_op2		!normalize divisor
+
+.L_div1:
+	sub	r7,r6
+	add	#127,r6			!r6=resultant exponent
+
+	mov     r3,r7
+	mov.l	.L_mask_mant,r3
+
+	and	r3,r4
+	!chk exponent for overflow
+        mov.l   .L_255,r2
+
+	and     r3,r5
+	or	r7,r4
+
+	cmp/ge  r2,r6
+	or	r7,r5
+
+	bt	.L_return_inf
+	mov	r0,r2
+
+	cmp/eq  r4,r5
+	bf      .L_den_one
+
+	cmp/ge	r6,r0
+	!numerator=denominator, quotient=1, remainder=0
+	mov	r7,r2			
+
+	mov     r0,r4
+	!chk exponent for underflow
+	bt	.L_underflow
+        bra     .L_pack
+        nop
+
+.L_den_one:
+	!denominator=1, result=numerator
+
+	cmp/eq  r7,r5
+        bf      .L_divide
+
+	!chk exponent for underflow
+	cmp/ge  r6,r0
+        mov    r4,r2           
+
+        SL(bt,    .L_underflow,
+	 mov	r0,r4)
+	bra     .L_pack
+	nop
+
+.L_divide:
+	!dividing the mantissas r4<-dividend, r5<-divisor
+
+	cmp/hi	r4,r5
+	bf	.L_loop
+
+	shll	r4		! if mantissa(op1)< mantissa(op2)
+	add     #-1,r6		! shift left the numerator and decrease the exponent.
+
+.L_loop:
+	!division loop
+
+	cmp/ge	r5,r4
+	bf	.L_skip
+
+	or	r7,r2
+	sub	r5,r4
+
+.L_skip:
+	shlr	r7
+	shll	r4
+
+	cmp/eq	r0,r7
+	bf	.L_loop
+
+	!chk the exponent for underflow
+	cmp/ge  r6,r0
+	bt      .L_underflow
+	
+	!apply rounding
+	cmp/gt	r5,r4
+	bt	.L_round1
+
+	cmp/eq	r4,r5
+	bt	.L_round2
+
+.L_pack:
+	!pack the result, r1=sign, r2=quotient, r6=exponent
+
+	mov    #23,r4
+	and     r3,r2
+
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLL23 (r6)
+#else
+	shld	r4,r6
+#endif
+	or	r2,r1
+
+	or	r6,r1
+	mov	r1,r0	
+	
+	rts
+	nop
+
+.L_round1:
+	!Apply proper rounding
+
+        bra     .L_pack
+        add     #1,r2
+
+.L_round2:
+	!Apply proper rounding
+
+        mov.l   .L_comp_1,r5
+        bra     .L_pack
+        and     r5,r2
+
+.L_op1_inv:
+	!chk if op1 is Inf or NaN
+
+	mov.l	.L_mask_mant,r3
+	mov	r4,r6
+
+	and	r3,r6
+	cmp/hi	r0,r6
+
+	bt	.L_ret_op1
+	cmp/eq	r2,r7
+
+	SL(bf,	.L_ret_op1,
+	 mov	r1,r0)
+
+	rts
+	mov	#-1,r0	! 0/0, return NaN
+	
+.L_op2_inv:
+	!chk if op2 is Inf or NaN
+
+	mov.l	.L_mask_mant,r3
+	mov	r5,r7
+	
+	and	r3,r7
+	cmp/hi	r0,r7
+
+	bt	.L_ret_op2
+	mov	r1,r0
+	
+	rts
+	nop
+
+.L_op1_zero:
+	!op1 is zero. If op2 is zero, return NaN, else return zero
+
+	cmp/eq	r0,r5
+
+	bf	.L_ret_op1	
+
+	rts
+	mov	#-1,r0
+
+.L_op2_zero:
+	!B is zero,return Inf
+
+	rts
+	or	r2,r0
+
+.L_return_inf:
+	mov.l	.L_inf,r0
+	
+	rts
+	or	r1,r0
+
+.L_norm_op1:
+	!normalize dividend
+
+	shll	r4
+	tst	r2,r4
+	
+	add     #-1,r6
+	bt	.L_norm_op1
+
+	bra	.L_chk_op2
+	add	#1,r6
+
+.L_norm_op2:
+	!normalize divisor
+
+	shll	r5
+	tst	r2,r5
+	
+	add	#-1,r7
+	bt	.L_norm_op2
+
+	bra	.L_div1
+	add	#1,r7
+
+.L_underflow:
+	!denormalize the result
+
+	add	#1,r6
+	mov	#-24,r7
+
+	cmp/gt	r6,r7
+	mov	r2,r5
+
+	bt	.L_return_zero
+	add     #-1,r6
+
+	mov	#32,r3
+	neg	r6,r7
+
+	add	#1,r7
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r6,r2
+#else
+	cmp/ge	r0,r6
+	bf	.L_mov_right
+
+.L_mov_left:
+	cmp/eq	r0,r6
+	bt	.L_out
+
+	shll	r2
+	bra	.L_mov_left
+	add	#-1,r6
+
+.L_mov_right:
+	cmp/eq	r0,r6
+	bt	.L_out
+
+	add	#1,r6
+	bra	.L_mov_right
+	shlr	r2
+	
+.L_out:
+#endif
+	sub	r7,r3
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r3,r5
+#else
+	cmp/ge	r0,r3
+	bf	.L_mov_right_1
+
+.L_mov_left_1:
+	shll	r5
+	add	#-1,r3
+
+	cmp/eq	r0,r3
+	bf	.L_mov_left_1
+
+	bt	.L_out_1
+
+.L_mov_right_1:
+	cmp/eq	r0,r3
+	bt	.L_out_1
+
+	add	#1,r3
+	bra	.L_mov_right_1
+	shlr	r5
+
+.L_out_1:
+#endif
+	shlr	r2
+	addc	r0,r2
+
+	cmp/eq	r4,r0		!r4 contains the remainder
+	mov      r2,r0
+
+	mov.l	.L_mask_sign,r7
+	bf	.L_return
+
+	mov.l   .L_comp_1,r2
+	cmp/eq	r7,r5
+
+	bf	.L_return
+	and	r2,r0
+
+.L_return:
+	rts
+	or     r1,r0
+	
+.L_ret_op1:
+	rts
+	or	r4,r0
+
+.L_ret_op2:
+	rts
+	or	r5,r0
+
+.L_return_zero:
+	rts
+	or	r1,r0
+
+
+
+	.align	2
+.L_inf:
+	.long	0x7f800000
+.L_mask_sign:
+	.long	0x80000000
+.L_mask_mant:
+	.long	0x007fffff
+.L_imp_bit:
+	.long	0x00800000
+.L_comp_1:
+	.long	0xfffffffe
+.L_255:
+	.long	255
+
+ENDFUNC (GLOBAL (divsf3))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/fixdfsi.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/fixdfsi.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/fixdfsi.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/fixdfsi.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,200 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+!conversion of double precision floating point number to signed integer
+!Author:Aanchal Khanna
+!
+!Entry:
+!r4,r5:operand
+!
+!Exit:
+!r0:result
+!
+!Note:argument is passed in regs r4 and r5, the result is returned in
+!reg r0.
+!
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+	.align 	5
+	.global GLOBAL (fixdfsi)
+	FUNC (GLOBAL (fixdfsi))
+
+GLOBAL (fixdfsi):
+
+#ifdef  __LITTLE_ENDIAN__
+        mov     r4,r1
+        mov     r5,r4
+        mov     r1,r5
+
+#endif
+	mov.l	.L_p_inf,r2
+	mov     #-20,r1
+	
+	mov	r2,r7
+	mov.l   .L_1023,r3
+
+	and	r4,r2
+	shll    r4
+        
+	movt    r6		! r6 contains the sign bit
+	
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r1,r2		! r2 contains the exponent
+#else
+        SHLR20 (r2)
+#endif
+	 shlr    r4
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r1,r7
+#else
+        SHLR20 (r7)
+#endif
+	cmp/hi	r2,r3		! if exp < 1023,return 0
+	mov.l	.L_mask_high_mant,r1
+
+	SL(bt,	.L_epil,
+	 mov	#0,r0)
+	and	r4,r1		! r1 contains high mantissa
+
+	cmp/eq	r2,r7		! chk if exp is invalid
+	mov.l	.L_1053,r7
+
+	bt	.L_inv_exp
+	mov	#11,r0
+	
+	cmp/hi	r7,r2		! If exp > 1053,return maxint
+	sub     r2,r7
+
+	mov.l	.L_21bit,r2
+	SL(bt,	.L_ret_max,
+	 add	#1,r7)		! r7 contains the number of shifts
+
+	or	r2,r1
+	mov	r7,r3
+	shll8   r1
+
+	neg     r7,r7
+	shll2	r1
+
+        shll	r1
+	cmp/hi	r3,r0
+
+	!chk if the result can be made only from higher mantissa
+	SL(bt,	.L_lower_mantissa,
+	 mov	#21,r0)
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r7,r1
+#else
+.L_loop:
+        tst	r7,r7
+        bt      .L_break1
+        add     #1,r7
+        bra     .L_loop
+        shlr    r1
+
+.L_break1:
+#endif
+	tst	r6,r6
+	SL(bt,	.L_epil,
+	 mov	r1,r0)
+
+	rts
+	neg	r0,r0
+
+.L_lower_mantissa:
+	!result is made from lower mantissa also
+	neg	r0,r0
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r0,r5
+#else
+        SHLR21 (r5)
+#endif
+
+	or	r5,r1		!pack lower and higher mantissas
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r7,r1
+#else
+.L_sh_loop:
+	tst	r7,r7
+	bt	.L_break
+	add	#1,r7
+	bra	.L_sh_loop
+	shlr	r1
+
+.L_break:
+#endif
+	mov	r1,r0
+	bra	.L_chk_sign
+	nop
+
+.L_epil:
+	rts
+	nop
+
+.L_inv_exp:
+	cmp/hi	r0,r5
+	bt	.L_epil
+
+	cmp/hi	r0,r1		!compare high mantissa,r1
+	bt	.L_epil
+
+.L_ret_max:
+	mov.l   .L_maxint,r0
+	tst	r6,r6
+	bt	.L_epil
+
+	rts
+	add	#1,r0
+
+.L_chk_sign:
+	tst	r6,r6		!sign bit is set, number is -ve
+	bt	.L_epil
+	
+	rts
+	neg	r0,r0
+
+	.align	2
+
+.L_maxint:
+	.long	0x7fffffff
+.L_p_inf:
+	.long	0x7ff00000
+.L_mask_high_mant:
+	.long	0x000fffff
+.L_1023:
+	.long	0x000003ff
+.L_1053:
+	.long	1053
+.L_21bit:
+	.long	0x00100000
+
+ENDFUNC (GLOBAL (fixdfsi))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/fixsfsi.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/fixsfsi.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/fixsfsi.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/fixsfsi.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,165 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+! Conversion routine for float to integer
+
+! Author: Rakesh Kumar
+
+! Arguments: r4 (in floating point format)
+! Return: r0
+
+! r4 is referred as op1
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+	.align 5
+	.global	GLOBAL (fixsfsi)
+	FUNC (GLOBAL (fixsfsi))
+
+GLOBAL (fixsfsi):
+	mov.l	.L_mask_sign,r7
+	mov	r4,r2
+
+	! Check for NaN
+	mov.l	.L_inf,r1
+	and	r7,r2
+
+	cmp/gt	r1,r2
+	mov	#127,r5
+
+	mov	r4,r3
+	SL(bt,	.L_epil,
+	 mov	#0,r0)
+
+	shll	r2
+	mov.l	.L_frac,r6
+
+	shlr16	r2
+	and	r6,r3	! r3 has fraction
+
+	shlr8	r2	! r2 has exponent
+	mov.l	.L_24bit,r1
+
+	! If exponent is less than 127, return 0
+	cmp/gt	r2,r5
+	or	r1,r3	! Set the implicit bit
+
+	mov.l	.L_157,r1
+	SL1(bt,	.L_epil,
+	 shll8	r3)
+
+	! If exponent is greater than 157,
+	! return the maximum/minumum integer
+	! value deducing from sign
+	cmp/gt	r1,r2
+	sub	r2,r1
+
+	mov.l	.L_sign,r2
+	SL(bt,	.L_ret_max,
+	 add	#1,r1)
+
+	and	r4,r2	! Sign in r2
+	neg	r1,r1
+
+	! Shift mantissa by exponent difference from 157
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r1,r3
+#else
+        cmp/gt  r0,r1
+        bt      .L_mov_left
+
+.L_mov_right:
+        cmp/eq  r1,r0
+        bt      .L_ret
+
+        add     #1,r1
+        bra     .L_mov_right
+
+        shlr    r3
+
+.L_mov_left:
+        add     #-1,r1
+
+        shll    r3
+        cmp/eq  r1,r0
+
+        bf      .L_mov_left
+.L_ret:
+#endif
+	! If op1 is negative, negate the result
+	cmp/eq	r0,r2
+	SL(bf,	.L_negate,
+	 mov	r3,r0)
+
+! r0 has the appropriate value
+.L_epil:
+	rts
+	nop
+
+! Return the max/min integer value
+.L_ret_max:
+	and	r4,r2	! Sign in r2
+	mov.l	.L_max,r3
+
+	mov.l	.L_sign,r1
+	cmp/eq	r0,r2
+
+	mov	r3,r0
+	bt	.L_epil
+
+	! Negative number, return min int
+	rts
+	mov	r1,r0
+
+! Negate the result
+.L_negate:
+	rts
+	neg	r0,r0
+
+	.align 2
+.L_inf:
+	.long 0x7F800000
+
+.L_157:
+	.long 157
+
+.L_max:
+	.long 0x7FFFFFFF
+
+.L_frac:
+	.long 0x007FFFFF
+
+.L_sign:
+	.long 0x80000000
+
+.L_24bit:
+	.long 0x00800000
+
+.L_mask_sign:
+	.long 0x7FFFFFFF
+
+ENDFUNC (GLOBAL (fixsfsi))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/fixunsdfsi.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/fixunsdfsi.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/fixunsdfsi.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/fixunsdfsi.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,181 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+!conversion of double precision floating point number to unsigned integer
+!Author:Aanchal Khanna
+!
+!Entry:
+!r4,r5:operand
+!
+!Exit:
+!r0:result
+!
+!Note:argument is passed in regs r4 and r5, the result is returned in
+!reg r0.
+!
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+	.align 5
+	.global GLOBAL (fixunsdfsi)
+	FUNC (GLOBAL (fixunsdfsi))
+
+GLOBAL (fixunsdfsi):
+
+#ifdef  __LITTLE_ENDIAN__
+        mov     r4,r1
+        mov     r5,r4
+        mov     r1,r5
+#endif
+	mov.l	.L_p_inf,r2
+	mov     #-20,r1
+	
+	mov	r2,r7
+	mov.l   .L_1023,r3
+
+	and	r4,r2
+	shll    r4
+
+        movt    r6		! r6 contains the sign bit
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r1,r2           ! r2 contains the exponent
+#else
+        SHLR20 (r2)
+#endif
+	shlr    r4
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r1,r7
+#else
+        SHLR20 (r7)
+#endif
+	tst	r6,r6	
+	SL(bf,	.L_epil,
+	 mov	#0,r0)
+
+	cmp/hi	r2,r3		! if exp < 1023,return 0
+	mov.l	.L_high_mant,r1
+
+	SL(bt,	.L_epil,
+	 and	r4,r1)		! r1 contains high mantissa
+
+	cmp/eq	r2,r7		! chk if exp is invalid
+	mov.l	.L_1054,r7
+
+	bt	.L_inv_exp
+	mov	#11,r0
+	
+	cmp/hi	r7,r2		! If exp > 1054,return maxint
+	sub     r2,r7		!r7 contains the number of shifts
+
+	mov.l	.L_21bit,r2
+	bt	.L_ret_max
+
+	or	r2,r1
+	mov	r7,r3
+
+	shll8   r1
+	neg     r7,r7
+
+	shll2	r1
+
+        shll	r1
+	cmp/hi	r3,r0
+
+	SL(bt,	.L_lower_mant,
+	 mov	#21,r0)
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r7,r1
+#else
+.L_sh_loop:
+        tst	r7,r7
+        bt      .L_break
+        add     #1,r7
+        bra     .L_sh_loop
+        shlr    r1
+
+.L_break:
+#endif
+	rts
+	mov     r1,r0
+
+.L_lower_mant:
+	neg	r0,r0
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r0,r5
+#else
+        SHLR21 (r5)
+#endif
+	or	r5,r1		!pack lower and higher mantissas
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r7,r1
+#else
+.L_loop:
+        tst	r7,r7
+        bt      .L_break1
+        add     #1,r7
+        bra     .L_loop
+        shlr    r1
+
+.L_break1:
+#endif
+	mov	r1,r0
+.L_epil:
+	rts
+	nop
+
+.L_inv_exp:
+	cmp/hi	r0,r5
+	bt	.L_epil
+
+	cmp/hi	r0,r1		!compare high mantissa,r1
+	bt	.L_epil
+
+.L_ret_max:
+	mov.l   .L_maxint,r0
+
+	rts
+	nop
+
+	.align	2
+
+.L_maxint:
+	.long	0xffffffff
+.L_p_inf:
+	.long	0x7ff00000
+.L_high_mant:
+	.long	0x000fffff
+.L_1023:
+	.long	0x000003ff
+.L_1054:
+	.long	1054
+.L_21bit:
+	.long	0x00100000
+
+ENDFUNC (GLOBAL (fixunsdfsi))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/fixunssfsi.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/fixunssfsi.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/fixunssfsi.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/fixunssfsi.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,155 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+! Conversion from floating point to unsigned integer
+
+! Author: Rakesh Kumar
+
+! Argument: r4 (in floating point format)
+! Result: r0
+
+! For negative floating point numbers, it returns zero
+
+! The argument is referred as op1
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+	.text
+	.align 5
+	.global	GLOBAL (fixunssfsi)
+	FUNC (GLOBAL (fixunssfsi))
+
+GLOBAL (fixunssfsi):
+	mov.l	.L_sign,r0
+	mov	r4,r2
+
+	! Check for NaN
+	mov.l	.L_inf,r1
+	and	r4,r0
+
+	mov.l	.L_mask_sign,r7
+	mov	#127,r5
+
+	! Remove sign bit
+	cmp/eq	#0,r0
+	and	r7,r2
+
+	! If number is negative, return 0
+	! LIBGCC deviates from standard in this regard.
+	mov	r4,r3
+	SL(bf,	.L_epil,
+	 mov	#0,r0)
+
+	mov.l	.L_frac,r6
+	cmp/gt	r1,r2
+
+	shll	r2
+	SL1(bt,	.L_epil,
+	 shlr16	r2)
+
+	shlr8	r2	! r2 has exponent
+	mov.l	.L_24bit,r1
+
+	and	r6,r3	! r3 has fraction
+	cmp/gt	r2,r5
+
+	! If exponent is less than 127, return 0
+	or	r1,r3
+	bt	.L_epil
+
+	! Process only if exponent is less than 158
+	mov.l	.L_158,r1
+	shll8	r3
+
+	cmp/gt	r1,r2
+	sub	r2,r1
+
+	neg	r1,r1
+	bt	.L_ret_max
+
+! Shift the mantissa with exponent difference from 158
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+	shld	r1,r3
+#else
+	cmp/gt	r0,r1
+	bt	.L_mov_left
+
+.L_mov_right:
+	cmp/eq	r1,r0
+	bt	.L_ret
+
+	add	#1,r1
+	bra	.L_mov_right
+	shlr	r3
+
+.L_mov_left:
+	add	#-1,r1
+	
+	shll	r3
+	cmp/eq	r1,r0
+
+	bf	.L_mov_left
+
+.L_ret:	
+#endif
+	rts
+	mov	r3,r0
+
+! r0 already has appropriate value
+.L_epil:
+	rts
+	nop
+
+! Return the maximum unsigned integer value
+.L_ret_max:
+	mov.l	.L_max,r3
+
+	rts
+	mov	r3,r0
+
+	.align 2
+.L_inf:
+	.long 0x7F800000
+
+.L_158:
+	.long 158
+
+.L_max:
+	.long 0xFFFFFFFF
+
+.L_frac:
+	.long 0x007FFFFF
+
+.L_sign:
+	.long 0x80000000
+
+.L_24bit:
+	.long 0x00800000
+
+.L_mask_sign:
+	.long 0x7FFFFFFF
+
+ENDFUNC (GLOBAL (fixunssfsi))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/floatsidf.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/floatsidf.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/floatsidf.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/floatsidf.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,151 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+!conversion of signed integer to double precision floating point number
+!Author:Rakesh Kumar
+!
+!Entry:
+!r4:operand 
+!
+!Exit:
+!r0,r1:result
+!
+!Note:argument is passed in reg r4 and the result is returned in 
+!regs r0 and r1.
+!
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+        .text
+        .align 5
+        .global GLOBAL (floatsidf)
+	FUNC (GLOBAL (floatsidf))
+
+GLOBAL (floatsidf):
+        mov.l   .L_sign,r0
+        mov     #0,r1
+
+	mov	r0,r2
+	tst	r4,r4 ! check r4 for zero
+
+	! Extract the sign
+	mov	r2,r3
+	SL(bt,	.L_ret_zero,
+	 and	r4,r0)
+
+	cmp/eq	r1,r0
+	not	r3,r3
+
+	mov	r1,r7
+	SL(bt,	.L_loop,
+	 and	r4,r3)
+
+	! Treat -2147483648 as special case
+	cmp/eq	r1,r3
+	neg	r4,r4
+
+	bt	.L_ret_min	
+
+.L_loop:
+	shll	r4	
+	mov	r4,r5
+
+	and	r2,r5
+	cmp/eq	r1,r5
+	
+	add	#1,r7
+	bt	.L_loop
+
+	mov.l	.L_initial_exp,r6
+	not	r2,r2
+	
+	and	r2,r4
+	mov	#21,r3
+
+	sub	r7,r6
+	mov	r4,r1
+
+	mov	#20,r7
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r3,r1
+#else
+        SHLL21 (r1)
+#endif
+	mov	#-11,r2
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r7,r6	! Exponent in proper place
+#else
+        SHLL20 (r6)
+#endif
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r2,r4
+#else
+        SHLR11 (r4)
+#endif
+	or	r6,r0
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+#ifdef __LITTLE_ENDIAN__
+	or	r4,r1
+#else
+	or	r4,r0
+#endif
+	
+.L_ret_zero:
+	rts
+	mov	#0,r0
+
+.L_ret_min:
+	mov.l	.L_min,r0
+	
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	nop
+
+	.align 2
+
+.L_initial_exp:
+	.long 0x0000041E
+
+.L_sign:
+	.long 0x80000000
+
+.L_min:
+	.long 0xC1E00000
+
+ENDFUNC (GLOBAL (floatsidf))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/floatsisf.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/floatsisf.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/floatsisf.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/floatsisf.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,200 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+! Conversion of integer to floating point
+
+! Author: Rakesh Kumar
+
+! Argument: r4
+! Result: r0
+
+! r4 is referred as op1
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+        .text
+        .align 5
+        .global GLOBAL (floatsisf)
+        FUNC (GLOBAL (floatsisf))
+
+GLOBAL (floatsisf):
+	mov.l	.L_sign,r2
+	mov	#23,r6
+
+	! Check for zero
+	tst	r4,r4
+	mov.l	.L_24_bits,r7
+
+	! Extract sign
+	and	r4,r2
+	bt	.L_ret
+
+	! Negative ???
+	mov.l	.L_imp_bit,r5
+	cmp/pl	r4
+
+	not	r7,r3
+	bf	.L_neg
+
+	! Decide the direction for shifting
+	cmp/gt	r7,r4
+	mov	r4,r0
+
+	and	r5,r0
+	bt	.L_shr_0
+
+	! Number may already be in normalized form
+	cmp/eq	#0,r0
+	bf	.L_pack
+
+! Shift the bits to the left. Adjust the exponent
+.L_shl:
+	shll	r4
+	mov	r4,r0
+
+	and	r5,r0
+	cmp/eq	#0,r0
+
+	SL(bt,	.L_shl,
+	 add	#-1,r6)
+
+! Pack the value in floating point format.
+! r6 has unbiased exponent, r4 has mantissa, r2 has sign
+.L_pack:
+	mov	#23,r3
+	not	r5,r5
+
+	mov	r2,r0
+	add	#127,r6
+
+	and	r5,r4
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLL23 (r6)
+#else
+	shld	r3,r6
+#endif
+
+	or	r6,r0
+	rts
+	or	r4,r0
+
+! Negate the number
+.L_neg:
+	! Take care for -2147483648.
+	mov	r4,r0
+	shll	r0
+	
+	cmp/eq	#0,r0
+	SL(bt,	.L_ret_min,
+	 neg	r4,r4)
+
+        cmp/gt  r7,r4
+        bt	.L_shr_0
+
+	mov	r4,r0
+	and	r5,r0
+
+	cmp/eq	#0,r0
+	bf	.L_pack
+	bt	.L_shl
+	
+.L_shr_0:
+	mov	#0,r1
+
+! Shift right the number with rounding
+.L_shr:
+	shlr	r4
+	movt	r7
+
+	tst	r7,r7
+
+	! Count number of ON bits shifted
+	bt	.L_shr_1
+	add	#1,r1
+
+.L_shr_1:
+	mov	r4,r0
+	add	#1,r6
+
+	and	r3,r0
+	cmp/eq	#0,r0
+
+	! Add MSB of shifted bits
+	bf	.L_shr
+	add	r7,r4
+
+	tst	r7,r7
+	bt	.L_pack
+
+.L_pack1:
+	mov	#1,r0
+	cmp/eq	r1,r0
+
+	bt	.L_rnd
+	mov	r4,r0
+
+	! Rounding may have misplaced MSB. Adjust.
+	and	r3,r0
+	cmp/eq	#0,r0
+
+	bf	.L_shr
+	bt	.L_pack
+
+! If only MSB of shifted bits is ON, we are halfway
+! between two numbers. Round towards even LSB of
+! resultant mantissa.
+.L_rnd:
+	shlr	r4
+	bra	.L_pack
+	shll	r4
+
+.L_ret:
+	rts
+	mov	r4,r0
+
+! Return value for -2147483648
+.L_ret_min:
+	mov.l	.L_min_val,r0
+	rts
+	nop
+
+	.align 2
+.L_sign:
+	.long 0x80000000
+
+.L_imp_bit:
+	.long 0x00800000
+
+.L_24_bits:
+	.long 0x00FFFFFF
+
+.L_nsign:
+	.long 0x7FFFFFFF
+
+.L_min_val:
+	.long 0xCF000000
+
+ENDFUNC (GLOBAL (floatsisf))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/floatunssidf.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/floatunssidf.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/floatunssidf.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/floatunssidf.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,76 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+!conversion of unsigned integer to double precision floating point number
+!Author:Rakesh Kumar
+!Rewritten for SH1 support: Joern Rennecke
+!
+!Entry:
+!r4:operand
+!
+!Exit:
+!r0,r1:result
+!
+!Note:argument is passed in reg r4 and the result is returned in
+!regs r0 and r1.
+!
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+        .text
+        .align 5
+        .global GLOBAL (floatunsidf)
+	FUNC (GLOBAL (floatunsidf))
+
+GLOBAL (floatunsidf):
+	mov.w	LOCAL(x41f0),DBLRH	! bias + 32
+	tst	r4,r4			! check for zero
+	bt	.L_ret_zero
+.L_loop:
+	shll	r4	
+	SL(bf,	.L_loop,
+	 add	#-16,DBLRH)
+
+	mov	r4,DBLRL
+
+        SHLL20 (DBLRL)
+
+        shll16	DBLRH ! put exponent in proper place
+
+        SHLR12 (r4)
+
+	rts
+	or	r4,DBLRH
+	
+.L_ret_zero:
+	mov	#0,r1
+	rts
+	mov	#0,r0
+
+LOCAL(x41f0):	.word	0x41f0
+	.align 2
+
+ENDFUNC (GLOBAL (floatunsidf))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/floatunssisf.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/floatunssisf.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/floatunssisf.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/floatunssisf.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,137 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+! Conversion of unsigned integer to floating point
+
+! Author: Rakesh Kumar
+
+! Argument: r4
+! Result: r0
+
+! r4 is referred as op1
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+        .text
+        .align 5
+        .global GLOBAL (floatunsisf)
+	FUNC (GLOBAL (floatunsisf))
+
+GLOBAL (floatunsisf):
+	tst	r4,r4
+	mov	#23,r6
+
+	mov.l	.L_set_24_bits,r7
+	SL(bt,	.L_return,
+	 not	r7,r3)
+
+	! Decide the direction for shifting
+	mov.l	.L_set_24_bit,r5
+	cmp/hi	r7,r4
+
+	not	r5,r2
+	SL(bt,	.L_shift_right,
+	 mov	#0,r7)
+
+	tst	r5,r4
+	
+	mov	#0,r0
+	bf	.L_pack_sf
+
+! Shift the bits to the left. Adjust the exponent
+.L_shift_left:
+	shll	r4
+	tst	r5,r4
+
+	add	#-1,r6
+	bt	.L_shift_left
+
+! Pack the value in floating point format.
+! r6 has unbiased exponent, r4 has mantissa
+.L_pack_sf:
+	mov	#23,r3
+	add	#127,r6
+
+	! Align the exponent
+	and	r2,r4
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+        SHLL23 (r6)
+#else
+	shld	r3,r6
+#endif
+
+	or	r6,r0
+	rts
+	or	r4,r0
+
+! Shift right the number with rounding
+.L_shift_right:
+	shlr	r4
+	rotcr	r7
+
+	tst	r4,r3
+	add	#1,r6
+
+	bf	.L_shift_right
+	
+	tst	r7,r7
+	bt	.L_sh_rt_1
+
+	shll	r7
+	movt	r1
+
+	add	r1,r4
+
+	tst	r7,r7
+	bf	.L_sh_rt_1
+
+	! Halfway between two numbers.
+	! Round towards LSB = 0
+	shlr	r4
+	shll	r4
+
+.L_sh_rt_1:
+	mov	r4,r0
+
+	! Rounding may have misplaced MSB. Adjust.
+	and	r3,r0
+	cmp/eq	#0,r0
+
+	bf	.L_shift_right
+	bt	.L_pack_sf
+
+.L_return:
+	rts
+	mov	r4,r0
+
+	.align 2
+.L_set_24_bit:
+	.long 0x00800000
+
+.L_set_24_bits:
+	.long 0x00FFFFFF
+
+ENDFUNC (GLOBAL (floatunsisf))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/adddf3.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/adddf3.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/adddf3.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/adddf3.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,614 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! adddf3 for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+!
+! This code is optimized for SH4-200 without FPU, but can also be used for SH3.
+! Numbers with same sign are added in typically 37 cycles, worst case is
+! 43 cycles, unless there is an overflow, in which case the addition can
+! take up to takes 47 cycles.
+! Normal numbers with different sign are added in 56 (57 for PIC) cycles
+! or less on SH4.
+! If one of the inputs is a denormal, the worst case is 59 (60 for PIC)
+! cycles. (Two denormal inputs are faster than normal inputs, and
+! denormal outputs don't slow down computation).
+! Subtraction takes two cycles to negate the second input and then drops
+! through to addition.
+
+/* If the input exponents of a difference of two normalized numbers
+   differ by more than one, the output does not need to be adjusted
+   by more than one bit position.  Hence, it makes sense to ensure that
+   the shifts by 0 & 1 are handled quickly to reduce average and worst
+   case times.  */
+FUNC(GLOBAL(adddf3))
+FUNC(GLOBAL(subdf3))
+	.global	GLOBAL(adddf3)
+	.global	GLOBAL(subdf3)
+LOCAL(denorm_arg1):
+	bt LOCAL(inf_nan_arg0)
+	tst	r0,r2
+	bt/s	LOCAL(denorm_both)
+	shlr	r1
+	mov.l	LOCAL(x00100000),r3
+	bra	LOCAL(denorm_arg1_done)
+	 sub	r2,r3
+
+! Handle denorm addition here because otherwise the ordinary addition would
+! have to check for denormal results.
+! Denormal subtraction could also be done faster, but the denorm subtraction
+! path here is still one cycles faster than the one for normalized input
+! numbers, and 16 instructions shorter than the fastest version.
+! Here we also generate +0.0 + +0.0 -> +0.0 ; -0.0 + -0.0 -> -0.0
+LOCAL(denorm_both):
+	div0s	r8,DBL1H
+	mov.l	LOCAL(x800fffff),r9
+	bt/s	LOCAL(denorm_sub)
+	and	r1,DBL1H
+	and	r9,r8
+	mov.l	@r15+,r9
+	mov	DBL0L,DBLRL
+	mov	r8,DBLRH
+	addc	DBL1L,DBLRL
+	mov.l	@r15+,r8
+	rts
+	 addc	DBL1H,DBLRH
+
+! N.B., since subtraction also generates +0.0 for subtraction of numbers
+! with identical fractions, this also covers the +0.0 + -0.0 -> +0.0 /
+! -0.0 + +0.0 -> +0.0 cases.
+LOCAL(denorm_sub):
+	mov	r8,DBL0H	! tentative result sign
+	and	r1,DBL0H
+	bra	LOCAL(sub_same_exp)
+	 addc	r1,r2	! exponent++, clear T
+
+LOCAL(inf_nan_arg0):
+	cmp/hs 	r0,r3
+	bf		LOCAL(inf_nan_ret)
+	tst	DBL1L,DBL1L
+	bf		LOCAL(ret_nan)
+	shlr	r1
+	and 	DBL1H,r1
+	tst	r1,r1
+	bf		LOCAL(ret_nan)
+	div0s	r8,DBL1H
+	bf		LOCAL(inf_nan_ret)
+LOCAL(ret_nan):
+	mov 	#-1,DBLRH
+	bra	LOCAL(pop_r8_r9)
+		mov DBLRH,DBLRL
+  
+LOCAL(inf_nan_ret):
+	mov	DBL0L,DBLRL
+	bra	LOCAL(pop_r8_r9)
+		mov r8,DBLRH
+
+LOCAL(ret_arg0):
+	mov.l LOCAL(x800fffff),DBLRH
+	mov	DBL0L,DBLRL
+	mov	r2,r3
+LOCAL(ret_arg):
+	mov.l	@r15+,r9
+	and	r8,DBLRH
+	mov.l	@r15+,r8
+	rts
+	or r3,DBLRH
+
+LOCAL(no_carry):
+	shlr	r0
+	mov.l	LOCAL(x000fffff),DBLRH
+	addc	r3,r9
+	mov.w	LOCAL(d0),DBL1H
+	mov	DBL0L,DBLRL
+	and	DBL0H,DBLRH	! mask out implicit 1
+	mov.l	LOCAL(x7ff00000),r3
+	addc	DBL1H,DBLRL
+	addc	r2,DBLRH
+	mov.l	@r15+,r9
+	add	DBL1H,DBLRH	! fraction overflow -> exp increase
+	bra	LOCAL(add_done)
+	 cmp/hi	r3,DBLRH
+
+LOCAL(inf):
+	mov	#0,DBLRL
+	bra	LOCAL(or_sign)
+	mov	r3,DBLRH
+
+	.balign	4
+GLOBAL(subdf3):
+	cmp/pz DBL1H
+	add 	DBL1H,DBL1H
+	rotcr	DBL1H
+	nop
+
+GLOBAL(adddf3):
+	mov.l	LOCAL(x7ff00000),r0
+	mov	DBL0H,r2
+	mov.l	LOCAL(x001fffff),r1
+	mov	DBL1H,r3
+	mov.l	r8,@-r15
+	and	r0,r2		! r2 <- exp0
+	mov.l	r9,@-r15
+	and	r0,r3		! r3 <- exp1
+	cmp/hi r2,r3
+	or		r0,DBL0H
+	or		r0,DBL1H
+	bt		LOCAL(arg1_gt)
+	tst	r0,r3
+	mov	#-20,r9
+	mov	DBL0H,r8	! tentative result sign
+	and	r1,DBL0H	! arg0 fraction
+	bt/s	LOCAL(denorm_arg1)
+		cmp/hs r0,r2
+	bt		LOCAL(inf_nan_arg0)
+	sub	r2,r3
+LOCAL(denorm_arg1_done):	! r2 is tentative result exponent
+	shad	r9,r3
+	mov.w	LOCAL(m32),r9
+	mov	DBL1H,r0	! the 'other' sign
+	and	r1,DBL1H	! arg1 fraction
+	cmp/ge r9,r3
+	mov	DBL1H,r1
+	bf/s	LOCAL(large_shift_arg1)
+	 shld	r3,DBL1H
+LOCAL(small_shift_arg1):
+	mov	DBL1L,r9
+	shld	r3,DBL1L
+	tst	r3,r3
+	add	#32,r3
+	bt/s	LOCAL(same_exp)
+	 div0s r8,r0	! compare signs
+	shld	r3,r1
+
+	or		r1,DBL1L
+	bf/s	LOCAL(add)
+	shld	r3,r9
+	clrt
+	negc	r9,r9
+	mov.l	LOCAL(x001f0000),r3
+LOCAL(sub_high):
+	mov	DBL0L,DBLRL
+	subc	DBL1L,DBLRL
+	mov	DBL0H,DBLRH
+	bra	LOCAL(subtract_done)
+	 subc	DBL1H,DBLRH
+
+LOCAL(large_shift_arg1):
+	mov	DBL1L,r9
+	shld	r3,r9
+	add	#64,r3
+	cmp/pl r3
+	shld	r3,r1
+	shld	r3,DBL1L
+	bf		LOCAL(ret_arg0)
+	tst	DBL1L,DBL1L
+	bt		LOCAL(large_shift_arg1_end)
+	mov	#1,DBL1L
+	or 	DBL1L,r9
+LOCAL(large_shift_arg1_end):
+	mov	DBL1H,DBL1L
+	mov	#0,DBL1H
+	add	r1,r9
+	div0s	r8,r0	! compare signs
+	bf		LOCAL(add)
+	clrt
+	mov.l	LOCAL(x001f0000),r3
+	bra	LOCAL(sub_high)
+	 negc	r9,r9
+
+LOCAL(add_clr_r9):
+	mov	#0,r9
+LOCAL(add):
+	mov.l	LOCAL(x00200000),r3
+	addc	DBL1L,DBL0L
+	addc	DBL1H,DBL0H
+	mov.l	LOCAL(x80000000),r1
+	tst	r3,DBL0H
+	mov.l	LOCAL(x7fffffff),r3
+	mov	DBL0L,r0
+	bt/s	LOCAL(no_carry)
+	and	r1,r8
+	tst	r9,r9
+	bf		LOCAL(add_one)
+	tst	#2,r0
+LOCAL(add_one):
+	subc	r9,r9
+	sett
+	mov	r0,DBLRL 
+	addc	r9,DBLRL
+	mov	DBL0H,DBLRH
+	addc	r9,DBLRH
+	shlr	DBLRH
+	mov.l	LOCAL(x7ff00000),r3
+	add	r2,DBLRH
+	mov.l	@r15+,r9
+	rotcr	DBLRL
+	cmp/hs r3,DBLRH
+LOCAL(add_done):
+	bt		LOCAL(inf)
+LOCAL(or_sign):
+	or		r8,DBLRH
+	rts
+	 mov.l @r15+,r8
+
+LOCAL(same_exp):
+	bf	LOCAL(add_clr_r9)
+	clrt
+LOCAL(sub_same_exp):
+	subc	DBL1L,DBL0L
+	mov.l	LOCAL(x001f0000),r3
+	subc	DBL1H,DBL0H
+	mov.w	LOCAL(d0),r9
+	bf	LOCAL(pos_difference_0)
+	clrt
+	negc	DBL0L,DBLRL
+	mov.l	LOCAL(x80000000),DBL0L
+	negc	DBL0H,DBLRH
+	mov.l	LOCAL(x00100000),DBL0H
+	tst	r3,DBLRH
+	not	r8,r8
+	bt/s	LOCAL(long_norm)
+	and	DBL0L,r8
+	bra	LOCAL(norm_loop_2)
+	 not	DBL0L,r3
+
+LOCAL(large_shift_arg0):
+	mov	DBL0L,r9
+	shld	r2,r9
+	add	#64,r2
+	cmp/pl	r2
+	shld	r2,r1
+	shld	r2,DBL0L
+	bf	LOCAL(ret_arg1_exp_r3)
+	tst	DBL0L,DBL0L
+	bt LOCAL(large_shift_arg0_end)
+	mov 	#1,DBL0L
+	or		DBL0L,r9 
+LOCAL(large_shift_arg0_end):
+	mov	DBL0H,DBL0L
+	mov	#0,DBL0H
+	add	r1,r9
+	div0s	r8,r0	! compare signs
+	mov	r3,r2	! tentative result exponent
+	bf	LOCAL(add)
+	clrt
+	negc	r9,r9
+	bra	LOCAL(subtract_arg0_arg1_done)
+	 mov	DBL1L,DBLRL
+
+LOCAL(arg1_gt):
+	tst	r0,r2			! r0 = 0x7ff00000 r2 = exp0
+	mov	#-20,r9
+	mov	DBL1H,r8		! tentative result sign
+	and	r1,DBL1H
+	bt/s	LOCAL(denorm_arg0)
+	cmp/hs	r0,r3
+	bt	LOCAL(inf_nan_arg1)
+	sub	r3,r2
+LOCAL(denorm_arg0_done):
+	shad	r9,r2			! r2 <- shifting value
+	mov.w	LOCAL(m32),r9
+	mov	DBL0H,r0		! the 'other' sign
+	and	r1,DBL0H
+	cmp/ge	r9,r2
+	mov	DBL0H,r1
+	bf/s	LOCAL(large_shift_arg0)
+		shld	r2,DBL0H
+LOCAL(small_shift_arg0):
+	mov	DBL0L,r9
+	shld	r2,DBL0L
+	mov.l	r3,@-r15
+	mov 	#32,r3
+	add	r3,r2
+	cmp/ge	r3,r2
+	bf LOCAL(shifting)
+	mov	#0,r1
+	mov 	r1,r9
+LOCAL(shifting):
+	shld	r2,r1
+	mov	r2,r3
+	shld	r3,r9
+	div0s	r8,r0		! compare signs
+	mov.l	@r15+,r2	! tentative result exponent
+	bf/s	LOCAL(add)
+	or	r1,DBL0L
+	clrt
+	negc	r9,r9
+	mov	DBL1L,DBLRL
+LOCAL(subtract_arg0_arg1_done):
+	subc	DBL0L,DBLRL
+	mov	DBL1H,DBLRH
+	mov.l	LOCAL(x001f0000),r3
+	subc	DBL0H,DBLRH
+/* Since the exponents were different, the difference is positive.  */
+/* Fall through */
+LOCAL(subtract_done):
+/* First check if a shift by a few bits is sufficient.  This not only
+   speeds up this case, but also alleviates the need for considering
+   lower bits from r9 or rounding in the other code.
+   Moreover, by handling the upper 1+4 bits of the fraction here, long_norm
+   can assume that DBLRH fits into 20 (20 < 16) bit.  */
+	tst	r3,DBLRH
+	mov.l	LOCAL(x80000000),r3
+	mov.l	LOCAL(x00100000),DBL0H
+	bt/s	LOCAL(long_norm)
+	and	r3,r8
+	mov.l	LOCAL(x7fffffff),r3
+LOCAL(norm_loop_2):	! Well, this used to be a loop...
+	tst	DBL0H,DBLRH
+	sub	DBL0H,r2
+	bf	LOCAL(norm_round)
+	shll	r9
+	rotcl	DBLRL
+	
+	rotcl	DBLRH
+	
+	 subc	DBL0H,r2
+LOCAL(norm_loop_1):
+	bt	LOCAL(denorm0_n)
+	tst	DBL0H,DBLRH
+	bf	LOCAL(norm_round)
+	shll	DBLRL
+	rotcl	DBLRH	! clears T
+	bra	LOCAL(norm_loop_1)
+	 subc	DBL0H,r2
+	 
+LOCAL(denorm_arg0):
+	bt	LOCAL(inf_nan_arg1)
+	mov.l	LOCAL(x00100000),r2
+	shlr	r1				! r1 <- 0xfffff
+	bra	LOCAL(denorm_arg0_done)
+	 sub	r3,r2			! r2 <- 1 - exp1
+
+LOCAL(inf_nan_arg1):
+	mov	DBL1L,DBLRL
+	bra	LOCAL(pop_r8_r9)
+	 mov	r8,DBLRH
+
+LOCAL(ret_arg1_exp_r3):
+	mov.l	LOCAL(x800fffff),DBLRH
+	bra	LOCAL(ret_arg)
+	 mov	DBL1L,DBLRL
+
+LOCAL(pos_difference_0):
+	tst	r3,DBL0H
+	mov	DBL0L,DBLRL
+	mov.l	LOCAL(x80000000),DBL0L
+	mov	DBL0H,DBLRH
+	mov.l	LOCAL(x00100000),DBL0H
+	bt/s	LOCAL(long_norm)
+	and	DBL0L,r8
+	bra	LOCAL(norm_loop_2)
+	 not	DBL0L,r3
+
+#ifdef __pic__
+	.balign 8
+#endif
+LOCAL(m32):
+	.word	-32
+LOCAL(d0):
+	.word	0
+#ifndef __pic__
+	.balign 8
+#endif
+! Because we had several bits of cancellations, we know that r9 contains
+! only one bit.
+! We'll normalize by shifting words so that DBLRH:DBLRL contains
+! the fraction with 0 < DBLRH <= 0x1fffff, then we shift DBLRH:DBLRL
+! up by 21 minus the number of non-zero bits in DBLRH.
+LOCAL(long_norm):
+	tst	DBLRH,DBLRH
+	mov.w	LOCAL(xff),DBL0L
+	mov	#21,r3
+	bf	LOCAL(long_norm_highset)
+	mov.l	LOCAL(x02100000),DBL1L	! shift 32, implicit 1
+	tst	DBLRL,DBLRL
+	extu.w	DBLRL,DBL0H
+	bt	LOCAL(zero_or_ulp)
+	mov	DBLRL,DBLRH
+	cmp/hi	DBL0H,DBLRL
+	bf	0f
+	mov.l	LOCAL(x01100000),DBL1L	! shift 16, implicit 1
+	clrt
+	shlr16  DBLRH
+	xtrct	DBLRL,r9
+	mov     DBLRH,DBL0H
+LOCAL(long_norm_ulp_done):
+0:	mov	r9,DBLRL	! DBLRH:DBLRL == fraction; DBL0H == DBLRH
+	subc	DBL1L,r2
+	bt	LOCAL(denorm1_b)
+#ifdef __pic__
+	mov.l	LOCAL(c__clz_tab),DBL1H
+LOCAL(long_norm_lookup):
+	mov	r0,r9
+	mova	LOCAL(c__clz_tab),r0
+	add	DBL1H,r0
+#else
+	mov	r0,r9
+LOCAL(long_norm_lookup):
+	mov.l	LOCAL(c__clz_tab),r0
+#endif /* __pic__ */
+	cmp/hi	DBL0L,DBL0H
+	bf	0f
+	shlr8	DBL0H
+0:	mov.b	@(r0,DBL0H),r0
+	bf	0f
+	add	#-8,r3
+0:	mov.w	LOCAL(d20),DBL0L
+	mov	#-20,DBL0H
+	clrt
+	sub	r0,r3
+	mov	r9,r0
+	mov	r3,DBL1H
+	shld	DBL0L,DBL1H
+	subc	DBL1H,r2
+	!
+	bf	LOCAL(no_denorm)
+	shad	DBL0H,r2
+	bra	LOCAL(denorm1_done)
+	add	r2,r3
+	
+LOCAL(norm_round):
+	cmp/pz	r2
+	mov	#0,DBL1H
+	bf	LOCAL(denorm0_1)
+	or	r8,r2
+	mov	DBLRL,DBL1L
+	shlr	DBL1L
+	addc	r3,r9
+	mov.l	@r15+,r9
+	addc	DBL1H,DBLRL	! round to even
+	mov.l	@r15+,r8
+	rts
+	 addc	r2,DBLRH
+
+LOCAL(norm_pack):
+	add	r8,DBLRH
+	mov.l	@r15+,r8
+	rts
+	add	r2,DBLRH
+
+LOCAL(denorm0_1):
+	mov.l	@r15+,r9
+	mov	r8,DBL0L
+	mov.l	@r15+,r8
+LOCAL(denorm0_shift):
+	shlr	DBLRH
+	rotcr	DBLRL
+
+	rts
+	add	DBL0L,DBLRH
+
+LOCAL(denorm0_n):
+	mov.l	@r15+,r9
+	mov	r8,DBL0L
+	addc	DBL0H,r2
+	mov.l	@r15+,r8
+	bra LOCAL(denorm0_shift)
+		  nop
+
+LOCAL(no_denorm):
+	add	r2,r8		! add (exponent - 1) to sign
+
+LOCAL(denorm1_done):
+	shld	r3,DBLRH
+	mov	DBLRL,DBL0L
+	shld	r3,DBLRL
+
+	add	r8,DBLRH	! add in sign and (exponent - 1)
+	mov.l	@r15+,r9
+	add	#-32,r3
+	mov.l	@r15+,r8
+	shld	r3,DBL0L
+
+	rts
+	add	DBL0L,DBLRH
+
+LOCAL(long_norm_highset):
+	mov.l	LOCAL(x00200000),DBL1L	! shift 1, implicit 1
+	shll	r9
+	rotcl	DBLRL
+	mov	DBLRH,DBL0H
+	rotcl	DBLRH	! clears T
+#ifdef __pic__
+	mov.l	LOCAL(c__clz_tab),DBL1H
+#else
+	mov	r0,r9
+#endif /* __pic__ */
+	subc	DBL1L,r2
+	add	#-1,r3
+	bf	LOCAL(long_norm_lookup)
+LOCAL(denorm1_a):
+	shlr	DBLRH
+	rotcr	DBLRL
+	mov.l	@r15+,r9
+	or	r8,DBLRH
+
+	rts
+	mov.l	@r15+,r8
+
+	.balign	4
+LOCAL(denorm1_b):
+	mov	#-20,DBL0L
+	shad	DBL0L,r2
+	mov	DBLRH,DBL0L
+	shld	r2,DBLRH
+	shld	r2,DBLRL
+	or	r8,DBLRH
+	mov.l	@r15+,r9
+	add	#32,r2
+	mov.l	@r15+,r8
+	shld	r2,DBL0L
+	rts
+	or	DBL0L,DBLRL
+
+LOCAL(zero_or_ulp):
+	tst	r9,r9
+	bf	LOCAL(long_norm_ulp_done)
+	! return +0.0
+LOCAL(pop_r8_r9):
+	mov.l	@r15+,r9
+	rts
+	mov.l	@r15+,r8
+
+LOCAL(d20):
+	.word	20
+LOCAL(xff):
+	.word 0xff
+	.balign	4
+LOCAL(x7ff00000):
+	.long	0x7ff00000
+LOCAL(x001fffff):
+	.long	0x001fffff
+LOCAL(x80000000):
+	.long	0x80000000
+LOCAL(x000fffff):
+	.long	0x000fffff
+LOCAL(x800fffff):
+	.long	0x800fffff
+LOCAL(x001f0000):
+	.long	0x001f0000
+LOCAL(x00200000):
+	.long	0x00200000
+LOCAL(x7fffffff):
+	.long	0x7fffffff
+LOCAL(x00100000):
+	.long	0x00100000
+LOCAL(x02100000):
+	.long	0x02100000
+LOCAL(x01100000):
+	.long	0x01100000
+LOCAL(c__clz_tab):
+#ifdef __pic__
+	.long	GLOBAL(clz_tab) - .
+#else
+	.long	GLOBAL(clz_tab)
+#endif
+ENDFUNC(GLOBAL(adddf3))
+ENDFUNC(GLOBAL(subdf3))
+
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/addsf3.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/addsf3.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/addsf3.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/addsf3.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,290 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! addsf3 for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+
+	.balign 4
+	.global GLOBAL(subsf3)
+	FUNC(GLOBAL(subsf3))
+	.global GLOBAL(addsf3)
+	FUNC(GLOBAL(addsf3))
+GLOBAL(subsf3):
+	cmp/pz	r5
+	add	r5,r5
+	rotcr	r5
+	.balign 4
+GLOBAL(addsf3):
+	mov.l	LOCAL(x7f800000),r3
+	mov	r4,r6
+	add	r6,r6
+	mov	r5,r7
+	add	r7,r7
+	mov	r4,r0
+	or	r3,r0
+	cmp/hi	r6,r7
+	mov	r5,r1
+	bf/s	LOCAL(r4_hs)
+	 or	r3,r1
+	cmp/eq	r5,r1
+	bt	LOCAL(ret_r5) /* sole Inf or NaN, return unchanged.  */
+	shll8	r0	! r4 fraction
+	shll8	r1	! r5 fraction
+	mov	r6,r3
+	mov	#-24,r2
+	mov	r7,r6
+	shld	r2,r6	! r5 exp
+	mov	r0,r7
+	shld	r2,r3	! r4 exp
+	tst	r3,r3
+	sub	r6,r3	! exp difference (negative or 0)
+	bt	LOCAL(denorm_r4)
+LOCAL(denorm_r4_done): ! r1: u1.31
+	shld	r3,r0	! Get 31 upper bits, including 8 guard bits
+	mov.l	LOCAL(xff000000),r2
+	add	#31,r3
+	mov.l	r5,@-r15 ! push result sign.
+	cmp/pl	r3	! r0 has no more than one bit set -> return arg 1
+	shld	r3,r7	! copy of lowest guard bit in r0 and lower guard bits
+	bf	LOCAL(ret_stack)
+	div0s	r4,r5
+	bf/s	LOCAL(add)
+	 cmp/pl	r7	/* Is LSB in r0 clear, but any lower guards bit set?  */
+	subc	r0,r1
+	mov.l	LOCAL(c__clz_tab),r7
+	tst	r2,r1
+	mov	#-24,r3
+	bf/s LOCAL(norm_r0)
+	 mov	r1,r0
+	extu.w	r1,r1
+	bra	LOCAL(norm_check2)
+	 cmp/eq	r0,r1
+LOCAL(ret_r5):
+	rts
+	mov	r5,r0
+LOCAL(ret_stack):
+	rts
+	mov.l	@r15+,r0
+
+/* We leave the numbers denormalized, but we change the bit position to be
+   consistent with normalized numbers.  This also removes the spurious
+   leading one that was inserted before.  */
+LOCAL(denorm_r4):
+	tst	r6,r6
+	add	r0,r0
+	bf	LOCAL(denorm_r4_done)
+	bra	LOCAL(denorm_r4_done)
+	add	r1,r1
+LOCAL(denorm_r5):
+	tst	r6,r6
+	add	r1,r1
+	bf	LOCAL(denorm_r5_done)
+	clrt
+	bra	LOCAL(denorm_r5_done)
+	add	r0,r0
+
+/* If the exponent differs by two or more, normalization is minimal, and
+   few guard bits are needed for an exact final result, so sticky guard
+   bit compresion before subtraction (or add) works fine.
+   If the exponent differs by one, only one extra guard bit is generated,
+   and effectively no guard bit compression takes place.  */
+
+	.balign	4
+LOCAL(r4_hs):
+	cmp/eq	r4,r0
+	mov	#-24,r3
+	bt	LOCAL(inf_nan_arg0)
+	shld	r3,r7
+	shll8	r0
+	tst	r7,r7
+	shll8	r1
+	mov.l	LOCAL(xff000000),r2
+	bt/s	LOCAL(denorm_r5)
+	shld	r3,r6
+LOCAL(denorm_r5_done):
+	mov	r1,r3
+	subc	r6,r7
+	bf	LOCAL(same_exp)
+	shld	r7,r1	/* Get 31 upper bits.  */
+	add	#31,r7
+	mov.l	r4,@-r15 ! push result sign.
+	cmp/pl	r7
+	shld	r7,r3
+	bf	LOCAL(ret_stack)
+	div0s	r4,r5
+	bf/s	LOCAL(add)
+	 cmp/pl	r3	/* Is LSB in r1 clear, but any lower guard bit set?  */
+	subc	r1,r0
+	mov.l	LOCAL(c__clz_tab),r7
+LOCAL(norm_check):
+	tst	r2,r0
+	mov	#-24,r3
+	bf LOCAL(norm_r0)
+	extu.w	r0,r1
+	cmp/eq	r0,r1
+LOCAL(norm_check2):
+	mov	#-8,r3
+	bt LOCAL(norm_r0)
+	mov	#-16,r3
+LOCAL(norm_r0):
+	mov	r0,r1
+	shld	r3,r0
+#ifdef __pic__
+	add	r0,r7
+	mova  LOCAL(c__clz_tab),r0
+#endif
+	mov.b	@(r0,r7),r7
+	add	#25,r3
+	add	#-9+1,r6
+	mov	r1,r0
+	sub	r7,r3
+	mov.l	LOCAL(xbfffffff),r7
+	sub	r3,r6	/* generate exp-1  */
+	mov.w	LOCAL(d24),r2
+	cmp/pz	r6	/* check exp > 0  */
+	shld	r3,r0	/* Leading 1 becomes +1 exp adjustment.  */
+	bf	LOCAL(zero_denorm)
+LOCAL(denorm_done):
+	add	#30,r3
+	shld	r3,r1
+	mov.w   LOCAL(m1),r3
+	tst	r7,r1	! clear T if rounding up
+	shld	r2,r6
+	subc	r3,r0	! round - overflow will boost exp adjustment to 2.
+	mov.l	@r15+,r2
+	add	r6,r0	! overflow will generate inf
+	cmp/ge	r2,r3	! get sign into T
+	rts
+	rotcr	r0
+LOCAL(ret_r4):
+	rts
+	mov	r4,r0
+
+/* At worst, we are shifting the number back in place where an incoming
+   denormal was.  Thus, the shifts won't get out of range.  They still
+   might generate a zero fraction, but that's OK, that makes it 0.  */
+LOCAL(zero_denorm):
+	add	r6,r3
+	mov	r1,r0
+	mov	#0,r6	/* leading one will become free (except for rounding) */
+	bra	LOCAL(denorm_done)
+	shld	r3,r0
+
+/* Handle abs(r4) >= abs(r5), same exponents specially so we don't need
+   check for a zero fraction in the main path.  */
+LOCAL(same_exp):
+	div0s	r4,r5
+	mov.l	r4,@-r15
+	bf	LOCAL(add)
+	cmp/eq	r1,r0
+	mov.l	LOCAL(c__clz_tab),r7
+	bf/s	LOCAL(norm_check)
+	 sub	r1,r0
+	rts	! zero difference -> return +zero
+	mov.l	@r15+,r1
+
+/* r2: 0xff000000 */
+LOCAL(add):
+	addc	r1,r0
+	mov.w	LOCAL(x2ff),r7
+	shll8	r6
+	bf/s	LOCAL(no_carry)
+	shll16	r6
+	tst	r7,r0		
+	shlr8	r0
+	mov.l	@r15+,r3	! discard saved sign
+	subc	r2,r0
+	sett
+	addc	r6,r0
+	cmp/hs	r2,r0
+	bt/s	LOCAL(inf)
+	div0s	r7,r4 /* Copy sign.  */
+	rts
+	rotcr	r0
+LOCAL(inf):
+	mov	r2,r0
+	rts
+	rotcr	r0
+	
+LOCAL(no_carry):
+	mov.w	LOCAL(m1),r3
+	tst	r6,r6
+	bt	LOCAL(denorm_add)
+	add	r0,r0
+	tst	r7,r0		! check if lower guard bit set or round to even
+	shlr8	r0
+	mov.l	@r15+,r1	! discard saved sign
+	subc	r3,r0	! round ; overflow -> exp++
+	cmp/ge	r4,r3	/* Copy sign.  */
+	add	r6,r0	! overflow -> inf
+	rts
+	rotcr	r0
+
+LOCAL(denorm_add):
+	cmp/ge	r4,r3	/* Copy sign.  */
+	shlr8	r0
+	mov.l	@r15+,r1	! discard saved sign
+	rts
+	rotcr	r0
+
+LOCAL(inf_nan_arg0):
+	cmp/eq	r5,r1
+	bf	LOCAL(ret_r4)
+	div0s	r4,r5		/* Both are inf or NaN, check signs.  */
+	bt	LOCAL(ret_nan)	/* inf - inf, or NaN.  */
+	mov	r4,r0		! same sign; return NaN if either is NaN.
+	rts
+	or	r5,r0
+LOCAL(ret_nan):
+	rts
+	mov	#-1,r0
+
+LOCAL(d24):
+	.word	24
+LOCAL(x2ff):
+	.word	0x2ff
+LOCAL(m1):
+	.word	-1
+	.balign	4
+LOCAL(x7f800000):
+	.long	0x7f800000
+LOCAL(xbfffffff):
+	.long	0xbfffffff
+LOCAL(xff000000):
+	.long	0xff000000
+LOCAL(xfe000000):
+	.long	0xfe000000
+LOCAL(c__clz_tab):
+#ifdef __pic__
+	.long	GLOBAL(clz_tab) - .
+#else
+	.long	GLOBAL(clz_tab)
+#endif
+
+	ENDFUNC(GLOBAL(addsf3))
+	ENDFUNC(GLOBAL(subsf3))
+
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/divdf3-rt.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/divdf3-rt.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/divdf3-rt.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/divdf3-rt.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,519 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! divdf3 for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke joern.rennecke@st.com
+
+/* This version is not quite finshed, since I've found that I can
+   get better average performance with a slightly altered algorithm.
+   Still, if you want a version for hard real time, this version here might
+   be a good starting point, since it has effectively no conditional
+   branches in the path that deals with normal numbers
+   (branches with zero offset are effectively conditional execution),
+   and thus it has a uniform execution time in this path.  */
+
+/* y = 1/x  ; x (- [1,2)
+   y0 = 1.5 - x/2 - tab[(1-x)*64] = y + d ; abs(d)/y <= 0x1.0c/256
+
+   y1 = y0 - ((y0) * x - 1) * y0  =  y-x*d^2
+   y2 = y1 - ((y1) * x - 1) * y1 =~= y-x^3*d^4
+
+   z0 = y2*a ;  a1 = a - z0*x /# 32 * 64 -> 64 bit #/
+   z1 = y2*a1 (round to nearest odd 0.5 ulp);
+   a2 = a1 - z1*x /# 32 * 64 -> 64 bit #/
+
+   z = a/x = z0 + z1 - 0.5 ulp + (a2 > 0) * ulp
+
+   Unless stated otherwise, multiplies can be done in 32 * 32 bit or less
+   with suitable scaling and/or top truncation.
+   x truncated to 20 bits is sufficient to calculate y0 or even y1.
+   Table entries are adjusted by about +128 to use full signed byte range.
+   This adjustment has been perturbed slightly to allow cse with the
+   shift count constant -26.
+   The threshold point for the shift adjust before rounding is found by
+   comparing the fractions, which is exact, unlike the top bit of y2.
+   Therefore, the top bit of y2 becomes slightly random after the adjustment
+   shift, but that's OK because this can happen only at the boundaries of
+   the interval, and the baising of the error means that it can in fact happen
+   only at the bottom end.  And there, the carry propagation will make sure
+   that in the end we will have in effect an implicit 1 (or two whem rounding
+   up...)  */
+/* If an exact result exists, it can have no more bits than the divident.
+   Hence, we don't need to bother with the round-to-even tie breaker
+   unless the result is denormalized.  */
+/* 70 cycles through main path for sh4-300 .  Some cycles might be
+   saved by more careful register allocation.
+   122 cycles for sh4-200.  If execution time for sh4-200 is of concern,
+   a specially scheduled version makes sense.  */
+
+#define x_h r12
+#define yn  r3
+
+FUNC(GLOBAL(divdf3))
+ .global GLOBAL(divdf3)
+
+/* Adjust arg0 now, too.  We still have to come back to denorm_arg1_done,
+   since we heven't done any of the work yet that we do till the denorm_arg0
+   entry point.  We know that neither of the arguments is inf/nan, but
+   arg0 might be zero.  Check for that first to avoid having to establish an
+   rts return address.  */
+LOCAL(both_denorm):
+	mov.l	r9,@-r15
+	mov	DBL0H,r1
+	mov.l	r0,@-r15
+	shll2	r1
+	mov.w LOCAL(both_denorm_cleanup_off),r9
+	or	DBL0L,r1
+	tst	r1,r1
+	mov	DBL0H,r0
+	bf/s	LOCAL(zero_denorm_arg0_1)
+	shll2	r0
+	mov.l	@(4,r15),r9
+	add	#8,r15
+	bra	LOCAL(ret_inf_nan_0)
+	mov	r1,DBLRH
+
+LOCAL(both_denorm_cleanup):
+	mov.l	@r15+,r0
+	!
+	mov.l	@r15+,r9
+ mov	#12,r3
+ mov.l	LOCAL(xfffe2006),r1	! yn := (-1. << 17) + (0x80 << 6) ; shift #-26
+	bra	LOCAL(denorm_arg1_done)
+	!
+	add	r0,DBL0H
+
+/* Denorm handling leaves the incoming denorm argument with an exponent of +1
+   (implicit 1).  To leave the result exponent unaltered, the other
+   argument's exponent is adjusted by the the shift count.  */
+
+	.balign 4
+LOCAL(arg0_tiny):
+	bsr	LOCAL(clz)
+	mov	DBL0L,r0
+	shll	DBL0H
+	add	#1,r0
+	mov	DBL0L,DBL0H
+	shld	r0,DBL0H
+	rotcr	DBL0H
+	tst	DBL0L,DBL0L	/* Check for divide of zero.  */
+	add	#-33,r0
+	shld	r0,DBL0L
+	bf/s	LOCAL(adjust_arg1_exp)
+	add	#64,r0
+LOCAL(return_0): /* Return 0 with appropriate sign.  */
+	mov.l	@r15+,r10
+	mov	#0,DBLRH
+	mov.l	@r15+,r9
+	bra	LOCAL(ret_inf_nan_0)
+	mov.l	@r15+,r8
+
+	.balign 4
+LOCAL(arg1_tiny):
+	bsr	LOCAL(clz)
+	mov	DBL1L,r0
+	shll	DBL1H
+	add	#1,r0
+	mov	DBL1L,DBL1H
+	shld	r0,DBL1H
+	rotcr	DBL1H
+	tst	DBL1L,DBL1L	/* Check for divide by zero.  */
+	add	#-33,r0
+	shld	r0,DBL1L
+	bf/s	LOCAL(adjust_arg0_exp)
+	add	#64,r0
+	mov	DBL0H,r0
+	add	r0,r0
+	tst	r0,r0	! 0 / 0 ?
+	mov	#-1,DBLRH
+	bf	LOCAL(return_inf)
+	!
+	bt	LOCAL(ret_inf_nan_0)
+	!
+
+	.balign 4
+LOCAL(zero_denorm_arg1):
+	not	DBL0H,r3
+	mov	DBL1H,r0
+	tst	r2,r3
+	shll2	r0
+	bt	LOCAL(early_inf_nan_arg0)
+	tst	r0,r0
+	mov.w	LOCAL(xff00),r12
+	bt/s	LOCAL(arg1_tiny)
+	sts.l	pr,@-r15
+	bsr	LOCAL(clz)
+	shlr2	r0
+	!
+	shll	DBL1H
+	mov	DBL1L,r3
+	shld	r0,DBL1H
+	shld	r0,DBL1L
+	rotcr	DBL1H
+	add	#-32,r0
+	shld	r0,r3
+	add	#32,r0
+	or	r3,DBL1H
+LOCAL(adjust_arg0_exp):
+	tst	r2,DBL0H
+	mov	#20,r3
+	shld	r3,r0
+	bt	LOCAL(both_denorm)
+	add	DBL0H,r0
+	div0s	r0,DBL0H	! Check for obvious overflow.  */
+	not	r0,r3		! Check for more subtle overflow - lest
+	bt	LOCAL(return_inf)
+	mov	r0,DBL0H
+	tst	r2,r3		! we mistake it for NaN later
+	mov	#12,r3
+	bf	LOCAL(denorm_arg1_done)
+LOCAL(return_inf): /* Return infinity with appropriate sign.  */
+	mov	#20,r3
+	mov	#-2,DBLRH
+	bra	LOCAL(ret_inf_nan_0)
+	shad	r3,DBLRH
+
+/* inf/n -> inf; inf/0 -> inf; inf/inf -> nan; inf/nan->nan  nan/x -> nan */
+LOCAL(inf_nan_arg0):
+	mov.l	@r15+,r10
+	mov.l	@r15+,r9
+	mov.l	@r15+,r8
+LOCAL(early_inf_nan_arg0):
+	not	DBL1H,r3
+	mov	DBL0H,DBLRH
+	tst	r2,r3	! both inf/nan?
+	add	DBLRH,DBLRH
+	bf	LOCAL(ret_inf_nan_0)
+	mov	#-1,DBLRH
+LOCAL(ret_inf_nan_0):
+	mov	#0,DBLRL
+	mov.l	@r15+,r12
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+	
+/* Already handled: inf/x, nan/x .  Thus: x/inf -> 0; x/nan -> nan */
+	.balign	4
+LOCAL(inf_nan_arg1):
+	mov	DBL1H,r2
+	mov	#12,r1
+	shld	r1,r2
+	mov.l	@r15+,r10
+	mov	#0,DBLRL
+	mov.l	@r15+,r9
+	or	DBL1L,r2
+	mov.l	@r15+,r8
+	cmp/hi	DBLRL,r2
+	mov.l	@r15+,r12
+	subc	DBLRH,DBLRH
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+	
+	.balign 4
+LOCAL(zero_denorm_arg0):
+	mov.w	LOCAL(denorm_arg0_done_off),r9
+	not	DBL1H,r1
+	mov	DBL0H,r0
+	tst	r2,r1
+	shll2	r0
+	bt	LOCAL(inf_nan_arg1)
+LOCAL(zero_denorm_arg0_1):
+	tst	r0,r0
+	mov.w	LOCAL(xff00),r12
+	bt/s	LOCAL(arg0_tiny)
+	sts.l	pr,@-r15
+	bsr	LOCAL(clz)
+	shlr2	r0
+	shll	DBL0H
+	mov	DBL0L,r12
+	shld	r0,DBL0H
+	shld	r0,DBL0L
+	rotcr	DBL0H
+	add	#-32,r0
+	shld	r0,r12
+	add	#32,r0
+	or	r12,DBL0H
+LOCAL(adjust_arg1_exp):
+	mov	#20,r12
+	shld	r12,r0
+	add	DBL1H,r0
+	div0s	r0,DBL1H	! Check for obvious underflow.  */
+	not	r0,r12		! Check for more subtle underflow - lest
+	bt	LOCAL(return_0)
+	mov	r0,DBL1H
+	tst	r2,r12		! we mistake it for NaN later
+	bt	LOCAL(return_0)
+	!
+	braf	r9
+	mov	#13,r0
+LOCAL(zero_denorm_arg1_dispatch):
+
+LOCAL(xff00):	.word 0xff00
+LOCAL(denorm_arg0_done_off):
+	.word LOCAL(denorm_arg0_done)-LOCAL(zero_denorm_arg1_dispatch)
+LOCAL(both_denorm_cleanup_off):
+	.word LOCAL(both_denorm_cleanup)-LOCAL(zero_denorm_arg1_dispatch)
+
+ .balign	8
+GLOBAL(divdf3):
+ mov.l	LOCAL(x7ff00000),r2
+ mov	#12,r3
+ mov.l	LOCAL(xfffe2006),r1	! yn := (-1. << 17) + (0x80 << 6) ; shift #-26
+ tst	r2,DBL1H
+ mov.l	r12,@-r15
+ bt	LOCAL(zero_denorm_arg1)
+
+LOCAL(denorm_arg1_done):
+ mov	DBL1H,x_h	! x_h live in r12
+ shld	r3,x_h	! x - 1 ; u0.20
+ mov	x_h,yn
+ mova	LOCAL(ytab),r0
+ mov.l	r8,@-r15
+ shld	r1,yn	! x-1 ; u26.6
+ mov.b	@(r0,yn),yn
+ mov	#6,r0
+ mov.l	r9,@-r15
+ mov	x_h,r8
+ mov.l	r10,@-r15
+ shlr16	x_h	! x - 1; u16.16	! x/2 - 0.5 ; u15.17
+ add	x_h,r1	! SH4-200 single-issues this insn
+ shld	r0,yn
+ sub	r1,yn	! yn := y0 ; u15.17
+ mov	DBL1L,r1
+ mov	#-20,r10
+ mul.l	yn,x_h	! r12 dead
+ swap.w	yn,r9
+ shld	r10,r1
+ sts	macl,r0	! y0 * (x-1) - n ; u-1.32
+ add	r9,r0	! y0 * x - 1     ; s-1.32
+ tst	r2,DBL0H
+ dmuls.l r0,yn
+ mov.w	LOCAL(d13),r0
+ or	r1,r8	! x  - 1; u0.32
+ add	yn,yn	! yn = y0 ; u14.18
+ bt	LOCAL(zero_denorm_arg0)
+
+LOCAL(denorm_arg0_done):	! This label must stay aligned.
+ sts	mach,r1	!      d0 ; s14.18
+ sub	r1,yn	! yn = y1 ; u14.18 ; <= 0x3fffc
+ mov	DBL0L,r12
+ shld	r0,yn	! yn = y1 ; u1.31 ; <= 0x7fff8000
+ mov.w	LOCAL(d12),r9
+ dmulu.l yn,r8
+ shld	r10,r12
+ mov	yn,r0
+ mov	DBL0H,r8
+ add	yn,yn	! yn = y1 ; u0.32 ; <= 0xffff0000
+ sts	mach,r1	! y1 * (x-1); u1.31
+ add	r0,r1	! y1 * x    ; u1.31
+ dmulu.l yn,r1
+ not	DBL0H,r10
+ shld	r9,r8
+ tst	r2,r10
+ or	r8,r12	! a - 1; u0.32
+ bt	LOCAL(inf_nan_arg0)
+ sts	mach,r1	! d1+yn; u1.31
+ sett		! adjust y2 so that it can be interpreted as s1.31
+ not	DBL1H,r10
+ subc	r1,yn	! yn := y2 ; u1.31 ; can be 0x7fffffff
+ mov.l	LOCAL(x001fffff),r9
+ dmulu.l yn,r12
+ tst	r2,r10
+ or	DBL1H,r2
+ bt	LOCAL(inf_nan_arg1)
+ mov.l	r11,@-r15
+ sts	mach,r11	! y2*(a-1) ; u1.31
+ add	yn,r11		! z0       ; u1.31
+ dmulu.l r11,DBL1L
+ mov.l	LOCAL(x40000000),DBLRH	! bias + 1
+ and	r9,r2		! x ; u12.20
+ cmp/hi	DBL0L,DBL1L
+ sts	macl,r8
+ mov	#-24,r12
+ sts	mach,r9 	! r9:r8 := z0 * DBL1L; u-19.64
+ subc	DBL1H,DBLRH
+ mul.l	r11,r2  	! (r9+macl):r8 == z0*x; u-19.64
+ shll	r8
+ add	DBL0H,DBLRH	! result sign/exponent + 1
+ mov	r8,r10
+ sts	macl,DBLRL
+ add	DBLRL,r9
+ rotcl	r9		! r9:r8 := z*x; u-20.63
+ shld	r12,r10
+ mov.l	LOCAL(x7fe00000),DBLRL
+ sub	DBL0L,r9	! r9:r8 := -a ; u-20.63
+ mov.l	LOCAL(x00200000),r12
+FIXME: the following  shift might loose the sign.
+ shll8	r9
+ or	r10,r9	! -a1 ; s-28.32
+ mov.l	LOCAL(x00100000),r10
+ dmuls.l r9,yn	! r3 dead
+ mov	DBL1H,r3
+ mov.l LOCAL(xfff00000),DBL0L
+ xor	DBL0H,r3	! calculate expected sign & bit20
+ div0s	r3,DBLRH
+ xor	DBLRH,r3
+ bt	LOCAL(ret_denorm_inf)
+ tst	DBLRL,DBLRH
+ bt	LOCAL(ret_denorm)
+ sub	r12,DBLRH ! calculate sign / exponent minus implicit 1
+ tst	r10,r3	! set T if a >= x
+ sts	mach,r12! -z1 ; s-27.32
+ bt	0f
+ add	r11,r11	! z0 ; u1.31 / u0.31
+0: mov	#6,r3
+ negc	r3,r10 ! shift count := a >= x ? -7 : -6; T := 1
+ shll8	r8	! r9:r8 := -a1 ; s-28.64
+ shad	r10,r12	! -z1 ; truncate to s-20.32 / s-21.32
+ rotcl	r12	! -z1 ; s-21.32 / s-22.32 / round to odd 0.5 ulp ; T := sign
+ add	#20,r10
+ dmulu.l r12,DBL1L ! r12 signed, DBL1L unsigned
+ and	DBL0L,DBLRH	! isolate sign / exponent
+ shld	r10,r9
+ mov	r8,r3
+ shld	r10,r8
+ sts	macl,DBL0L
+ sts	mach,DBLRL
+ add	#-32,r10
+ shld	r10,r3
+ mul.l r12,r2
+ bf	0f	! adjustment for signed/unsigned multiply
+ sub	DBL1L,DBLRL	! DBL1L dead
+0: shar	r12	! -z1 ; truncate to s-20.32 / s-21.32
+ sts	macl,DBL1L
+ or	r3,r9	! r9:r8 := -a1 ;             s-41.64/s-42.64
+ !
+ cmp/hi	r8,DBL0L
+ add	DBLRL,DBL1L ! DBL1L:DBL0L := -z1*x ; s-41.64/s-42.64
+ subc	DBL1L,r9
+ not	r12,DBLRL ! z1, truncated to s-20.32 / s-21.32
+ shll	r9	! T :=  a2 > 0
+ mov	r11,r2
+ mov	#21,r7
+ shld	r7,r11
+ addc	r11,DBLRL
+ mov.l	@r15+,r11
+ mov.l	@r15+,r10
+ mov	#-11,r7
+ mov.l	@r15+,r9
+ shld	r7,r2
+ mov.l	@r15+,r8
+ addc	r2,DBLRH
+ rts
+ mov.l	@r15+,r12
+
+LOCAL(ret_denorm):
+	tst	r10,DBLRH
+	bra	LOCAL(denorm_have_count)
+	movt	DBLRH	! calculate shift count (off by 2)
+
+LOCAL(ret_denorm_inf):
+	mov	DBLRH,r12
+	add	r12,r12
+	cmp/pz	r12
+	mov	#-21,DBLRL
+	bt	LOCAL(ret_inf_late)
+	shld	DBLRL,DBLRH
+LOCAL(denorm_have_count):
+	add	#-2,DBLRH
+/* FIXME */
+	bra	LOCAL(return_0)
+	mov.l	@r15+,r11
+
+LOCAL(ret_inf_late):
+	mov.l	@r15+,r11
+	!
+	mov.l	@r15+,r10
+	!
+	mov.l	@r15+,r9
+	bra	LOCAL(return_inf)
+	mov.l	@r15+,r8
+
+	.balign	4
+LOCAL(clz):
+	mov.l	r8,@-r15
+	extu.w	r0,r8
+	mov.l	r9,@-r15
+	cmp/eq	r0,r8
+	bt/s	0f
+	mov	#8-11,r9
+	xtrct	r0,r8
+	add	#16,r9
+0:	tst	r12,r8	! 0xff00
+	mov.l	LOCAL(c_clz_tab),r0
+	bt	0f
+	shlr8	r8
+0:	bt	0f
+	add	#8,r9
+0:
+#ifdef	__PIC__
+	add	r0,r8
+	mova	LOCAL(c_clz_tab),r0
+#endif
+	mov.b	@(r0,r8),r8
+	mov	r9,r0
+	mov.l	@r15+,r9
+	!
+	!
+	!
+	sub	r8,r0
+	mov.l	@r15+,r8
+	rts
+	lds.l	@r15+,pr
+
+!	We encode even some words as pc-relative that would fit as immediate
+!	in the instruction in order to avoid some pipeline stalls on
+!	SH4-100 / SH4-200.
+LOCAL(d1):	.word 1
+LOCAL(d12):	.word 12
+LOCAL(d13):	.word 13
+
+	.balign 4
+LOCAL(x7ff00000): .long 0x7ff00000
+LOCAL(xfffe2006): .long 0xfffe2006
+LOCAL(x001fffff): .long 0x001fffff
+LOCAL(x40000000): .long 0x40000000
+LOCAL(x7fe00000): .long 0x7fe00000
+LOCAL(x00100000): .long 0x00100000
+LOCAL(x00200000): .long 0x00200000
+LOCAL(xfff00000): .long 0xfff00000
+LOCAL(c_clz_tab):
+#ifdef __pic__
+        .long   GLOBAL(clz_tab) - .
+#else
+        .long   GLOBAL(clz_tab)
+#endif
+LOCAL(ytab):
+        .byte   120, 105,  91,  78,  66,  54,  43,  33
+        .byte    24,  15,   8,   0,  -5, -12, -17, -22
+        .byte   -27, -31, -34, -37, -40, -42, -44, -45
+        .byte   -46, -46, -47, -46, -46, -45, -44, -42
+        .byte   -41, -39, -36, -34, -31, -28, -24, -20
+        .byte   -17, -12,  -8,  -4,   0,   5,  10,  16
+        .byte    21,  27,  33,  39,  45,  52,  58,  65
+        .byte    72,  79,  86,  93, 101, 109, 116, 124
+ENDFUNC(GLOBAL(divdf3))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/divdf3.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/divdf3.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/divdf3.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/divdf3.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,668 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! divdf3 for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke joern.rennecke@st.com
+
+/* y = 1/x  ; x (- [1,2)
+   y0 = 1.5 - x/2 - tab[(1-x)*64] = y + d ; abs(d)/y <= 0x1.0c/256
+
+   y1 = y0 - ((y0) * x - 1) * y0  =  y-x*d^2
+   y2 = y1 - ((y1) * x - 1) * y1 =~= y-x^3*d^4
+
+   z0 = y2*a ;  a1 = a - z0*x /# 32 * 64 -> 64 bit #/
+   z1 = y2*a1 (round to nearest odd 0.5 ulp);
+   a2 = a1 - z1*x /# 32 * 64 -> 64 bit #/
+
+   z = a/x = z0 + z1 - 0.5 ulp + (a2 > 0) * ulp
+
+   Unless stated otherwise, multiplies can be done in 32 * 32 bit or less
+   with suitable scaling and/or top truncation.
+   We use a slightly modified algorithm here that checks if the lower
+   bits in z1 are sufficient to determine the outcome of rounding - in that
+   case a2 is not computed.
+   -z1 is computed in units of 1/128 ulp, with an error in the range
+   -0x3.e/128 .. +0 ulp.
+   Thus, after adding three, the result can be safely rounded for normal
+   numbers if any of the bits 5..2 is set, or if the highest guard bit
+   (bit 6 if y <1, otherwise bit 7) is set.
+   (Because of the way truncation works, we would be fine for an open
+    error interval of (-4/128..+1/128) ulp )
+   For denormal numbers, the rounding point lies higher, but it would be
+   quite cumbersome to calculate where exactly; it is sufficient if any
+   of the bits 7..3 is set.
+   x truncated to 20 bits is sufficient to calculate y0 or even y1.
+   Table entries are adjusted by about +128 to use full signed byte range.
+   This adjustment has been perturbed slightly to allow cse with the
+   shift count constant -26.
+   The threshold point for the shift adjust before rounding is found by
+   comparing the fractions, which is exact, unlike the top bit of y2.
+   Therefore, the top bit of y2 becomes slightly random after the adjustment
+   shift, but that's OK because this can happen only at the boundaries of
+   the interval, and the biasing of the error means that it can in fact happen
+   only at the bottom end.  And there, the carry propagation will make sure
+   that in the end we will have in effect an implicit 1 (or two whem rounding
+   up...)  */
+/* If an exact result exists, it can have no more bits than the divident.
+   Hence, we don't need to bother with the round-to-even tie breaker
+   unless the result is denormalized.  */
+/* 64 cycles through main path for sh4-300 (about 93.7% of normalized numbers),
+   82 for the path for rounding tie-breaking for normalized numbers
+   (including one branch mispredict).
+   Some cycles might be saved by more careful register allocation.  */
+
+#define x_h r12
+#define yn  r3
+
+FUNC(GLOBAL(divdf3))
+ .global GLOBAL(divdf3)
+
+/* Adjust arg0 now, too.  We still have to come back to denorm_arg1_done,
+   since we heven't done any of the work yet that we do till the denorm_arg0
+   entry point.  We know that neither of the arguments is inf/nan, but
+   arg0 might be zero.  Check for that first to avoid having to establish an
+   rts return address.  */
+LOCAL(both_denorm):
+	mov.l	r9,@-r15
+	mov	DBL0H,r1
+	mov.l	r0,@-r15
+	shll2	r1
+	mov.w LOCAL(both_denorm_cleanup_off),r9
+	or	DBL0L,r1
+	tst	r1,r1
+	mov	DBL0H,r0
+	bf/s	LOCAL(zero_denorm_arg0_1)
+	shll2	r0
+	mov.l	@(4,r15),r9
+	add	#8,r15
+	bra	LOCAL(ret_inf_nan_0)
+	mov	r1,DBLRH
+
+LOCAL(both_denorm_cleanup):
+	mov.l	@r15+,r0
+	!
+	mov.l	@r15+,r9
+ mov	#12,r3
+ mov.l	LOCAL(xfffe2006),r1	! yn := (-1. << 17) + (0x80 << 6) ; shift #-26
+	bra	LOCAL(denorm_arg1_done)
+	!
+	add	r0,DBL0H
+
+/* Denorm handling leaves the incoming denorm argument with an exponent of +1
+   (implicit 1).  To leave the result exponent unaltered, the other
+   argument's exponent is adjusted by the the shift count.  */
+
+	.balign 4
+LOCAL(arg0_tiny):
+	bsr	LOCAL(clz)
+	mov	DBL0L,r0
+	shll	DBL0H
+	add	#1,r0
+	mov	DBL0L,DBL0H
+	shld	r0,DBL0H
+	rotcr	DBL0H
+	
+	cmp/pl r0
+	bf/s	LOCAL(a0t_dpt_neg)
+	tst	DBL0L,DBL0L	/* Check for divide of zero.  */
+	add	#-32,r0
+	shld	r0,DBL0L
+	bf/s	LOCAL(adjust_arg1_exp)
+	add	#63,r0
+	bra 	LOCAL(return_0)
+	nop
+
+LOCAL(a0t_dpt_neg):
+	add 	#31,r0
+	bf/s	LOCAL(adjust_arg1_exp)
+	shld	r0,DBL0L
+		  
+LOCAL(return_0): /* Return 0 with appropriate sign.  */
+	mov.l	@r15+,r10
+	mov	#0,DBLRH
+	mov.l	@r15+,r9
+	bra	LOCAL(ret_inf_nan_0)
+	mov.l	@r15+,r8
+
+	.balign 4
+LOCAL(arg1_tiny):
+	bsr	LOCAL(clz)
+	mov	DBL1L,r0
+	shll	DBL1H
+	add	#1,r0
+	mov	DBL1L,DBL1H
+	shld	r0,DBL1H
+	rotcr	DBL1H
+
+	cmp/pl r0
+	bf/s	LOCAL(a1t_dpt_neg)
+	tst	DBL1L,DBL1L	/* Check for divide by zero.  */
+	add	#-32,r0
+	shld	r0,DBL1L
+	bf/s	LOCAL(adjust_arg0_exp)
+	add	#63,r0
+	bra 	LOCAL(a1t_end)
+	nop
+
+LOCAL(a1t_dpt_neg):
+	add 	#31,r0
+	bf/s	LOCAL(adjust_arg0_exp)
+	shld	r0,DBL1L
+	
+LOCAL(a1t_end):		  		  
+	mov	DBL0H,r0
+	add	r0,r0
+	tst	r0,r0	! 0 / 0 ?
+	mov	#-1,DBLRH
+	bf	LOCAL(return_inf)
+	!
+	tst   DBL0L,DBL0L
+	bf	LOCAL(return_inf)
+	bt	LOCAL(ret_inf_nan_0)
+	!
+
+	.balign 4
+LOCAL(zero_denorm_arg1):
+	not	DBL0H,r3
+	mov	DBL1H,r0
+	tst	r2,r3
+	shll2	r0
+	bt	LOCAL(early_inf_nan_arg0)
+	tst	r0,r0
+	mov.w	LOCAL(xff00),r12
+	bt/s	LOCAL(arg1_tiny)
+	sts.l	pr,@-r15
+	bsr	LOCAL(clz)
+	shlr2	r0
+	!
+	shll	DBL1H
+	mov	DBL1L,r3
+	shld	r0,DBL1H
+	shld	r0,DBL1L
+	rotcr	DBL1H
+	add	#-32,r0
+	shld	r0,r3
+	add	#32,r0
+	or	r3,DBL1H
+LOCAL(adjust_arg0_exp):
+	tst	r2,DBL0H
+	mov	#20,r3
+	shld	r3,r0
+	bt	LOCAL(both_denorm)
+	add	DBL0H,r0
+	div0s	r0,DBL0H	! Check for obvious overflow.  */
+	not	r0,r3		! Check for more subtle overflow - lest
+	bt	LOCAL(return_inf)
+	mov	r0,DBL0H
+	tst	r2,r3		! we mistake it for NaN later
+	mov	#12,r3
+	bf	LOCAL(denorm_arg1_done)
+LOCAL(return_inf): /* Return infinity with appropriate sign.  */
+	mov	#20,r3
+	mov	#-2,DBLRH
+	bra	LOCAL(ret_inf_nan_0)
+	shad	r3,DBLRH
+
+/* inf/n -> inf; inf/0 -> inf; inf/inf -> nan; inf/nan->nan  nan/x -> nan */
+LOCAL(inf_nan_arg0):
+	mov.l	@r15+,r10
+	mov.l	@r15+,r9
+	mov.l	@r15+,r8
+LOCAL(early_inf_nan_arg0):
+	not	DBL1H,r3
+	mov	DBL0H,DBLRH
+	tst	r2,r3	! both inf/nan?
+	add	DBLRH,DBLRH
+	bf	LOCAL(ret_inf_nan_0)
+	mov	#-1,DBLRH
+LOCAL(ret_inf_nan_0):
+	mov	#0,DBLRL
+	mov.l	@r15+,r12
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+	
+/* Already handled: inf/x, nan/x .  Thus: x/inf -> 0; x/nan -> nan */
+	.balign	4
+LOCAL(inf_nan_arg1):
+	mov	DBL1H,r2
+	mov	#12,r1
+	shld	r1,r2
+	mov.l	@r15+,r10
+	mov	#0,DBLRL
+	mov.l	@r15+,r9
+	or	DBL1L,r2
+	mov.l	@r15+,r8
+	cmp/hi	DBLRL,r2
+	mov.l	@r15+,r12
+	subc	DBLRH,DBLRH
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+	
+	.balign 4
+LOCAL(zero_denorm_arg0):
+	mov.w	LOCAL(denorm_arg0_done_off),r9
+	not	DBL1H,r1
+	mov	DBL0H,r0
+	tst	r2,r1
+	shll2	r0
+	bt	LOCAL(inf_nan_arg1)
+LOCAL(zero_denorm_arg0_1):
+	tst	r0,r0
+	mov.w	LOCAL(xff00),r12
+	bt/s	LOCAL(arg0_tiny)
+	sts.l	pr,@-r15
+	bsr	LOCAL(clz)
+	shlr2	r0
+	shll	DBL0H
+	mov	DBL0L,r12
+	shld	r0,DBL0H
+	shld	r0,DBL0L
+	rotcr	DBL0H
+	add	#-32,r0
+	shld	r0,r12
+	add	#32,r0
+	or	r12,DBL0H
+LOCAL(adjust_arg1_exp):
+	mov	#20,r12
+	shld	r12,r0
+	add	DBL1H,r0
+	div0s	r0,DBL1H	! Check for obvious underflow.  */
+	not	r0,r12		! Check for more subtle underflow - lest
+	bt	LOCAL(return_0)
+	mov	r0,DBL1H
+	tst	r2,r12		! we mistake it for NaN later
+	bt	LOCAL(return_0)
+	!
+	braf	r9
+	mov	#13,r0
+LOCAL(zero_denorm_arg1_dispatch):
+
+LOCAL(xff00):	.word 0xff00
+LOCAL(denorm_arg0_done_off):
+	.word LOCAL(denorm_arg0_done)-LOCAL(zero_denorm_arg1_dispatch)
+LOCAL(both_denorm_cleanup_off):
+	.word LOCAL(both_denorm_cleanup)-LOCAL(zero_denorm_arg1_dispatch)
+
+ .balign	8
+GLOBAL(divdf3):
+ mov.l	LOCAL(x7ff00000),r2
+ mov	#12,r3
+ mov.l	LOCAL(xfffe2006),r1	! yn := (-1. << 17) + (0x80 << 6) ; shift #-26
+ tst	r2,DBL1H
+ mov.l	r12,@-r15
+ bt	LOCAL(zero_denorm_arg1)
+
+LOCAL(denorm_arg1_done):
+ mov	DBL1H,x_h	! x_h live in r12
+ shld	r3,x_h	! x - 1 ; u0.20
+ mov	x_h,yn
+ mova	LOCAL(ytab),r0
+ mov.l	r8,@-r15
+ shld	r1,yn	! x-1 ; u26.6
+ mov.b	@(r0,yn),yn
+ mov	#6,r0
+ mov.l	r9,@-r15
+ mov	x_h,r8
+ mov.l	r10,@-r15
+ shlr16	x_h	! x - 1; u16.16	! x/2 - 0.5 ; u15.17
+ add	x_h,r1	! SH4-200 single-issues this insn
+ shld	r0,yn
+ sub	r1,yn	! yn := y0 ; u15.17
+ mov	DBL1L,r1
+ mov	#-20,r10
+ mul.l	yn,x_h	! r12 dead
+ swap.w	yn,r9
+ shld	r10,r1
+ sts	macl,r0	! y0 * (x-1) - n ; u-1.32
+ add	r9,r0	! y0 * x - 1     ; s-1.32
+ tst	r2,DBL0H
+ dmuls.l r0,yn
+ mov.w	LOCAL(d13),r0
+ or	r1,r8	! x  - 1; u0.32
+ add	yn,yn	! yn = y0 ; u14.18
+ bt	LOCAL(zero_denorm_arg0)
+
+LOCAL(denorm_arg0_done):
+ sts	mach,r1	!      d0 ; s14.18
+ sub	r1,yn	! yn = y1 ; u14.18 ; <= 0x3fffc
+ mov	DBL0L,r12
+ shld	r0,yn	! yn = y1 ; u1.31 ; <= 0x7fff8000
+ mov.w	LOCAL(d12),r9
+ dmulu.l yn,r8
+ shld	r10,r12
+ mov	yn,r0
+ mov	DBL0H,r8
+ add	yn,yn	! yn = y1 ; u0.32 ; <= 0xffff0000
+ sts	mach,r1	! y1 * (x-1); u1.31
+ add	r0,r1	! y1 * x    ; u1.31
+ dmulu.l yn,r1
+ not	DBL0H,r10
+ shld	r9,r8
+ tst	r2,r10
+ or	r8,r12	! a - 1; u0.32
+ bt	LOCAL(inf_nan_arg0)
+ sts	mach,r1	! d1+yn; u1.31
+ sett		! adjust y2 so that it can be interpreted as s1.31
+ not	DBL1H,r10
+ subc	r1,yn	! yn := y2 ; u1.31 ; can be 0x7fffffff
+ mov.l	LOCAL(x001fffff),r9
+ dmulu.l yn,r12
+ tst	r2,r10
+ or	DBL1H,r2
+ bt	LOCAL(inf_nan_arg1)
+ mov.l	r11,@-r15
+ sts	mach,r12	! y2*(a-1) ; u1.31
+ add	yn,r12		! z0       ; u1.31
+ dmulu.l r12,DBL1L
+ mov.l	LOCAL(x40000000),DBLRH ! bias + 1
+ and	r9,r2		! x ; u12.20
+ cmp/hi	DBL0L,DBL1L
+ sts	macl,r8
+ mov	#-24,r11
+ sts	mach,r9 	! r9:r8 := z0 * DBL1L; u-19.64
+ 
+ subc	DBL1H,DBLRH
+ mul.l	r12,r2  	! (r9+macl):r8 == z0*x; u-19.64
+ shll	r8
+ add	DBL0H,DBLRH	! result sign/exponent + 1
+ mov	r8,r10
+ sts	macl,DBLRL
+ add	DBLRL,r9
+ rotcl	r9		! r9:r8 := z*x; u-20.63
+ shld	r11,r10
+
+! mov.l	LOCAL(xfff00000),DBLRL
+! mov DBL1H,r11
+! and DBLRL,r11
+! subc r11,DBLRH
+! add DBL0H,DBLRH
+		  
+ mov.l	LOCAL(x7fe00000),DBLRL
+ sub	DBL0L,r9	! r9:r8 := -a ; u-20.63
+ cmp/pz	r9		! In corner cases this shift can loose ..
+ shll8	r9		!  .. the sign, so check it first.
+ mov.l	LOCAL(x00200000),r11
+ !mov.l	LOCAL(x00100000),r11
+ or	r10,r9	! -a1 ; s-28.32
+ mov.l	LOCAL(x00100000),r10
+ dmulu.l r9,yn	! sign for r9 is in T
+ xor	DBL0H,DBL1H	! calculate expected sign & bit20
+ mov.w	LOCAL(d120),DBL0H ! to test bits 6..4
+ xor	DBLRH,DBL1H
+ !
+ sts	mach,DBL0L	! -z1 ; s-27.32
+ bt 0f
+ sub	yn,DBL0L	! multiply adjust for -a1 negative; r3 dies here
+0:tst	r10,DBL1H		! set T if a >= x
+ mov.l LOCAL(xfff00000),r3
+ bt	0f
+ add	DBL0L,DBL0L	! z1 ; s-27.32 / s-28.32
+0:bt 0f
+ add	r12,r12	! z0 ; u1.31 / u0.31
+0:add	#6-64,DBL0L
+ and	r3,DBLRH	! isolate sign / exponent
+ tst	DBL0H,DBL0L
+ bf/s	LOCAL(exact)	! make the hot path taken for best branch prediction
+ cmp/pz	DBL1H
+
+! Unless we follow the next branch, we need to test which way the rounding
+! should go.
+! For normal numbers, we know that the result is not exact, so the sign
+! of the rest will be conclusive.
+! We generate a number that looks safely rounded so that denorm handling
+! can safely test the number twice.
+! r10:r8 == 0 will indicate if the number was exact, which can happen
+! when we come here for denormals to check a number that is close or
+! equal to a result in whole ulps.
+ bf	LOCAL(ret_denorm_inf)	! denorm or infinity, DBLRH has inverted sign
+ add	#64,DBL0L
+LOCAL(find_adjust): tst	r10,DBL1H ! set T if a >= x
+ mov	#-2,r10
+ addc	r10,r10
+ mov	DBL0L,DBLRL	! z1 ; s-27.32 / s-28.32 ; lower 4 bits unsafe.
+ shad	r10,DBLRL	! tentatively rounded z1 ; s-24.32
+ shll8	r8		! r9:r8 := -a1 ; s-28.64
+ clrt
+ dmuls.l DBLRL,DBL1L	! DBLRL signed, DBL1L unsigned
+ mov	r8,r10
+ shll16	r8		! r8  := lowpart  of -a1 ; s-44.48
+ xtrct	r9,r10		! r10 := highpart of -a1 ; s-44.48
+ !
+ sts	macl,r3
+ subc	r3,r8
+ sts	mach,r3
+ subc	r3,r10
+ cmp/pz	DBL1L
+ mul.l	DBLRL,r2
+ bt	0f
+ sub	DBLRL,r10	! adjust for signed/unsigned multiply
+0: mov.l	LOCAL(x7fe00000),DBLRL
+ mov	#-26,r2
+ sts	macl,r9
+ sub	r9,r10		! r10:r8 := -a2
+ add	#-64+16,DBL0L	! the denorm code negates this adj. for exact results
+ shld	r2,r10		! convert sign into adjustment in the range 32..63
+ sub	r10,DBL0L
+ cmp/pz	DBL1H
+
+ .balign 4
+LOCAL(exact):
+ bf	LOCAL(ret_denorm_inf)	! denorm or infinity, DBLRH has inverted sign
+ tst	DBLRL,DBLRH
+ bt	LOCAL(ret_denorm_inf)	! denorm, DBLRH has correct sign
+ mov	#-7,DBL1H
+ cmp/pz	DBL0L		! T is sign extension of z1
+ not	DBL0L,DBLRL
+ subc	r11,DBLRH	! calculate sign / exponent minus implicit 1 minus T
+ mov.l	@r15+,r11
+ mov.l	@r15+,r10
+ shad	DBL1H,DBLRL
+ mov.l	@r15+,r9
+ mov	#-11,DBL1H
+ mov	r12,r8		! z0 contributes to DBLRH and DBLRL
+ shld	DBL1H,r12
+ mov	#21,DBL1H
+ clrt
+ shld	DBL1H,r8
+ addc	r8,DBLRL
+ mov.l	@r15+,r8
+ addc	r12,DBLRH
+ rts
+ mov.l	@r15+,r12
+
+!	sign in DBLRH ^ DBL1H
+! If the last 7 bits are in the range 64..64+7, we might have an exact
+! value in the preceding bits - or we might not. For denorms, we need to
+! find out.
+! if r10:r8 is zero, we just have found out that there is an exact value.
+	.balign	4
+LOCAL(ret_denorm_inf):
+	mov	DBLRH,r3
+	add	r3,r3
+	div0s	DBL1H,r3
+!	mov	#248,DBLRL
+	mov	#120,DBLRL
+	bt	LOCAL(ret_inf_late)
+	add	#64,DBL0L
+	tst	DBLRL,DBL0L
+	mov	#-21,DBLRL
+	bt	LOCAL(find_adjust)
+	or	r10,r8
+!	add	#-64,DBL0L
+	tst	r8,r8		! check if find_adjust found an exact value.
+	shad	DBLRL,r3
+	bf	0f
+	add	#-16,DBL0L	! if yes, cancel adjustment
+0:	mov	#-8,DBLRL	! remove the three lowest (inexact) bits
+	and	DBLRL,DBL0L
+	add	#-2-11,r3	! shift count for denorm generation
+	neg 	DBL0L,DBL0L
+	mov	#-28,r2
+	mov	DBL0L,DBLRL
+	mov.l	@r15+,r11
+	mov.l	@r15+,r10
+	shll2	DBLRL
+	mov.l	@r15+,r9
+	shad	r2,DBL0L
+	mov.l	@r15+,r8
+	mov	#-31,r2
+	cmp/ge	r2,r3
+	shll2	DBLRL
+	bt/s	0f
+	add	DBL0L,r12	! fraction in r12:DBLRL ; u1.63
+	mov	#0,r2
+	cmp/hi r2,DBLRL
+	mov	#-33,r2
+	add	#31,r3
+	mov	r12,DBLRL
+	rotcl	DBLRL		! put in sticky bit
+	movt	r12
+	cmp/ge	r3,r2
+	bt	LOCAL(test1)
+0:	div0s	DBL1H,DBLRH	! calculate sign
+	mov	r12,DBLRH
+	shld	r3,DBLRH
+	mov	DBLRL,r2
+	shld	r3,DBLRL
+	add	#32,r3
+	add	DBLRH,DBLRH
+	mov.l	LOCAL(x80000000),DBL1H
+	shld	r3,r12
+	rotcr	DBLRH		! combine sign with highpart
+	add	#-1,r3
+	shld	r3,r2
+	mov	#0,r3
+	rotl	r2
+	cmp/hi	DBL1H,r2
+	addc	r12,DBLRL
+	mov.l	@r15+,r12
+	rts
+	addc	r3,DBLRH
+
+LOCAL(test1):
+	cmp/ge	r2,r3
+	bf/s	LOCAL(return_0_late)
+	div0s	DBL1H,DBLRH
+	mov #0,DBLRH
+	mov	DBLRL,r2
+	mov #0,DBLRL
+	rotcr	DBLRH		! combine sign with highpart
+	mov	#0,r3
+	rotl	r2
+	cmp/hi	r3,r2
+	addc	r3,DBLRL
+	mov.l	@r15+,r12
+	rts
+	addc	r3,DBLRH
+		  
+		  
+LOCAL(ret_inf_late):
+	mov.l	@r15+,r11
+	mov.l	@r15+,r10
+	mov	DBLRH,DBL0H
+	mov.l	@r15+,r9
+	bra	LOCAL(return_inf)
+	mov.l	@r15+,r8
+
+LOCAL(return_0_late):
+	div0s	DBLRH,DBL1H
+	mov.l	@r15+,r12
+	mov	#0,DBLRH
+	mov	#0,DBLRL
+	rts
+	rotcr	DBLRH
+
+	
+	
+	.balign	4
+LOCAL(clz):
+	mov.l	r8,@-r15
+	extu.w	r0,r8
+	mov.l	r9,@-r15
+	cmp/eq	r0,r8
+	bt/s	0f
+	mov	#21,r9
+	shlr16	r0
+	extu.w	r0,r8
+	add	#-16,r9
+0:	tst	r12,r8	! 0xff00
+	mov.l	LOCAL(c_clz_tab),r0
+	bt	0f
+	shlr8	r8
+0:	bt	0f
+	add	#-8,r9
+0:
+#ifdef	__PIC__
+	add	r0,r8
+	mova	LOCAL(c_clz_tab),r0
+#endif
+	mov.b	@(r0,r8),r8
+	mov	r9,r0
+	mov.l	@r15+,r9
+	!
+	!
+	!
+	sub	r8,r0
+	mov.l	@r15+,r8
+	rts
+	lds.l	@r15+,pr
+
+!	We encode even some words as pc-relative that would fit as immediate
+!	in the instruction in order to avoid some pipeline stalls on
+!	SH4-100 / SH4-200.
+LOCAL(d1):	.word 1
+LOCAL(d12):	.word 12
+LOCAL(d13):	.word 13
+LOCAL(d120):	.word 120
+
+	.balign 4
+LOCAL(x7ff00000): .long 0x7ff00000
+LOCAL(xfffe2006): .long 0xfffe2006
+LOCAL(x001fffff): .long 0x001fffff
+LOCAL(x40000000): .long 0x40000000
+LOCAL(x7fe00000): .long 0x7fe00000
+LOCAL(x00100000): .long 0x00100000
+LOCAL(x00200000): .long 0x00200000
+LOCAL(xfff00000): .long 0xfff00000
+LOCAL(x80000000): .long 0x80000000
+LOCAL(c_clz_tab):
+#ifdef __pic__
+        .long   GLOBAL(clz_tab) - .
+#else
+        .long   GLOBAL(clz_tab)
+#endif
+LOCAL(ytab):
+        .byte   120, 105,  91,  78,  66,  54,  43,  33
+        .byte    24,  15,   8,   0,  -5, -12, -17, -22
+        .byte   -27, -31, -34, -37, -40, -42, -44, -45
+        .byte   -46, -46, -47, -46, -46, -45, -44, -42
+        .byte   -41, -39, -36, -34, -31, -28, -24, -20
+        .byte   -17, -12,  -8,  -4,   0,   5,  10,  16
+        .byte    21,  27,  33,  39,  45,  52,  58,  65
+        .byte    72,  79,  86,  93, 101, 109, 116, 124
+ENDFUNC(GLOBAL(divdf3))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/divsf3.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/divsf3.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/divsf3.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/divsf3.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,375 @@
+/* Copyright (C) 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! divsf3 for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+!
+! This code is optimized for SH4 without FPU, but can also be used for SH3.
+
+! long 0th..3rd significant byte
+#ifdef __LITTLE_ENDIAN__
+#define L0SB	3
+#define L1SB	2
+#define L2SB	1
+#define L3SB	0
+#else
+#define L0SB	0
+#define L1SB	1
+#define L2SB	2
+#define L3SB	3
+#endif
+
+! clobbered: r0,r1,r2,r3,r6,r7,T (and for sh.md's purposes PR)
+!
+! Note: When the divisor is larger than the divident, we have to adjust the
+! exponent down by one.  We do this automatically when subtracting the entire
+! exponent/fraction bitstring as an integer, by means of the borrow from
+! bit 23 to bit 24.
+! Note: non-denormal rounding of a division result cannot cause fraction
+! overflow / exponent change. (r4 > r5 : fraction must stay in (2..1] interval;
+! r4 < r5: having an extra bit of precision available, even the smallest
+! possible difference of the result from one is rounded in all rounding modes
+! to a fraction smaller than one.)
+! sh4-200: 59 cycles
+! sh4-300: 44 cycles
+! tab indent: exponent / sign computations
+! tab+space indent: fraction computation
+FUNC(GLOBAL(divsf3))
+	.global GLOBAL(divsf3)
+	.balign	4
+GLOBAL(divsf3):
+	mov.l	LOCAL(x7f800000),r3
+	mov	#1,r2
+	mov	r4,r6
+	 shll8	 r6
+	mov	r5,r7
+	 shll8	 r7
+	rotr	r2
+	tst	r3,r4
+	or	r2,r6
+	bt/s	LOCAL(denorm_arg0)
+	or	r2,r7
+	tst	r3,r5
+	bt	LOCAL(denorm_arg1)
+	mov.l	LOCAL(x3f000000),r3	! bias minus explict leading 1
+	 div0u
+LOCAL(denorm_done):
+!	mov.l	LOCAL(x3f000000),r3	! bias minus explict leading 1
+	cmp/hs	r7,r6
+	mov.l	r8,@-r15
+	mov.l	LOCAL(xff800000),r8
+	bt		LOCAL(no_norm)
+	add  	r8,r3
+LOCAL(no_norm):
+	shlr	 r6
+	 div1	 r7,r6
+	 bt	 0f
+	 div1	r7,r6
+0:	mov.l	r9,@-r15
+	 div1	 r7,r6
+	mov	r4,r1
+	and	r8,r1
+	add	r1,r3
+	 div1	 r7,r6
+	and	r5,r8
+	sub	r8,r3	! result sign/exponent minus 1 if no overflow/underflow
+	 div1	 r7,r6
+	or	r3,r2
+	 div1	 r7,r6
+	mov.w	LOCAL(xff00),r9
+	 div1	 r7,r6
+	mov.l	r2,@-r15 ! L0SB is 0xff iff denorm / infinity exp is computed
+	 div1	 r7,r6
+	mov.w	LOCAL(m23),r2
+	 div1	 r7,r6
+	mov	r4,r0
+	 div1	 r7,r6
+	 extu.b	 r6,r1
+	 and	 r9,r6
+	 swap.w	 r1,r1	! first 8 bits of result fraction in bit 23..16
+	 div1	 r7,r6
+	shld	r2,r0
+	 div1	 r7,r6
+	mov.b	r0,@(L3SB,r15)	! 0xff iff divident was infinity / nan
+	 div1	 r7,r6
+	mov	r5,r0
+	 div1	 r7,r6
+	shld	r2,r0
+	 div1	 r7,r6
+	mov.b	r0,@(L2SB,r15)	! 0xff iff divisor was infinity / nan
+	 div1	 r7,r6
+	mov	r4,r0
+	 div1	 r7,r6
+	mov.w	LOCAL(m31),r2
+	 div1	 r7,r6
+	 extu.b	 r6,r8	! second 8 bits of result fraction in bit 7..0
+	 and	 r9,r6
+	mov.l	LOCAL(xff800000),r9
+	 div1	 r7,r6
+	xor	r5,r0	! msb := correct result sign
+	 div1	 r7,r6
+	xor	r3,r0	! xor with sign of result sign/exponent word
+	 div1	 r7,r6
+	shad	r2,r0
+	 div1	 r7,r6
+	mov.b	r0,@(L1SB,r15)	! 0xff	iff exponent over/underflows
+	and	r9,r3	! isolate sign / exponent
+	 div1	 r7,r6
+	 swap.b	r8,r0	! second 8 bits of result fraction in bit 15..8
+	 div1	 r7,r6
+	 or	r1,r0	! first 16 bits of result fraction in bit 23..8
+	 div1	 r7,r6
+	mov.w	LOCAL(m1),r9
+	 div1	 r7,r6
+	mov.l	@r15+,r8 ! load encoding of unusal exponent conditions
+	 extu.b	 r6,r1
+	 or	 r1,r0	! 24 bit result fraction with explicit leading 1
+	addc	r3,r0	! add in exponent / sign
+	cmp/str	r9,r8
+	! (no stall *here* for SH4-100 / SH4-200)
+	bt/s	LOCAL(inf_nan_denorm_zero)
+	mov.l	@r15+,r9
+	rts
+	mov.l	@r15+,r8
+
+/* The exponennt adjustment for denormal numbers is done by leaving an
+   adjusted value in r3; r4/r5 are not changed.  */
+	.balign	4
+LOCAL(denorm_arg0):
+	mov.w	LOCAL(xff00),r1
+	sub	r2,r6	! 0x800000000 : remove implict 1
+	tst	r6,r6
+	bt	LOCAL(div_zero)
+	sts.l	pr,@-r15
+	bsr	LOCAL(clz)
+	mov	r6,r0
+	shld	r0,r6
+	tst	r3,r5
+	mov.l	LOCAL(x3f800000),r3	! bias - 1 + 1
+	mov	#23,r1
+	shld	r1,r0
+	bt/s	LOCAL(denorm_arg1_2)
+	sub	r0,r3
+	bra	LOCAL(denorm_done)
+	 div0u
+
+LOCAL(denorm_arg1):
+	mov.l	LOCAL(x3f000000),r3	! bias - 1
+LOCAL(denorm_arg1_2):
+	sub	r2,r7	! 0x800000000 : remove implict 1
+	mov.w	LOCAL(xff00),r1
+	tst	r7,r7
+	bt	LOCAL(div_by_zero)
+	sts.l	pr,@-r15
+	bsr	LOCAL(clz)
+	mov	r7,r0
+	shld	r0,r7
+	add	#-1,r0
+	mov	#23,r1
+	shld	r1,r0
+	add	r0,r3
+	bra	LOCAL(denorm_done)
+	 div0u
+
+	.balign	4
+LOCAL(inf_nan_denorm_zero):
+! r0 has the rounded result, r6 has the non-rounded lowest bits & rest.
+! the bit just below the LSB of r6 is available as ~Q
+
+! Alternative way to get at ~Q:
+! if rounding took place, ~Q must be set.
+! if the rest appears to be zero, ~Q must be set.
+! if the rest appears to be nonzero, but rounding didn't take place,
+! ~Q must be clear;  the apparent rest will then require adjusting to test if 
+! the actual rest is nonzero.
+	mov	r0,r2
+	not	r8,r0
+	tst	#0xff,r0
+	shlr8	r0
+	mov.l	@r15+,r8
+	bt/s	LOCAL(div_inf_or_nan)
+	tst	#0xff,r0
+	mov	r4,r0
+	bt	LOCAL(div_by_inf_or_nan)
+	add	r0,r0
+	mov	r5,r1
+	add	r1,r1
+	cmp/hi	r1,r0
+	mov	r6,r0
+	bt	LOCAL(overflow)
+	sub	r2,r0
+	exts.b	r0,r0	! -1 if rounding took place
+	shlr8	r6	! isolate div1-mangled rest
+	addc	r2,r0	! generate carry if rounding took place
+	shlr8	r7
+	mov.l	LOCAL(xffffff),r1
+	sub	r3,r0	! pre-rounding fraction
+	bt	0f ! going directly to denorm_sticky would cause mispredicts
+	tst	r6,r6	! rest can only be zero if lost bit was set
+0:	add	r7,r6	! (T ? corrupt : reconstruct) actual rest
+	bt	0f
+	and r1,r6
+	cmp/pl	r6
+0:	mov.w	LOCAL(m24),r1
+	addc	r0,r0	! put in sticky bit
+	add	#-1,r3
+	mov.l	LOCAL(x80000000),r6
+	add	r3,r3
+	mov	r0,r2
+	shad	r1,r3	! exponent ; s32.0
+	!
+	cmp/pl	r3
+	bt/s	LOCAL(zero_nan)	! return zero
+	clrt
+	shld	r3,r0
+	add	#31,r3
+	cmp/pl	r3
+	shld	r3,r2
+	bf	LOCAL(zero_nan)	! return zero
+	rotl	r2
+	cmp/hi	r6,r2
+	mov	#0,r7
+	addc	r7,r0
+	shll	r0
+	div0s	r4,r5
+	rts
+	rotcr	r0
+	
+! ????
+! undo normal rounding (lowest bits still in r6). then do denormal rounding.
+	
+LOCAL(overflow):
+	mov.l	LOCAL(xff000000),r0
+	div0s	r4,r5
+	rts
+	rotcr	r0
+	
+LOCAL(div_inf_or_nan):
+	mov	r4,r0
+	bra	LOCAL(nan_if_t)
+	add	r0,r0
+	
+LOCAL(div_by_inf_or_nan):
+	mov.l	LOCAL(xff000000),r1
+	mov	#0,r0
+	mov	r5,r2
+	add	r2,r2
+	bra	LOCAL(nan_if_t)
+	cmp/hi	r1,r2
+
+
+
+! still need to check for divide by zero or divide by nan
+! r3: 0x7f800000
+	.balign	4
+LOCAL(div_zero):
+	mov	r5,r1
+	add	r1,r1
+	tst	r1,r1	! 0 / 0 -> nan
+	bt	LOCAL(nan)
+	add	r3,r3
+	cmp/hi	r3,r1	! 0 / nan -> nan (but 0 / inf -> 0)
+LOCAL(zero_nan):
+	mov	#0,r0
+LOCAL(nan_if_t):
+	bf	0f:
+LOCAL(nan):
+	mov	#-1,r0
+0:	div0s	r4,r5	! compute sign
+	rts
+	rotcr	r0	! insert sign
+
+LOCAL(div_by_zero):
+	mov.l	LOCAL(xff000000),r0
+	mov	r4,r2
+	add	r2,r2
+	bra	LOCAL(nan_if_t)
+	cmp/hi	r0,r2
+	
+	.balign	4
+LOCAL(clz):
+	mov.l	r8,@-r15
+	extu.w	r0,r8
+	mov.l	r9,@-r15
+	cmp/eq	r0,r8
+	bt/s	0f
+	mov	#32,r9
+	shlr16	r0
+	extu.w	r0,r8
+	add	#-16,r9
+0:	tst	r1,r8	! 0xff00
+	mov.l	LOCAL(c_clz_tab),r0
+	bt	0f
+	shlr8	r8
+0:	bt	0f
+	add	#-8,r9
+0:
+#ifdef	__PIC__
+	add	r0,r8
+	mova	LOCAL(c_clz_tab),r0
+#endif
+	mov.b	@(r0,r8),r8
+	mov	r9,r0
+	mov.l	@r15+,r9
+	!
+	!
+	!
+	sub	r8,r0
+	mov.l	@r15+,r8
+	rts
+	lds.l	@r15+,pr
+
+!	We encode even some words as pc-relative that would fit as immediate
+!	in the instruction in order to avoid some pipeline stalls on
+!	SH4-100 / SH4-200.
+LOCAL(m23):	.word -23
+LOCAL(m24):	.word -24
+LOCAL(m31):	.word -31
+LOCAL(xff01):	.word 0xff01
+	.balign	4
+LOCAL(xff000000): .long 0xff000000
+#ifdef __LITTLE_ENDIAN__
+LOCAL(xff00):	.word 0xff00
+LOCAL(m1):	.word -1
+#else
+LOCAL(m1):	.word -1
+LOCAL(xff00):	.word 0xff00
+#endif
+LOCAL(xffffff): .long 0xffffff
+LOCAL(x7f800000): .long 0x7f800000
+LOCAL(x3f000000): .long 0x3f000000
+LOCAL(x3f800000): .long 0x3f800000
+LOCAL(xff800000): .long 0xff800000
+LOCAL(x40000000): .long 0x40000000
+LOCAL(x80000000): .long 0x80000000
+LOCAL(c_clz_tab):
+#ifdef __pic__
+        .long   GLOBAL(clz_tab) - .
+#else
+        .long   GLOBAL(clz_tab)
+#endif
+ENDFUNC(GLOBAL(divsf3))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/fixdfsi.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/fixdfsi.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/fixdfsi.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/fixdfsi.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,113 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!! fixdfsi for Renesas SH / STMicroelectronics ST40 CPUs
+!! Contributed by J"orn Rennecke joern.rennecke@st.com
+
+	! What is a bit unusal about this implementation is that the
+	! sign bit influences the result for NANs: for cleared sign bit, you
+	! get UINT_MAX, for set sign bit, you get 0.
+	! However, since the result for NANs is undefined, this should be no
+	! problem.
+	! N.B. This is scheduled both for SH4-200 and SH4-300
+	.balign 4
+	.global GLOBAL(fixdfsi)
+	FUNC(GLOBAL(fixdfsi))
+	.balign	4
+GLOBAL(fixdfsi):
+	mov.w	LOCAL(x413),r1
+	mov	DBL0H,r0
+	shll	DBL0H
+	mov.l	LOCAL(mask),r3
+	mov	#-21,r2
+	shld	r2,DBL0H	! SH4-200 will start this insn in a new cycle
+	bt/s	LOCAL(neg)
+	sub	r1,DBL0H
+	cmp/pl	DBL0H		! SH4-200 will start this insn in a new cycle
+	and	r3,r0
+	bf/s	LOCAL(ignore_low)
+	addc	r3,r0	! uses T == 1; sets implict 1
+	mov	#10,r2
+	shld	DBL0H,r0	! SH4-200 will start this insn in a new cycle
+	cmp/gt	r2,DBL0H
+	add	#-32,DBL0H
+	bt	LOCAL(retmax)
+	shld	DBL0H,DBL0L
+	rts
+	or	DBL0L,r0
+
+	.balign	8
+LOCAL(ignore_low):
+	mov	#-21,r2
+	cmp/gt	DBL0H,r2	! SH4-200 will start this insn in a new cycle
+	bf	0f		! SH4-200 will start this insn in a new cycle
+	mov	#-31,DBL0H	! results in 0 return
+0:	add	#1,r0
+	rts
+	shld	DBL0H,r0
+
+	.balign 4
+LOCAL(neg):
+	cmp/pl	DBL0H
+	and	r3,r0
+	bf/s	LOCAL(ignore_low_neg)
+	addc	r3,r0	! uses T == 1; sets implict 1
+	mov	#10,r2
+	shld	DBL0H,r0	! SH4-200 will start this insn in a new cycle
+	cmp/gt	r2,DBL0H
+	add	#-32,DBL0H
+	bt	LOCAL(retmin)
+	shld	DBL0H,DBL0L
+	or	DBL0L,r0	! SH4-200 will start this insn in a new cycle
+	rts
+	neg	r0,r0
+
+	.balign 4
+LOCAL(ignore_low_neg):
+	mov	#-21,r2
+	cmp/gt	DBL0H,r2	! SH4-200 will start this insn in a new cycle
+	add	#1,r0
+	shld	DBL0H,r0
+	bf	0f
+	mov	#0,r0		! results in 0 return
+0:	rts
+	neg	r0,r0
+
+LOCAL(retmax):
+	mov	#-1,r0
+	rts
+	shlr	r0
+
+LOCAL(retmin):
+	mov	#1,r0
+	rts
+	rotr	r0
+
+LOCAL(x413): .word 0x413
+
+	.balign 4
+LOCAL(mask): .long 0x000fffff
+	ENDFUNC(GLOBAL(fixdfsi))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/fixunsdfsi.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/fixunsdfsi.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/fixunsdfsi.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/fixunsdfsi.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,81 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!! fixunsdfsi for Renesas SH / STMicroelectronics ST40 CPUs
+!! Contributed by J"orn Rennecke joern.rennecke@st.com
+
+	! What is a bit unusal about this implementation is that the
+	! sign bit influences the result for NANs: for cleared sign bit, you
+	! get INT_MAX, for set sign bit, you get INT_MIN.
+	! However, since the result for NANs is undefined, this should be no
+	! problem.
+	! N.B. This is scheduled both for SH4-200 and SH4-300
+	.balign 4
+	.global GLOBAL(fixunsdfsi)
+	FUNC(GLOBAL(fixunsdfsi))
+	.balign	4
+GLOBAL(fixunsdfsi):
+	mov.w	LOCAL(x413),r1	! bias + 20
+	mov	DBL0H,r0
+	shll	DBL0H
+	mov.l	LOCAL(mask),r3
+	mov	#-21,r2
+	shld	r2,DBL0H	! SH4-200 will start this insn in a new cycle
+	bt/s	LOCAL(ret0)
+	sub	r1,DBL0H
+	cmp/pl	DBL0H		! SH4-200 will start this insn in a new cycle
+	and	r3,r0
+	bf/s	LOCAL(ignore_low)
+	addc	r3,r0	! uses T == 1; sets implict 1
+	mov	#11,r2
+	shld	DBL0H,r0	! SH4-200 will start this insn in a new cycle
+	cmp/gt	r2,DBL0H
+	add	#-32,DBL0H
+	bt	LOCAL(retmax)
+	shld	DBL0H,DBL0L
+	rts
+	or	DBL0L,r0
+
+	.balign	8
+LOCAL(ignore_low):
+	mov	#-21,r2
+	cmp/gt	DBL0H,r2	! SH4-200 will start this insn in a new cycle
+	add	#1,r0
+	bf	0f
+LOCAL(ret0): mov #0,r0		! results in 0 return
+0:	rts
+	shld	DBL0H,r0
+
+LOCAL(retmax):
+	rts
+	mov	#-1,r0
+
+LOCAL(x413): .word 0x413
+
+	.balign 4
+LOCAL(mask): .long 0x000fffff
+	ENDFUNC(GLOBAL(fixunsdfsi))
+
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/floatsidf.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/floatsidf.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/floatsidf.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/floatsidf.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,103 @@
+/* Copyright (C) 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! floatsidf for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+!
+! This code is optimized for SH4 without FPU, but can also be used for SH3.
+
+FUNC(GLOBAL(floatsidf))
+	.global GLOBAL(floatsidf)
+	.balign	4
+GLOBAL(floatsidf):
+	tst	r4,r4
+	mov	r4,r1
+	bt	LOCAL(ret0)
+	cmp/pz	r4
+	bt	0f
+	neg	r4,r1
+0:	mov.l	LOCAL(c_clz_tab),r0
+	extu.w	r1,r5
+	mov.w	LOCAL(xff00),r3
+	cmp/eq	r1,r5
+	mov	#21,r2
+	bt	0f
+	mov	r1,r5
+	shlr16	r5
+	add	#-16,r2
+0:	tst	r3,r5	! 0xff00
+	bt	0f
+	shlr8	r5
+0:	bt	0f
+	add	#-8,r2
+0:
+#ifdef	__PIC__
+	add	r0,r5
+	mova	LOCAL(c_clz_tab),r0
+#endif
+	mov.b	@(r0,r5),r5
+	cmp/pz	r4
+	mov.l	LOCAL(x41200000),r3	! bias + 20 - implicit 1
+	bt	0f
+	mov.l	LOCAL(xc1200000),r3	! sign + bias + 20 - implicit 1
+0:	mov	r1,r0	! DBLRL & DBLRH
+	sub	r5,r2
+	mov	r2,r5
+	shld	r2,DBLRH
+	cmp/pz	r2
+	add	r3,DBLRH
+	add	#32,r2
+	shld	r2,DBLRL
+	bf	0f
+	mov.w	LOCAL(d0),DBLRL
+0:	mov	#20,r2
+	shld	r2,r5
+	rts
+	sub	r5,DBLRH
+LOCAL(ret0):
+	mov	#0,DBLRL
+	rts
+	mov	#0,DBLRH
+
+LOCAL(xff00):	.word 0xff00
+	.balign	4
+LOCAL(x41200000):
+#ifdef __LITTLE_ENDIAN__
+LOCAL(d0):	  .word 0
+		  .word 0x4120
+#else
+		  .word 0x4120
+LOCAL(d0):	  .word 0
+#endif
+LOCAL(xc1200000): .long 0xc1200000
+LOCAL(c_clz_tab):
+#ifdef __pic__
+        .long   GLOBAL(clz_tab) - .
+#else
+        .long   GLOBAL(clz_tab)
+#endif
+ENDFUNC(GLOBAL(floatsidf))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/floatsisf.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/floatsisf.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/floatsisf.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/floatsisf.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,106 @@
+/* Copyright (C) 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! floatsisf for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+!
+! This code is optimized for SH4 without FPU, but can also be used for SH3.
+
+FUNC(GLOBAL(floatsisf))
+	.global GLOBAL(floatsisf)
+	.balign	4
+GLOBAL(floatsisf):
+	cmp/pz	r4
+	mov	r4,r5
+	bt	0f
+	neg	r4,r5
+0:	mov.l	LOCAL(c_clz_tab),r0
+	extu.w	r5,r1
+	mov.w	LOCAL(xff00),r3
+	cmp/eq	r5,r1
+	mov	#24,r2
+	bt	0f
+	mov	r5,r1
+	shlr16	r1
+	add	#-16,r2
+0:	tst	r3,r1	! 0xff00
+	bt	0f
+	shlr8	r1
+0:	bt	0f
+	add	#-8,r2
+0:
+#ifdef	__PIC__
+	add	r0,r1
+	mova	LOCAL(c_clz_tab),r0
+#endif
+	mov.b	@(r0,r1),r1
+	cmp/pz	r4
+	mov.l	LOCAL(x4a800000),r3	! bias + 23 - implicit 1
+	bt	0f
+	mov.l	LOCAL(xca800000),r3	! sign + bias + 23 - implicit 1
+0:	mov	r5,r0
+	sub	r1,r2
+	mov.l	LOCAL(x80000000),r1
+	shld	r2,r0
+	cmp/pz	r2
+	add	r3,r0
+	bt	LOCAL(noround)
+	add	#31,r2
+	shld	r2,r5
+	add	#-31,r2
+	rotl	r5
+	cmp/hi	r1,r5
+	mov	#0,r3
+	addc	r3,r0
+	mov	#23,r1
+	shld	r1,r2
+	rts
+	sub	r2,r0
+	.balign	8
+LOCAL(noround):
+	mov	#23,r1
+	tst	r4,r4
+	shld	r1,r2
+	bt	LOCAL(ret0)
+	rts
+	sub	r2,r0
+LOCAL(ret0):
+	rts
+	mov	#0,r0
+
+LOCAL(xff00):	.word 0xff00
+	.balign	4
+LOCAL(x4a800000): .long 0x4a800000
+LOCAL(xca800000): .long 0xca800000
+LOCAL(x80000000): .long 0x80000000
+LOCAL(c_clz_tab):
+#ifdef __pic__
+        .long   GLOBAL(clz_tab) - .
+#else
+        .long   GLOBAL(clz_tab)
+#endif
+ENDFUNC(GLOBAL(floatsisf))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/floatunssidf.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/floatunssidf.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/floatunssidf.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/floatunssidf.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,96 @@
+/* Copyright (C) 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! floatunssidf for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+!
+! This code is optimized for SH4 without FPU, but can also be used for SH3.
+
+FUNC(GLOBAL(floatunsidf))
+	.global GLOBAL(floatunsidf)
+	.balign	4
+GLOBAL(floatunsidf):
+	mov.l	LOCAL(c_clz_tab),r0
+	extu.w	r4,r1
+	mov.w	LOCAL(0xff00),r3
+	cmp/eq	r4,r1
+	mov	#21,r2
+	bt	0f
+	mov	r4,r1
+	shlr16	r1
+	add	#-16,r2
+0:	tst	r3,r1	! 0xff00
+	bt	0f
+	shlr8	r1
+0:	bt	0f
+	add	#-8,r2
+0:
+#ifdef	__PIC__
+	add	r0,r1
+	mova	LOCAL(c_clz_tab),r0
+#endif
+	mov.b	@(r0,r1),r5
+	mov	r4,DBLRL
+	mov.l	LOCAL(x41200000),r3	! bias + 20 - implicit 1
+	tst	r4,r4
+	mov	r4,DBLRH
+	bt	LOCAL(ret0)
+	sub	r5,r2
+	mov	r2,r5
+	shld	r2,DBLRH
+	cmp/pz	r2
+	add	r3,DBLRH
+	add	#32,r2
+	shld	r2,DBLRL
+	bf	0f
+	mov.w	LOCAL(d0),DBLRL
+0:	mov	#20,r2
+	shld	r2,r5
+	rts
+	sub	r5,DBLRH
+LOCAL(ret0):
+	mov	r4,DBLRL
+	rts
+	mov	r4,DBLRH
+
+LOCAL(0xff00):	.word  0xff00
+	.balign	4
+LOCAL(x41200000):
+#ifdef __LITTLE_ENDIAN__
+LOCAL(d0):	  .word 0
+		  .word 0x4120
+#else
+		  .word 0x4120
+LOCAL(d0):	  .word 0
+#endif
+LOCAL(c_clz_tab):
+#ifdef __pic__
+        .long   GLOBAL(clz_tab) - .
+#else
+        .long   GLOBAL(clz_tab)
+#endif
+ENDFUNC(GLOBAL(floatunsidf))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/floatunssisf.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/floatunssisf.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/floatunssisf.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/floatunssisf.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,94 @@
+/* Copyright (C) 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! floatsisf for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+!
+! This code is optimized for SH4 without FPU, but can also be used for SH3.
+
+FUNC(GLOBAL(floatunsisf))
+	.global GLOBAL(floatunsisf)
+	.balign	4
+GLOBAL(floatunsisf):
+	mov.l	LOCAL(c_clz_tab),r0
+	extu.w	r4,r1
+	mov.w	LOCAL(xff00),r3
+	cmp/eq	r4,r1
+	mov	#24,r2
+	bt	0f
+	mov	r4,r1
+	shlr16	r1
+	add	#-16,r2
+0:	tst	r3,r1	! 0xff00
+	bt	0f
+	shlr8	r1
+0:	bt	0f
+	add	#-8,r2
+0:
+#ifdef	__PIC__
+	add	r0,r1
+	mova	LOCAL(c_clz_tab),r0
+#endif
+	mov.b	@(r0,r1),r1
+	mov	r4,r0
+	mov.l	LOCAL(x4a800000),r3	! bias + 23 - implicit 1
+	tst	r4,r4
+	bt	LOCAL(ret0)
+	!
+	sub	r1,r2
+	mov.l	LOCAL(x80000000),r1
+	shld	r2,r0
+	cmp/pz	r2
+	add	r3,r0
+	bt	LOCAL(noround)
+	add	#31,r2
+	shld	r2,r4
+	rotl	r4
+	add	#-31,r2
+	cmp/hi	r1,r4
+	mov	#0,r3
+	addc	r3,r0
+LOCAL(noround):
+	mov	#23,r1
+	shld	r1,r2
+	rts
+	sub	r2,r0
+LOCAL(ret0):
+	rts
+	nop
+
+LOCAL(xff00):	.word 0xff00
+	.balign	4
+LOCAL(x4a800000): .long 0x4a800000
+LOCAL(x80000000): .long 0x80000000
+LOCAL(c_clz_tab):
+#ifdef __pic__
+        .long   GLOBAL(clz_tab) - .
+#else
+        .long   GLOBAL(clz_tab)
+#endif
+ENDFUNC(GLOBAL(floatunsisf))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/muldf3.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/muldf3.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/muldf3.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/muldf3.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,502 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! muldf3 for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+!
+! This code is optimized for SH4 without FPU, but can also be used for SH3.
+! Normal numbers are multiplied in 53 or 54 cycles on SH4-200.
+
+FUNC(GLOBAL(muldf3))
+	.global GLOBAL(muldf3)
+LOCAL(normalize_arg53):
+	tst	r2,DBL0H
+	mov	#1,r2
+	bt	LOCAL(normalize_arg48)
+	mov	DBL0H,r1
+	shlr16	r1
+	bra	LOCAL(normalize_DBL0H)
+	mov	#21-16,r3
+
+LOCAL(normalize_arg16):
+	mov.w	LOCAL(m31),r2 ! 1-32
+	mov	#0,DBL0L
+LOCAL(normalize_arg48):
+	mov	DBL0H,r1
+	mov	#21,r3
+LOCAL(normalize_DBL0H):
+	extu.b	r1,r8
+	mov.l	LOCAL(c__clz_tab),r0
+	cmp/eq	r8,r1
+	!
+	bt	0f
+	shlr8	r1
+0:
+#ifdef	__pic__
+	add	r0,r1
+
+	mova	LOCAL(c__clz_tab),r0
+
+#endif /* __pic__ */
+	mov.b	@(r0,r1),r8
+	mov	DBL0L,r1
+	mov.l	@r15+,r0
+	bt	0f
+	add	#-8,r3
+0:	clrt
+	sub	r8,r3
+	mov.w	LOCAL(d20),r8
+	shld	r3,DBL0H 	! Normalization
+	shld	r3,DBL0L
+	sub	r3,r2 	! r2 <- shifting number
+	add	#-32,r3
+	shld	r3,r1
+	or	r1,DBL0H
+	shld	r8,r2 	! positioning r2 for exp
+	mov.l	@r15+,r8
+
+	! Here :  test tinyness 
+	mov 	DBL1H, r1
+	neg 	r2,r3
+	shll 	r1
+	shll 	r3
+	cmp/hi r1,r3
+	bt LOCAL(zero)
+	
+	add	r2,DBL1H
+	mov.l	LOCAL(x001fffff),r2
+	mov.l LOCAL(x00100000),r3
+	dmulu.l	DBL0L,DBL1L
+	bra	LOCAL(arg_denorm_done)
+	or	r3,r0		! set implicit 1 bit
+
+LOCAL(inf_nan_denorm_or_zero_a):
+	mov.l r8,@-r15
+	sub 	r3,DBL0H 	! isolate high fraction (r3 = 0xfff00000)
+	mov.l @(4,r15),r8 ! original DBL0H (with sign & exp)
+	mov.l r0,@-r15
+	mov.l	r10,@-r15
+	mov 	r1,r10
+	sub 	r3,r1 	! r1 <- 0x7ff00000
+	mov.l LOCAL(x60000000),r3
+	shll16 	r2 	! r2 <- 0xffff0000
+	!			  no stall here for sh4-200
+	!
+	tst 	r1,r8 	! test DBL0 Inf or NaN ?
+	bf LOCAL(inf_nan_a)
+	tst r10,r0 	! test for DBL1 inf, nan or small
+	mov.l	@r15+,r10
+	bt LOCAL(ret_inf_nan_zero)
+LOCAL(normalize_arg):
+	tst 	DBL0H,DBL0H
+	bf LOCAL(normalize_arg53)
+	tst 	DBL0L,DBL0L 	! test for DBL0 is zero
+	bt LOCAL(a_zero)
+	tst 	r2,DBL0L 	! test DBL0L = 0x0000xxxx
+	mov 	DBL0L,DBL0H ! left shift 32
+	bt LOCAL(normalize_arg16)
+	shlr16 	DBL0H
+	mov.w LOCAL(m15),r2	! 1-16
+	bra 	LOCAL(normalize_arg48)
+	shll16 	DBL0L
+
+LOCAL(a_zero):
+	mov.l	@(4,r15),r8
+	add	#8,r15
+LOCAL(zero):
+	mov	#0,DBLRH
+	bra	LOCAL(pop_ret)
+	mov	#0,DBLRL
+
+! both inf / nan -> result is nan if at least one is none, else inf.
+! BBL0 inf/nan, DBL1 zero   -> result is nan
+! DBL0 inf/nan, DBL1 finite -> result is DBL0 with sign adjustemnt
+LOCAL(inf_nan_a):
+	mov.l	@r15+,r10
+	mov	r8,DBL0H
+	mov.l	@(4,r15),r8
+	tst	r1,r0	! arg1 inf/nan ?
+	mov	DBL0H,DBLRH
+	add	#8,r15
+	mov	DBL0L,DBLRL
+	bt	LOCAL(both_inf_nan)
+	tst	DBL1L,DBL1L
+	mov	DBL1H,r2
+	bf	LOCAL(pop_ret)
+	add	r2,r2
+	tst	r2,r2
+	!
+	bf	LOCAL(pop_ret)
+LOCAL(nan):
+	mov	#-1,DBLRL
+	bra	LOCAL(pop_ret)
+	mov	#-1,DBLRH
+
+LOCAL(both_inf_nan):
+	or	DBL1L,DBLRL
+	bra	LOCAL(pop_ret)
+	or	DBL1H,DBLRH
+
+LOCAL(ret_inf_nan_zero):
+	tst	r1,r0
+	mov.l	@(4,r15),r8
+	or	DBL0L,DBL0H
+	bf/s	LOCAL(zero)
+	add	#8,r15
+	tst	DBL0H,DBL0H
+	bt	LOCAL(nan)
+LOCAL(inf_nan_b):
+	mov	DBL1L,DBLRL
+	mov	DBL1H,DBLRH
+LOCAL(pop_ret):
+	mov.l	@r15+,DBL0H
+	add	DBLRH,DBLRH
+
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+
+	.balign	4
+/* Argument a has already been tested for being zero or denorm.
+   On the other side, we have to swap a and b so that we can share the
+   normalization code.
+   a: sign/exponent : @r15 fraction: DBL0H:DBL0L
+   b: sign/exponent: DBL1H fraction:    r0:DBL1L  */
+LOCAL(inf_nan_denorm_or_zero_b):
+	sub	r3,r1		! 0x7ff00000
+	mov.l	@r15,r2		! get original DBL0H
+	tst	r1,DBL1H
+	sub	r3,r0		! isolate high fraction
+	bf	LOCAL(inf_nan_b)
+	mov.l	DBL1H,@r15
+	mov	r0,DBL0H
+	mov.l	r8,@-r15
+	mov	r2,DBL1H
+	mov.l	LOCAL(0xffff0000),r2
+	mov.l	DBL1H,@-r15
+	mov	DBL1L,r1
+	mov	DBL0L,DBL1L
+	bra	LOCAL(normalize_arg)
+	mov	r1,DBL0L
+
+LOCAL(d20):
+	.word	20
+LOCAL(m15):
+	.word	-15
+LOCAL(m31):
+	.word	-31
+LOCAL(xff):
+	.word	0xff
+
+	.balign	4
+LOCAL(0xffff0000): .long 0xffff0000
+
+	! calculate a (DBL0H:DBL0L) * b (DBL1H:DBL1L)
+	.balign	4
+GLOBAL(muldf3):
+	mov.l	LOCAL(xfff00000),r3
+	mov	DBL1H,r0
+	dmulu.l	DBL0L,DBL1L
+	mov.l	LOCAL(x7fe00000),r1
+	sub	r3,r0
+	mov.l	DBL0H,@-r15
+	sub	r3,DBL0H
+	tst	r1,DBL0H
+	or	r3,DBL0H
+	mov.l	LOCAL(x001fffff),r2
+	bt	LOCAL(inf_nan_denorm_or_zero_a)
+	tst	r1,r0
+	or	r3,r0		! r0:DBL1L    := b fraction ; u12.52
+	bt	LOCAL(inf_nan_denorm_or_zero_b) ! T clear on fall-through
+LOCAL(arg_denorm_done):
+	and	r2,r0		! r0:DBL1L    := b fraction ; u12.52
+	sts	macl,r3
+	sts	mach,r1
+	dmulu.l	DBL0L,r0 ! r0 = DBL1H - exp
+	and	r2,DBL0H	! DBL0H:DBL0L := a fraction ; u12.52
+	mov.l	r8,@-r15
+	mov	#0,DBL0L
+	mov.l	r9,@-r15
+	sts	macl,r2
+	sts	mach,r8
+	dmulu.l	DBL0H,DBL1L
+	addc	r1,r2
+
+	addc	DBL0L,r8	! add T; clears T
+
+	sts	macl,r1
+	sts	mach,DBL1L
+	dmulu.l	DBL0H,r0
+	addc	r1,r2
+	mov.l	LOCAL(x7ff00000),DBL0H
+	addc	DBL1L,r8	! clears T
+	mov.l	@(8,r15),DBL1L	! a sign/exp w/fraction
+	sts	macl,DBLRL
+	sts	mach,DBLRH
+	and	DBL0H,DBL1L	! a exponent
+	mov.w	LOCAL(x200),r9
+	addc	r8,DBLRL
+	mov.l	LOCAL(x3ff00000),r8	! bias
+	addc	DBL0L,DBLRH	! add T
+	cmp/hi	DBL0L,r3	! 32 guard bits -> sticky: T := r3 != 0
+	movt	r3
+	tst	r9,DBLRH	! T := fraction < 2
+	or	r3,r2		! DBLRH:DBLRL:r2 := result fraction; u24.72
+	bt/s	LOCAL(shll12)
+	sub	r8,DBL1L
+	mov.l	LOCAL(x002fffff),r8
+	and	DBL1H,DBL0H	! b exponent
+	mov.l	LOCAL(x00100000),r9
+	add	DBL0H,DBL1L ! result exponent - 1
+	tst	r8,r2
+	mov.w	LOCAL(m20),r8
+	subc	DBL0L,r9
+	addc	r2,r9 ! r2 value is still needed for denormal rounding
+	mov.w	LOCAL(d11),DBL0L
+	rotcr	r9
+	clrt
+	shld	r8,r9
+	mov.w	LOCAL(m21),r8
+	mov	DBLRL,r3
+	shld	DBL0L,DBLRL
+	addc	r9,DBLRL
+	mov.l	@r15+,r9
+	shld	r8,r3
+	mov.l	@r15+,r8
+	shld	DBL0L,DBLRH
+	mov.l	@r15+,DBL0H
+	addc	r3,DBLRH
+	mov.l	LOCAL(x7ff00000),DBL0L
+	add	DBL1L,DBLRH	! implicit 1 adjusts exponent
+	mov.l	LOCAL(xffe00000),r3
+	cmp/hs	DBL0L,DBLRH
+	add	DBLRH,DBLRH
+	bt	LOCAL(ill_exp_11)
+	tst	r3,DBLRH
+	bt	LOCAL(denorm_exp0_11)
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+
+
+LOCAL(shll12):
+	mov.l	LOCAL(x0017ffff),r8
+	extu.b	DBLRH,DBLRH	! remove implicit 1.
+	mov.l	LOCAL(x00080000),r9
+	and	DBL1H,DBL0H	! b exponent
+	add	DBL0H,DBL1L	! result exponent
+	tst	r8,r2		! rounding adjust for lower guard ...
+	mov.w	LOCAL(m19),r8
+	subc	DBL0L,r9	! ... bits and round to even; clear T
+	addc	r2,r9 ! r2 value is still needed for denormal rounding
+	mov.w	LOCAL(d12),DBL0L
+	rotcr	r9
+	clrt
+	shld	r8,r9
+	mov.w	LOCAL(m20),r8
+	mov	DBLRL,r3
+	shld	DBL0L,DBLRL
+	addc	r9,DBLRL
+	mov.l	@r15+,r9
+	shld	r8,r3
+	mov.l	@r15+,r8
+	shld	DBL0L,DBLRH
+	mov.l	LOCAL(x7ff00000),DBL0L
+	addc	r3,DBLRH
+	mov.l	@r15+,DBL0H
+	add	DBL1L,DBLRH
+	mov.l	LOCAL(xffe00000),r3
+	cmp/hs	DBL0L,DBLRH
+	add	DBLRH,DBLRH
+	bt	LOCAL(ill_exp_12)
+	tst	r3,DBLRH
+	bt	LOCAL(denorm_exp0_12)
+LOCAL(insert_sign):
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+
+LOCAL(overflow):
+	mov	r3,DBLRH
+	mov	#0,DBLRL
+	bra	LOCAL(insert_sign)
+	mov.l	@r15+,r8
+
+LOCAL(denorm_exp0_11):
+	mov.l	r8,@-r15
+	mov	#-21,r8
+	mov.l	r9,@-r15
+	bra	LOCAL(denorm)
+	mov	#-2,DBL1L	! one for denormal, and one for sticky bit
+
+LOCAL(ill_exp_11):
+	mov	DBL1H,DBL1L
+	and	r3,DBL0L	! 0x7fe00000
+	add	DBL1L,DBL1L
+	mov.l	r8,@-r15
+	cmp/hi	DBL1L,DBL0L	! check if exp a was large
+	mov	#-20,DBL0L
+	bf	LOCAL(overflow)
+	mov	#-21,r8
+	mov	DBLRH,DBL1L
+	rotcr	DBL1L		! shift in negative sign
+	mov.l	r9,@-r15
+	shad	DBL0L,DBL1L	! exponent ; s32
+	bra	LOCAL(denorm)
+	add	#-2,DBL1L	! add one for denormal, and one for sticky bit
+
+LOCAL(denorm_exp0_12):
+	mov.l	r8,@-r15
+	mov	#-20,r8
+	mov.l	r9,@-r15
+	bra	LOCAL(denorm)
+	mov	#-2,DBL1L	! one for denormal, and one for sticky bit
+
+	.balign 4		! also aligns LOCAL(denorm)
+LOCAL(ill_exp_12):
+	and	r3,DBL0L	! 0x7fe00000
+	mov	DBL1H,DBL1L
+	add	DBL1L,DBL1L
+	mov.l	r8,@-r15
+	cmp/hi	DBL1L,DBL0L	! check if exp a was large
+	bf	LOCAL(overflow)
+	mov	DBLRH,DBL1L
+	rotcr	DBL1L		! shift in negative sign
+	mov	#-20,r8
+	shad	r8,DBL1L	! exponent ; s32
+	mov.l	r9,@-r15
+	add	#-2,DBL1L	! add one for denormal, and one for sticky bit
+LOCAL(denorm):
+	not	r3,r9		! 0x001fffff
+	mov.l	r10,@-r15
+	mov	r2,r10
+	shld	r8,r10	! 11 or 12 lower bit valid
+	and	r9,DBLRH ! Mask away vestiges of exponent.
+	add	#32,r8
+	sub	r3,DBLRH ! Make leading 1 explicit.
+	shld	r8,r2	! r10:r2 := unrounded result lowpart
+	shlr	DBLRH	! compensate for doubling at end of normal code
+	sub	DBLRL,r10	! reconstruct effect of previous rounding
+	exts.b	r10,r9
+	shad	r3,r10	! sign extension
+	mov	#0,r3
+	clrt
+	addc	r9,DBLRL	! Undo previous rounding.
+	bt LOCAL(unround_done)
+	addc	r9,DBLRH
+LOCAL(unround_done):
+	mov.w	LOCAL(m32),r9
+	cmp/hi	r3,r2
+	rotcl	DBLRL	! fit in the rest of r2 as a sticky bit.
+	mov.l	@r15+,r10
+	rotcl	DBLRH
+	cmp/ge	r9,DBL1L
+	bt	LOCAL(small_norm_shift)
+	cmp/hi	r3,DBLRL
+	add	#31,DBL1L
+	movt	DBLRL
+	shll 	DBLRH
+	cmp/ge	r9,DBL1L
+	or	DBLRH,DBLRL
+	bt/s	LOCAL(small_norm_shift)
+	mov	r3,DBLRH
+	mov	r3,DBLRL	! exponent too negative to shift - return zero
+	mov.l	@r15+,r9
+	mov.l	@r15+,r8
+	div0s	DBL0H,DBL1H
+	rts
+	rotcr	DBLRH
+	.balign	4
+LOCAL(small_norm_shift):
+	mov	DBLRL,r2	! stash away guard bits
+	shld	DBL1L,DBLRL
+	mov	DBLRH,DBL0L
+	shld	DBL1L,DBLRH
+	mov.l	LOCAL(x7fffffff),r9
+	add	#32,DBL1L
+	shld	DBL1L,r2
+	shld	DBL1L,DBL0L
+	or	DBL0L,DBLRL
+	or	DBLRL,DBL0L
+	shlr	DBL0L
+	addc	r2,r9
+	mov.l	@r15+,r9
+	mov.l	@r15+,r8
+	addc	r3,DBLRL
+	addc	r3,DBLRH
+	div0s	DBL0H,DBL1H
+	add	DBLRH,DBLRH
+	rts
+	rotcr	DBLRH
+
+
+LOCAL(x200):
+	.word 0x200
+LOCAL(m19):
+	.word	-19
+LOCAL(m20):
+	.word	-20
+LOCAL(m21):
+	.word	-21
+LOCAL(m32):
+	.word	-32
+LOCAL(d11):
+	.word	11
+LOCAL(d12):
+	.word	12
+	.balign	4
+LOCAL(x60000000):
+	.long	0x60000000
+LOCAL(c__clz_tab):
+#ifdef __pic__
+	.long	GLOBAL(clz_tab) - .
+#else
+	.long	GLOBAL(clz_tab)
+#endif
+LOCAL(xfff00000):
+	.long	0xfff00000
+LOCAL(x7fffffff):
+	.long	0x7fffffff
+LOCAL(x00100000):
+	.long	0x00100000
+LOCAL(x7fe00000):
+	.long	0x7fe00000
+LOCAL(x001fffff):
+	.long	0x001fffff
+LOCAL(x7ff00000):
+	.long	0x7ff00000
+LOCAL(x3ff00000):
+	.long	0x3ff00000
+LOCAL(x002fffff):
+	.long	0x002fffff
+LOCAL(xffe00000):
+	.long	0xffe00000
+LOCAL(x0017ffff):
+	.long	0x0017ffff
+LOCAL(x00080000):
+	.long	0x00080000
+ENDFUNC(GLOBAL(muldf3))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/mulsf3.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/mulsf3.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/m3/mulsf3.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/m3/mulsf3.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,269 @@
+/* Copyright (C) 2004 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+! mulsf3 for the Renesas SH / STMicroelectronics ST40 CPUs.
+! Contributed by Joern Rennecke
+! joern.rennecke@st.com
+
+	.balign 4
+	.global GLOBAL(mulsf3)
+	FUNC(GLOBAL(mulsf3))
+GLOBAL(mulsf3):
+   mov.l   LOCAL(x7f800000),r1
+   not     r4,r2
+	mov		r4,r3
+	not		r5,r0
+	tst		r1,r2
+	or			r1,r3
+	bt/s		LOCAL(inf_nan_arg0)
+	 tst		r1,r0
+	bt			LOCAL(inf_nan_arg1)
+	tst		r1,r5
+	mov		r1,r2
+	shll8		r3
+	or			r5,r1
+	bt/s		LOCAL(zero_denorm_arg1)
+	 shll8		r1
+	tst		r2,r4
+	bt			LOCAL(zero_denorm_arg0)
+	dmulu.l	r3,r1
+	mov		r4,r0
+	and		r2,r0
+LOCAL(arg_norm):
+	and		r5,r2
+	mov.l 	LOCAL(x3f800000),r3
+	sts		mach,r1
+	sub		r3,r0
+	sts		macl,r3
+	add		r2,r0
+	cmp/pz	r1
+	mov.w 	LOCAL(x100),r2
+	bf/s		LOCAL(norm_frac) 
+	 tst		r3,r3
+	shll2		r1	 ! Shift one up, replace leading 1 with 0.  
+	shlr		r1
+	tst		r3,r3
+LOCAL(norm_frac):
+	mov.w 	LOCAL(mx80),r3
+	bf			LOCAL(round_frac)
+	tst		r2,r1
+LOCAL(round_frac):
+	mov.l 	LOCAL(xff000000),r2
+	subc		r3,r1	! Even overflow gives right result: exp++, frac=0. 
+	shlr8 	r1
+	add		r1,r0
+	shll		r0
+	bt			LOCAL(ill_exp)
+	tst		r2,r0
+	bt			LOCAL(denorm)
+	cmp/hs	r2,r0
+	bt			LOCAL(inf)
+LOCAL(insert_sign):
+	div0s	r4,r5
+	rts
+	rotcr		r0
+LOCAL(denorm0):
+	tst	r1,r1
+	mov.w 	LOCAL(x100),r2
+	bf			LOCAL(round_den0)
+	tst		r2,r0
+LOCAL(round_den0):
+	mov 		#-7,r2
+	mov.w 	LOCAL(mx80),r3
+	subc 		r3,r0
+	bra		LOCAL(insert_sign)
+	 shld 		r2,r0
+LOCAL(zero_denorm_arg1):
+	mov.l 	LOCAL(x60000000),r2	/* Check exp0 >= -64	*/
+	add		r1,r1
+	tst		r1,r1	/* arg1 == 0 ? */
+	mov		#0,r0
+	bt			LOCAL(insert_sign) /* argument 1 is zero ==> return 0  */
+	tst		r4,r2
+	bt			LOCAL(insert_sign) /* exp0 < -64  ==> return 0 */
+	mov.l 	LOCAL(c__clz_tab),r0
+	mov		r3,r2
+	mov		r1,r3
+	bra		LOCAL(arg_normalize)
+	mov		r2,r1
+LOCAL(zero_denorm_arg0):
+	mov.l 	LOCAL(x60000000),r2	/* Check exp1 >= -64	*/
+	add		r3,r3
+	tst		r3,r3	/* arg0 == 0 ? */
+	mov		#0,r0
+	bt			LOCAL(insert_sign) /* argument 0 is zero ==> return 0  */
+	tst		r5,r2
+	bt			LOCAL(insert_sign) /* exp1 < -64  ==> return 0 */
+	mov.l 	LOCAL(c__clz_tab),r0
+LOCAL(arg_normalize):
+	mov.l	r7,@-r15
+	extu.w	r3,r7
+	cmp/eq	r3,r7
+	mov.l 	LOCAL(xff000000),r7
+	mov		#-8,r2
+	bt			0f
+	tst		r7,r3
+	mov		#-16,r2
+	bt			0f
+	mov		#-24,r2
+0:
+	mov		r3,r7
+	shld		r2,r7
+#ifdef __pic__
+	add		r0,r7
+	mova  	LOCAL(c__clz_tab),r0
+#endif
+	mov.b	@(r0,r7),r0
+	add		#32,r2
+	mov		r2,r7
+	mov		#23,r2
+	sub		r0,r7
+	mov.l	LOCAL(x7f800000),r0
+	shld		r7,r3
+	shld		r2,r7
+	mov		r0,r2
+	and		r4,r0
+	sub		r7,r0
+	mov.l	@r15+,r7
+	bra		LOCAL(arg_norm)
+	 dmulu.l	r3,r1
+#if 0 /* This is slightly slower, but could be used if table lookup causes
+         cache thrashing.  */
+	bt			LOCAL(insert_sign) /* exp1 < -64  ==> return 0 */
+	mov.l 	LOCAL(xff000000),r2
+	mov		r4,r0
+LOCAL(arg_normalize):
+	tst		r2,r3
+	bf			LOCAL(arg_bit_norm)
+LOCAL(arg_byte_loop):
+	tst		r2,r3
+	add		r2,r0
+	shll8		r3
+	bt			LOCAL(arg_byte_loop)
+	add		r4,r0
+LOCAL(arg_bit_norm):
+	mov.l 	LOCAL(x7f800000),r2
+	rotl		r3
+LOCAL(arg_bit_loop):
+	add		r2,r0
+	bf/s		LOCAL(arg_bit_loop)
+	 rotl		r3
+	rotr		r3
+	rotr		r3
+	sub		r2,r0
+	bra		LOCAL(arg_norm)
+	 dmulu.l	r3,r1
+#endif /* 0 */
+LOCAL(inf):
+	bra		LOCAL(insert_sign)
+	 mov		r2,r0
+LOCAL(inf_nan_arg0):
+	bt			LOCAL(inf_nan_both)
+	add		r0,r0
+!	cmp/eq	#-1,r0	Here : modif -1 replace by -2 
+	cmp/eq	#-2,r0	/* arg1 zero? -> NAN */
+	bt			LOCAL(insert_sign)
+	mov		r4,r0
+LOCAL(inf_insert_sign):
+	bra		LOCAL(insert_sign)
+	 add		r0,r0
+LOCAL(inf_nan_both):
+	mov		r4,r0
+	bra		LOCAL(inf_insert_sign)
+	 or		r5,r0
+LOCAL(inf_nan_arg1):
+	mov		r2,r0
+	add		r0,r0
+! cmp/eq	#-1,r0	Here : modif -1 replace by -2 
+	cmp/eq	#-2,r0	/* arg0 zero? */
+	bt			LOCAL(insert_sign)
+	bra		LOCAL(inf_insert_sign)
+	 mov		r5,r0
+LOCAL(ill_exp):
+	cmp/pz	r0
+	bt			LOCAL(inf)
+LOCAL(denorm):
+	mov		#-24,r3
+	add		r1,r1
+	mov		r0,r2
+	sub		r1,r2	! remove fraction to get back pre-rounding exponent.
+	tst 		r2,r2
+	sts		mach,r0
+	sts		macl,r1
+	bt			LOCAL(denorm0)
+	shad		r3,r2
+	mov		r0,r3
+	shld		r2,r0
+	add		#32,r2
+	cmp/pz	r2
+	shld		r2,r3
+	bf			LOCAL(zero)
+	or			r1,r3
+	mov		#-1,r1
+	tst		r3,r3
+	mov.w	LOCAL(x100),r3
+	bf/s		LOCAL(denorm_round_up)
+	mov		#-0x80,r1
+	tst		r3,r0
+LOCAL(denorm_round_up):
+	mov		#-7,r3
+	subc		r1,r0
+	bra		LOCAL(insert_sign)
+	 shld		r3,r0
+LOCAL(zero):
+	bra		LOCAL(insert_sign)
+	 mov 	#0,r0
+LOCAL(x100):
+	.word	0x100
+LOCAL(x200):
+	.word	0x200
+LOCAL(x17f):
+	.word	0x17f
+LOCAL(x80):
+	.word	0x80
+LOCAL(mx80):
+	.word	-0x80
+	.balign	4
+LOCAL(mx100):
+	.word	-0x100
+	.balign	4
+LOCAL(x7f800000):
+	.long 0x7f800000
+LOCAL(x3f800000):
+	.long 0x3f800000
+LOCAL(x1000000):
+	.long	0x1000000
+LOCAL(xff000000):
+	.long	0xff000000
+LOCAL(x60000000):
+	.long	0x60000000
+LOCAL(c__clz_tab):
+#ifdef __pic__
+	.long	GLOBAL(clz_tab) - .
+#else
+	.long	GLOBAL(clz_tab)
+#endif
+	ENDFUNC(GLOBAL(mulsf3))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/muldf3.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/muldf3.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/muldf3.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/muldf3.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,601 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+!multiplication of two double precision floating point numbers
+!Author:Aanchal Khanna
+!SH1 Support / Simplifications: Joern Rennecke
+!
+!Entry:
+!r4,r5:operand 1
+!
+!r6,r7:operand 2
+!
+!Exit:
+!r0,r1:result
+!
+!Notes: argument 1 is passed in regs r4 and r5 and argument 2 is passed in regs
+!r6 and r7, result is returned in regs r0 and r1. operand 1 is referred as op1
+!and operand 2 as op2.
+!
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+	.text
+	.align	5	
+	.global	GLOBAL (muldf3)
+	FUNC (GLOBAL (muldf3))
+
+GLOBAL (muldf3):
+
+#ifdef  __LITTLE_ENDIAN__
+        mov     r4,r1
+        mov     r5,r4
+        mov     r1,r5
+
+        mov     r6,r1
+        mov     r7,r6
+        mov     r1,r7
+#endif
+	mov.l	.L_mask_sign,r0
+	mov	r4,r2
+
+	and	r0,r2		
+	mov	#0,r1
+
+	shll	r4
+	and	r6,r0		
+	
+	xor     r2,r0		!r0 contains the result's sign bit
+	shlr	r4
+
+	mov.l   .L_inf,r2
+	shll	r6
+
+	mov	r4,r3
+	shlr	r6
+	
+.L_chk_a_inv:
+	!chk if op1 is Inf/NaN
+	and	r2,r3
+	mov.l	r8,@-r15
+
+	cmp/eq	r3,r2
+	mov.l	.L_mask_high_mant,r8
+
+	mov	r2,r3
+	bf	.L_chk_b_inv
+
+	mov	r8,r3
+	and	r4,r8
+
+	cmp/hi  r1,r8		
+	bt	.L_return_a	!op1 NaN, return op1
+
+	cmp/hi  r1,r5	
+	mov	r2,r8
+
+	bt      .L_return_a	!op1 NaN, return op1
+	and	r6,r8
+
+	cmp/eq	r8,r2		
+	and	r6,r3
+
+	bt      .L_b_inv
+	cmp/eq	r1,r6		
+
+	bf	.L_return_a	!op1 Inf,op2= normal no return op1
+	cmp/eq	r1,r7
+
+	bf	.L_return_a	!op1 Inf,op2= normal no return op1
+	mov.l   @r15+,r8	
+
+	rts
+	mov	#-1,DBLRH	!op1=Inf, op2=0,return nan
+
+.L_b_inv:
+	!op2 is NaN/Inf
+	cmp/hi	r1,r7
+	mov	r1,r2
+
+	mov	r5,r1
+	bt	.L_return_b	!op2=NaN,return op2
+
+	cmp/hi	r2,r6
+	or	r4,r0
+
+	bt	.L_return_b	!op2=NaN,return op2
+	mov.l   @r15+,r8
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+
+	rts			!op1=Inf,op2=Inf,return Inf with sign
+	nop
+
+.L_chk_b_inv:
+	!Chk if op2 is NaN/Inf
+	and	r6,r2
+	cmp/eq	r3,r2
+
+	bf	.L_chk_a_for_zero
+	and	r6,r8
+
+	cmp/hi	r1,r8
+	bt	.L_return_b	 !op2=NaN,return op2
+
+	cmp/hi	r1,r7
+	bt	.L_return_b	 !op2=NaN,return op2
+
+	cmp/eq	r5,r1
+	bf      .L_return_b	 !op1=normal number,op2=Inf,return Inf
+
+	mov	r7,r1
+	cmp/eq	r4,r1
+
+	bf	.L_return_b	/* op1=normal number, op2=Inf,return Inf */
+	mov.l   @r15+,r8
+
+	rts
+	mov	#-1,DBLRH	!op1=0,op2=Inf,return NaN
+
+.L_return_a:
+	mov	r5,r1
+	or	r4,r0
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+
+	rts
+	mov.l   @r15+,r8
+
+.L_return_b:
+	mov	r7,r1
+	or	r6,r0	
+	
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+
+	rts
+	mov.l	@r15+,r8
+	
+.L_chk_a_for_zero:
+	!Chk if op1 is zero
+	cmp/eq	r1,r4
+	bf	.L_chk_b_for_zero
+	
+	cmp/eq	r1,r5
+	bf	.L_chk_b_for_zero
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	mov.l	@r15+,r8
+
+.L_chk_b_for_zero:
+	!op1=0,chk if op2 is zero
+        cmp/eq  r1,r6
+        mov	r1,r3
+	
+	mov.l   .L_inf,r1
+	bf      .L_normal_nos
+
+        cmp/eq  r3,r7
+        bf      .L_normal_nos
+
+	mov	r3,r1
+	mov.l   @r15+,r8
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	nop
+
+.L_normal_nos:
+	!op1 and op2 are normal nos
+	mov.l	r9,@-r15
+	mov	r4,r3
+
+	mov     #-20,r9	
+	and	r1,r3	
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r9,r2
+#else
+        SHLR20 (r2)
+#endif
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r9,r3
+#else
+        SHLR20 (r3)
+#endif
+	cmp/pl	r3
+
+	bf	.L_norm_a	!normalize op1
+.L_chk_b:	
+	cmp/pl	r2
+	bf	.L_norm_b	!normalize op2
+
+.L_mul1:
+	add	r3,r2
+	mov.l  .L_1023,r1
+	
+	!resultant exponent in r2
+	add     r1,r2
+	mov.l   .L_2047,r1	
+
+	!Chk the exponent for overflow
+	cmp/ge	r1,r2
+	and     r8,r4
+
+	bt	.L_return_inf
+	mov.l	.L_imp_bit,r1
+	
+	or	r1,r4		
+	and	r8,r6
+
+	or	r1,r6
+	clrt
+
+	!multiplying the mantissas
+	DMULU_SAVE
+	DMULUL	(r7,r5,r1) 	!bits 0-31 of product 	
+
+	DMULUH	(r3)
+	
+	DMULUL	(r4,r7,r8)
+
+	addc	r3,r8
+
+	DMULUH	(r3)
+
+	movt	r9
+	clrt
+
+	DMULUL	(r5,r6,r7)
+
+	addc	r7,r8		!bits 63-32 of product
+
+	movt	r7
+	add	r7,r9
+
+	DMULUH	(r7)
+
+	add	r7,r3
+
+	add	r9,r3
+	clrt
+
+	DMULUL	(r4,r6,r7)
+
+	addc	r7,r3		!bits 64-95 of product
+
+	DMULUH	(r7)
+	DMULU_RESTORE
+	
+	mov	#0,r5
+	addc	r5,r7		!bits 96-105 of product
+
+	cmp/eq	r5,r1
+	mov     #1,r4
+
+	bt	.L_skip
+	or	r4,r8
+.L_skip:
+	mov.l   .L_106_bit,r4
+	mov	r8,r9
+
+.L_chk_extra_msb:
+	!chk if exra MSB is generated
+	and     r7,r4
+	cmp/eq	r5,r4
+
+	mov     #12,r4
+	SL(bf,	.L_shift_rt_by_1,
+	 mov     #31,r5)
+	
+.L_pack_mantissa:
+	!scale the mantissa t0 53 bits
+	mov	#-19,r6
+	mov.l	.L_mask_high_mant,r5
+
+        SHLRN (19, r6, r8)
+
+	and	r3,r5
+
+	shlr	r8
+	movt	r1
+
+        SHLLN (12, r4, r5)
+
+	add	#-1,r6
+
+	or	r5,r8		!lower bits of resulting mantissa
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r6,r3
+#else
+        SHLR20 (r3)
+#endif
+
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r4,r7
+#else
+        SHLL12 (r7)
+#endif
+	clrt
+
+	or	r7,r3		!higher bits of resulting mantissa
+	mov     #0,r7
+
+	!chk the exponent for underflow
+	cmp/ge	r2,r7
+	bt	.L_underflow
+
+	addc    r1,r8           !rounding
+	mov	r8,r1
+
+	addc	r7,r3		!rounding
+	mov.l	.L_mask_22_bit,r5
+
+	and	r3,r5
+	!chk if extra msb is generated after rounding
+	cmp/eq	r7,r5
+
+	mov.l	.L_mask_high_mant,r8
+	bt	.L_pack_result
+
+	add	#1,r2
+	mov.l	.L_2047,r6
+
+	cmp/ge	r6,r2
+
+	bt	.L_return_inf
+	shlr	r3
+
+	rotcr	r1
+
+.L_pack_result:
+	!pack the result, r2=exponent, r3=higher mantissa, r1=lower mantissa
+	!r0=sign bit
+	mov	#20,r6
+	and	r8,r3
+	
+#if !defined (__sh1__) && !defined (__sh2__) && !defined (__SH2E__)
+        shld    r6,r2
+#else
+        SHLL20 (r2)
+#endif
+	or	r3,r0
+	
+	or      r2,r0
+	mov.l   @r15+,r9
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	mov.l   @r15+,r8
+
+.L_norm_a:
+	!normalize op1
+	shll	r5
+	mov.l	.L_imp_bit,r1
+
+	rotcl	r4
+	add	#-1,r3
+
+	tst	r1,r4
+	bt	.L_norm_a
+
+	bra	.L_chk_b
+	add	#1,r3
+
+.L_norm_b:
+	!normalize op2
+        shll    r7
+        mov.l   .L_imp_bit,r1
+
+        rotcl   r6
+        add     #-1,r2
+
+        tst     r1,r6
+        bt      .L_norm_b
+
+        bra     .L_mul1
+        add     #1,r2
+
+.L_shift_rt_by_1:
+	!adjust the extra msb
+
+	add     #1,r2           !add 1 to exponent
+	mov.l	.L_2047,r6
+
+	cmp/ge	r6,r2
+	mov	#20,r6
+
+	bt	.L_return_inf
+	shlr	r7		!r7 contains bit 96-105 of product
+
+	rotcr	r3		!r3 contains bit 64-95 of product
+
+	rotcr	r8		!r8 contains bit 32-63 of product
+	bra	.L_pack_mantissa
+
+	rotcr	r1		!r1 contains bit 31-0 of product
+
+.L_return_inf:
+	!return Inf
+	mov.l	.L_inf,r2
+	mov     #0,r1
+
+	or	r2,r0
+	mov.l   @r15+,r9
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	mov.l   @r15+,r8
+	
+.L_underflow:
+	!check if the result needs to be denormalized
+	mov	#-53,r1
+	add	#1,r2
+
+	cmp/gt	r2,r1
+	mov	#32,r4
+
+	add	#-2,r2
+	bt	.L_return_zero
+
+	add	r2,r4
+	mov	r7,r1
+	
+	cmp/ge	r7,r4
+	mov	r2,r6
+
+	mov	#-54,r2
+	bt	.L_denorm
+
+	mov	#-32,r6
+	
+.L_denorm:
+	!denormalize the result
+	shlr	r8
+	rotcr	r1	
+
+	shll	r8
+	add	#1,r6
+
+	shlr	r3
+	rotcr	r8
+
+	cmp/eq	r7,r6
+	bf	.L_denorm
+
+	mov	r4,r6
+	cmp/eq	r2,r4
+
+	bt	.L_break
+	mov	r7,r5
+
+	cmp/gt	r6,r7
+	bf	.L_break
+
+	mov	r2,r4
+	mov	r1,r5
+
+	mov	r7,r1
+	bt	.L_denorm
+
+.L_break:
+	mov	#0,r2
+
+	cmp/gt	r1,r2
+
+	addc	r2,r8
+	mov.l	.L_comp_1,r4
+	
+	addc	r7,r3
+	or	r3,r0
+
+	cmp/eq	r9,r7
+	bf	.L_return
+
+	cmp/eq	r7,r5
+	mov.l	.L_mask_sign,r6
+
+	bf	.L_return
+	cmp/eq	r1,r6
+	
+	bf	.L_return
+	and	r4,r8
+
+.L_return:
+	mov.l	@r15+,r9
+	mov	r8,r1
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+	rts
+	mov.l   @r15+,r8
+
+.L_return_zero:
+	mov.l	@r15+,r9
+	mov	r7,r1
+
+#ifdef __LITTLE_ENDIAN__
+        mov     r0,r2
+        mov     r1,r0
+        mov     r2,r1
+#endif
+
+	rts
+	mov.l	@r15+,r8
+
+	.align	2
+
+.L_mask_high_mant:
+	.long	0x000fffff
+.L_inf:
+	.long	0x7ff00000	
+.L_mask_sign:
+	.long	0x80000000
+.L_1023:
+	.long	-1023
+.L_2047:
+	.long	2047
+.L_imp_bit:
+	.long	0x00100000
+.L_mask_22_bit:
+	.long	0x00200000
+.L_106_bit:
+	.long	0x00000200
+.L_comp_1:
+	.long	0xfffffffe
+
+ENDFUNC (GLOBAL (muldf3))
diff -urN gcc-4.7.3/libgcc/config/sh/IEEE-754/mulsf3.S st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/mulsf3.S
--- gcc-4.7.3/libgcc/config/sh/IEEE-754/mulsf3.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/IEEE-754/mulsf3.S	2012-04-04 14:39:21.000000000 +0200
@@ -0,0 +1,352 @@
+/* Copyright (C) 2004, 2006 Free Software Foundation, Inc.
+
+This file is free software; you can redistribute it and/or modify it
+under the terms of the GNU General Public License as published by the
+Free Software Foundation; either version 2, or (at your option) any
+later version.
+
+In addition to the permissions in the GNU General Public License, the
+Free Software Foundation gives you unlimited permission to link the
+compiled version of this file into combinations with other programs,
+and to distribute those combinations without any restriction coming
+from the use of this file.  (The General Public License restrictions
+do apply in other respects; for example, they cover modification of
+the file, and distribution when not linked into a combine
+executable.)
+
+This file is distributed in the hope that it will be useful, but
+WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program; see the file COPYING.  If not, write to
+the Free Software Foundation, 51 Franklin Street, Fifth Floor,
+Boston, MA 02110-1301, USA.  */
+
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+! Routine for multiplying two floating point numbers
+
+! Author: Rakesh Kumar
+
+! Arguments: r4 and r5
+! Result: r0
+
+! The arguments are referred as op1 and op2
+!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
+
+        .text
+        .align 5
+        .global GLOBAL (mulsf3)
+        FUNC (GLOBAL (mulsf3))
+
+GLOBAL (mulsf3):
+	! Extract the sign bits
+	mov.l	.L_sign,r3
+	mov	r3,r0
+
+	and	r4,r3		! sign bit for op1
+	mov.l	.L_sign_mask,r6
+
+	! Mask out the sign bit from op1 and op2
+	and	r5,r0		! sign bit for op2
+	mov.l	.L_inf,r2
+
+	and	r6,r4
+	xor	r3,r0		! Final sign in r0
+
+	and	r6,r5
+	tst	r4,r4
+
+	! Check for zero
+	mov	r5,r7
+	! Check op1 for zero
+	SL(bt,	.L_op1_zero,
+	 mov	r4,r6)
+
+	tst	r5,r5
+	bt	.L_op2_zero	! op2 is zero
+
+	! Extract the exponents
+	and	r2,r6		! Exponent of op1
+	cmp/eq	r2,r6
+
+	and	r2,r7
+	bt	.L_inv_op1	! op1 is NaN or Inf
+
+	mov.l	.L_mant,r3
+	cmp/eq	r2,r7
+
+	and	r3,r4	! Mantissa of op1
+	bt	.L_ret_op2	! op2 is Nan or Inf
+
+	and	r3,r5	! Mantissa of op2
+
+	mov	#-23,r3
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLR23 (r6)
+	SHLR23 (r7)
+#else
+	shld	r3,r6
+	shld	r3,r7
+#endif
+	! Check for denormals
+	mov.l	.L_24bit,r3
+	tst	r6,r6
+
+	bt	.L_norm_op1	! op1 is denormal
+	add	#-127,r6	! Unbias op1's exp
+
+	tst	r7,r7
+	bt	.L_norm_op2	! op2 is denormal
+
+	add	#-127,r7	! Unbias op2's exp
+
+.L_multiply:
+	add	r6,r7	! Final exponent in r7
+	mov.l	.L_24bit,r1
+
+	! set 24th bit of mantissas
+	mov	#127,r3
+	or	r1,r4
+
+	DMULU_SAVE
+
+	! Multiply
+	or	r1,r5
+	DMULUL	(r4,r5,r4)
+
+	DMULUH	(r5)
+
+	DMULU_RESTORE
+
+	mov.l	.L_16bit,r6
+
+	! Check for extra MSB generated
+	tst	r5,r6
+
+	mov.l	.L_255,r1
+	bf	.L_shift_by_1	! Adjust the extra MSB
+	
+! Normalize the result with rounding
+.L_epil:
+	! Bias the exponent
+	add	#127,r7
+	cmp/ge	r1,r7
+	
+	! Check exponent overflow and underflow
+	bt	.L_ret_inf
+
+	cmp/pl	r7
+	bf	.L_denorm
+
+.L_epil_0:
+	mov	#-23,r3
+	shll	r5
+	mov	#0,r6
+
+! Fit resultant mantissa in 24 bits
+! Apply default rounding
+.L_loop_epil_0:
+        tst	r3,r3
+	bt	.L_loop_epil_out
+
+	add	#1,r3
+	shlr	r4
+
+	bra	.L_loop_epil_0
+	rotcr	r6
+
+! Round mantissa
+.L_loop_epil_out:
+	shll8	r5
+	or	r5,r4
+
+	mov.l	.L_mant,r2
+	mov	#23,r3
+
+	! Check last bit shifted out of result
+	tst	r6,r6
+	bt	.L_epil_2
+
+	! Round
+	shll	r6
+	movt	r5
+
+	add	r5,r4
+
+	! If this is the only ON bit shifted
+	! Round towards LSB = 0
+	tst	r6,r6
+	bf	.L_epil_2
+
+	shlr	r4
+	shll	r4
+
+.L_epil_2:
+	! Rounding may have produced extra MSB.
+	mov.l	.L_25bit,r5
+	tst	r4,r5
+
+	bt	.L_epil_1
+
+	add	#1,r7
+	shlr	r4
+
+.L_epil_1:
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+	SHLL23 (r7)
+#else
+	shld	r3,r7
+#endif
+
+	and	r2,r4
+
+	or	r7,r4
+	rts
+	or	r4,r0
+
+.L_denorm:
+	mov	#0,r3
+
+.L_den_1:
+	shlr	r5
+	rotcr	r4
+
+	cmp/eq	r3,r7
+	bt	.L_epil_0
+
+	bra	.L_den_1
+	add	#1,r7
+	
+
+! Normalize the first argument
+.L_norm_op1:
+	shll	r4
+	tst	r3,r4
+
+	add	#-1,r6
+	bt	.L_norm_op1
+
+	! The biasing is by 126
+	add	#-126,r6
+	tst	r7,r7
+
+	bt      .L_norm_op2
+
+	bra	.L_multiply
+	add	#-127,r7
+
+! Normalize the second argument
+.L_norm_op2:
+	shll	r5
+	tst	r3,r5
+
+	add	#-1,r7
+	bt	.L_norm_op2
+
+	bra	.L_multiply
+	add	#-126,r7
+
+! op2 is zero. Check op1 for exceptional cases
+.L_op2_zero:
+	mov.l	.L_inf,r2
+	and	r2,r6
+
+	! Check if op1 is deterministic
+	cmp/eq	r2,r6
+	SL(bf,	.L_ret_op2,
+	 mov	#1,r1)
+
+	! Return NaN
+	rts
+	mov	#-1,r0
+
+! Adjust the extra MSB
+.L_shift_by_1:
+	shlr	r5
+	rotcr	r4
+
+	add	#1,r7		! Show the shift in exponent
+
+	cmp/gt	r3,r7
+	bf	.L_epil
+
+	! The resultant exponent is invalid
+	mov.l	.L_inf,r1
+	rts
+	or	r1,r0
+
+.L_ret_op1:
+	rts
+	or	r4,r0
+
+! op1 is zero. Check op2 for exceptional cases
+.L_op1_zero:
+	mov.l	.L_inf,r2
+	and	r2,r7
+	
+	! Check if op2 is deterministic
+	cmp/eq	r2,r7
+	SL(bf,	.L_ret_op1,
+	 mov	#1,r1)
+
+	! Return NaN
+	rts
+	mov	#-1,r0
+
+.L_inv_op1:
+	mov.l	.L_mant,r3
+	mov	r4,r6
+
+	and	r3,r6
+	tst	r6,r6
+
+	bf	.L_ret_op1	! op1 is Nan
+	! op1 is not Nan. It is Inf
+
+	cmp/eq	r2,r7
+	bf	.L_ret_op1	! op2 has a valid exponent
+
+! op2 has a invalid exponent. It could be Inf, -Inf, Nan.
+! It doesn't make any difference.
+.L_ret_op2:
+	rts
+	or	r5,r0
+
+.L_ret_inf:
+	rts
+	or	r2,r0
+
+.L_ret_zero:
+	mov	#0,r2
+	rts
+	or	r2,r0
+
+	
+	.align 2
+.L_mant:
+	.long 0x007FFFFF
+
+.L_inf:
+	.long 0x7F800000
+
+.L_24bit:
+	.long 0x00800000
+
+.L_25bit:
+	.long 0x01000000
+
+.L_16bit:
+	.long 0x00008000
+
+.L_sign:
+	.long 0x80000000
+
+.L_sign_mask:
+	.long 0x7FFFFFFF
+
+.L_255:
+	.long 0x000000FF
+
+ENDFUNC (GLOBAL (mulsf3))
diff -urN gcc-4.7.3/libgcc/config/sh/ieee-754-df.S st40-4.7.3-13080/gcc/libgcc/config/sh/ieee-754-df.S
--- gcc-4.7.3/libgcc/config/sh/ieee-754-df.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/ieee-754-df.S	2013-04-30 15:17:53.000000000 +0200
@@ -0,0 +1,795 @@
+/* Copyright (C) 2006, 2008, 2009 Free Software Foundation, Inc.
+   Copyright (c) 2010 STMicroelectronics.
+
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+
+   GCC is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   Under Section 7 of GPL version 3, you are granted additional
+   permissions described in the GCC Runtime Library Exception, version
+   3.1, as published by the Free Software Foundation.
+
+   You should have received a copy of the GNU General Public License and
+   a copy of the GCC Runtime Library Exception along with this program;
+   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+   <http://www.gnu.org/licenses/>.  */
+
+!! libgcc software floating-point routines for Renesas SH /
+!! STMicroelectronics ST40 CPUs
+!! Contributed by J"orn Rennecke joern.rennecke@st.com
+
+#ifndef __SH_FPU_DOUBLE__
+
+#include "lib1funcs.h"
+
+#define DF_NAN_MASK		0x7ff80000
+
+/* Double-precision floating-point emulation.
+   We handle NANs, +-infinity, and +-zero.
+   However, we assume that for NANs, the topmost bit of the fraction is set.  */
+
+#ifdef __LITTLE_ENDIAN__
+#define DBL0L r4
+#define DBL0H r5
+#define DBL1L r6
+#define DBL1H r7
+#define DBLRL r0
+#define DBLRH r1
+#else
+#define DBL0L r5
+#define DBL0H r4
+#define DBL1L r7
+#define DBL1H r6
+#define DBLRL r1
+#define DBLRH r0
+#endif
+
+#ifdef __SH_FPU_ANY__
+#define RETURN_R0_MAIN
+#define RETURN_R0 bra LOCAL(return_r0)
+#define RETURN_FR0 \
+LOCAL(return_r0): \
+ lds r0,fpul; \
+ rts; \
+ fsts fpul,fr0
+#define ARG_TO_R4 \
+ flds fr4,fpul; \
+ sts fpul,r4
+#else /* ! __SH_FPU_ANY__ */
+#define RETURN_R0_MAIN rts
+#define RETURN_R0 rts
+#define RETURN_FR0
+#define ARG_TO_R4
+#endif /* ! __SH_FPU_ANY__ */
+
+#ifdef L_nedf2
+/* -fno-finite-math-only -mb inline version, T := r4:DF == r6:DF
+	cmp/eq	r5,r7
+	mov	r4,r0
+	bf	0f
+	cmp/eq	r4,r6
+	bt	0f
+	or	r6,r0
+	add	r0,r0
+	or	r5,r0
+	tst	r0,r0
+	0:			*/
+	.balign 4
+	.global GLOBAL(nedf2)
+	HIDDEN_FUNC(GLOBAL(nedf2))
+GLOBAL(nedf2):
+	cmp/eq	DBL0L,DBL1L
+	bf.s 	LOCAL(ne)
+	mov     #1,r0
+	cmp/eq	DBL0H,DBL1H
+	mov.l   LOCAL(c_DF_NAN_MASK),r1
+	bt.s	LOCAL(check_nan)
+	not	DBL0H,r0
+	mov	DBL0H,r0
+	or	DBL1H,r0
+	add	r0,r0
+	rts
+	or	DBL0L,r0
+LOCAL(check_nan):
+	tst	r1,r0
+	bt.s 	LOCAL(nan)
+	mov	#12,r2
+	shll16  r2
+	xor 	r2,r1
+	tst 	r1,r0
+LOCAL(nan):
+	movt	r0
+LOCAL(ne):
+	rts
+	nop
+
+	.balign 4
+LOCAL(c_DF_NAN_MASK):
+	.long DF_NAN_MASK
+	ENDFUNC(GLOBAL(nedf2))
+#endif /* L_nedf2 */
+
+#ifdef L_unord_df
+	.balign 4
+	.global GLOBAL(unorddf2)
+	HIDDEN_FUNC(GLOBAL(unorddf2))
+GLOBAL(unorddf2):
+	mov.l	LOCAL(c_DF_NAN_MASK),r1
+	not	DBL0H,r0
+	tst	r1,r0
+	not	r6,r0
+	bt	LOCAL(unord)
+	tst	r1,r0
+LOCAL(unord):
+	rts
+	movt	r0
+	.balign	4
+LOCAL(c_DF_NAN_MASK):
+	.long DF_NAN_MASK
+	ENDFUNC(GLOBAL(unorddf2))
+#endif /* L_unord_df */
+
+#if defined(L_gtdf2f) || defined(L_gtdf2f_trap)
+/* -fno-finite-math-only version of _gt_df */
+#ifdef L_gtdf2f
+#define fun_label GLOBAL(gtdf2f)
+#else
+#define fun_label GLOBAL(gtdf2f_trap)
+#endif
+	.balign 4
+	.global fun_label
+	HIDDEN_FUNC(fun_label)
+fun_label:
+	/* If the raw values compare greater, the result true, unless
+	   any of them is a nan (but infinity is fine), or both values are
+	   +- zero.  Otherwise, the result false.  */
+	mov.l	LOCAL(c_DF_NAN_MASK),r1
+	cmp/pz	DBL0H
+	not	DBL1H,r0
+	SLC(bf,	LOCAL(neg),
+	 tst	r1,r0)
+	mov	DBL0H,r0
+	bt	LOCAL(nan) /* return zero if DBL1 is NAN.  */
+	cmp/eq	DBL1H,DBL0H
+	bt	LOCAL(cmp_low)
+	cmp/gt	DBL1H,DBL0H
+	or	DBL1H,r0
+	SLC(bf,	LOCAL(check_nan),
+	 cmp/gt	DBL0H,r1)
+	add	r0,r0
+	bf	LOCAL(nan) /* return zero if DBL0 is NAN.  */
+	or	DBL0L,r0
+	rts
+	or	DBL1L,r0 /* non-zero unless both DBL0 and DBL1 are +-zero.  */
+LOCAL(cmp_low):
+	cmp/hi	DBL1L,DBL0L
+	rts
+	movt	r0
+LOCAL(neg):
+	SLI(tst	r1,r0)
+	bt	LOCAL(nan) /* return zero if DBL1 is NAN.  */
+	cmp/eq	DBL1H,DBL0H
+	SLC(bt,	LOCAL(neg_cmp_low),
+	 cmp/hi	DBL0L,DBL1L)
+	not	DBL0H,r0
+	tst	r1,r0
+	bt	LOCAL(nan) /* return zero if DBL0 is NAN.  */
+	cmp/hi	DBL0H,DBL1H
+	SLI(rts	!,)
+	SLI(movt r0 !,)
+LOCAL(neg_cmp_low):
+	SLI(cmp/hi	DBL0L,DBL1L)
+	rts
+	movt	r0
+LOCAL(check_nan):
+#ifdef L_gtdf2f
+LOCAL(nan):
+	rts
+	mov	#0,r0
+#else
+	SLI(cmp/gt DBL0H,r1)
+	bf	LOCAL(nan) /* return zero if DBL0 is NAN.  */
+	rts
+	mov	#0,r0
+LOCAL(nan):
+	mov	#0,r0
+	trapa	#0
+#endif
+	.balign	4
+LOCAL(c_DF_NAN_MASK):
+	.long DF_NAN_MASK
+	ENDFUNC(fun_label)
+#endif /* defined(L_gtdf2f) || defined(L_gtdf2f_trap) */
+
+#ifdef L_gedf2f
+	.balign 4
+	.global GLOBAL(gedf2f)
+	HIDDEN_FUNC(GLOBAL(gedf2f))
+GLOBAL(gedf2f):
+	/* -fno-finite-math-only version of _ge_df */
+	/* If the raw values compare greater or equal, the result is
+	   true, unless any of them is a nan, or both are the
+	   same infinity.  If both are -+zero, the result is true;
+	   otherwise, it is false.
+	   We use 0 as true and nonzero as false for this function.  */
+	mov.l	LOCAL(c_DF_NAN_MASK),r1
+	cmp/pz	DBL1H
+	not	DBL0H,r0
+	SLC(bf,	LOCAL(neg),
+	 tst	r1,r0)
+	mov	DBL0H,r0
+	bt	LOCAL(nan)
+	cmp/eq	DBL0H,DBL1H
+	bt	LOCAL(cmp_low)
+	cmp/gt	DBL0H,DBL1H
+	or	DBL1H,r0
+	SLC(bf,	LOCAL(check_nan),
+	 cmp/ge	r1,DBL1H)
+	add	r0,r0
+	bt	LOCAL(nan)
+	or	DBL0L,r0
+	rts
+	or	DBL1L,r0
+LOCAL(cmp_low):
+	cmp/hi	DBL0L,DBL1L
+#if defined(L_gedf2f) && defined(DELAYED_BRANCHES)
+LOCAL(nan): LOCAL(check_nan):
+#endif
+	rts
+	movt	r0
+#if defined(L_gedf2f) && ! defined(DELAYED_BRANCHES)
+LOCAL(check_nan):
+	SLI(cmp/ge	r1,DBL1H)
+LOCAL(nan):
+	rts
+	movt	r0
+#elif defined(L_gedf2f_trap)
+LOCAL(check_nan):
+	SLI(cmp/ge	r1,DBL1H)
+	bt	LOCAL(nan)
+	rts
+LOCAL(nan):
+	movt	r0
+	trapa	#0
+#endif /* L_gedf2f_trap */
+LOCAL(neg):
+	SLI(tst	r1,r0)
+	bt	LOCAL(nan)
+	cmp/eq	DBL0H,DBL1H
+	not	DBL1H,r0
+	SLC(bt,	LOCAL(neg_cmp_low),
+	 cmp/hi	DBL1L,DBL0L)
+	tst	r1,r0
+	bt	LOCAL(nan)
+	cmp/hi	DBL1H,DBL0H
+	SLI(rts !,)
+	SLI(movt	r0 !,)
+LOCAL(neg_cmp_low):
+	SLI(cmp/hi	DBL1L,DBL0L)
+	rts
+	movt	r0
+	.balign	4
+LOCAL(c_DF_NAN_MASK):
+	.long DF_NAN_MASK
+	ENDFUNC(GLOBAL(gedf2f))
+#endif /* L_gedf2f */
+
+#ifndef DYN_SHIFT /* SH1 / SH2 code */
+#ifdef L_sf_to_df
+	.balign 4
+	.global GLOBAL(extendsfdf2)
+	FUNC(GLOBAL(extendsfdf2))
+GLOBAL(extendsfdf2):
+	ARG_TO_R4
+	mov.l	LOCAL(x7f800000),r3
+	mov	r4,DBLRL
+	tst	r3,r4
+	bt	LOCAL(zero_denorm)
+	mov.l	LOCAL(xe0000000),r2
+	rotr	DBLRL
+	rotr	DBLRL
+	rotr	DBLRL
+	and	r2,DBLRL
+	mov	r4,DBLRH
+	not	r4,r2
+	tst	r3,r2
+	mov.l	LOCAL(x38000000),r2
+	bf	0f
+	add	r2,r2	! infinity / NaN adjustment
+0:	shll	DBLRH
+	shlr2	DBLRH
+	shlr2	DBLRH
+	add	DBLRH,DBLRH
+	rotcr	DBLRH
+	rts
+	add	r2,DBLRH
+LOCAL(zero_denorm):
+	mov.l	r4,@-r15
+	add	r4,r4
+	tst	r4,r4
+	bt	LOCAL(zero)
+	shlr8	r3	/* 0x007f8000 */
+	mov.w	LOCAL(x389),r2
+LOCAL(shift_byte):
+	tst	r3,r4
+	shll8	r4
+	SL(bt,	LOCAL(shift_byte),
+	 add	#-8,r2)
+LOCAL(shift_bit):
+	shll	r4
+	SL(bf,	LOCAL(shift_bit),
+	 add	#-1,r2)
+	mov	#0,DBLRL
+	mov	r4,DBLRH
+	mov.l	@r15+,r4
+	shlr8	DBLRH
+	shlr2	DBLRH
+	shlr	DBLRH
+	rotcr	DBLRL
+	cmp/gt	r4,DBLRH	! get sign
+	rotcr	DBLRH
+	rotcr	DBLRL
+	shll16	r2
+	shll8	r2
+	rts
+	add	r2,DBLRH
+LOCAL(zero):
+	mov.l	@r15+,DBLRH
+	rts
+	mov	#0,DBLRL
+LOCAL(x389):	.word 0x389
+	.balign	4
+LOCAL(x7f800000):
+	.long	0x7f800000
+LOCAL(x38000000):
+	.long	0x38000000
+LOCAL(xe0000000):
+	.long	0xe0000000
+	ENDFUNC(GLOBAL(extendsfdf2))
+#endif /* L_sf_to_df */
+
+#ifdef L_df_to_sf
+	.balign 4
+	.global GLOBAL(truncdfsf2)
+	FUNC(GLOBAL(truncdfsf2))
+GLOBAL(truncdfsf2):
+	mov.l	LOCAL(x38000000),r3	! exponent adjustment DF -> SF
+	mov	DBL0H,r1
+	mov.l	LOCAL(x70000000),r2	! mask for out-of-range exponent bits
+	mov	DBL0H,r0
+	mov.l	DBL0L,@-r15
+	sub	r3,r1
+	tst	r2,r1
+	shll8	r0			!
+	shll2	r0			! Isolate highpart fraction.
+	shll2	r0			!
+	bf	LOCAL(ill_exp)
+	shll2	r1
+	mov.l	LOCAL(x2fffffff),r2 /* Fraction lsb | lower guard bits.  */
+	shll2	r1
+	mov.l	LOCAL(xff000000),r3
+	shlr8	r0
+	tst	r2,DBL0L /* Check if msb guard bit wants rounding up.  */
+	shlr16	DBL0L
+	shlr8	DBL0L
+	shlr2	DBL0L
+	SL1(bt,	LOCAL(add_frac),
+	 shlr2	DBL0L)
+	add	#1,DBL0L
+LOCAL(add_frac):
+	add	DBL0L,r0
+	mov.l	LOCAL(x01000000),r2
+	and	r3,r1
+	mov.l	@r15+,DBL0L
+	add	r1,r0
+	tst	r3,r0
+	bt	LOCAL(inf_denorm0)
+	cmp/hs	r3,r0
+LOCAL(denorm_noup_sh1):
+	bt	LOCAL(inf)
+	div0s	DBL0H,r2	/* copy orig. sign into T.  */
+RETURN_R0_MAIN
+	rotcr	r0
+RETURN_FR0
+LOCAL(inf_denorm0):	!  We might need to undo previous rounding.
+	mov.l	LOCAL(x2fffffff),r3 /* Old fraction lsb | lower guard bits.  */
+	tst	r1,r1
+	bf	LOCAL(inf)
+	add	#-1,r0
+	tst	r3,DBL0L /* Check if msb guard bit was rounded up.  */
+	mov.l	LOCAL(x5fffffff),r3 /* Fraction lsb | lower guard bits.  */
+	addc	r2,r0
+	shlr	r0
+	tst	r3,DBL0L /* Check if msb guard bit wants rounding up.  */
+#ifdef DELAYED_BRANCHES
+	bt/s	LOCAL(denorm_noup)
+#else
+	bt	LOCAL(denorm_noup_sh1)
+#endif
+	div0s	DBL0H,r2	/* copy orig. sign into T.  */
+	add	#1,r0
+LOCAL(denorm_noup):
+	RETURN_R0
+	rotcr	r0
+LOCAL(ill_exp):
+	div0s	DBL0H,r1
+	mov.l	LOCAL(x7ff80000),r2
+	add	r1,r1
+	bf	LOCAL(inf_nan)
+	mov.w	LOCAL(m32),r3 /* Handle denormal or zero.  */
+	shlr16	r1
+	exts.w	r1,r1
+	shll2	r1
+	add	r1,r1
+	shlr8	r1
+	exts.w	r1,r1
+	add	#-8,r1	/* Go from 9 to 1 guard bit in MSW.  */
+	cmp/gt	r3,r1
+	mov.l	@r15+,r3 /* DBL0L */
+	bf	LOCAL(zero)
+	mov.l	DBL0L, @-r15
+	shll8	DBL0L
+	rotcr	r0	/* Insert leading 1.  */
+	shlr16	r3
+	shll2	r3
+	add	r3,r3
+	shlr8	r3
+	cmp/pl	DBL0L	/* Check lower 23 guard bits if guard bit 23 is 0.  */
+	addc	r3,r0	/* Assemble fraction with compressed guard bits.  */
+	mov.l	@r15+,DBL0L
+	mov	#0,r2
+	neg	r1,r1
+LOCAL(denorm_loop):
+	shlr	r0
+	rotcl	r2
+	dt	r1
+	bf	LOCAL(denorm_loop)
+	tst	#2,r0
+	rotcl	r0
+	tst	r2,r2
+	rotcl	r0
+	xor	#3,r0
+	add	#3,r0	/* Even overflow gives the correct result.  */
+	shlr2	r0
+	div0s	r0,DBL0H
+	RETURN_R0
+	rotcr	r0
+LOCAL(zero):
+	mov	#0,r0
+	div0s	r0,DBL0H
+	RETURN_R0
+	rotcr	r0
+LOCAL(inf_nan):
+	not	DBL0H,r0
+	tst	r2,r0
+	mov.l	@r15+,DBL0L
+	bf	LOCAL(inf)
+	RETURN_R0
+	mov	#-1,r0	/* NAN */
+LOCAL(inf):	/* r2 must be positive here.  */
+	mov.l	LOCAL(xff000000),r0
+	div0s	r2,DBL0H
+	RETURN_R0
+	rotcr	r0
+LOCAL(m32):
+	.word	-32
+	.balign	4
+LOCAL(x38000000):
+	.long	0x38000000
+LOCAL(x70000000):
+	.long	0x70000000
+LOCAL(x2fffffff):
+	.long	0x2fffffff
+LOCAL(x01000000):
+	.long	0x01000000
+LOCAL(xff000000):
+	.long	0xff000000
+LOCAL(x5fffffff):
+	.long	0x5fffffff
+LOCAL(x7ff80000):
+	.long	0x7ff80000
+	ENDFUNC(GLOBAL(truncdfsf2))
+#endif /*  L_df_to_sf */
+#ifdef L_addsub_df
+#include "IEEE-754/adddf3.S"
+#endif /* _addsub_df */
+
+#ifdef L_mul_df
+#include "IEEE-754/muldf3.S"
+#endif /* L_mul_df */
+
+#ifdef L_df_to_usi
+#include "IEEE-754/fixunsdfsi.S"
+#endif /* L_df_to_usi */
+
+#ifdef L_df_to_si
+#include "IEEE-754/fixdfsi.S"
+#endif /* L_df_to_si */
+
+#ifdef L_usi_to_df
+#include "IEEE-754/floatunssidf.S"
+#endif /* L_usi_to_df */
+
+#ifdef L_si_to_df
+#include "IEEE-754/floatsidf.S"
+#endif /* L_si_df */
+
+#ifdef L_div_df
+#include "IEEE-754/divdf3.S"
+#endif /* L_div_df */
+#endif /* ! DYN_SHIFT */
+
+/* The actual arithmetic uses dynamic shift.  Supporting SH1 / SH2 here would
+   make this code too hard to maintain, so if you want to add SH1 / SH2
+   support, do it in a separate copy.  */
+#ifdef DYN_SHIFT
+#ifdef L_sf_to_df
+	.balign 4
+	.global GLOBAL(extendsfdf2)
+	FUNC(GLOBAL(extendsfdf2))
+GLOBAL(extendsfdf2):
+	ARG_TO_R4
+	mov.l	LOCAL(x7f800000),r2
+	mov	#29,r3
+	mov	r4,DBLRL
+	not	r4,DBLRH
+	tst	r2,r4
+	shld	r3,DBLRL
+	bt	LOCAL(zero_denorm)
+	mov	#-3,r3
+	tst	r2,DBLRH
+	mov	r4,DBLRH
+	mov.l	LOCAL(x38000000),r2
+	bt/s	LOCAL(inf_nan)
+	 shll	DBLRH
+	shld	r3,DBLRH
+	rotcr	DBLRH
+	rts
+	add	r2,DBLRH
+	.balign	4
+LOCAL(inf_nan):
+	shld	r3,DBLRH
+	add	r2,r2
+	rotcr	DBLRH
+	rts
+	add	r2,DBLRH
+LOCAL(zero_denorm):
+	mov.l	r4,@-r15
+	add	r4,r4
+	tst	r4,r4
+	extu.w	r4,r2
+	bt	LOCAL(zero)
+	cmp/eq	r4,r2
+	extu.b	r4,r1
+	mov.l	LOCAL(c__clz_tab),r0
+	bf	LOCAL(three_bytes)
+	nop
+	cmp/eq	r4,r1
+	mov	#22,DBLRH
+	bt	LOCAL(one_byte)
+	shlr8	r2
+	mov	#14,DBLRH
+LOCAL(one_byte):
+#ifdef __pic__
+	add	r0,r2
+	mova  LOCAL(c__clz_tab),r0
+#endif
+	mov.b	@(r0,r2),r2
+	mov	#21,r3
+	mov.w	LOCAL(x0),DBLRL
+	sub	r2,DBLRH
+LOCAL(norm_shift):
+	shld	DBLRH,r4
+	neg	DBLRH,DBLRH
+	mov.l	@r15+,r2
+	shld	r3,DBLRH
+	mov.l	LOCAL(x6fa00000),r3
+	add	r4,DBLRH
+	mov r2,r4
+	add	r3,DBLRH
+
+	div0s	r3,r4
+	rts
+	rotcr	DBLRH
+LOCAL(three_bytes):
+	mov	r4,r2
+	shlr16	r2
+#ifdef __pic__
+	add	r0,r2
+	mova  LOCAL(c__clz_tab),r0
+#endif
+	mov.b	@(r0,r2),r2
+	mov	#21,r3
+	mov	#6+10,DBLRH
+	sub	r2,DBLRH
+	mov	r4,DBLRL
+	shld	r3,DBLRL
+	shld	DBLRH,DBLRL
+	bra	LOCAL(norm_shift)
+	add	#-10,DBLRH
+LOCAL(zero):
+	rts	/* DBLRL has already been zeroed above.  */
+	mov.l @r15+,DBLRH
+LOCAL(x0):
+	.word 0
+	.balign	4
+LOCAL(x7f800000):
+	.long	0x7f800000
+LOCAL(x38000000):
+	.long	0x38000000
+LOCAL(x6fa00000):
+	/* Flip sign back, do exponent adjustment, and remove leading one.  */
+	.long 0x6fa00000 
+LOCAL(c__clz_tab):
+#ifdef __pic__
+	.long	GLOBAL(clz_tab) - .
+#else
+	.long	GLOBAL(clz_tab)
+#endif
+	ENDFUNC(GLOBAL(extendsfdf2))
+#endif /* L_sf_to_df */
+
+#ifdef L_df_to_sf
+	.balign 4
+	.global GLOBAL(truncdfsf2)
+	FUNC(GLOBAL(truncdfsf2))
+GLOBAL(truncdfsf2):
+	mov.l	LOCAL(x38000000),r3
+	mov	DBL0H,r1
+	mov.l	LOCAL(x70000000),r2
+	mov	DBL0H,r0
+	sub	r3,r1
+	mov.l	DBL0L,@-r15
+	tst	r2,r1
+	mov	#12,r3
+	shld	r3,r0			! Isolate highpart fraction.
+	bf	LOCAL(ill_exp)
+	shll2	r1
+	mov.l	LOCAL(x2fffffff),r2 /* Fraction lsb | lower guard bits.  */
+	shll2	r1
+	mov.l	LOCAL(xff000000),r3
+	shlr8	r0
+	tst	r2,DBL0L /* Check if msb guard bit wants rounding up.  */
+	mov	#-28,r2
+	bt/s	LOCAL(add_frac)
+	 shld	r2,DBL0L
+	add	#1,DBL0L
+LOCAL(add_frac):
+	add	DBL0L,r0
+	mov.l	LOCAL(x01000000),r2
+	and	r3,r1
+	mov.l	@r15+,DBL0L
+	add	r1,r0
+	tst	r3,r0
+	bt	LOCAL(inf_denorm0)
+	cmp/hs	r3,r0
+	bt	LOCAL(inf)
+	div0s	DBL0H,r2	/* copy orig. sign into T.  */
+	RETURN_R0_MAIN
+	rotcr	r0
+RETURN_FR0
+LOCAL(inf_denorm0):	! We might need to undo previous rounding.
+	mov.l	LOCAL(x2fffffff),r3 /* Old fraction lsb | lower guard bits.  */
+	tst	r1,r1
+	bf	LOCAL(inf)
+	add	#-1,r0
+	tst	r3,DBL0L /* Check if msb guard bit was rounded up.  */
+	mov.l	LOCAL(x5fffffff),r3 /* Fraction lsb | lower guard bits.  */
+	addc	r2,r0
+	shlr	r0
+	tst	r3,DBL0L /* Check if msb guard bit wants rounding up.  */
+	bt/s	LOCAL(denorm_noup)
+	 div0s	DBL0H,r2	/* copy orig. sign into T.  */
+	add	#1,r0
+LOCAL(denorm_noup):
+	RETURN_R0
+	rotcr	r0
+LOCAL(ill_exp):
+	div0s	DBL0H,r1
+	mov.l	LOCAL(x7ff80000),r2
+	add	r1,r1
+	bf	LOCAL(inf_nan)
+	mov.w	LOCAL(m32),r3 /* Handle denormal or zero.  */
+	mov	#-21,r2
+	shad	r2,r1
+	add	#-8,r1	/* Go from 9 to 1 guard bit in MSW.  */
+	cmp/gt	r3,r1
+	mov.l	@r15+,r3 /* DBL0L */
+	bf	LOCAL(zero)
+	mov.l	DBL0L, @-r15
+	shll8	DBL0L
+	rotcr	r0	/* Insert leading 1.  */
+	shld	r2,r3
+	cmp/pl	DBL0L	/* Check lower 23 guard bits if guard bit 23 is 0.  */
+	addc	r3,r0	/* Assemble fraction with compressed guard bits.  */
+	mov	r0,r2
+	shld	r1,r0
+	mov.l	@r15+,DBL0L
+	add	#32,r1
+	shld	r1,r2
+	tst	#2,r0
+	rotcl	r0
+	tst	r2,r2
+	rotcl	r0
+	xor	#3,r0
+	add	#3,r0	/* Even overflow gives the correct result.  */
+	shlr2	r0
+	div0s	r0,DBL0H
+	RETURN_R0
+	rotcr	r0
+LOCAL(zero):
+	mov	#0,r0
+	div0s	r0,DBL0H
+	RETURN_R0
+	rotcr	r0
+LOCAL(inf_nan):
+	not	DBL0H,r0
+	tst	r2,r0
+	mov.l	@r15+,DBL0L
+	bf	LOCAL(inf)
+	RETURN_R0
+	mov	#-1,r0	/* NAN */
+LOCAL(inf):	/* r2 must be positive here.  */
+	mov.l	LOCAL(xff000000),r0
+	div0s	r2,DBL0H
+	RETURN_R0
+	rotcr	r0
+LOCAL(m32):
+	.word	-32
+	.balign	4
+LOCAL(x38000000):
+	.long	0x38000000
+LOCAL(x70000000):
+	.long	0x70000000
+LOCAL(x2fffffff):
+	.long	0x2fffffff
+LOCAL(x01000000):
+	.long	0x01000000
+LOCAL(xff000000):
+	.long	0xff000000
+LOCAL(x5fffffff):
+	.long	0x5fffffff
+LOCAL(x7ff80000):
+	.long	0x7ff80000
+	ENDFUNC(GLOBAL(truncdfsf2))
+#endif /* L_df_to_sf */
+
+
+#ifdef L_addsub_df
+#include "IEEE-754/m3/adddf3.S"
+#endif /* _addsub_df */
+
+#ifdef L_mul_df
+#include "IEEE-754/m3/muldf3.S"
+#endif /* L_mul_df */
+
+#ifdef L_df_to_usi
+#include "IEEE-754/m3/fixunsdfsi.S"
+#endif /* L_df_to_usi */
+
+#ifdef L_df_to_si
+#include "IEEE-754/m3/fixdfsi.S"
+#endif /* L_df_to_si */
+
+#ifdef L_usi_to_df
+#include "IEEE-754/m3/floatunssidf.S"
+#endif /* L_usi_to_df */
+
+#ifdef L_si_to_df
+#include "IEEE-754/m3/floatsidf.S"
+#endif /* L_si_to_df */
+
+#ifdef L_div_df
+#include "IEEE-754/m3/divdf3.S"
+#endif /* L_div_df */
+#endif /* DYN_SHIFT */
+
+#endif /* __SH_FPU_DOUBLE__ */
diff -urN gcc-4.7.3/libgcc/config/sh/ieee-754-sf.S st40-4.7.3-13080/gcc/libgcc/config/sh/ieee-754-sf.S
--- gcc-4.7.3/libgcc/config/sh/ieee-754-sf.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/ieee-754-sf.S	2013-04-30 15:17:53.000000000 +0200
@@ -0,0 +1,704 @@
+/* Copyright (C) 2006, 2008, 2009 Free Software Foundation, Inc.
+   Copyright (c) 2010 STMicroelectronics.
+
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+
+   GCC is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   Under Section 7 of GPL version 3, you are granted additional
+   permissions described in the GCC Runtime Library Exception, version
+   3.1, as published by the Free Software Foundation.
+
+   You should have received a copy of the GNU General Public License and
+   a copy of the GCC Runtime Library Exception along with this program;
+   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+   <http://www.gnu.org/licenses/>.  */
+
+!! libgcc software floating-point routines for Renesas SH /
+!! STMicroelectronics ST40 CPUs
+!! Contributed by J"orn Rennecke joern.rennecke@st.com
+
+#ifndef __SH_FPU_ANY__
+
+#include "lib1funcs.h"
+
+#define SF_NAN_MASK		0x7fc00000
+
+/* Single-precision floating-point emulation.
+   We handle NANs, +-infinity, and +-zero.
+   However, we assume that for NANs, the topmost bit of the fraction is set.  */
+#ifdef L_nesf2
+/* -fno-finite-math-only inline version, T := r4:SF == r5:SF
+	cmp/eq	r4,r5
+	mov	r4,r0
+	bt	0f
+	or	r5,r0
+	add	r0,r0
+	tst	r0,r0	! test for +0.0 == -0.0 ; -0.0 == +0.0
+	0:			*/
+	.balign 4
+	.global GLOBAL(nesf2)
+	HIDDEN_FUNC(GLOBAL(nesf2))
+GLOBAL(nesf2):
+        /* If the raw values are unequal, the result is unequal, unless
+	   both values are +-zero.
+	   If the raw values are equal, the result is equal, unless
+	   the values are NaN.  */
+	cmp/eq	r4,r5
+	mov.l   LOCAL(c_SF_NAN_MASK),r1
+	bt.s	LOCAL(check_nan)
+	not	r4,r0
+	mov	r4,r0
+	or	r5,r0
+	rts
+	add	r0,r0
+LOCAL(check_nan):
+	tst	r1,r0
+	bt.s 	LOCAL(nan)
+	mov	#96,r2
+	shll16  r2
+	xor 	r2,r1
+	tst	r1,r0	
+LOCAL(nan):		
+	rts
+	movt	r0
+	
+	.balign 4
+LOCAL(c_SF_NAN_MASK):
+	.long SF_NAN_MASK
+LOCAL(c_SF_SNAN_MASK):
+	ENDFUNC(GLOBAL(nesf2))
+#endif /* L_nesf2 */
+
+#ifdef L_unord_sf
+	.balign 4
+	.global GLOBAL(unordsf2)
+	HIDDEN_FUNC(GLOBAL(unordsf2))
+GLOBAL(unordsf2):
+	mov.l	LOCAL(c_SF_NAN_MASK),r1
+	not	r4,r0
+	tst	r1,r0
+	not	r5,r0
+	bt	LOCAL(unord)
+	tst	r1,r0
+LOCAL(unord):
+	rts
+	movt	r0
+	.balign	4
+LOCAL(c_SF_NAN_MASK):
+	.long SF_NAN_MASK
+	ENDFUNC(GLOBAL(unordsf2))
+#endif /* L_unord_sf */
+
+#if defined(L_gtsf2f) || defined(L_gtsf2f_trap)
+/* -fno-finite-math-only inline version, T := r4:SF > r5:SF ? 0 : 1
+	cmp/pz	r4
+	mov	r4,r0
+	bf/s	0f
+	 cmp/hs	r5,r4
+	cmp/ge	r4,r5
+	or	r5,r0
+	bt	0f
+	add	r0,r0
+	tst	r0,r0
+	0:			*/
+#ifdef L_gtsf2f
+#define fun_label GLOBAL(gtsf2f)
+#else
+#define fun_label GLOBAL(gtsf2f_trap)
+#endif
+	.balign 4
+	.global fun_label
+	HIDDEN_FUNC(fun_label)
+fun_label:
+	/* If the raw values compare greater, the result true, unless
+	   any of them is a nan (but infinity is fine), or both values are
+	   +- zero.  Otherwise, the result false.  */
+	mov.l	LOCAL(c_SF_NAN_MASK),r1
+	cmp/pz	r4
+	not	r5,r0
+	SLC(bf,	LOCAL(neg),
+	 tst	r1,r0)
+	mov	r4,r0
+	bt	LOCAL(nan)
+	cmp/gt	r5,r4
+	SLC(bf,	LOCAL(check_nan),
+	 cmp/gt	r4,r1)
+	bf	LOCAL(nan)
+	or	r5,r0
+	rts
+	add	r0,r0
+LOCAL(neg):
+	SLI(tst	r1,r0)
+	bt	LOCAL(nan)
+	not	r4,r0
+	tst	r1,r0
+	bt	LOCAL(nan)
+	cmp/hi	r4,r5
+#if defined(L_gtsf2f) && defined(DELAYED_BRANCHES)
+LOCAL(check_nan):
+#endif /* DELAYED_BRANCHES */
+	rts
+	movt	r0
+#ifdef L_gtsf2f
+LOCAL(check_nan):
+LOCAL(nan):
+	rts
+	mov	#0,r0
+#else /* ! L_gtsf2f */
+LOCAL(check_nan):
+	SLI(cmp/gt	r4,r1)
+	bf	LOCAL(nan)
+	rts
+	movt	r0
+LOCAL(nan):
+	mov	#0,r0
+	trapa	#0
+#endif /* ! L_gtsf2f */
+	.balign	4
+LOCAL(c_SF_NAN_MASK):
+	.long SF_NAN_MASK
+	ENDFUNC(fun_label)
+#endif /* L_gtsf2f */
+
+#if defined(L_gesf2f) || defined(L_gesf2f_trap)
+/* -fno-finite-math-only inline version, T := r4:SF >= r5:SF */
+	cmp/pz	r5
+	mov	r4,r0
+	bf/s	0f
+	 cmp/hs	r4,r5
+	cmp/ge	r5,r4
+	or	r5,r0
+	bt	0f
+	add	r0,r0
+	tst	r0,r0
+	0:
+#ifdef L_gesf2f
+#define fun_label GLOBAL(gesf2f)
+#else
+#define fun_label GLOBAL(gesf2f_trap)
+#endif
+	.balign 4
+	.global fun_label
+	HIDDEN_FUNC(fun_label)
+fun_label:
+	/* If the raw values compare greater or equal, the result is
+	   true, unless any of them is a nan.  If both are -+zero, the
+	   result is true; otherwise, it is false.
+	   We use 0 as true and nonzero as false for this function.  */
+	mov.l	LOCAL(c_SF_NAN_MASK),r1
+	cmp/pz	r5
+	not	r4,r0
+	SLC(bf,	LOCAL(neg),
+	 tst	r1,r0)
+	mov	r4,r0
+	bt	LOCAL(nan)
+	cmp/gt	r4,r5
+	SLC(bf,	LOCAL(check_nan),
+	 cmp/ge	r1,r5)
+	bt	LOCAL(nan)
+	or	r5,r0
+	rts
+	add	r0,r0
+LOCAL(neg):
+	SLI(tst	r1,r0)
+	bt	LOCAL(nan)
+	not	r5,r0
+	tst	r1,r0
+	bt	LOCAL(nan)
+	cmp/hi	r5,r4
+#if defined(L_gesf2f) && defined(DELAYED_BRANCHES)
+LOCAL(nan): LOCAL(check_nan):
+#endif
+	rts
+	movt	r0
+#if defined(L_gesf2f) && ! defined(DELAYED_BRANCHES)
+LOCAL(check_nan):
+	cmp/ge	r1,r5
+LOCAL(nan):
+	rts
+	movt	r0
+#endif /* ! DELAYED_BRANCHES */
+#ifdef L_gesf2f_trap
+LOCAL(check_nan):
+	SLI(cmp/ge	r1,r5)
+	bt	LOCAL(nan)
+	rts
+LOCAL(nan):
+	movt	r0
+	trapa	#0
+#endif /* L_gesf2f_trap */
+	.balign	4
+LOCAL(c_SF_NAN_MASK):
+	.long SF_NAN_MASK
+	ENDFUNC(GLOBAL(gesf2f))
+#endif /* L_gesf2f */
+
+#ifndef DYN_SHIFT /* SH1 / SH2 code */
+#ifdef L_addsub_sf
+#include "IEEE-754/addsf3.S"
+#endif /* _addsub_sf */
+
+#ifdef L_mul_sf
+#include "IEEE-754/mulsf3.S"
+#endif /* L_mul_sf */
+
+#ifdef L__fixunssfsi
+#include "IEEE-754/fixunssfsi.S"
+#endif /* L_fixunssfsi */
+
+#ifdef L_sf_to_si
+#include "IEEE-754/fixsfsi.S"
+#endif /* L_sf_to_si */
+
+#ifdef L_usi_to_sf
+#include "IEEE-754/floatunssisf.S"
+#endif /* L_usi_to_sf */
+
+#ifdef L_si_to_sf
+#include "IEEE-754/floatsisf.S"
+#endif /* L_si_to_sf */
+
+#ifdef L_div_sf
+#include "IEEE-754/divsf3.S"
+#endif /* L_div_sf */
+#endif /* ! DYN_SHIFT */
+
+/* The actual arithmetic uses dynamic shift.  Supporting SH1 / SH2 here would
+   make this code too hard to maintain, so if you want to add SH1 / SH2
+   support, do it in a separate copy.  */
+#ifdef DYN_SHIFT
+#ifdef L_addsub_sf
+#include "IEEE-754/m3/addsf3.S"
+#endif /* L_addsub_sf */
+
+#ifdef L_mul_sf
+#include "IEEE-754/m3/mulsf3.S"
+#endif /* L_mul_sf */
+
+#ifdef L_fixunssfsi
+	! What is a bit unusal about this implementation is that the
+	! sign bit influences the result for NANs: for cleared sign bit, you
+	! get UINT_MAX, for set sign bit, you get 0.
+	! However, since the result for NANs is undefined, this should be no
+	! problem.
+	! N.B. This is scheduled both for SH4-200 and SH4-300
+	.balign 4
+	.global GLOBAL(fixunssfsi)
+	FUNC(GLOBAL(fixunssfsi))
+GLOBAL(fixunssfsi):
+	mov.l	LOCAL(max),r2
+	mov	#-23,r1
+	mov	r4,r0
+	shad	r1,r4
+	mov.l	LOCAL(mask),r1
+	add	#-127,r4
+	cmp/ge	r2,r0
+	or	r2,r0
+	bt	LOCAL(retmax)
+	cmp/pz	r4
+	and	r1,r0
+	bf	LOCAL(ret0)
+	add	#-23,r4
+	rts
+	shld	r4,r0
+LOCAL(ret0):
+LOCAL(retmax):
+	rts
+	subc	r0,r0
+	.balign 4
+LOCAL(mask):
+	.long	0x00ffffff
+LOCAL(max):
+	.long	0x4f800000
+	ENDFUNC(GLOBAL(fixunssfsi))
+#endif /* L_fixunssfsi */
+
+#ifdef L_sf_to_si
+	! What is a bit unusal about this implementation is that the
+	! sign bit influences the result for NANs: for cleared sign bit, you
+	! get INT_MAX, for set sign bit, you get INT_MIN.
+	! However, since the result for NANs is undefined, this should be no
+	! problem.
+	! N.B. This is scheduled both for SH4-200 and SH4-300
+	.balign 4
+	.global GLOBAL(fixsfsi)
+	FUNC(GLOBAL(fixsfsi))
+	.balign	4
+GLOBAL(fixsfsi):
+	mov	r4,r0
+	shll	r4
+	mov	#-24,r1
+	bt	LOCAL(neg)
+	mov.l	LOCAL(max),r2
+	shld	r1,r4
+	mov.l	LOCAL(mask),r1
+	add	#-127,r4
+	cmp/pz	r4
+	add	#-23,r4
+	bf	LOCAL(ret0)
+	cmp/gt	r0,r2
+	bf	LOCAL(retmax)
+	and	r1,r0
+	addc	r1,r0
+	rts
+	shld	r4,r0
+
+	.balign	4
+LOCAL(neg):
+	mov.l	LOCAL(min),r2
+	shld	r1,r4
+	mov.l	LOCAL(mask),r1
+	add	#-127,r4
+	cmp/pz	r4
+	add	#-23,r4
+	bf	LOCAL(ret0)
+	cmp/gt	r0,r2
+	bf	LOCAL(retmin)
+	and	r1,r0
+	addc	r1,r0
+	shld	r4,r0	! SH4-200 will start this insn on a new cycle
+	rts
+	neg	r0,r0
+
+	.balign	4
+LOCAL(ret0):
+	rts
+	mov	#0,r0
+
+LOCAL(retmax):
+	mov	#-1,r0
+	rts
+	shlr	r0
+
+LOCAL(retmin):
+	mov	#1,r0
+	rts
+	rotr	r0
+
+	.balign 4
+LOCAL(mask):
+	.long	0x007fffff
+LOCAL(max):
+	.long	0x4f000000
+LOCAL(min):
+	.long	0xcf000000
+	ENDFUNC(GLOBAL(fixsfsi))
+#endif /* L_sf_to_si */
+
+#ifdef L_usi_to_sf
+#include "IEEE-754/m3/floatunssisf.S"
+#endif /* L_usi_to_sf */
+
+#ifdef L_si_to_sf
+#include "IEEE-754/m3/floatsisf.S"
+#endif /* L_si_to_sf */
+
+#ifdef L_div_sf
+#include "IEEE-754/m3/divsf3.S"
+#endif /* L_div_sf */
+
+#ifdef L_hypotf
+	.balign 4
+	.global GLOBAL(hypotf)
+	FUNC(GLOBAL(hypotf))
+GLOBAL(hypotf):
+/* This integer implementation takes 71 to 72 cycles in the main path.
+   This is a bit slower than the SH4 can do this computation using double
+   precision hardware floating point - 57 cycles, or 69 with mode switches.  */
+ /* First, calculate x (r4) as the sum of the square of the fractions -
+    the exponent is calculated separately in r3.
+    Then, calculate sqrt(x) for the fraction by reciproot iteration.
+    We get an 7.5 bit inital value using linear approximation with two slopes
+    that are powers of two.
+    x (- [1. .. 2.)  y0 := 1.25 - x/4 - tab(x)   y (- (0.8 .. 1.0)
+    x (- [2. .. 4.)  y0 := 1.   - x/8 - tab(x)   y (- (0.5 .. 0.8)
+ x is represented with two bits before the point,
+ y with 0 bits before the binary point.
+ Thus, to calculate y0 := 1. - x/8 - tab(x), all you have to do is to shift x
+ right by 1, negate it, and subtract tab(x).  */
+
+ /* y1 := 1.5*y0 - 0.5 * (x * y0) * (y0 * y0)
+    z0 := x * y1
+    z1 := z0 + 0.5 * (y1 - (y1*y1) * z0) */
+
+	mov.l	LOCAL(xff000000),r1
+	add	r4,r4
+	mov	r4,r0
+	add	r5,r5
+	cmp/hs	r5,r4
+	sub	r5,r0
+	mov	#-24,r2
+	bf/s	LOCAL(r5_large)
+	shad	r2,r0
+	mov	r4,r3
+	shll8	r4
+	rotcr	r4
+	tst	#0xe0,r0
+	neg	r0,r0
+	bt	LOCAL(ret_abs_r3)
+	tst	r1,r5
+	shll8	r5
+	bt/s	LOCAL(denorm_r5)
+	cmp/hi	r3,r1
+	dmulu.l	r4,r4
+	bf	LOCAL(inf_nan)
+	rotcr	r5
+	shld	r0,r5
+LOCAL(denorm_r5_done):
+	sts	mach,r4
+	dmulu.l	r5,r5
+	mov.l	r6,@-r15
+	mov	#20,r6
+
+	sts	mach,r5
+LOCAL(add_frac):
+	mova	LOCAL(tab)-32,r0
+	mov.l	r7,@-r15
+	mov.w	LOCAL(x1380),r7
+	and	r1,r3
+	addc	r5,r4
+	mov.w	LOCAL(m25),r2	! -25
+	bf	LOCAL(frac_ok)
+	sub	r1,r3
+	rotcr	r4
+	cmp/eq	r1,r3	! did we generate infinity ?
+	bt	LOCAL(inf_nan)
+	shlr	r4
+	mov	r4,r1
+	shld	r2,r1
+	mov.b	@(r0,r1),r0
+	mov	r4,r1
+	shld	r6,r1
+	bra	LOCAL(frac_low2)
+	sub	r1,r7
+
+LOCAL(frac_ok):
+	mov	r4,r1
+	shld	r2,r1
+	mov.b	@(r0,r1),r1
+	cmp/pz	r4
+	mov	r4,r0
+	bt/s	LOCAL(frac_low)
+	shld	r6,r0
+	mov.w	LOCAL(xf80),r7
+	shlr	r0
+LOCAL(frac_low):
+	sub	r0,r7
+LOCAL(frac_low2):
+	mov.l	LOCAL(x40000080),r0 ! avoid denorm results near 1. << r3
+	sub	r1,r7	! {0.12}
+	mov.l	LOCAL(xfffe0000),r5 ! avoid rounding overflow near 4. << r3
+	swap.w	r7,r1	! {0.28}
+	dmulu.l	r1,r4 /* two issue cycles */
+	mulu.w	r7,r7  /* two issue cycles */
+	sts	mach,r2	! {0.26}
+	mov	r1,r7
+	shlr	r1
+	sts	macl,r6	! {0.24}
+	cmp/hi	r0,r4
+	shlr2	r2
+	bf	LOCAL(near_one)
+	shlr	r2	! {0.23} systemic error of linear approximation keeps y1 < 1
+	dmulu.l	r2,r6
+	cmp/hs	r5,r4
+	add	r7,r1	! {1.28}
+	bt	LOCAL(near_four)
+	shlr2	r1	! {1.26}
+	sts	mach,r0	! {0.15} x*y0^3 == {0.16} 0.5*x*y0^3
+	shlr2	r1	! {1.24}
+	shlr8	r1	! {1.16}
+	sett		! compensate for truncation of subtrahend, keep y1 < 1
+	subc	r0,r1   ! {0.16} y1;  max error about 3.5 ulp
+	swap.w	r1,r0
+	dmulu.l	r0,r4	! { 1.30 }
+	mulu.w	r1,r1
+	sts	mach,r2
+	shlr2	r0
+	sts	macl,r1
+	add	r2,r0
+	mov.l	LOCAL(xff000000),r6
+	add	r2,r0
+	dmulu.l	r1,r2
+	add	#127,r0
+	add	r6,r3	! precompensation for adding leading 1
+	sts	mach,r1
+	shlr	r3
+	mov.l	@r15+,r7
+	sub	r1,r0	! {0.31} max error about 50 ulp (+127)
+	mov.l	@r15+,r6
+	shlr8	r0	! {0.23} max error about 0.7 ulp
+	rts
+	add	r3,r0
+	
+LOCAL(r5_large):
+	mov	r5,r3
+	mov	#-31,r2
+	cmp/ge	r2,r0
+	shll8	r5
+	bf	LOCAL(ret_abs_r3)
+	rotcr	r5
+	tst	r1,r4
+	shll8	r4
+	bt/s	LOCAL(denorm_r4)
+	cmp/hi	r3,r1
+	dmulu.l	r5,r5
+	bf	LOCAL(inf_nan)
+	rotcr	r4
+LOCAL(denorm_r4_done):
+	shld	r0,r4
+	sts	mach,r5
+	dmulu.l	r4,r4
+	mov.l	r6,@-r15
+	mov	#20,r6
+	bra	LOCAL(add_frac)
+	sts	mach,r4
+
+LOCAL(near_one):
+	bra	LOCAL(assemble_sqrt)
+	mov	#0,r0
+LOCAL(near_four):
+	! exact round-to-nearest would add 255.  We add 256 for speed & compactness.
+	mov	r4,r0
+	shlr8	r0
+	add	#1,r0
+	tst	r0,r0
+	addc	r0,r3	! might generate infinity.
+LOCAL(assemble_sqrt):
+	mov.l	@r15+,r7
+	shlr	r3
+	mov.l	@r15+,r6
+	rts
+	add	r3,r0
+LOCAL(inf_nan):
+LOCAL(ret_abs_r3):
+	mov	r3,r0
+	rts
+	shlr	r0
+LOCAL(denorm_r5):
+	bf	LOCAL(inf_nan)
+	tst	r1,r4
+	bt	LOCAL(denorm_both)
+	dmulu.l	r4,r4
+	bra	LOCAL(denorm_r5_done)
+	shld	r0,r5
+LOCAL(denorm_r4):
+	bf	LOCAL(inf_nan)
+	tst	r1,r5
+	dmulu.l	r5,r5
+	bf	LOCAL(denorm_r4_done)
+LOCAL(denorm_both):	! normalize according to r3.
+	extu.w	r3,r2
+	mov.l	LOCAL(c__clz_tab),r0
+	cmp/eq	r3,r2
+	mov	#-8,r2
+	bt	0f
+	tst	r1,r3
+	mov	#-16,r2
+	bt	0f
+	mov	#-24,r2
+0:
+	shld	r2,r3
+	mov.l	r7,@-r15
+#ifdef __pic__
+	add	r0,r3
+	mova	 LOCAL(c__clz_tab),r0
+#endif
+	mov.b	@(r0,r3),r0
+	add	#32,r2
+	sub	r0,r2
+	shld	r2,r4
+	mov	r2,r7
+	dmulu.l	r4,r4
+	sts.l	pr,@-r15
+	mov	#1,r3
+	bsr	LOCAL(denorm_r5_done)
+	shld	r2,r5
+	mov.l	LOCAL(x01000000),r1
+	neg	r7,r2
+	lds.l	@r15+,pr
+	tst	r1,r0
+	mov.l	@r15+,r7
+	bt	0f
+	add	#1,r2
+	sub	r1,r0
+0:
+	rts
+	shld	r2,r0
+
+LOCAL(m25):
+	.word	-25
+LOCAL(x1380):
+	.word	0x1380
+LOCAL(xf80):
+	.word	0xf80
+	.balign	4
+LOCAL(xff000000):
+	.long	0xff000000
+LOCAL(x40000080):
+	.long	0x40000080
+LOCAL(xfffe0000):
+	.long	0xfffe0000
+LOCAL(x01000000):
+	.long	0x01000000
+LOCAL(c__clz_tab):
+#ifdef __pic__
+	.long	GLOBAL(clz_tab) - .
+#else
+	.long	GLOBAL(clz_tab)
+#endif
+
+/*
+double err(double x)
+{
+  return (x < 2. ? 1.25 - x/4. : 1. - x/8.) - 1./sqrt(x);
+}
+
+int
+main ()
+{
+  int i = 0;
+  double x, s, v;
+  double lx, hx;
+
+  s = 1./32.;
+  for (x = 1.; x < 4; x += s, i++)
+    {
+      lx = x;
+      hx = x + s - 1. / (1 << 30);
+      v = 0.5 * (err (lx) + err (hx));
+      printf ("%s% 4d%c",
+              (i & 7) == 0 ? "\t.byte\t" : "",
+              (int)(v * 4096 + 0.5) - 128,
+              (i & 7) == 7 ? '\n' : ',');
+    }
+  return 0;
+} */
+
+	.balign	4
+LOCAL(tab):
+	.byte	-113, -84, -57, -33, -11,   8,  26,  41
+	.byte	  55,  67,  78,  87,  94, 101, 106, 110
+	.byte	 113, 115, 115, 115, 114, 112, 109, 106
+	.byte	 101,  96,  91,  84,  77,  69,  61,  52
+	.byte	  51,  57,  63,  68,  72,  77,  80,  84
+	.byte	  87,  89,  91,  93,  95,  96,  97,  97
+	.byte	  97,  97,  97,  96,  95,  94,  93,  91
+	.byte	  89,  87,  84,  82,  79,  76,  72,  69
+	.byte	  65,  61,  57,  53,  49,  44,  39,  34
+	.byte	  29,  24,  19,  13,   8,   2,  -4, -10
+	.byte	 -17, -23, -29, -36, -43, -50, -57, -64
+	.byte	 -71, -78, -85, -93,-101,-108,-116,-124
+	ENDFUNC(GLOBAL(hypotf))
+#endif /* L_hypotf */
+#endif /* DYN_SHIFT */
+
+#endif /* __SH_FPU_ANY__ */
diff -urN gcc-4.7.3/libgcc/config/sh/lib1funcs-4-300.S st40-4.7.3-13080/gcc/libgcc/config/sh/lib1funcs-4-300.S
--- gcc-4.7.3/libgcc/config/sh/lib1funcs-4-300.S	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/lib1funcs-4-300.S	2012-04-04 14:14:24.000000000 +0200
@@ -251,8 +251,8 @@
 	   don't get such an adjustment, it's OK to also compute one's -> two's
 	   complement adjustment suppression for a dividend of 0.  */
 	.balign 4
-GLOBAL(sdivsi3_i4i):
-	mov.l r6,@-r15
+GLOBAL(sdivsi3_i4i):	
+	mov.l r6,@-r15	
 	exts.b r5,r6
 	cmp/eq r5,r6
 	mov #-1,r1
@@ -403,12 +403,12 @@
 	addc r6,r0
 	rotcr r0
 	mov.l @r15+,r6
-	shad r1,r0
+	shld r1,r0	
 	rts
 	neg r0,r0
 	ENDFUNC(GLOBAL(udivsi3_i4i))
 	ENDFUNC(GLOBAL(sdivsi3_i4i))
-
+	
 /* This table has been generated by divtab-sh4.c.  */
 	.balign 4
 	.byte	-7
diff -urN gcc-4.7.3/libgcc/config/sh/lib1funcs.h st40-4.7.3-13080/gcc/libgcc/config/sh/lib1funcs.h
--- gcc-4.7.3/libgcc/config/sh/lib1funcs.h	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/lib1funcs.h	2012-04-04 14:14:24.000000000 +0200
@@ -1,6 +1,7 @@
 /* Copyright (C) 1994, 1995, 1997, 1998, 1999, 2000, 2001, 2002, 2003,
    2004, 2005, 2006, 2009
    Free Software Foundation, Inc.
+   Copyright (c) 2006  STMicroelectronics.
 
 This file is free software; you can redistribute it and/or modify it
 under the terms of the GNU General Public License as published by the
@@ -64,13 +65,152 @@
 #endif /* !__LITTLE_ENDIAN__ */
 
 #ifdef __sh1__
+/* branch with two-argument delay slot insn */
 #define SL(branch, dest, in_slot, in_slot_arg2) \
 	in_slot, in_slot_arg2; branch dest
+/* branch with one-argument delay slot insn */
 #define SL1(branch, dest, in_slot) \
 	in_slot; branch dest
+/* branch with comparison in delay slot */
+#define SLC(branch, dest, in_slot, in_slot_arg2) \
+        branch dest; in_slot, in_slot_arg2
+/* comparison in a delay slot, at branch destination */
+#define SLI(in_slot, in_slot_arg2) in_slot, in_slot_arg2
+#define SLCMP(branch, cmp1, cmp1arg2, cmp2, cmp2arg2) \
+	branch .+6; bra .+6; cmp2, cmp2arg2; cmp1, cmp1arg2
+#define DMULU_SAVE \
+ mov.l r10,@-r15; \
+ mov.l r11,@-r15; \
+ mov.l r12,@-r15; \
+ mov.l r13,@-r15
+#define DMULUL(m1, m2, rl) \
+ swap.w m1,r12; \
+ mulu.w r12,m2; \
+ swap.w m2,r13; \
+ sts macl,r10; \
+ mulu.w r13,m1; \
+ clrt; \
+ sts macl,r11; \
+ mulu.w r12,r13; \
+ addc r11,r10; \
+ sts macl,r12; \
+ mulu.w m1,m2; \
+ movt r11; \
+ sts macl,rl; \
+ mov r10,r13; \
+ shll16 r13; \
+ addc r13,rl; \
+ xtrct r11,r10; \
+ addc r10,r12 \
+/* N.B. the carry is cleared here.  */
+#define DMULUH(rh) mov r12,rh
+#define DMULU_RESTORE \
+ mov.l @r15+,r13; \
+ mov.l @r15+,r12; \
+ mov.l @r15+,r11; \
+ mov.l @r15+,r10
 #else /* ! __sh1__ */
+/* branch with two-argument delay slot insn */
 #define SL(branch, dest, in_slot, in_slot_arg2) \
-	branch##.s dest; in_slot, in_slot_arg2
+	branch##/s dest; in_slot, in_slot_arg2
+/* branch with one-argument delay slot insn */
 #define SL1(branch, dest, in_slot) \
 	branch##/s dest; in_slot
+/* branch with comparison in delay slot */
+#define SLC(branch, dest, in_slot, in_slot_arg2) \
+        branch##/s dest; in_slot, in_slot_arg2
+/* comparison in a delay slot, at branch destination */
+#define SLI(in_slot, in_slot_arg)
+#define SLCMP(branch, cmp1, cmp1arg2, cmp2, cmp2arg2) \
+	branch##/s .+6; cmp1, cmp1arg2; cmp2, cmp2arg2
+#define DMULU_SAVE
+#define DMULUL(m1, m2, rl) dmulu.l m1,m2; sts macl,rl
+#define DMULUH(rh) sts mach,rh
+#define DMULU_RESTORE
 #endif /* !__sh1__ */
+
+#if defined (__sh1__) || defined (__sh2__) || defined (__SH2E__)
+/* don't #define DYN_SHIFT */
+  #define SHLL4(REG)	\
+	shll2	REG;	\
+	shll2	REG
+
+  #define SHLR4(REG)	\
+	shlr2	REG;	\
+	shlr2	REG
+
+  #define SHLL6(REG)	\
+	shll2	REG;	\
+	shll2	REG;	\
+	shll2	REG
+
+  #define SHLR6(REG)	\
+	shlr2	REG;	\
+	shlr2	REG;	\
+	shlr2	REG
+
+  #define SHLL12(REG)	\
+	shll8	REG;	\
+	SHLL4 (REG)
+
+  #define SHLR12(REG)	\
+	shlr8	REG;	\
+	SHLR4 (REG)
+
+  #define SHLR19(REG)	\
+	shlr16	REG;	\
+	shlr2	REG;	\
+	shlr	REG
+
+  #define SHLL23(REG)	\
+	shll16	REG;	\
+	shlr	REG;	\
+	shll8	REG
+
+  #define SHLR24(REG)	\
+	shlr16	REG;	\
+	shlr8	REG
+
+  #define SHLR21(REG)	\
+	shlr16	REG;	\
+	shll2	REG;	\
+	add	REG,REG;\
+	shlr8	REG
+
+  #define SHLL21(REG)	\
+	shll16	REG;	\
+	SHLL4 (REG);	\
+	add	REG,REG
+
+  #define SHLR11(REG)	\
+	shlr8	REG;	\
+	shlr2	REG;	\
+	shlr	REG
+
+  #define SHLR22(REG)	\
+	shlr16	REG;	\
+	shll2	REG;	\
+	shlr8	REG
+
+  #define SHLR23(REG)	\
+	shlr16	REG;	\
+	add	REG,REG;\
+	shlr8	REG
+
+  #define SHLR20(REG)	\
+	shlr16	REG;	\
+	SHLR4 (REG)
+
+  #define SHLL20(REG)	\
+	shll16	REG;	\
+	SHLL4 (REG)
+#define SHLD_COUNT(N,COUNT)
+#define SHLRN(N,COUNT,REG) SHLR##N(REG)
+#define SHLLN(N,COUNT,REG) SHLL##N(REG)
+#else
+#define SHLD_COUNT(N,COUNT) mov #N,COUNT
+#define SHLRN(N,COUNT,REG) shld COUNT,REG
+#define SHLLN(N,COUNT,REG) shld COUNT,REG
+#define DYN_SHIFT 1
+#endif
+
diff -urN gcc-4.7.3/libgcc/config/sh/lib1funcs-Os-4-200.S st40-4.7.3-13080/gcc/libgcc/config/sh/lib1funcs-Os-4-200.S
--- gcc-4.7.3/libgcc/config/sh/lib1funcs-Os-4-200.S	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/lib1funcs-Os-4-200.S	2012-04-04 14:14:24.000000000 +0200
@@ -1,4 +1,5 @@
 /* Copyright (C) 2006, 2009 Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is free software; you can redistribute it and/or modify it
 under the terms of the GNU General Public License as published by the
@@ -39,7 +40,7 @@
 	.global GLOBAL(udivsi3_i4i)
 	FUNC(GLOBAL(udivsi3_i4i))
 GLOBAL(udivsi3_i4i):
-	mova L1,r0
+	mova LOCAL(L1),r0
 	cmp/pz r5
 	sts fpscr,r1
 	lds.l @r0+,fpscr
@@ -106,7 +107,7 @@
 	movt r0
 
 	.p2align 2
-L1:
+LOCAL(L1):
 #ifndef FMOVD_WORKS
 	.long 0x80000
 #else
@@ -272,7 +273,7 @@
 GLOBAL(sdivsi3_i4i):
 	sts.l fpscr,@-r15
 	sts fpul,r1
-	mova L1,r0
+	mova LOCAL(L1),r0
 	lds.l @r0+,fpscr
 	lds r4,fpul
 #ifdef FMOVD_WORKS
@@ -309,7 +310,7 @@
 	lds r1,fpul
 
 	.p2align 2
-L1:
+LOCAL(L1):
 #ifndef FMOVD_WORKS
 	.long 0x80000
 #else
@@ -320,3 +321,4 @@
 #endif /* __SH_FPU_DOUBLE__ */
 #endif /* L_sdivsi3_i4i */
 #endif /* !__SHMEDIA__ */
+	
diff -urN gcc-4.7.3/libgcc/config/sh/lib1funcs.S st40-4.7.3-13080/gcc/libgcc/config/sh/lib1funcs.S
--- gcc-4.7.3/libgcc/config/sh/lib1funcs.S	2013-03-26 12:38:31.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/lib1funcs.S	2013-07-24 10:08:04.000000000 +0200
@@ -1,6 +1,7 @@
 /* Copyright (C) 1994, 1995, 1997, 1998, 1999, 2000, 2001, 2002, 2003,
    2004, 2005, 2006, 2009
    Free Software Foundation, Inc.
+   Copyright (c) 2009  STMicroelectronics.
 
 This file is free software; you can redistribute it and/or modify it
 under the terms of the GNU General Public License as published by the
@@ -713,7 +714,7 @@
 GLOBAL(movmem):
 	sts.l	pr,@-r15
 	shll2	r6
-	bsr	GLOBAL(movmemSI52+2)
+	bsr	LOCAL(movmemSI52)+2
 	mov.l	@(48,r5),r0
 	.balign	4
 LOCAL(movmem_loop): /* Reached with rts */
@@ -729,10 +730,10 @@
 	add	#64,r5
 	mov.l	r0,@(52,r4)
 	add	#64,r4
-	bt	GLOBAL(movmemSI52)
+	bt	LOCAL(movmemSI52)
 ! done all the large groups, do the remainder
 ! jump to movmem+
-	mova	GLOBAL(movmemSI4)+4,r0
+	mova	LOCAL(movmemSI4)+4,r0
 	add	r6,r0
 	jmp	@r0
 LOCAL(movmem_done): ! share slot insn, works out aligned.
@@ -742,102 +743,86 @@
 	rts
 	mov.l	r0,@(52,r4)
 	.balign	4
-! ??? We need aliases movstr* for movmem* for the older libraries.  These
-! aliases will be removed at the some point in the future.
 	.global	GLOBAL(movmemSI64)
 	HIDDEN_FUNC(GLOBAL(movmemSI64))
-	HIDDEN_ALIAS(movstrSI64,movmemSI64)
 GLOBAL(movmemSI64):
 	mov.l	@(60,r5),r0
 	mov.l	r0,@(60,r4)
 	.global	GLOBAL(movmemSI60)
 	HIDDEN_FUNC(GLOBAL(movmemSI60))
-	HIDDEN_ALIAS(movstrSI60,movmemSI60)
 GLOBAL(movmemSI60):
 	mov.l	@(56,r5),r0
 	mov.l	r0,@(56,r4)
 	.global	GLOBAL(movmemSI56)
 	HIDDEN_FUNC(GLOBAL(movmemSI56))
-	HIDDEN_ALIAS(movstrSI56,movmemSI56)
 GLOBAL(movmemSI56):
 	mov.l	@(52,r5),r0
 	mov.l	r0,@(52,r4)
 	.global	GLOBAL(movmemSI52)
 	HIDDEN_FUNC(GLOBAL(movmemSI52))
-	HIDDEN_ALIAS(movstrSI52,movmemSI52)
 GLOBAL(movmemSI52):
+LOCAL(movmemSI52):
 	mov.l	@(48,r5),r0
 	mov.l	r0,@(48,r4)
 	.global	GLOBAL(movmemSI48)
 	HIDDEN_FUNC(GLOBAL(movmemSI48))
-	HIDDEN_ALIAS(movstrSI48,movmemSI48)
 GLOBAL(movmemSI48):
 	mov.l	@(44,r5),r0
 	mov.l	r0,@(44,r4)
 	.global	GLOBAL(movmemSI44)
 	HIDDEN_FUNC(GLOBAL(movmemSI44))
-	HIDDEN_ALIAS(movstrSI44,movmemSI44)
 GLOBAL(movmemSI44):
 	mov.l	@(40,r5),r0
 	mov.l	r0,@(40,r4)
 	.global	GLOBAL(movmemSI40)
 	HIDDEN_FUNC(GLOBAL(movmemSI40))
-	HIDDEN_ALIAS(movstrSI40,movmemSI40)
 GLOBAL(movmemSI40):
 	mov.l	@(36,r5),r0
 	mov.l	r0,@(36,r4)
 	.global	GLOBAL(movmemSI36)
 	HIDDEN_FUNC(GLOBAL(movmemSI36))
-	HIDDEN_ALIAS(movstrSI36,movmemSI36)
 GLOBAL(movmemSI36):
 	mov.l	@(32,r5),r0
 	mov.l	r0,@(32,r4)
 	.global	GLOBAL(movmemSI32)
 	HIDDEN_FUNC(GLOBAL(movmemSI32))
-	HIDDEN_ALIAS(movstrSI32,movmemSI32)
 GLOBAL(movmemSI32):
 	mov.l	@(28,r5),r0
 	mov.l	r0,@(28,r4)
 	.global	GLOBAL(movmemSI28)
 	HIDDEN_FUNC(GLOBAL(movmemSI28))
-	HIDDEN_ALIAS(movstrSI28,movmemSI28)
 GLOBAL(movmemSI28):
 	mov.l	@(24,r5),r0
 	mov.l	r0,@(24,r4)
 	.global	GLOBAL(movmemSI24)
 	HIDDEN_FUNC(GLOBAL(movmemSI24))
-	HIDDEN_ALIAS(movstrSI24,movmemSI24)
 GLOBAL(movmemSI24):
 	mov.l	@(20,r5),r0
 	mov.l	r0,@(20,r4)
 	.global	GLOBAL(movmemSI20)
 	HIDDEN_FUNC(GLOBAL(movmemSI20))
-	HIDDEN_ALIAS(movstrSI20,movmemSI20)
 GLOBAL(movmemSI20):
 	mov.l	@(16,r5),r0
 	mov.l	r0,@(16,r4)
 	.global	GLOBAL(movmemSI16)
 	HIDDEN_FUNC(GLOBAL(movmemSI16))
-	HIDDEN_ALIAS(movstrSI16,movmemSI16)
 GLOBAL(movmemSI16):
 	mov.l	@(12,r5),r0
 	mov.l	r0,@(12,r4)
 	.global	GLOBAL(movmemSI12)
 	HIDDEN_FUNC(GLOBAL(movmemSI12))
-	HIDDEN_ALIAS(movstrSI12,movmemSI12)
 GLOBAL(movmemSI12):
 	mov.l	@(8,r5),r0
 	mov.l	r0,@(8,r4)
 	.global	GLOBAL(movmemSI8)
 	HIDDEN_FUNC(GLOBAL(movmemSI8))
-	HIDDEN_ALIAS(movstrSI8,movmemSI8)
 GLOBAL(movmemSI8):
 	mov.l	@(4,r5),r0
 	mov.l	r0,@(4,r4)
 	.global	GLOBAL(movmemSI4)
 	HIDDEN_FUNC(GLOBAL(movmemSI4))
-	HIDDEN_ALIAS(movstrSI4,movmemSI4)
 GLOBAL(movmemSI4):
+LOCAL(movmemSI4):
 	mov.l	@(0,r5),r0
 	rts
 	mov.l	r0,@(0,r4)
@@ -876,7 +861,7 @@
 	HIDDEN_ALIAS(movstrSI12_i4,movmemSI12_i4)
 
 	.p2align	5
-L_movmem_2mod4_end:
+LOCAL(movmem_2mod4_end):
 	mov.l	r0,@(16,r4)
 	rts
 	mov.l	r1,@(20,r4)
@@ -885,7 +870,7 @@
 
 GLOBAL(movmem_i4_even):
 	mov.l	@r5+,r0
-	bra	L_movmem_start_even
+	bra	LOCAL(movmem_start_even)
 	mov.l	@r5+,r1
 
 GLOBAL(movmem_i4_odd):
@@ -896,20 +881,20 @@
 	mov.l	r1,@(4,r4)
 	mov.l	r2,@(8,r4)
 
-L_movmem_loop:
+LOCAL(movmem_loop):
 	mov.l	r3,@(12,r4)
 	dt	r6
 	mov.l	@r5+,r0
-	bt/s	L_movmem_2mod4_end
+	bt/s	LOCAL(movmem_2mod4_end)
 	mov.l	@r5+,r1
 	add	#16,r4
-L_movmem_start_even:
+LOCAL(movmem_start_even):
 	mov.l	@r5+,r2
 	mov.l	@r5+,r3
 	mov.l	r0,@r4
 	dt	r6
 	mov.l	r1,@(4,r4)
-	bf/s	L_movmem_loop
+	bf/s	LOCAL(movmem_loop)
 	mov.l	r2,@(8,r4)
 	rts
 	mov.l	r3,@(12,r4)
@@ -947,17 +932,23 @@
 ! aa = bb*dd + (aa*dd*65536) + (cc*bb*65536)
 !
 
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif
 GLOBAL(mulsi3):
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	nop
+#endif	
 	mulu.w  r4,r5		! multiply the lsws  macl=bb*dd
 	mov     r5,r3		! r3 = ccdd
 	swap.w  r4,r2		! r2 = bbaa
 	xtrct   r2,r3		! r3 = aacc
 	tst  	r3,r3		! msws zero ?
-	bf      hiset
+	bf      LOCAL(hiset)
 	rts			! yes - then we have the answer
 	sts     macl,r0
 
-hiset:	sts	macl,r0		! r0 = bb*dd
+LOCAL(hiset):	sts	macl,r0		! r0 = bb*dd
 	mulu.w	r2,r5		! brewing macl = aa*dd
 	sts	macl,r1
 	mulu.w	r3,r4		! brewing macl = cc*bb
@@ -978,6 +969,9 @@
 
 	.global	GLOBAL(sdivsi3_i4)
 	HIDDEN_FUNC(GLOBAL(sdivsi3_i4))
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	5
+#endif	
 GLOBAL(sdivsi3_i4):
 	lds r4,fpul
 	float fpul,dr0
@@ -1248,13 +1242,18 @@
 	blink tr2,r63
 	ENDFUNC(GLOBAL(sdivsi3))
 #else /* ! __SHMEDIA__ */
+	
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif
+	
 	FUNC(GLOBAL(sdivsi3))
 GLOBAL(sdivsi3):
 	mov	r4,r1
 	mov	r5,r0
 
 	tst	r0,r0
-	bt	div0
+	bt	LOCAL(div0)
 	mov	#0,r2
 	div0s	r2,r1
 	subc	r3,r3
@@ -1329,8 +1328,10 @@
 	rts
 	mov	r1,r0
 
-
-div0:	rts
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	nop
+#endif		
+LOCAL(div0):	rts
 	mov	#0,r0
 
 	ENDFUNC(GLOBAL(sdivsi3))
@@ -1344,16 +1345,19 @@
 !! args in r4 and r5, result in fpul, clobber r0, r1, r4, r5, dr0, dr2, dr4,
 !! and t bit
 
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif
 	.global	GLOBAL(udivsi3_i4)
 	HIDDEN_FUNC(GLOBAL(udivsi3_i4))
 GLOBAL(udivsi3_i4):
 	mov #1,r1
 	cmp/hi r1,r5
-	bf trivial
+	bf LOCAL(trivial)
 	rotr r1
 	xor r1,r4
 	lds r4,fpul
-	mova L1,r0
+	mova 1f,r0
 #ifdef FMOVD_WORKS
 	fmov.d @r0+,dr4
 #else
@@ -1370,7 +1374,7 @@
 	rts
 	ftrc dr0,fpul
 
-trivial:
+LOCAL(trivial):
 	rts
 	lds r4,fpul
 
@@ -1378,7 +1382,7 @@
 #ifdef FMOVD_WORKS
 	.align 3	! make double below 8 byte aligned.
 #endif
-L1:
+1:
 	.double 2147483648
 
 	ENDFUNC(GLOBAL(udivsi3_i4))
@@ -1405,15 +1409,14 @@
 #endif /* ! __SH5__ || __SH5__ == 32 */
 #elif defined (__SH2A_SINGLE__) || defined (__SH2A_SINGLE_ONLY__) || defined(__SH4_SINGLE__) || defined(__SH4_SINGLE_ONLY__)
 !! args in r4 and r5, result in fpul, clobber r0, r1, r4, r5, dr0, dr2, dr4
-
 	.global	GLOBAL(udivsi3_i4)
 	HIDDEN_FUNC(GLOBAL(udivsi3_i4))
 GLOBAL(udivsi3_i4):
 	mov #1,r1
 	cmp/hi r1,r5
-	bf trivial
+	bf LOCAL(trivial)
 	sts.l fpscr,@-r15
-	mova L1,r0
+	mova 1f,r0
 	lds.l @r0+,fpscr
 	rotr r1
 	xor r1,r4
@@ -1438,12 +1441,12 @@
 #ifdef FMOVD_WORKS
 	.align 3	! make double below 8 byte aligned.
 #endif
-trivial:
+LOCAL(trivial):
 	rts
 	lds r4,fpul
 
 	.align 2
-L1:
+1:
 #ifndef FMOVD_WORKS
 	.long 0x80000
 #else
@@ -1458,7 +1461,6 @@
 #ifdef L_udivsi3
 /* __SH4_SINGLE_ONLY__ keeps this part for link compatibility with
    sh2e/sh3e code.  */
-
 !! args in r4 and r5, result in r0, clobbers r4, pr, and t bit
 	.global	GLOBAL(udivsi3)
 	HIDDEN_FUNC(GLOBAL(udivsi3))
@@ -1600,7 +1602,15 @@
  div1 r5,r4; rotcl r0
  div1 r5,r4; rotcl r0
  div1 r5,r4; rotcl r0
- rts; div1 r5,r4
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	nop
+#endif		
+ rts
+ div1 r5,r4
+
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif
 
 GLOBAL(udivsi3):
  sts.l pr,@-r15
@@ -1614,6 +1624,9 @@
  div0u
  swap.w r4,r0
  shlr16 r4
+#ifdef	DB_ST40300_BUG_WORKAROUND
+ nop
+#endif			
  bsr LOCAL(div8)
  shll16 r5
  bsr LOCAL(div7)
@@ -1638,6 +1651,9 @@
  mov #0,r0
  xtrct r4,r0
  xtrct r0,r4
+#ifdef	DB_ST40300_BUG_WORKAROUND
+ nop
+#endif		
  bsr LOCAL(divx4)
  rotcl r0
  bsr LOCAL(divx4)
@@ -1965,6 +1981,10 @@
 #ifdef __SH5__
 	.mode	SHcompact
 #endif
+	
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif	
 	.global GLOBAL(set_fpscr)
 	HIDDEN_FUNC(GLOBAL(set_fpscr))
 GLOBAL(set_fpscr):
@@ -2006,6 +2026,9 @@
 #endif
 #if defined(__SH4__) || defined (__SH2A_DOUBLE__)
 	swap.w r0,r2
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	nop
+#endif		
 	rts
 	mov.l r2,@r1
 #else /* defined(__SH2E__) || defined(__SH3E__) || defined(__SH4_SINGLE*__) */
@@ -2042,6 +2065,54 @@
 #endif /* SH2E / SH3E / SH4 */
 #endif /* __SH2A_NOFPU__ */
 #endif /* L_set_fpscr */
+
+/* i-cache flushing
+ * For system code, we use ic_invalidate_line_i, but user code
+ * needs a different mechanism.  There are a number of ways of doing
+ * this:
+ *	1.  A kernel syscall (generally not available, slow but supports multiple arch variants)
+ *	2.  A kernel vsyscall (optimum solution, supports multiple arch variants)
+ *	3.  A jump table (supports 1 arch variant)
+ * For 3, different SH4 variants use different sizes and associativities
+ * of the Icache.  We use a small bit of dispatch code that can be put
+ * hidden in every shared object, which calls the actual processor-specific
+ * invalidation code in a separate module.
+ */
+
+/*
+ * SYSCALL method for i-cache flushing
+ */
+
+#ifdef L_ic_invalidate_syscall
+#include <asm/unistd.h>
+#include <asm/cachectl.h>
+
+	.global GLOBAL(ic_invalidate_syscall)
+	HIDDEN_FUNC(GLOBAL(ic_invalidate_syscall))
+	HIDDEN_ALIAS(ic_invalidate,ic_invalidate_syscall)
+GLOBAL(ic_invalidate_syscall):
+	mov.l	1f, r6
+	mov.l	2f, r3
+	/* Note: L1 cacheline size is not exposed to userspace
+	 *       so we use a length of 4 so it will work for
+	 *       different cacheline sizes
+	 */
+	mov	#4, r5
+	trapa	#0x13
+	rts
+	 nop
+	.balign 4
+1:	.long (CACHEFLUSH_D_WB | CACHEFLUSH_I)
+2:	.long __NR_cacheflush
+
+	ENDFUNC(GLOBAL(ic_invalidate_syscall))
+
+#endif /* L_ic_invalidate_syscall */
+
+/*
+ * Jump table method for i-cache flushing
+ */
+
 #ifdef L_ic_invalidate
 #if __SH5__ == 32
 	.mode	SHmedia
@@ -2075,7 +2146,7 @@
 	synci
 	blink	tr0, r63
 	ENDFUNC(GLOBAL(ic_invalidate))
-#elif defined(__SH4A__)
+#elif defined(__SH4A__) || defined(__FORCE_SH4A__)
 	.global GLOBAL(ic_invalidate)
 	HIDDEN_FUNC(GLOBAL(ic_invalidate))
 GLOBAL(ic_invalidate):
@@ -2086,18 +2157,11 @@
 	  nop
 	ENDFUNC(GLOBAL(ic_invalidate))
 #elif defined(__SH4_SINGLE__) || defined(__SH4__) || defined(__SH4_SINGLE_ONLY__) || (defined(__SH4_NOFPU__) && !defined(__SH5__))
-	/* For system code, we use ic_invalidate_line_i, but user code
-	   needs a different mechanism.  A kernel call is generally not
-	   available, and it would also be slow.  Different SH4 variants use
-	   different sizes and associativities of the Icache.  We use a small
-	   bit of dispatch code that can be put hidden in every shared object,
-	   which calls the actual processor-specific invalidation code in a
-	   separate module.
-	   Or if you have operating system support, the OS could mmap the
-	   procesor-specific code from a single page, since it is highly
-	   repetitive.  */
 	.global GLOBAL(ic_invalidate)
 	HIDDEN_FUNC(GLOBAL(ic_invalidate))
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	2
+#endif	
 GLOBAL(ic_invalidate):
 #ifdef __pic__
 #ifdef __vxworks
@@ -2142,7 +2206,6 @@
 
 #ifdef L_ic_invalidate_array
 #if defined(__SH4A__) || (defined (__FORCE_SH4A__) && (defined(__SH4_SINGLE__) || defined(__SH4__) || defined(__SH4_SINGLE_ONLY__) || (defined(__SH4_NOFPU__) && !defined(__SH5__))))
-	.global GLOBAL(ic_invalidate_array)
 	/* This is needed when an SH4 dso with trampolines is used on SH4A.  */
 	.global GLOBAL(ic_invalidate_array)
 	FUNC(GLOBAL(ic_invalidate_array))
@@ -3045,7 +3108,7 @@
  .global GLOBAL(sdivsi3)
 GLOBAL(sdivsi3):
 #ifdef TEXT_DATA_BUG
- ptb datalabel Local_div_table,tr0
+ ptb datalabel LOCAL(Ldiv_table),tr0
 #else
  ptb GLOBAL(div_table_internal),tr0
 #endif
@@ -3099,8 +3162,8 @@
 #endif /* __pic__ */
 #if defined(TEXT_DATA_BUG) && defined(__pic__) && defined(__SHMEDIA__)
 	.balign 2
-	.type	Local_div_table,@object
-	.size	Local_div_table,128
+	.type	LOCAL(Ldiv_table),@object
+	.size	LOCAL(Ldiv_table),128
 /* negative division constants */
 	.word	-16638
 	.word	-17135
@@ -3136,7 +3199,7 @@
 	.byte	214
 	.byte	241
 	.skip 16
-Local_div_table:
+LOCAL(Ldiv_table):
 	.skip 16
 /* positive division factors */
 	.byte	241
@@ -3268,11 +3331,19 @@
 #define L_MSWLSB 1
 #endif
 
+	
 	.balign 4
 	.global	GLOBAL(udivsi3_i4i)
 	FUNC(GLOBAL(udivsi3_i4i))
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	5
+#endif			
 GLOBAL(udivsi3_i4i):
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	mov.w LOCAL(c128_lw), r1
+#else
 	mov.w LOCAL(c128_w), r1
+#endif
 	div0u
 	mov r4,r0
 	shlr8 r0
@@ -3320,8 +3391,14 @@
 	rts
 	shld r1,r0
 
+#ifdef	DB_ST40300_BUG_WORKAROUND	
+LOCAL(c128_lw):
+	.word 128
+#else
 LOCAL(div_by_1_neg):
 	neg r4,r0
+#endif
+	
 LOCAL(div_by_1):
 	mov.l @r15+,r5
 	rts
@@ -3391,6 +3468,17 @@
 	FUNC(GLOBAL(sdivsi3_i4i))
 	/* This is link-compatible with a GLOBAL(sdivsi3) call,
 	   but we effectively clobber only r1.  */
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	5
+	
+LOCAL(div_by_1_neg):
+	neg r4,r0
+LOCAL(div_by_12):
+	mov.l @r15+,r5
+	rts
+	mov.l @r15+,r4
+#endif			
+	
 GLOBAL(sdivsi3_i4i):
 	mov.l r4,@-r15
 	cmp/pz r5
@@ -3887,6 +3975,9 @@
 	/* n1 < d, but n1 might be larger than d1.  */
 	.global GLOBAL(udiv_qrnnd_16)
 	.balign 8
+#ifdef	DB_ST40300_BUG_WORKAROUND
+	.align	5
+#endif		
 GLOBAL(udiv_qrnnd_16):
 	div0u
 	cmp/hi r6,r0
@@ -3927,3 +4018,8 @@
 	ENDFUNC(GLOBAL(udiv_qrnnd_16))
 #endif /* !__SHMEDIA__ */
 #endif /* L_udiv_qrnnd_16 */
+
+#ifndef L_div_table
+#include "ieee-754-sf.S"
+#include "ieee-754-df.S"
+#endif
diff -urN gcc-4.7.3/libgcc/config/sh/supervisor-atomic.S st40-4.7.3-13080/gcc/libgcc/config/sh/supervisor-atomic.S
--- gcc-4.7.3/libgcc/config/sh/supervisor-atomic.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/supervisor-atomic.S	2013-08-07 14:40:47.000000000 +0200
@@ -0,0 +1,199 @@
+/* Copyright (C) 2006, 2008, 2009 Free Software Foundation, Inc.
+   Copyright (c) 2010 STMicroelectronics.
+
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+
+   GCC is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   Under Section 7 of GPL version 3, you are granted additional
+   permissions described in the GCC Runtime Library Exception, version
+   3.1, as published by the Free Software Foundation.
+
+   You should have received a copy of the GNU General Public License and
+   a copy of the GCC Runtime Library Exception along with this program;
+   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+   <http://www.gnu.org/licenses/>.  */
+
+!! Atomic routines for the Renesas / SuperH SH CPUs for applications
+!! executing in supervisor mode.
+
+/* http://gcc.gnu.org/onlinedocs/gcc/_005f_005fatomic-Builtins.html
+   Just create a working set of atomic routines: When implementing patterns for these built-in functions, the memory model parameter can be ignored as long as the pattern implements the most restrictive __ATOMIC_SEQ_CST model. Any of the other memory models execute correctly with this memory model but they may not execute as efficiently as they could with a more appropriate implementation of the relaxed requirements. */
+
+#include "lib1funcs.h"
+
+#if ! __SH5__
+
+#define ATOMIC_BOOL_COMPARE_AND_SWAP(N,T) \
+	.global	GLOBAL(atomic_compare_exchange_##N); \
+	.align	1; \
+GLOBAL(atomic_compare_exchange_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	mov.##T	@r5, r3; \
+	cmp/eq	r2, r3; \
+	bf/s	0f; \
+	movt	r0; \
+	mov.##T	r6, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	nop; \
+0:	mov.##T	r2, @r5; \
+	ldc	r1, sr; \
+	rts; \
+	nop; \
+	ENDFUNC(GLOBAL(atomic_compare_exchange_##N))
+
+ATOMIC_BOOL_COMPARE_AND_SWAP(1,b)
+ATOMIC_BOOL_COMPARE_AND_SWAP(2,w)
+ATOMIC_BOOL_COMPARE_AND_SWAP(4,l)
+
+#define ATOMIC_EXCHANGE(N,T) \
+	.global	GLOBAL(atomic_exchange_##N); \
+	.align	1; \
+GLOBAL(atomic_exchange_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	mov.##T	r5, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	mov	r2, r0; \
+	ENDFUNC(GLOBAL(atomic_exchange_##N))
+
+ATOMIC_EXCHANGE(1,b)
+ATOMIC_EXCHANGE(2,w)
+ATOMIC_EXCHANGE(4,l)
+
+#define SYNC_FETCH_AND_OP(OP,N,T,EXT) \
+	.global	GLOBAL(atomic_fetch_##OP##_##N); \
+	.align	1; \
+GLOBAL(atomic_fetch_##OP##_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	mov	r5, r3; \
+	OP	r2, r3; \
+	mov.##T	r3, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	 EXT	r2, r0; \
+	ENDFUNC(GLOBAL(atomic_fetch_##OP##_##N))
+
+SYNC_FETCH_AND_OP(add,1,b,extu.b)
+SYNC_FETCH_AND_OP(add,2,w,extu.w)
+SYNC_FETCH_AND_OP(add,4,l,extu.w)
+
+SYNC_FETCH_AND_OP(or,1,b,extu.b)
+SYNC_FETCH_AND_OP(or,2,w,extu.w)
+SYNC_FETCH_AND_OP(or,4,l,mov)
+
+SYNC_FETCH_AND_OP(and,1,b,extu.b)
+SYNC_FETCH_AND_OP(and,2,w,extu.w)
+SYNC_FETCH_AND_OP(and,4,l,mov)
+
+SYNC_FETCH_AND_OP(xor,1,b,extu.b)
+SYNC_FETCH_AND_OP(xor,2,w,extu.w)
+SYNC_FETCH_AND_OP(xor,4,l,mov)
+
+#define SYNC_FETCH_AND_COMBOP(OP,OP0,OP1,N,T,EXT) \
+	.global	GLOBAL(atomic_fetch_##OP##_##N); \
+	.align	1; \
+GLOBAL(atomic_fetch_##OP##_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	mov	r5, r3; \
+	OP0	r2, r3; \
+	OP1	r3, r3; \
+	mov.##T	r3, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	 EXT	r2, r0; \
+	ENDFUNC(GLOBAL(atomic_fetch_##OP##_##N))
+
+SYNC_FETCH_AND_COMBOP(sub,sub,neg,1,b,extu.b)
+SYNC_FETCH_AND_COMBOP(sub,sub,neg,2,w,extu.w)
+SYNC_FETCH_AND_COMBOP(sub,sub,neg,4,l,mov)
+
+SYNC_FETCH_AND_COMBOP(nand,and,not,1,b,extu.b)
+SYNC_FETCH_AND_COMBOP(nand,and,not,2,w,extu.w)
+SYNC_FETCH_AND_COMBOP(nand,and,not,4,l,mov)
+
+#define SYNC_OP_AND_FETCH(OP,N,T,EXT) \
+	.global	GLOBAL(atomic_##OP##_fetch_##N); \
+	.align	1; \
+GLOBAL(atomic_##OP##_fetch_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	mov	r5, r3; \
+	OP	r2, r3; \
+	mov.##T	r3, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	 EXT	r3, r0; \
+	ENDFUNC(GLOBAL(atomic_##OP##_fetch_##N))
+
+SYNC_OP_AND_FETCH(add,1,b,extu.b)
+SYNC_OP_AND_FETCH(add,2,w,extu.w)
+SYNC_OP_AND_FETCH(add,4,l,mov)
+
+SYNC_OP_AND_FETCH(or,1,b,extu.b)
+SYNC_OP_AND_FETCH(or,2,w,extu.w)
+SYNC_OP_AND_FETCH(or,4,l,mov)
+
+SYNC_OP_AND_FETCH(and,1,b,extu.b)
+SYNC_OP_AND_FETCH(and,2,w,extu.w)
+SYNC_OP_AND_FETCH(and,4,l,mov)
+
+SYNC_OP_AND_FETCH(xor,1,b,extu.b)
+SYNC_OP_AND_FETCH(xor,2,w,extu.w)
+SYNC_OP_AND_FETCH(xor,4,l,mov)
+
+#define SYNC_COMBOP_AND_FETCH(OP,OP0,OP1,N,T,EXT) \
+	.global	GLOBAL(atomic_##OP##_fetch_##N); \
+	.align	1; \
+GLOBAL(atomic_##OP##_fetch_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	mov	r5, r3; \
+	OP0	r2, r3; \
+	OP1	r3, r3; \
+	mov.##T	r3, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	EXT	r3, r0; \
+	ENDFUNC(GLOBAL(atomic_##OP##_fetch_##N))
+
+SYNC_COMBOP_AND_FETCH(sub,sub,neg,1,b,extu.b)
+SYNC_COMBOP_AND_FETCH(sub,sub,neg,2,w,extu.w)
+SYNC_COMBOP_AND_FETCH(sub,sub,neg,4,l,mov)
+
+SYNC_COMBOP_AND_FETCH(nand,not,and,1,b,extu.b)
+SYNC_COMBOP_AND_FETCH(nand,not,and,2,w,extu.w)
+SYNC_COMBOP_AND_FETCH(nand,not,and,4,l,mov)
+
+#endif /* ! __SH5__ */
diff -urN gcc-4.7.3/libgcc/config/sh/supervisor-sync.S st40-4.7.3-13080/gcc/libgcc/config/sh/supervisor-sync.S
--- gcc-4.7.3/libgcc/config/sh/supervisor-sync.S	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/supervisor-sync.S	2013-08-07 14:40:47.000000000 +0200
@@ -0,0 +1,215 @@
+/* Copyright (C) 2006, 2008, 2009 Free Software Foundation, Inc.
+   Copyright (c) 2010 STMicroelectronics.
+
+   This file is part of GCC.
+
+   GCC is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 3, or (at your option)
+   any later version.
+
+   GCC is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   Under Section 7 of GPL version 3, you are granted additional
+   permissions described in the GCC Runtime Library Exception, version
+   3.1, as published by the Free Software Foundation.
+
+   You should have received a copy of the GNU General Public License and
+   a copy of the GCC Runtime Library Exception along with this program;
+   see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+   <http://www.gnu.org/licenses/>.  */
+
+!! Atomic routines for the Renesas / SuperH SH CPUs for applications
+!! executing in supervisor mode.
+
+/* http://gcc.gnu.org/onlinedocs/gcc/_005f_005fatomic-Builtins.html
+   Just create a working set of atomic routines: When implementing patterns for these built-in functions, the memory model parameter can be ignored as long as the pattern implements the most restrictive __SYNC_SEQ_CST model. Any of the other memory models execute correctly with this memory model but they may not execute as efficiently as they could with a more appropriate implementation of the relaxed requirements. */
+
+#include "lib1funcs.h"
+
+#if ! __SH5__
+
+#define SYNC_TEST_AND_SET(N,T,EXT) \
+	.global	GLOBAL(sync_lock_test_and_set_##N); \
+	.align	1; \
+GLOBAL(sync_lock_test_and_set_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	mov.##T	r5, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	 EXT	r2, r0; \
+	ENDFUNC(GLOBAL(sync_lock_test_and_set_##N)) 
+
+SYNC_TEST_AND_SET(1,b,extu.b)
+SYNC_TEST_AND_SET(2,w,extu.w)
+SYNC_TEST_AND_SET(4,l,mov)
+
+#define SYNC_VAL_COMPARE_AND_SWAP(N,T) \
+	.global	GLOBAL(sync_val_compare_and_swap_##N); \
+	.align	1; \
+GLOBAL(sync_val_compare_and_swap_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	cmp/eq	r2, r5; \
+	bf	0f; \
+	mov.##T	r6, @r4; \
+0:	ldc	r1, sr; \
+	rts; \
+	mov	r2, r0; \
+	ENDFUNC(GLOBAL(sync_val_compare_and_swap_##N))
+
+SYNC_VAL_COMPARE_AND_SWAP(1,b)
+SYNC_VAL_COMPARE_AND_SWAP(2,w)
+SYNC_VAL_COMPARE_AND_SWAP(4,l)
+
+#define SYNC_BOOL_COMPARE_AND_SWAP(N,T) \
+	.global	GLOBAL(sync_bool_compare_and_swap_##N); \
+	.align	1; \
+GLOBAL(sync_bool_compare_and_swap_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	cmp/eq	r2, r5; \
+	bf/s	0f; \
+	movt	r0; \
+	mov.##T	r6, @r4; \
+0:	ldc	r1, sr; \
+	rts; \
+	nop; \
+	ENDFUNC(GLOBAL(sync_bool_compare_and_swap_##N))
+
+SYNC_BOOL_COMPARE_AND_SWAP(1,b)
+SYNC_BOOL_COMPARE_AND_SWAP(2,w)
+SYNC_BOOL_COMPARE_AND_SWAP(4,l)
+
+#define SYNC_FETCH_AND_OP(OP,N,T,EXT) \
+	.global	GLOBAL(sync_fetch_and_##OP##_##N); \
+	.align	1; \
+GLOBAL(sync_fetch_and_##OP##_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	mov	r5, r3; \
+	OP	r2, r3; \
+	mov.##T	r3, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	 EXT	r2, r0; \
+	ENDFUNC(GLOBAL(sync_fetch_and_##OP##_##N))
+
+SYNC_FETCH_AND_OP(add,1,b,extu.b)
+SYNC_FETCH_AND_OP(add,2,w,extu.w)
+SYNC_FETCH_AND_OP(add,4,l,extu.w)
+
+SYNC_FETCH_AND_OP(or,1,b,extu.b)
+SYNC_FETCH_AND_OP(or,2,w,extu.w)
+SYNC_FETCH_AND_OP(or,4,l,mov)
+
+SYNC_FETCH_AND_OP(and,1,b,extu.b)
+SYNC_FETCH_AND_OP(and,2,w,extu.w)
+SYNC_FETCH_AND_OP(and,4,l,mov)
+
+SYNC_FETCH_AND_OP(xor,1,b,extu.b)
+SYNC_FETCH_AND_OP(xor,2,w,extu.w)
+SYNC_FETCH_AND_OP(xor,4,l,mov)
+
+#define SYNC_FETCH_AND_COMBOP(OP,OP0,OP1,N,T,EXT) \
+	.global	GLOBAL(sync_fetch_and_##OP##_##N); \
+	.align	1; \
+GLOBAL(sync_fetch_and_##OP##_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	mov	r5, r3; \
+	OP0	r2, r3; \
+	OP1	r3, r3; \
+	mov.##T	r3, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	 EXT	r2, r0; \
+	ENDFUNC(GLOBAL(sync_fetch_and_##OP##_##N))
+
+SYNC_FETCH_AND_COMBOP(sub,sub,neg,1,b,extu.b)
+SYNC_FETCH_AND_COMBOP(sub,sub,neg,2,w,extu.w)
+SYNC_FETCH_AND_COMBOP(sub,sub,neg,4,l,mov)
+
+SYNC_FETCH_AND_COMBOP(nand,and,not,1,b,extu.b)
+SYNC_FETCH_AND_COMBOP(nand,and,not,2,w,extu.w)
+SYNC_FETCH_AND_COMBOP(nand,and,not,4,l,mov)
+
+#define SYNC_OP_AND_FETCH(OP,N,T,EXT) \
+	.global	GLOBAL(sync_##OP##_and_fetch_##N); \
+	.align	1; \
+GLOBAL(sync_##OP##_and_fetch_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	mov	r5, r3; \
+	OP	r2, r3; \
+	mov.##T	r3, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	 EXT	r3, r0; \
+	ENDFUNC(GLOBAL(sync_##OP##_and_fetch_##N))
+
+SYNC_OP_AND_FETCH(add,1,b,extu.b)
+SYNC_OP_AND_FETCH(add,2,w,extu.w)
+SYNC_OP_AND_FETCH(add,4,l,mov)
+
+SYNC_OP_AND_FETCH(or,1,b,extu.b)
+SYNC_OP_AND_FETCH(or,2,w,extu.w)
+SYNC_OP_AND_FETCH(or,4,l,mov)
+
+SYNC_OP_AND_FETCH(and,1,b,extu.b)
+SYNC_OP_AND_FETCH(and,2,w,extu.w)
+SYNC_OP_AND_FETCH(and,4,l,mov)
+
+SYNC_OP_AND_FETCH(xor,1,b,extu.b)
+SYNC_OP_AND_FETCH(xor,2,w,extu.w)
+SYNC_OP_AND_FETCH(xor,4,l,mov)
+
+#define SYNC_COMBOP_AND_FETCH(OP,OP0,OP1,N,T,EXT) \
+	.global	GLOBAL(sync_##OP##_and_fetch_##N); \
+	.align	1; \
+GLOBAL(sync_##OP##_and_fetch_##N):; \
+	stc	sr, r1; \
+	mov	r1, r0; \
+	or	#0xf0, r0; \
+	ldc	r0, sr; \
+	mov.##T	@r4, r2; \
+	mov	r5, r3; \
+	OP0	r2, r3; \
+	OP1	r3, r3; \
+	mov.##T	r3, @r4; \
+	ldc	r1, sr; \
+	rts; \
+	EXT	r3, r0; \
+	ENDFUNC(GLOBAL(sync_##OP##_and_fetch_##N))
+
+SYNC_COMBOP_AND_FETCH(sub,sub,neg,1,b,extu.b)
+SYNC_COMBOP_AND_FETCH(sub,sub,neg,2,w,extu.w)
+SYNC_COMBOP_AND_FETCH(sub,sub,neg,4,l,mov)
+
+SYNC_COMBOP_AND_FETCH(nand,and,not,1,b,extu.b)
+SYNC_COMBOP_AND_FETCH(nand,and,not,2,w,extu.w)
+SYNC_COMBOP_AND_FETCH(nand,and,not,4,l,mov)
+
+#endif /* ! __SH5__ */
diff -urN gcc-4.7.3/libgcc/config/sh/t-generic st40-4.7.3-13080/gcc/libgcc/config/sh/t-generic
--- gcc-4.7.3/libgcc/config/sh/t-generic	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/t-generic	2013-02-14 12:55:08.000000000 +0100
@@ -0,0 +1,2 @@
+# Provide dummy generic threads functions
+LIB2ADD += $(srcdir)/gthr-generic.c
diff -urN gcc-4.7.3/libgcc/config/sh/t-linux st40-4.7.3-13080/gcc/libgcc/config/sh/t-linux
--- gcc-4.7.3/libgcc/config/sh/t-linux	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/t-linux	2012-04-13 08:58:03.000000000 +0200
@@ -1,8 +1,12 @@
-LIB1ASMFUNCS_CACHE = _ic_invalidate _ic_invalidate_array
+# Use a syscall for i-cache flushing so that all SoCs are supported by default
+# In future we will change this to a vsyscall for efficiency
+LIB1ASMFUNCS_CACHE=_ic_invalidate_syscall
+
+LIB1ASMFUNCS_DIVTABLE= _div_table 
 
 LIB2ADD = $(srcdir)/config/sh/linux-atomic.S
 
-HOST_LIBGCC2_CFLAGS += -mieee -DNO_FPSCR_VALUES
+HOST_LIBGCC2_CFLAGS += -fpic -DNO_FPSCR_VALUES
 
 # Override t-slibgcc-elf-ver to export some libgcc symbols with
 # the symbol versions that glibc used, and hide some lib1func
@@ -12,3 +16,6 @@
 	libgcc-std.ver \
 	$(srcdir)/config/sh/libgcc-excl.ver \
 	$(srcdir)/config/sh/libgcc-glibc.ver
+
+
+
diff -urN gcc-4.7.3/libgcc/config/sh/trap-handler.c st40-4.7.3-13080/gcc/libgcc/config/sh/trap-handler.c
--- gcc-4.7.3/libgcc/config/sh/trap-handler.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/trap-handler.c	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,10 @@
+extern void exit(int) __attribute__ ((noreturn));
+
+void
+_superh_trap_handler (unsigned int trap_reason)
+{
+  exit(*(int*)0xff000024);  /* return EXPEVT */
+
+  /* in case exit returns ... */
+  while(1);
+}
diff -urN gcc-4.7.3/libgcc/config/sh/t-sh st40-4.7.3-13080/gcc/libgcc/config/sh/t-sh
--- gcc-4.7.3/libgcc/config/sh/t-sh	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/t-sh	2013-04-30 15:17:53.000000000 +0200
@@ -17,29 +17,66 @@
 # along with GCC; see the file COPYING3.  If not see
 # <http://www.gnu.org/licenses/>.
 
+# _nesf2f _nedf2f _gtsf2f _gtdf2f _gesf2f _gedf2f: no-finite-math-only optimized
+# versions of _ne_sf _ne_df _gt_sf _gt_df _ge_sf _ge_df
+# _div_table
+# XXX gtdf2f, _gedf2f, gtsf2f, gesf2f,  broken, use fp-bit version.
 LIB1ASMSRC = sh/lib1funcs.S
 LIB1ASMFUNCS = _ashiftrt _ashiftrt_n _ashiftlt _lshiftrt _movmem \
   _movmem_i4 _mulsi3 _sdivsi3 _sdivsi3_i4 _udivsi3 _udivsi3_i4 _set_fpscr \
-  _div_table _udiv_qrnnd_16 \
+  _udiv_qrnnd_16 \
+  _nesf2 _nedf2 \
+  _addsub_sf _mul_sf _addsub_df _mul_df \
+  _hypotf \
+  _sf_to_df _df_to_sf \
+  _fixunssfsi _sf_to_si _usi_to_sf _si_to_sf \
+  _usi_to_df _si_to_df \
+  _div_sf \
+  $(LIB1ASMFUNCS_DIVTABLE) \
   $(LIB1ASMFUNCS_CACHE)
 LIB1ASMFUNCS_CACHE = _ic_invalidate _ic_invalidate_array
 
+# notyet. move above and remove bellow!
+# unord_sf/unord_df
+# _div_df \
+# _df_to_usi \
+# _df_to_si \
+
+FPBIT_FUNCS = _pack_sf _unpack_sf \
+    _fpcmp_parts_sf _compare_sf _eq_sf _gt_sf _ge_sf \
+    _lt_sf _le_sf _unord_sf _negate_sf _make_sf \
+    _sf_to_tf _thenan_sf
+
+DPBIT_FUNCS = _pack_df _unpack_df _div_df \
+    _fpcmp_parts_df _compare_df _eq_df _gt_df _ge_df \
+    _lt_df _le_df _unord_df _negate_df _make_df \
+    _df_to_tf _thenan_df _df_to_usi _df_to_si
+
 crt1.o: $(srcdir)/config/sh/crt1.S
 	$(gcc_compile) -c $<
 
+ic_invalidate_array.o: $(srcdir)/config/sh/lib1funcs.S
+	$(gcc_compile) -c -DL_ic_invalidate_array $<
+ic_invalidate.o: $(srcdir)/config/sh/lib1funcs.S
+	$(gcc_compile) -c -DL_ic_invalidate $<
+libic_invalidate.a: ic_invalidate_array.o ic_invalidate.o
+	$(AR_CREATE_FOR_TARGET) $@ $<
+
 ic_invalidate_array_4-100.o: $(srcdir)/config/sh/lib1funcs.S
 	$(gcc_compile) -c -DL_ic_invalidate_array -DWAYS=1 -DWAY_SIZE=0x2000 $<
-libic_invalidate_array_4-100.a: ic_invalidate_array_4-100.o
+libic_invalidate_4-100.a: ic_invalidate_array_4-100.o ic_invalidate.o
 	$(AR_CREATE_FOR_TARGET) $@ $<
 
 ic_invalidate_array_4-200.o: $(srcdir)/config/sh/lib1funcs.S
 	$(gcc_compile) -c -DL_ic_invalidate_array -DWAYS=2 -DWAY_SIZE=0x2000 $<
-libic_invalidate_array_4-200.a: ic_invalidate_array_4-200.o
+libic_invalidate_4-200.a: ic_invalidate_array_4-200.o ic_invalidate.o
 	$(AR_CREATE_FOR_TARGET) $@ $<
 
+ic_invalidate_4a.o: $(srcdir)/config/sh/lib1funcs.S
+	$(gcc_compile) -c -DL_ic_invalidate -D__FORCE_SH4A__ -Wa,-isa=st40-300 $<
 ic_invalidate_array_4a.o: $(srcdir)/config/sh/lib1funcs.S
 	$(gcc_compile) -c -DL_ic_invalidate_array -D__FORCE_SH4A__ $<
-libic_invalidate_array_4a.a: ic_invalidate_array_4a.o
+libic_invalidate_4a.a: ic_invalidate_array_4a.o ic_invalidate_4a.o
 	$(AR_CREATE_FOR_TARGET) $@ $<
 
 sdivsi3_i4i-Os-4-200.o: $(srcdir)/config/sh/lib1funcs-Os-4-200.S
@@ -53,11 +90,20 @@
 libgcc-Os-4-200.a: $(OBJS_Os_4_200)
 	$(AR_CREATE_FOR_TARGET) $@ $(OBJS_Os_4_200)
 
+div_table-4-200.o: $(srcdir)/config/sh/lib1funcs.S
+	$(gcc_compile) -c -DL_div_table $<
+
+libgcc-4-200.a: div_table-4-200.o $(GCC_PASSES)
+	$(AR_CREATE_FOR_TARGET) $@ div_table-4-200.o
+
 div_table-4-300.o: $(srcdir)/config/sh/lib1funcs-4-300.S
 	$(gcc_compile) -c -DL_div_table $<
 
 libgcc-4-300.a: div_table-4-300.o
 	$(AR_CREATE_FOR_TARGET) $@ div_table-4-300.o
 
-HOST_LIBGCC2_CFLAGS += -mieee
+# HOST_LIBGCC2_CFLAGS += -mieee
 
+# Local Variables:
+# mode: Makefile
+# End:
diff -urN gcc-4.7.3/libgcc/config/sh/t-superh st40-4.7.3-13080/gcc/libgcc/config/sh/t-superh
--- gcc-4.7.3/libgcc/config/sh/t-superh	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libgcc/config/sh/t-superh	2013-02-12 10:45:43.000000000 +0100
@@ -1,3 +1,5 @@
+LIB2ADD = $(srcdir)/config/sh/supervisor-atomic.S $(srcdir)/config/sh/supervisor-sync.S
+
 # Compile crt1-mmu.o as crt1.o with -DMMU_SUPPORT
 crt1-mmu.o: $(srcdir)/config/sh/crt1.S
 	$(gcc_compile) -c -DMMU_SUPPORT $<
@@ -9,3 +11,6 @@
 # For sh4-400: Compile gcrt1.o as crt1.o with -DPROFILE
 gcrt1.o: $(srcdir)/config/sh/crt1.S
 	$(gcc_compile) -c -DPROFILE $<
+
+trap-handler.o: $(srcdir)/config/sh/trap-handler.c
+	$(gcc_compile) $(MULTILIB_CFLAGS) -c $<
diff -urN gcc-4.7.3/libgcc/config.host st40-4.7.3-13080/gcc/libgcc/config.host
--- gcc-4.7.3/libgcc/config.host	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/config.host	2013-04-25 10:54:55.000000000 +0200
@@ -957,10 +957,11 @@
 sh-*-elf* | sh[12346l]*-*-elf*)
 	tmake_file="$tmake_file sh/t-sh t-crtstuff-pic t-fdpbit"
 	extra_parts="$extra_parts crt1.o crti.o crtn.o crtbeginS.o crtendS.o \
-		libic_invalidate_array_4-100.a \
-		libic_invalidate_array_4-200.a \
-		libic_invalidate_array_4a.a \
-		libgcc-Os-4-200.a libgcc-4-300.a"
+		libic_invalidate_4-100.a \
+		libic_invalidate_4-200.a \
+		libic_invalidate_4a.a \
+		libic_invalidate.a \
+		libgcc-4-200.a libgcc-Os-4-200.a libgcc-4-300.a"
 	case ${host} in sh64*-*-*)
 		tmake_file="$tmake_file sh/t-sh64"
 		;;
@@ -969,11 +970,18 @@
 	sh*-superh-elf)
 		tmake_file="$tmake_file sh/t-superh"
 		extra_parts="$extra_parts crt1-mmu.o gcrt1-mmu.o gcrt1.o"
+		extra_parts="$extra_parts trap-handler.o"
  		;;
  	esac
+	case ${target_thread_file} in
+	  generic)
+	    tmake_file="${tmake_file} sh/t-generic"
+	    ;;
+	esac
 	;;
 sh-*-linux* | sh[2346lbe]*-*-linux*)
 	tmake_file="${tmake_file} sh/t-sh t-slibgcc-libgcc sh/t-linux t-fdpbit"
+	extra_parts="$extra_parts libgcc-4-200.a libgcc-Os-4-200.a libgcc-4-300.a"
 	case ${host} in sh64*-*-linux*)
 		tmake_file="$tmake_file sh/t-sh64"
 		;;
diff -urN gcc-4.7.3/libgcc/configure st40-4.7.3-13080/gcc/libgcc/configure
--- gcc-4.7.3/libgcc/configure	2012-06-18 11:00:11.000000000 +0200
+++ st40-4.7.3-13080/gcc/libgcc/configure	2012-06-18 16:10:36.000000000 +0200
@@ -4479,6 +4479,7 @@
     single)	thread_header=gthr-single.h ;;
     tpf)	thread_header=config/s390/gthr-tpf.h ;;
     vxworks)	thread_header=config/gthr-vxworks.h ;;
+    generic)	thread_header=gthr-generic.h ;;
     win32)	thread_header=config/i386/gthr-win32.h ;;
 esac
 
diff -urN gcc-4.7.3/libgcc/configure.ac st40-4.7.3-13080/gcc/libgcc/configure.ac
--- gcc-4.7.3/libgcc/configure.ac	2012-06-18 11:00:11.000000000 +0200
+++ st40-4.7.3-13080/gcc/libgcc/configure.ac	2012-06-18 16:10:36.000000000 +0200
@@ -376,6 +376,7 @@
     single)	thread_header=gthr-single.h ;;
     tpf)	thread_header=config/s390/gthr-tpf.h ;;
     vxworks)	thread_header=config/gthr-vxworks.h ;;
+    generic)	thread_header=gthr-generic.h ;;
     win32)	thread_header=config/i386/gthr-win32.h ;;
 esac
 
diff -urN gcc-4.7.3/libgcc/gthr-generic.c st40-4.7.3-13080/gcc/libgcc/gthr-generic.c
--- gcc-4.7.3/libgcc/gthr-generic.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/gthr-generic.c	2012-04-26 11:18:16.000000000 +0200
@@ -0,0 +1,181 @@
+/* Generic threads supplementary implementation. */
+/* Compile this one with gcc.  */
+/* Copyright (C) 1997, 1999, 2000, 2002, 2006 Free Software Foundation, Inc.
+   Copyright (c) 2006, 2012 STMicroelectronics.
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify it under
+the terms of the GNU General Public License as published by the Free
+Software Foundation; either version 3, or (at your option) any later
+version.
+
+GCC is distributed in the hope that it will be useful, but WITHOUT ANY
+WARRANTY; without even the implied warranty of MERCHANTABILITY or
+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+for more details.
+
+Under Section 7 of GPL version 3, you are granted additional
+permissions described in the GCC Runtime Library Exception, version
+3.1, as published by the Free Software Foundation.
+
+You should have received a copy of the GNU General Public License and
+a copy of the GCC Runtime Library Exception along with this program;
+see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+<http://www.gnu.org/licenses/>.  */
+
+#define __GTHR_WEAK __attribute__ ((weak))
+
+#include "tconfig.h"
+#include "gthr.h"
+
+#ifndef __gthr_generic_h
+#error "Generic thread support package not supported"
+#endif
+
+/* These are stub functions.  When threading is available, a suitable set of definitions should be linked in.  */
+
+/* Return 1 if thread system is active, 0 if not.  */
+int
+__generic_gxx_active_p (void)
+{
+  return 0;
+}
+
+/* The following functions should return zero on success or the error
+   number.  If the operation is not supported, -1 is returned.
+
+   __generic_gxx_once
+   __generic_gxx_key_create
+   __generic_gxx_key_delete
+   __generic_gxx_setspecific
+   __generic_gxx_mutex_lock
+   __generic_gxx_mutex_trylock
+   __generic_gxx_mutex_unlock
+   __generic_gxx_recursive_mutex_lock
+   __generic_gxx_recursive_mutex_trylock
+   __generic_gxx_recursive_mutex_unlock  */
+
+/* FUNC is a function that should be called without parameters.
+   *ONCE has been initialized to __GTHREAD_ONCE_INIT and is otherwise only
+   used in calls to __generic_gxx_once with FUNC as the second parameter.
+   If __generic_gxx_once succeeds, FUNC will have been called exactly once
+   since the initialization of ONCE through any number of calls of
+   __generic_gxx_once with this pair of ONCE and FUNC values.  */
+int
+__generic_gxx_once (__gthread_once_t *once ATTRIBUTE_UNUSED,
+		    void (*func)(void) ATTRIBUTE_UNUSED)
+{
+  return -1;
+}
+
+/* Assign a key to *KEY that can be used in calls to
+   __generic_gxx_setspecific / __generic_gxx_getspecific.
+   If DTOR is nonzero, and at thread exit the value associated with the key
+   is nonzero, DTOR will be called at thread exit with the value associated
+   with the key as its only argument.  */
+int
+__generic_gxx_key_create (__gthread_key_t *key ATTRIBUTE_UNUSED,
+			  void (*dtor)(void *) ATTRIBUTE_UNUSED)
+{
+  return -1;
+}
+
+/* KEY is a key previously allocated by __generic_gxx_key_create.
+   Remove it from the set of keys known for this thread.  */
+int
+__generic_gxx_key_delete (__gthread_key_t key ATTRIBUTE_UNUSED)
+{
+  return -1;
+}
+
+/* Return thread-specific data associated with KEY.  */
+void *
+__generic_gxx_getspecific (__gthread_key_t key ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
+
+/* Set thread-specific data associated with KEY to PTR.  */
+int
+__generic_gxx_setspecific (__gthread_key_t key ATTRIBUTE_UNUSED,
+		      const void *ptr ATTRIBUTE_UNUSED)
+{
+  return -1;
+}
+
+/* Initialize *MUTEX.  */
+void
+__generic_gxx_mutex_init_function (__gthread_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+}
+
+/* Destroy *MUTEX.  */
+int
+__generic_gxx_mutex_destroy (__gthread_mutex_t *__mutex ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
+
+/* Acquire a lock on *MUTEX.  The behaviour is undefined if a lock on *MUTEX
+   has already been acquired by the same thread.  */
+int
+__generic_gxx_mutex_lock (__gthread_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
+
+/* Try to acquire a lock on *MUTEX.  If a lock on *MUTEX already exists,
+   return an error code.  */
+int
+__generic_gxx_mutex_trylock (__gthread_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
+
+/* A lock on *MUTEX has previously been acquired with __generic_gxx_mutex_lock
+   or __generic_gxx_mutex_trylock.  Release the lock.  */
+int
+__generic_gxx_mutex_unlock (__gthread_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
+
+/* Initialize *MUTEX.  */
+void
+__generic_gxx_recursive_mutex_init_function (__gthread_recursive_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+}
+
+/* Destroy *MUTEX.  */
+int
+__generic_gxx_recursive_mutex_destroy (__gthread_recursive_mutex_t *__mutex ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
+
+/* Acquire a lock on *MUTEX.  If a lock on *MUTEX has already been acquired by
+   the same thread, succeed.  */
+int
+__generic_gxx_recursive_mutex_lock (__gthread_recursive_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
+
+/* Try to acquire a lock on *MUTEX.  If a lock on *MUTEX has already been
+   acquired by the same thread, succeed.  If any other lock on *MUTEX
+   already exists, return an error code.  */
+int
+__generic_gxx_recursive_mutex_trylock (__gthread_recursive_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
+
+/* A lock on *MUTEX has previously been acquired with
+   __generic_gxx_recursive_mutex_lock or
+   __generic_gxx_recursive_mutex_trylock.  Release the lock.  */
+int
+__generic_gxx_recursive_mutex_unlock (__gthread_recursive_mutex_t *mutex ATTRIBUTE_UNUSED)
+{
+  return 0;
+}
diff -urN gcc-4.7.3/libgcc/gthr-generic.h st40-4.7.3-13080/gcc/libgcc/gthr-generic.h
--- gcc-4.7.3/libgcc/gthr-generic.h	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libgcc/gthr-generic.h	2012-04-26 11:18:16.000000000 +0200
@@ -0,0 +1,385 @@
+/* Generic threads compatibility routines for libgcc2 and libobjc. */
+/* Compile this one with gcc.  */
+/* Copyright (C) 1997, 1999, 2000, 2002, 2006 Free Software Foundation, Inc.
+   Copyright (c) 2006  STMicroelectronics.
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify it under
+the terms of the GNU General Public License as published by the Free
+Software Foundation; either version 3, or (at your option) any later
+version.
+
+GCC is distributed in the hope that it will be useful, but WITHOUT ANY
+WARRANTY; without even the implied warranty of MERCHANTABILITY or
+FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
+for more details.
+
+Under Section 7 of GPL version 3, you are granted additional
+permissions described in the GCC Runtime Library Exception, version
+3.1, as published by the Free Software Foundation.
+
+You should have received a copy of the GNU General Public License and
+a copy of the GCC Runtime Library Exception along with this program;
+see the files COPYING3 and COPYING.RUNTIME respectively.  If not, see
+<http://www.gnu.org/licenses/>.  */
+
+#ifndef __gthr_generic_h
+#define __gthr_generic_h
+
+#define __GTHREADS 1
+
+#define __GTHREAD_ONCE_INIT 0
+#define __GTHREAD_MUTEX_INIT_FUNCTION __gthread_mutex_init_function
+#define __GTHREAD_RECURSIVE_MUTEX_INIT_FUNCTION __gthread_recursive_mutex_init_function
+
+#ifdef __cplusplus
+extern "C" {
+#endif
+
+/* Avoid depedency on specific headers.
+   The general idea is that you dynamically allocate the required data
+   structures, and a void * is used to point to this dynamically allocated
+   data.  If your implementation can put all the required information in
+   the void * itself, that's fine, too, of course.
+   libstdc++ inherits from the mutex types, whcih is why they need to be
+   wrapped up as structs.  */
+typedef void *__gthread_key_t;
+typedef void *__gthread_once_t;
+typedef struct __gthread_mutex_s { void *__p; } __gthread_mutex_t;
+typedef struct __gthread_recursive_mutex_s { void *__p; } __gthread_recursive_mutex_t;
+
+/* We should always link with at least one definition, so we want strong
+   references.  The stub definitions are weak so that they can be overriden.  */
+#ifndef __GTHR_WEAK
+#define __GTHR_WEAK
+#endif
+
+extern int __generic_gxx_active_p (void) __GTHR_WEAK;
+
+extern int __generic_gxx_once (__gthread_once_t *, void (*)(void)) __GTHR_WEAK;
+
+extern int __generic_gxx_key_create (__gthread_key_t *,
+				     void (*)(void *)) __GTHR_WEAK;
+
+extern int __generic_gxx_key_delete (__gthread_key_t key) __GTHR_WEAK;
+
+extern void *__generic_gxx_getspecific (__gthread_key_t key) __GTHR_WEAK;
+
+extern int __generic_gxx_setspecific (__gthread_key_t, const void *) __GTHR_WEAK;
+
+extern void __generic_gxx_mutex_init_function (__gthread_mutex_t *) __GTHR_WEAK;
+
+extern int __generic_gxx_mutex_destroy (__gthread_mutex_t *) __GTHR_WEAK;
+
+extern int __generic_gxx_mutex_lock (__gthread_mutex_t *) __GTHR_WEAK;
+
+extern int __generic_gxx_mutex_trylock (__gthread_mutex_t *) __GTHR_WEAK;
+
+extern int __generic_gxx_mutex_unlock (__gthread_mutex_t *) __GTHR_WEAK;
+
+extern void __generic_gxx_recursive_mutex_init_function (__gthread_recursive_mutex_t *) __GTHR_WEAK;
+
+extern int __generic_gxx_recursive_mutex_destroy (__gthread_recursive_mutex_t *) __GTHR_WEAK;
+
+extern int __generic_gxx_recursive_mutex_lock (__gthread_recursive_mutex_t *) __GTHR_WEAK;
+
+extern int __generic_gxx_recursive_mutex_trylock (__gthread_recursive_mutex_t *) __GTHR_WEAK;
+
+extern int __generic_gxx_recursive_mutex_unlock (__gthread_recursive_mutex_t *) __GTHR_WEAK;
+
+#ifdef __cplusplus
+}
+#endif
+
+#ifdef _LIBOBJC
+
+extern int __generic_gxx_objc_init_thread_system (void) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_close_thread_system (void) __GTHR_WEAK;
+
+extern objc_thread_t __generic_gxx_objc_thread_detach (void (*)(void *), void *) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_thread_set_priority (int priority) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_thread_get_priority (void) __GTHR_WEAK;
+
+extern void __generic_gxx_objc_thread_yield (void) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_thread_exit (void) __GTHR_WEAK;
+
+extern objc_thread_t __generic_gxx_objc_thread_id (void) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_thread_set_data (void *value) __GTHR_WEAK;
+
+extern void *__generic_gxx_objc_thread_get_data (void) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_mutex_allocate (objc_mutex_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_mutex_deallocate (objc_mutex_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_mutex_lock (objc_mutex_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_mutex_trylock (objc_mutex_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_mutex_unlock (objc_mutex_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_condition_allocate (objc_condition_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_condition_deallocate (objc_condition_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_condition_wait (objc_condition_t, objc_mutex_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_condition_broadcast (objc_condition_t) __GTHR_WEAK;
+
+extern int __generic_gxx_objc_condition_signal (objc_condition_t) __GTHR_WEAK;
+
+/* Backend initialization functions */
+
+/* Initialize the threads subsystem.  */
+static inline int
+__gthread_objc_init_thread_system (void)
+{
+  return __generic_gxx_objc_init_thread_system ();
+}
+
+/* Close the threads subsystem.  */
+static inline int
+__gthread_objc_close_thread_system (void)
+{
+  return __generic_gxx_objc_close_thread_system ();
+}
+
+/* Backend thread functions */
+
+/* Create a new thread of execution.  */
+static inline objc_thread_t
+__gthread_objc_thread_detach (void (* func)(void *), void * arg)
+{
+  return __generic_gxx_objc_thread_detach (func, arg);
+}
+
+/* Set the current thread's priority.  */
+static inline int
+__gthread_objc_thread_set_priority (int priority)
+{
+  return __generic_gxx_objc_thread_set_priority (priority);
+}
+
+/* Return the current thread's priority.  */
+static inline int
+__gthread_objc_thread_get_priority (void)
+{
+  return __generic_gxx_objc_thread_get_priority ();
+}
+
+/* Yield our process time to another thread.  */
+static inline void
+__gthread_objc_thread_yield (void)
+{
+  __generic_gxx_objc_thread_yield ();
+}
+
+/* Terminate the current thread.  */
+static inline int
+__gthread_objc_thread_exit (void)
+{
+  return __generic_gxx_objc_thread_exit ();
+}
+
+/* Returns an integer value which uniquely describes a thread.  */
+static inline objc_thread_t
+__gthread_objc_thread_id (void)
+{
+  return __generic_gxx_objc_thread_id ();
+}
+
+/* Sets the thread's local storage pointer.  */
+static inline int
+__gthread_objc_thread_set_data (void *value)
+{
+  return __generic_gxx_objc_thread_set_data (value);
+}
+
+/* Returns the thread's local storage pointer.  */
+static inline void *
+__gthread_objc_thread_get_data (void)
+{
+  return __generic_gxx_objc_thread_get_data ();
+}
+
+/* Backend mutex functions */
+
+/* Allocate a mutex.  */
+static inline int
+__gthread_objc_mutex_allocate (objc_mutex_t mutex)
+{
+  return __generic_gxx_objc_mutex_allocate (mutex);
+}
+
+/* Deallocate a mutex.  */
+static inline int
+__gthread_objc_mutex_deallocate (objc_mutex_t mutex)
+{
+  return __generic_gxx_objc_mutex_deallocate (mutex);
+}
+
+/* Grab a lock on a mutex.  */
+static inline int
+__gthread_objc_mutex_lock (objc_mutex_t mutex)
+{
+  return __generic_gxx_objc_mutex_lock (mutex);
+}
+
+/* Try to grab a lock on a mutex.  */
+static inline int
+__gthread_objc_mutex_trylock (objc_mutex_t mutex)
+{
+  return __generic_gxx_objc_mutex_trylock (mutex);
+}
+
+/* Unlock the mutex */
+static inline int
+__gthread_objc_mutex_unlock (objc_mutex_t mutex)
+{
+  return __generic_gxx_objc_mutex_unlock (mutex);
+}
+
+/* Backend condition mutex functions */
+
+/* Allocate a condition.  */
+static inline int
+__gthread_objc_condition_allocate (objc_condition_t condition)
+{
+  return __generic_gxx_objc_condition_allocate (condition);
+}
+
+/* Deallocate a condition.  */
+static inline int
+__gthread_objc_condition_deallocate (objc_condition_t condition)
+{
+  return __generic_gxx_objc_condition_deallocate (condition);
+}
+
+/* Wait on the condition */
+static inline int
+__gthread_objc_condition_wait (objc_condition_t condition, objc_mutex_t mutex)
+{
+  return __generic_gxx_objc_condition_wait (condition, mutex);
+}
+
+/* Wake up all threads waiting on this condition.  */
+static inline int
+__gthread_objc_condition_broadcast (objc_condition_t condition)
+{
+  return __generic_gxx_objc_condition_broadcast ( condition);
+}
+
+/* Wake up one thread waiting on this condition.  */
+static inline int
+__gthread_objc_condition_signal (objc_condition_t condition)
+{
+  return __generic_gxx_objc_condition_signal (condition);
+}
+
+#else /* !_LIBOBJC */
+
+static inline int
+__gthread_active_p (void)
+{
+  return __generic_gxx_active_p ();
+}
+
+static inline int
+__gthread_once (__gthread_once_t *once, void (*func)(void))
+{
+  return __generic_gxx_once (once, func);
+}
+
+static inline int
+__gthread_key_create (__gthread_key_t *key, void (*dtor)(void *))
+{
+  return __generic_gxx_key_create (key, dtor);
+}
+
+static inline int
+__gthread_key_delete (__gthread_key_t key)
+{
+  return __generic_gxx_key_delete (key);
+}
+
+static inline void *
+__gthread_getspecific (__gthread_key_t key)
+{
+  return __generic_gxx_getspecific (key);
+}
+
+static inline int
+__gthread_setspecific (__gthread_key_t key, const void *ptr)
+{
+  return __generic_gxx_setspecific (key, ptr);
+}
+
+static inline void
+__gthread_mutex_init_function (__gthread_mutex_t *mutex)
+{
+  __generic_gxx_mutex_init_function (mutex);
+}
+
+static inline int
+__gthread_mutex_destroy (__gthread_mutex_t * mutex)
+{
+  return __generic_gxx_mutex_destroy (mutex);
+}
+
+static inline int
+__gthread_mutex_lock (__gthread_mutex_t * mutex)
+{
+  return __generic_gxx_mutex_lock (mutex);
+}
+
+static inline int
+__gthread_mutex_trylock (__gthread_mutex_t * mutex)
+{
+  return __generic_gxx_mutex_trylock (mutex);
+}
+
+static inline int
+__gthread_mutex_unlock (__gthread_mutex_t * mutex)
+{
+  return __generic_gxx_mutex_unlock (mutex);
+}
+
+static inline void
+__gthread_recursive_mutex_init_function (__gthread_recursive_mutex_t *mutex)
+{
+  __generic_gxx_recursive_mutex_init_function (mutex);
+}
+
+static inline int
+__gthread_recursive_mutex_destroy (__gthread_recursive_mutex_t * mutex)
+{
+  return __generic_gxx_recursive_mutex_destroy (mutex);
+}
+
+static inline int
+__gthread_recursive_mutex_lock (__gthread_recursive_mutex_t * mutex)
+{
+  return __generic_gxx_recursive_mutex_lock (mutex);
+}
+
+static inline int
+__gthread_recursive_mutex_trylock (__gthread_recursive_mutex_t * mutex)
+{
+  return __generic_gxx_recursive_mutex_trylock (mutex);
+}
+
+static inline int
+__gthread_recursive_mutex_unlock (__gthread_recursive_mutex_t * mutex)
+{
+  return __generic_gxx_recursive_mutex_unlock (mutex);
+}
+
+#endif /* _LIBOBJC */
+
+#endif /* __gthr_generic_h */
diff -urN gcc-4.7.3/libgcc/longlong.h st40-4.7.3-13080/gcc/libgcc/longlong.h
--- gcc-4.7.3/libgcc/longlong.h	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libgcc/longlong.h	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
    Copyright (C) 1991, 1992, 1994, 1995, 1996, 1997, 1998, 1999, 2000,
    2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011
    Free Software Foundation, Inc.
+   Copyright (c) 2013  STMicroelectronics.
 
    This file is part of the GNU C Library.
 
@@ -1048,6 +1049,30 @@
 /* This is the same algorithm as __udiv_qrnnd_c.  */
 #define UDIV_NEEDS_NORMALIZATION 1
 
+#ifdef	DB_ST40300_BUG_WORKAROUND
+#define udiv_qrnnd(q, r, n1, n0, d) \
+  do {									\
+    extern UWtype __udiv_qrnnd_16 (UWtype, UWtype)			\
+                        __attribute__ ((visibility ("hidden")));	\
+    /* r0: rn r1: qn */ /* r0: n1 r4: n0 r5: d r6: d1 */ /* r2: __m */	\
+    __asm__ (								\
+"	.align	2\n"                                                    \
+"       mov%M4 %4,r5\n"						        \
+"	swap.w %3,r4\n"							\
+"	swap.w r5,r6\n"							\
+"       nop\n"                                                          \
+"	jsr @%5\n"							\
+"	shll16 r6\n"							\
+"	swap.w r4,r4\n"							\
+"       nop\n"                                                          \
+"	jsr @%5\n"							\
+"	swap.w r1,%0\n"							\
+"	or r1,%0"							\
+	: "=r" (q), "=&z" (r)						\
+	: "1" (n1), "r" (n0), "rm" (d), "r" (&__udiv_qrnnd_16)		\
+        : "r1", "r2", "r4", "r5", "r6", "pr", "t");			\
+  } while (0)
+#else
 #define udiv_qrnnd(q, r, n1, n0, d) \
   do {									\
     extern UWtype __udiv_qrnnd_16 (UWtype, UWtype)			\
@@ -1067,6 +1092,7 @@
 	: "1" (n1), "r" (n0), "rm" (d), "r" (&__udiv_qrnnd_16)		\
 	: "r1", "r2", "r4", "r5", "r6", "pr", "t");			\
   } while (0)
+#endif
 
 #define UDIV_TIME 80
 
diff -urN gcc-4.7.3/libiberty/ChangeLog.STM st40-4.7.3-13080/gcc/libiberty/ChangeLog.STM
--- gcc-4.7.3/libiberty/ChangeLog.STM	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libiberty/ChangeLog.STM	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,25 @@
+2010-04-12  Christian Bruel  <christian.bruel@st.com>
+
+	* wrap_file.c: Fix prototypes.
+	Remove rename wrapper.
+	* cygpath.c: Shut-up warnings.
+
+2009-12-07  Yvan Roux  <yvan.roux@st.com>
+
+	* wrap_file.c: New file.
+	* Makefile.in: Add wrap_file.[co].
+	* config/mh-mingw: Add wrap_file.o.
+
+2006-05-15  Andrew Stubbs  <andrew.stubbs@st.com>
+
+	* cygpath.c (cygpath): Convert pathnames consisting only of a
+	drive specifier to a valid directory (e.g 'c:' -> 'c:/').
+
+2006-03-27  Andrew Stubbs  <andrew.stubbs@st.com>
+
+libiberty/
+	* cygpath.c: New file.
+	* config/mh-mingw: New file.
+	* configure.ac: Add mh-mingw makefile fragment when host is MinGW.
+	* configure: Regenerate.
+	* Makefile.in: Add cygpath.[co] .
diff -urN gcc-4.7.3/libiberty/config/mh-mingw st40-4.7.3-13080/gcc/libiberty/config/mh-mingw
--- gcc-4.7.3/libiberty/config/mh-mingw	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libiberty/config/mh-mingw	2013-03-05 11:20:46.000000000 +0100
@@ -0,0 +1 @@
+EXTRA_OFILES=cygpath.o wrap_file.o
diff -urN gcc-4.7.3/libiberty/configure st40-4.7.3-13080/gcc/libiberty/configure
--- gcc-4.7.3/libiberty/configure	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libiberty/configure	2012-04-04 14:14:24.000000000 +0200
@@ -4842,6 +4842,7 @@
   *-*-freebsd2.2.[012])	frag=mh-fbsd21 ;;
   i370-*-opened*)       frag=mh-openedition ;;
   i[34567]86-*-windows*)	frag=mh-windows ;;
+  *-*-mingw*)		frag=mh-mingw ;;
 esac
 
 if [ -n "${frag}" ]; then
diff -urN gcc-4.7.3/libiberty/configure.ac st40-4.7.3-13080/gcc/libiberty/configure.ac
--- gcc-4.7.3/libiberty/configure.ac	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libiberty/configure.ac	2012-04-04 14:14:24.000000000 +0200
@@ -185,6 +185,7 @@
   *-*-freebsd2.2.[[012]])	frag=mh-fbsd21 ;;
   i370-*-opened*)       frag=mh-openedition ;;
   i[[34567]]86-*-windows*)	frag=mh-windows ;;
+  *-*-mingw*)		frag=mh-mingw ;;
 esac
 
 if [[ -n "${frag}" ]]; then
diff -urN gcc-4.7.3/libiberty/cygpath.c st40-4.7.3-13080/gcc/libiberty/cygpath.c
--- gcc-4.7.3/libiberty/cygpath.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libiberty/cygpath.c	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,358 @@
+/* Basic Cygwin pathname support for MinGW.
+
+   Copyright (C) 2006 STMicroelectronics
+
+   This file is part of the libiberty library.
+
+   This program is free software; you can redistribute it and/or modify
+   it under the terms of the GNU General Public License as published by
+   the Free Software Foundation; either version 2 of the License, or
+   (at your option) any later version.
+
+   This program is distributed in the hope that it will be useful,
+   but WITHOUT ANY WARRANTY; without even the implied warranty of
+   MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+   GNU General Public License for more details.
+
+   You should have received a copy of the GNU General Public License
+   along with this program; if not, write to the Free Software
+   Foundation, Inc., 51 Franklin Street - Fifth Floor,
+   Boston, MA 02110-1301, USA.
+
+
+   This file implements a limited amount of support for Cygwin paths.
+   It is intended for use by MinGW programs that must interact with Cygwin.
+
+   It is limited to absolute paths only.  I.e. Those beginning with Cygwin
+   mounts, such as /cygdrive/...  See the comment on cygpath() below.  */
+
+#include "libiberty.h"
+#include <string.h>
+#include <ctype.h>
+#include <windows.h>
+
+
+/* These are all the possible settings for the ST_CYGPATH_MODE
+   environment variable.  */
+static enum
+{
+  mode_unset,
+  mode_off,
+  mode_normal,
+  mode_full
+} mode = mode_unset;
+
+
+/* These are the values extracted from the registry.
+   They are extracted the first time cygpath is called.  */
+static const char *cygdrive = NULL;
+static struct mount
+{
+  /* The name of the Cygwin mount point.  E.g. "/usr/bin"  */
+  char *mount;
+
+  /* The actual Windows path that the mount translates to.  */
+  char *actual;
+
+  struct mount *next;
+} *mounts = NULL;
+
+
+/* Read a string from the Windows Registry.
+   KEY should be a valid handle from RegOpenKeyEx().
+   NAME should be the name of the value within the key.
+   The value should be of type REG_SZ.
+   If the value does not exist, is of the wrong typei, or another error
+   occurs, then NULL is returned.
+   Otherwise a malloced string is returned.  */
+static char *
+read_string_from_registry (HKEY key, const char *name)
+{
+  DWORD valuetype = REG_NONE;
+  DWORD valuesize = 0;
+  char *value = NULL;
+
+  if (RegQueryValueEx (key, name, NULL, &valuetype,
+		       NULL, &valuesize) == ERROR_SUCCESS
+      && valuetype == REG_SZ)
+    {
+      value = (char *)xmalloc (valuesize);
+      if (RegQueryValueEx (key, name, NULL, &valuetype, (unsigned char *)value,
+			   &valuesize) != ERROR_SUCCESS)
+	{
+	  free (value);
+	  value = NULL;
+	}
+    }
+
+  return value;
+}
+
+
+/* Fill in the mounts list (mounts is defined statically above).
+   All subkeys (not values) of KEY that contain a REG_SZ value named 'native'
+   are added to the start of the mounts list.  */
+static void
+read_mounts (HKEY key)
+{
+  int mountsize = 15;
+  char *mount = (char *)xmalloc (mountsize);
+  DWORD size = mountsize;
+  int index = 0;
+  int retval = 0;
+
+  /* For each subkey ...  */
+  while ((retval = RegEnumKeyEx (key, index, mount, &size, 0, NULL, 0, NULL))
+	 != ERROR_NO_MORE_ITEMS)
+    {
+      struct mount *newmount;
+      HKEY subkey;
+      char *actual;
+
+      switch (retval) {
+      case ERROR_MORE_DATA:
+	/* The buffer wasn't large enough for this key name.
+	   Unlike RegQueryValueEx, RegEnumKeyEx won't tell us how big it
+	   should be, so just make it bigger and try again.
+	   Note that this code path does NOT increment index.
+       	   Most of the time we will only be dealing with short strings.  */
+	mountsize += 10;
+	mount = (char *)xrealloc (mount, mountsize);
+	break;
+
+      case ERROR_SUCCESS:
+	/* Find the actual windows path.  */
+  	if (RegOpenKeyEx (key, mount, 0, KEY_READ, &subkey) != ERROR_SUCCESS)
+	  {
+	    index++;
+	    break;
+	  }
+	actual = read_string_from_registry (subkey, "native");	
+	RegCloseKey (subkey);
+	if (actual == NULL)
+	  {
+	    index++;
+	    break;
+	  }
+
+	/* Create the new entry in the mount table.  */
+	newmount = (struct mount *)xmalloc (sizeof (struct mount));
+	newmount->mount = xstrdup (mount);
+	newmount->actual = actual;
+	newmount->next = mounts;
+	mounts = newmount;
+	index++;
+	break;
+
+      default:
+	/* Don't infinite loop should any other return value occur.  */
+        index++;
+      }
+
+      /* The last call to RegEnumKeyEx may have clobbered size.
+         Fix it before the next call.  */
+      size = mountsize;
+    }
+
+  free (mount);
+}
+
+
+/* The top level registry reading function.
+   Open the keys, call the above functions to get the right values,
+   and clean up.  */
+static void
+read_registry (void)
+{
+  HKEY hcu_key, hlm_key;
+
+  /* Get key handles for the two places cygwin keeps its registry data.  */
+  if (RegOpenKeyEx (HKEY_CURRENT_USER,
+		    "Software\\Cygnus Solutions\\Cygwin\\mounts v2",
+		    0, KEY_READ, &hcu_key) != ERROR_SUCCESS)
+    hcu_key = NULL;
+
+  if (RegOpenKeyEx (HKEY_LOCAL_MACHINE,
+		    "SOFTWARE\\Cygnus Solutions\\Cygwin\\mounts v2",
+		    0, KEY_READ, &hlm_key) != ERROR_SUCCESS)
+    hlm_key = NULL;
+
+  /* Get the virtual mount point used for windows drives.  */
+  if (hcu_key)
+    cygdrive = read_string_from_registry (hcu_key, "cygdrive prefix");
+  if (hlm_key && cygdrive == NULL)
+    cygdrive = read_string_from_registry (hlm_key, "cygdrive prefix");
+
+  /* Read the other mount points.
+     Read hlm before hcu to ensure hcu settings get used by preference
+     by being closer on the mounts stack.  */
+  if (hlm_key)
+    read_mounts (hlm_key);
+  if (hcu_key)
+    read_mounts (hcu_key);
+
+  if (hlm_key)
+    RegCloseKey (hlm_key);
+  if (hcu_key)
+    RegCloseKey (hcu_key);
+}
+
+
+/* Given a path of unknown variety, return the same path with any
+   Cygwin mount points substituted.
+   This function always returns a malloced string which should be
+   freed when the the caller is finished with it.
+
+   The mapping is affected by the ST_CYGPATH_MODE environment variable.
+   See the fprintf messages below for full information.
+
+   It can replace /cygdrive/<letter>/..... style pathnames, even if the
+   user has used 'mount -c' to an alternative string.
+
+   It can replace (if enabled) other Cygwin mount points, such as
+   the usual '/', '/usr/bin', '/usr/lib', as well as any other user defined
+   mount points.
+
+   It does NOT attempt to convert any pathnames that look like native Windows
+   names - such as those starting with '<letter>:' or double slash (UNC).
+
+   It does NOT handle relative pathnames passing through cygwin mounts
+   (e.g. '../cygdrive/c'), or absolute paths with repeated directory
+   separators or relative elements within the mount name
+   (e.g. '/usr/./bin').
+   
+   It does NOT allow backslash \ directory separators within the actual mount
+   path (e.g. '/usr\bin').  Cygwin does not always allow them there either.  */
+char *
+cygpath (const char *path)
+{
+  char *result = NULL;
+
+  if (path == NULL)
+    return NULL;
+
+  /* If this is the first time this function has been called then read the
+     environment and registry.  */
+  if (mode == mode_unset)
+    {
+      char *env = getenv ("ST_CYGPATH_MODE");
+
+      if (env == NULL || strcmp (env, "normal") == 0)
+    	mode = mode_normal;
+      else if (strcmp (env, "full") == 0)
+	mode = mode_full;
+      else if (strcmp (env, "off") == 0)
+	mode = mode_off;
+
+      if (mode != mode_off)
+	read_registry();
+
+      if (mode == mode_unset)
+	{
+	  /* The variable was set, but not to any known value.
+	     Set up a default and print an informational message
+	     for the user.  */
+	  mode = mode_normal;
+	  fprintf (stderr, "ST_CYGPATH_MODE should be one of:\n");
+	  fprintf (stderr, " off    - Disable all path translation.\n");
+	  fprintf (stderr, " normal - Translate %s only.\n", cygdrive);
+	  fprintf (stderr, " full   - Translate all Cygwin mounts.\n");
+	}
+    }
+
+  /* First, test if this can only be a windows (non-cygwin) path.
+     This includes paths that start with a drive letter or UNC double slash.  */
+  if ((isalpha (path[0]) && path[1] == ':')
+      || ((path[0] == '\\' || path[0] == '/')
+	  && (path[1] == '\\' || path[1] == '/')))
+    result = xstrdup (path);
+
+  /* Second, handle /cygdrive/<letter>/ (or whatever) paths.  */
+  if (!result && cygdrive != NULL && (mode == mode_normal || mode == mode_full))
+    {
+      int length = strlen (cygdrive);
+      /* Note that cygwin does not allow '\\' instead of '/' in cygdrive.  */
+      if (strncmp (cygdrive, path, length) == 0
+	  && (path[length] == '/' || path[length] == '\\'
+	      || path[length] == '\0')
+	  && isalpha (path[length+1]))
+        {
+	  result = (char *)xmalloc (strlen (path) - length+1 + 1);
+	  result[0] = path[length+1];
+	  result[1] = ':';
+	  strcpy (result + 2, path + length + 2);
+	}
+    }
+
+  /* Third, handle other types of cygwin path.  */
+  if (!result && mounts != NULL && mode == mode_full)
+    {
+      int matched = 0;
+      struct mount *foundat = NULL;
+      struct mount *mount = mounts;
+      /* Find the longest matching mount point.
+	 This is important. If we just used the first matching mount point
+	 it would probably always match '/' when '/usr/bin' is right.
+	 Use the first of equal length matches - this allows current-user
+	 mounts to override 'local machine' mounts (can this happen?).
+         It is a match only if the matching part is followed by a directory
+         separator or the end of the path, except for the root mount point.  */
+      while (mount != NULL)
+	{
+	  int length = strlen (mount->mount);
+	  if (strncmp (mount->mount, path, length) == 0
+	      && matched < length
+	      && (length == 1 /* Special case for root mount point '/'.  */
+		  || path[length] == '/' || path[length] == '\\'
+		  || path[length] == '\0'))
+	    {
+	      matched = length;
+	      foundat = mount;
+	    }
+	  mount = mount->next;
+	}
+      if (matched)
+	{
+	  /* There was a match so do the substitution.
+	     If matched is 1 then it can only be the root mount point, in
+	     which case we do not want to remove the matched part as it is the 
+	     directory separator.  */
+	  if (matched == 1)
+	    matched = 0;
+	  result = (char *)xmalloc (strlen (foundat->actual) + strlen (path) + 1
+			    - matched);
+	  strcpy (result, foundat->actual);
+	  strcat (result, path + matched);
+	}
+    }
+
+  if (result)
+    {
+      /* Ensure that the return is never just a drive letter.
+	 This is not a valid directory on Windows, but code often
+	 trims trailing slashes.  */
+      int length = strlen(result);
+      if (result[length-1] == ':')
+	{
+	  result = (char *)xrealloc (result, length+2);
+	  result[length] = '/';
+	  result[length+1] = '\0';
+	}
+      return result;
+    }
+
+  /* If we get here then it must have been some other kind of path.  */
+  return xstrdup (path);
+}
+
+
+/* This is just to make inserting the conversion more convenient.
+   The CYGPATH_REPLACE is conditionally compiled so it is harder to
+   add clean up code to go with it without this.  */
+void
+cygpath_replace (char **path)
+{
+  char *result = cygpath (*path);
+  free (*path);
+  *path = result;
+}
diff -urN gcc-4.7.3/libiberty/Makefile.in st40-4.7.3-13080/gcc/libiberty/Makefile.in
--- gcc-4.7.3/libiberty/Makefile.in	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libiberty/Makefile.in	2012-04-04 14:14:24.000000000 +0200
@@ -125,7 +125,7 @@
 CFILES = alloca.c argv.c asprintf.c atexit.c				\
 	basename.c bcmp.c bcopy.c bsearch.c bzero.c			\
 	calloc.c choose-temp.c clock.c concat.c cp-demangle.c		\
-	 cp-demint.c cplus-dem.c crc32.c				\
+	 cp-demint.c cplus-dem.c crc32.c cygpath.c			\
 	dyn-string.c							\
 	fdmatch.c ffs.c fibheap.c filename_cmp.c floatformat.c		\
 	fnmatch.c fopen_unlocked.c					\
@@ -155,7 +155,7 @@
 	timeval-utils.c tmpnam.c					\
 	unlink-if-ordinary.c						\
 	vasprintf.c vfork.c vfprintf.c vprintf.c vsnprintf.c vsprintf.c	\
-	waitpid.c							\
+	waitpid.c wrap_file.c						\
 	xatexit.c xexit.c xmalloc.c xmemdup.c xstrdup.c xstrerror.c	\
 	 xstrndup.c
 
@@ -197,7 +197,7 @@
 	./basename.$(objext) ./bcmp.$(objext) ./bcopy.$(objext)		\
 	./bsearch.$(objext) ./bzero.$(objext)				\
 	./calloc.$(objext) ./clock.$(objext) ./copysign.$(objext)	\
-	./_doprnt.$(objext)						\
+	./cygpath.$(object) ./_doprnt.$(objext)				\
 	 ./ffs.$(objext)						\
 	./getcwd.$(objext) ./getpagesize.$(objext)			\
 	 ./gettimeofday.$(objext)					\
@@ -220,7 +220,7 @@
 	./tmpnam.$(objext)						\
 	./vasprintf.$(objext) ./vfork.$(objext) ./vfprintf.$(objext)	\
 	 ./vprintf.$(objext) ./vsnprintf.$(objext) ./vsprintf.$(objext)	\
-	./waitpid.$(objext)
+	./waitpid.$(objext) ./wrap_file.$(object)
 
 # These files are installed if the library has been configured to do so.
 INSTALLED_HEADERS =                                                     \
@@ -628,6 +628,13 @@
 	else true; fi
 	$(COMPILE.c) $(srcdir)/dyn-string.c $(OUTPUT_OPTION)
 
+./cygpath.$(objext): $(srcdir)/cygpath.c $(INCDIR)/ansidecl.h \
+	 $(INCDIR)/libiberty.h
+	if [ x"$(PICFLAG)" != x ]; then \
+	  $(COMPILE.c) $(PICFLAG) $(srcdir)/cygpath.c -o pic/$@; \
+	else true; fi
+	$(COMPILE.c) $(srcdir)/cygpath.c $(OUTPUT_OPTION)
+
 ./fdmatch.$(objext): $(srcdir)/fdmatch.c config.h $(INCDIR)/ansidecl.h \
 	$(INCDIR)/libiberty.h
 	if [ x"$(PICFLAG)" != x ]; then \
@@ -1206,6 +1213,13 @@
 	else true; fi
 	$(COMPILE.c) $(srcdir)/waitpid.c $(OUTPUT_OPTION)
 
+./wrap_file.$(objext): $(srcdir)/wrap_file.c config.h $(INCDIR)/ansidecl.h \
+	$(INCDIR)/libiberty.h
+	if [ x"$(PICFLAG)" != x ]; then \
+	  $(COMPILE.c) $(PICFLAG) $(srcdir)/wrap_file.c -o pic/$@; \
+	else true; fi
+	$(COMPILE.c) $(srcdir)/wrap_file.c $(OUTPUT_OPTION)
+
 ./xatexit.$(objext): $(srcdir)/xatexit.c config.h $(INCDIR)/ansidecl.h \
 	$(INCDIR)/libiberty.h
 	if [ x"$(PICFLAG)" != x ]; then \
diff -urN gcc-4.7.3/libiberty/wrap_file.c st40-4.7.3-13080/gcc/libiberty/wrap_file.c
--- gcc-4.7.3/libiberty/wrap_file.c	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libiberty/wrap_file.c	2012-04-04 14:14:24.000000000 +0200
@@ -0,0 +1,138 @@
+/*
+  THIS FILE HAS BEEN MODIFIED OR ADDED BY STMicroelectronics, Inc. 1999-2009
+*/
+/*
+ * wrap_fopen.c
+ *
+ * This file redefines the standard library functions 
+ * open, create, fopen, fdopen, freopen, remove, rename, unlink, stat for native WIN32 build.
+ * Its purpose is to preprocess argument strings in order to
+ * convert CYGWIN like paths specifiers into native WIN32 paths
+ * It uses the GNU ld -wrap functionality to replace
+ * at link time calls to fopen into calls to __wrap_fopen.
+ *
+ * This file must be linked with any DLL or EXE object
+ * and the linker command line must have the following  option:
+ * -Wl,-wrap,open,-wrap,creat,-wrap,fopen,-wrap,freopen,-wrap,remove,-wrap,rename,-wrap,unlink,-wrap,stat
+ *
+ */
+
+#ifdef __MINGW32__
+#include <stdio.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <dirent.h>
+#include <unistd.h>
+
+#include "libiberty.h"
+
+/*
+ * Declare real versions of functions.
+ */
+extern int __real_open (const char *pathname, int flags, mode_t mode);
+extern int __real_creat (const char *pathname, mode_t mode);
+extern FILE *__real_fopen (const char *path, const char *mode);
+extern FILE *__real_freopen (const char *path, const char *mode, FILE *stream);
+extern int __real_unlink (const char *pathname);
+extern int __real_remove (const char *pathname);
+extern int __real_stat (const char *file_name, struct stat *buf);
+extern int __real_chdir (const char *path);
+extern int __real_rmdir (const char *pathname); 
+extern DIR *__real_opendir (const char *name);
+extern int __real_access (const char *pathname, int mode);
+
+/*
+ * Following is the implementation of replacement functions.
+ */
+int 
+__wrap_open (const char *pathname, int flags, mode_t mode)
+{
+  int r;
+  char *path = cygpath (pathname);
+  r = __real_open (path, flags, mode);
+  return r;
+}
+
+int 
+__wrap_creat (const char *pathname, mode_t mode)
+{
+  int r;
+  char *path = cygpath (pathname);
+  r = __real_creat (path, mode);
+  return r;
+}
+
+FILE *
+__wrap_fopen (const char *pathname, const char *mode)
+{
+  FILE *f;
+  char *path = cygpath (pathname);
+  f = __real_fopen (path, mode);
+  return f;
+}
+
+FILE *__wrap_freopen (const char *pathname, const char *mode, FILE *stream)
+{
+  FILE *f;
+  char *path = cygpath (pathname);
+  f = __real_freopen (path, mode, stream);
+  return f;
+}
+
+int __wrap_unlink (const char *pathname) 
+{
+  int r;
+  char *path = cygpath (pathname);
+  r = __real_unlink (path);
+  return r;
+}
+
+int __wrap_remove (const char *pathname)
+{
+  int r;
+  char *path = cygpath (pathname);
+  r = __real_remove (path);
+  return r;
+}
+
+int __wrap_stat(const char *pathname, struct stat *buf)
+{
+  int r;
+  char *path = cygpath (pathname);
+  r = __real_stat (path, buf);
+  return r;
+}
+
+int __wrap_chdir(const char *pathname)
+{
+  int r;
+  char *path = cygpath (pathname);
+  r = __real_chdir (path);
+  return r;
+}
+
+int __wrap_rmdir(const char *pathname)
+{
+  int r;
+  char *path = cygpath (pathname);
+  r = __real_rmdir (path);
+  return r;
+}
+
+DIR *__wrap_opendir(const char *pathname)
+{
+  DIR *d;
+  char *path = cygpath (pathname);
+  d = __real_opendir (path);
+  return d;
+}
+
+int __wrap_access(const char *pathname, int mode)
+{
+  int r; 
+  char *path = cygpath (pathname);
+  r = __real_access (path, mode);
+  return r;
+}
+
+#endif /* __MINGW32__ */
diff -urN gcc-4.7.3/libstdc++-v3/ChangeLog.STM st40-4.7.3-13080/gcc/libstdc++-v3/ChangeLog.STM
--- gcc-4.7.3/libstdc++-v3/ChangeLog.STM	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/libstdc++-v3/ChangeLog.STM	2013-04-30 11:08:54.000000000 +0200
@@ -0,0 +1,45 @@
+2012-04-25  Laurent Alfonsi  <laurent.alfonsi@st.com>
+
+        * testsuite/lib/libstdc++.exp (libstdc++_init): uses 
+        GCC_UNDER_TEST, GXX_UNDER_TEST. 
+        (v3_target_compile, v3_target_compile_as_c): Appends 
+	additional linker flag if exists.
+
+2012-04-17  Antony King  <antony.king@st.com>
+
+        * include/ext/concurrence.h (~__mutex): Check _M_init instead of
+        __gthread_active_p.
+        (~__recursive_mutex): Likewise.
+        (__recursive_mutex::_S_destroy): New template function for default
+        implementation using __gthread_recursive_mutex_t.
+
+2012-04-13  Laurent Alfonsi  <laurent.alfonsi@st.com>
+
+	PR libstdc++/52604
+	* src/c++98/mt_allocator.cc: (__freelist::~__freelist): Reset pointer.
+
+2011-11-23  Christian Bruel  <christian.bruel@st.com>
+
+	* testsuite/23_containers/vector/bool/modifiers/insert/31370.cc:
+	xfail for sh-superh-elf.
+
+2009-10-06  Antony King  <antony.king@st.com>
+
+	INSbl30052:
+	* configure.host: Enable atomic builtins for sh*-superh-elf.
+	* configure: Regenerate.
+
+2009-02-24  Antony King  <antony.king@st.com>
+	    Christian Bruel  <christian.bruel@st.com>
+
+	INSbl28513:
+	* include/ext/concurrence.h (__scoped_gmutex_lock): Defined.
+	(__mutex:_M_init): Declare and initialize.
+	(__recursive_mutex:_M_init): Idem.
+	(__mutex:lock): Initialize mutex if needed.
+	(__recursive_mutex:lock): Idem.
+	* libsupc++/eh_globals.cc (__cxa_get_globals): Initialize eh_globals.
+	(__eh_globals_init:_M_create): New function
+	(__eh_globals_init): Initialize _M_once.
+	(__cxa_get_globals): Call init_create once.
+
diff -urN gcc-4.7.3/libstdc++-v3/include/ext/concurrence.h st40-4.7.3-13080/gcc/libstdc++-v3/include/ext/concurrence.h
--- gcc-4.7.3/libstdc++-v3/include/ext/concurrence.h	2012-10-01 13:18:40.000000000 +0200
+++ st40-4.7.3-13080/gcc/libstdc++-v3/include/ext/concurrence.h	2013-04-30 11:08:54.000000000 +0200
@@ -2,6 +2,7 @@
 
 // Copyright (C) 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012
 // Free Software Foundation, Inc.
+// Copyright (c) 2013  STMicroelectronics.
 //
 // This file is part of the GNU ISO C++ Library.  This library is free
 // software; you can redistribute it and/or modify it under the
@@ -140,6 +141,63 @@
   }
 #endif
  
+#if __GTHREADS
+  class __scoped_gmutex_lock
+  {
+  private:
+    __scoped_gmutex_lock(const __scoped_gmutex_lock&);
+    __scoped_gmutex_lock& operator=(const __scoped_gmutex_lock&);
+
+    class __mutex_type
+    {
+    public:
+      __gthread_mutex_t _M_mutex;
+      __gthread_once_t  _M_once;
+
+      __mutex_type() : _M_once(__GTHREAD_ONCE_INIT) { }
+
+      ~__mutex_type() { }
+
+      void
+      _M_create()
+      {
+#if defined __GTHREAD_MUTEX_INIT
+	__gthread_mutex_t __tmp = __GTHREAD_MUTEX_INIT;
+	_M_mutex = __tmp;
+#else
+	__GTHREAD_MUTEX_INIT_FUNCTION(&_M_mutex);
+#endif
+      }
+    };
+
+    static __mutex_type _M_device;
+
+    static void
+    __M_device_create()
+    { _M_device._M_create(); }
+
+  public:
+    explicit __scoped_gmutex_lock()
+    {
+      // Do not need to check __gthread_active_p() as assume already
+      // checked before a sentry is created.
+      __gthread_once(&_M_device._M_once, __M_device_create);
+
+      if (__gthread_mutex_lock(&_M_device._M_mutex) != 0)
+	__throw_concurrence_lock_error();
+    }
+
+    ~__scoped_gmutex_lock() throw()
+    {
+      if (__gthread_mutex_unlock(&_M_device._M_mutex) != 0)
+	__throw_concurrence_unlock_error();
+    }
+  };
+
+  __scoped_gmutex_lock::__mutex_type __attribute__((weak))
+    __scoped_gmutex_lock::_M_device;
+#endif
+
   class __mutex 
   {
   private:
@@ -148,24 +206,31 @@
 #else
     __gthread_mutex_t _M_mutex;
 #endif
+    bool	      _M_init;
 
     __mutex(const __mutex&);
     __mutex& operator=(const __mutex&);
 
   public:
-    __mutex() 
+    __mutex() : _M_init(false)
     { 
 #if __GTHREADS && ! defined __GTHREAD_MUTEX_INIT
       if (__gthread_active_p())
-	__GTHREAD_MUTEX_INIT_FUNCTION(&_M_mutex);
+        {
+          __GTHREAD_MUTEX_INIT_FUNCTION(&_M_mutex);
+          _M_init = true;
+        }
 #endif
     }
 
 #if __GTHREADS && ! defined __GTHREAD_MUTEX_INIT
     ~__mutex() 
     { 
-      if (__gthread_active_p())
-	__gthread_mutex_destroy(&_M_mutex); 
+      if (__builtin_expect(_M_init == true, true))
+        {
+          __gthread_mutex_destroy(&_M_mutex); 
+	  _M_init = false;
+        }
     }
 #endif 
 
@@ -174,12 +239,27 @@
 #if __GTHREADS
       if (__gthread_active_p())
 	{
+	  if (__builtin_expect(_M_init == false, false))
+	    {
+	      __scoped_gmutex_lock sentry;
+	      if (_M_init == false)
+		{
+#if defined __GTHREAD_MUTEX_INIT
+		  __gthread_mutex_t __tmp = __GTHREAD_MUTEX_INIT;
+		  _M_mutex = __tmp;
+#else
+		  __GTHREAD_MUTEX_INIT_FUNCTION(&_M_mutex);
+#endif
+		  _M_init = true;
+		}
+	    }
+
 	  if (__gthread_mutex_lock(&_M_mutex) != 0)
 	    __throw_concurrence_lock_error();
 	}
 #endif
     }
-    
+
     void unlock()
     {
 #if __GTHREADS
@@ -203,24 +283,31 @@
 #else
     __gthread_recursive_mutex_t _M_mutex;
 #endif
+    bool			_M_init;
 
     __recursive_mutex(const __recursive_mutex&);
     __recursive_mutex& operator=(const __recursive_mutex&);
 
   public:
-    __recursive_mutex() 
+    __recursive_mutex()  : _M_init(false)
     { 
 #if __GTHREADS && ! defined __GTHREAD_RECURSIVE_MUTEX_INIT
       if (__gthread_active_p())
-	__GTHREAD_RECURSIVE_MUTEX_INIT_FUNCTION(&_M_mutex);
+        {
+          __GTHREAD_RECURSIVE_MUTEX_INIT_FUNCTION(&_M_mutex);
+          _M_init = true;
+        }
 #endif
     }
 
 #if __GTHREADS && ! defined __GTHREAD_RECURSIVE_MUTEX_INIT
     ~__recursive_mutex()
     {
-      if (__gthread_active_p())
-	_S_destroy(&_M_mutex);
+      if (__builtin_expect(_M_init == true, true))
+        {
+          _S_destroy(&_M_mutex);
+	  _M_init = false;
+        }
     }
 #endif
 
@@ -229,6 +316,22 @@
 #if __GTHREADS
       if (__gthread_active_p())
 	{
+	  if (__builtin_expect(_M_init == false, false))
+	    {
+	      __scoped_gmutex_lock sentry;
+	      if (_M_init == false)
+		{
+#if defined __GTHREAD_RECURSIVE_MUTEX_INIT
+		  __gthread_recursive_mutex_t __tmp =
+		    __GTHREAD_RECURSIVE_MUTEX_INIT;
+		  _M_mutex = __tmp;
+#else
+		  __GTHREAD_RECURSIVE_MUTEX_INIT_FUNCTION(&_M_mutex);
+#endif
+		  _M_init = true;
+		}
+	    }
+
 	  if (__gthread_recursive_mutex_lock(&_M_mutex) != 0)
 	    __throw_concurrence_lock_error();
 	}
@@ -284,6 +387,14 @@
         void>::__type
       _S_destroy(_Rm* __mx)
       { __gthread_mutex_destroy(__mx); }
+
+    // default match.
+    template<typename _Rm>
+      static typename
+      __enable_if<std::__are_same<_Rm, __gthread_recursive_mutex_t>::__value,
+        void>::__type
+      _S_destroy(_Rm* __mx)
+      { __gthread_recursive_mutex_destroy(__mx); }
 #endif
   };
 
diff -urN gcc-4.7.3/libstdc++-v3/include/std/mutex st40-4.7.3-13080/gcc/libstdc++-v3/include/std/mutex
--- gcc-4.7.3/libstdc++-v3/include/std/mutex	2013-03-25 12:27:21.000000000 +0100
+++ st40-4.7.3-13080/gcc/libstdc++-v3/include/std/mutex	2013-05-07 10:18:01.000000000 +0200
@@ -2,6 +2,7 @@
 
 // Copyright (C) 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2013
 // Free Software Foundation, Inc.
+// Copyright (c) 2012 STMicroelectronics.
 //
 // This file is part of the GNU ISO C++ Library.  This library is free
 // software; you can redistribute it and/or modify it under the
@@ -138,6 +139,14 @@
         __mx->sema = __rmx->sema;
         __gthread_mutex_destroy(__mx);
       }
+
+    // default match
+    template<typename _Rm>
+      static 
+      typename enable_if<is_same<_Rm, __gthread_recursive_mutex_t>::__value,
+        void>::__type
+      _S_destroy(_Rm* __mx)
+      { __gthread_recursive_mutex_destroy(__mx); }
 #endif
   };
 
diff -urN gcc-4.7.3/libstdc++-v3/libsupc++/eh_globals.cc st40-4.7.3-13080/gcc/libstdc++-v3/libsupc++/eh_globals.cc
--- gcc-4.7.3/libstdc++-v3/libsupc++/eh_globals.cc	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libstdc++-v3/libsupc++/eh_globals.cc	2012-04-26 11:18:16.000000000 +0200
@@ -1,6 +1,7 @@
 // -*- C++ -*- Manage the thread-local exception globals.
 // Copyright (C) 2001, 2002, 2003, 2004, 2005, 2006, 2009, 2011
 // Free Software Foundation, Inc.
+// Copyright (c) 2009  STMicroelectronics.
 //
 // This file is part of GCC.
 //
@@ -29,6 +30,7 @@
 #include "cxxabi.h"
 #include "unwind-cxx.h"
 #include "bits/gthr.h"
+#include <ext/concurrence.h>
 
 #if _GLIBCXX_HOSTED
 using std::free;
@@ -92,12 +94,10 @@
 {
   __gthread_key_t  	_M_key;
   bool 			_M_init;
+  __gthread_once_t	_M_once;
 
-  __eh_globals_init() : _M_init(false)
-  { 
-    if (__gthread_active_p())
-      _M_init = __gthread_key_create(&_M_key, eh_globals_dtor) == 0; 
-  }
+  __eh_globals_init() : _M_init(false), _M_once(__GTHREAD_ONCE_INIT)
+  { }
 
   ~__eh_globals_init()
   {
@@ -105,14 +105,23 @@
       __gthread_key_delete(_M_key);
     _M_init = false;
   }
+
+  inline void
+  _M_create()
+  { _M_init = __gthread_key_create(&_M_key, eh_globals_dtor) == 0; }
 };
 
 static __eh_globals_init init;
 
+static void
+init_create()
+{ init._M_create(); }
+
 extern "C" __cxa_eh_globals*
 __cxxabiv1::__cxa_get_globals_fast() _GLIBCXX_NOTHROW
 {
   __cxa_eh_globals* g;
+
   if (init._M_init)
     g = static_cast<__cxa_eh_globals*>(__gthread_getspecific(init._M_key));
   else
@@ -124,6 +133,11 @@
 __cxxabiv1::__cxa_get_globals() _GLIBCXX_NOTHROW
 {
   __cxa_eh_globals* g;
+
+  if (__builtin_expect(init._M_init == false, false)
+      && __gthread_active_p())
+    __gthread_once(&init._M_once, init_create);
+
   if (init._M_init)
     {
       g = static_cast<__cxa_eh_globals*>(__gthread_getspecific(init._M_key));
diff -urN gcc-4.7.3/libstdc++-v3/src/c++98/mt_allocator.cc st40-4.7.3-13080/gcc/libstdc++-v3/src/c++98/mt_allocator.cc
--- gcc-4.7.3/libstdc++-v3/src/c++98/mt_allocator.cc	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libstdc++-v3/src/c++98/mt_allocator.cc	2013-04-30 11:08:54.000000000 +0200
@@ -1,6 +1,7 @@
 // Allocator details.
 
 // Copyright (C) 2004, 2005, 2006, 2009, 2010 Free Software Foundation, Inc.
+// Copyright (c) 2013  STMicroelectronics.
 //
 // This file is part of the GNU ISO C++ Library.  This library is free
 // software; you can redistribute it and/or modify it under the
@@ -48,6 +49,7 @@
 	{
 	  __gthread_key_delete(_M_key);
 	  ::operator delete(static_cast<void*>(_M_thread_freelist_array));
+	  _M_thread_freelist = NULL;
 	}
     }
   };
diff -urN gcc-4.7.3/libstdc++-v3/testsuite/lib/libstdc++.exp st40-4.7.3-13080/gcc/libstdc++-v3/testsuite/lib/libstdc++.exp
--- gcc-4.7.3/libstdc++-v3/testsuite/lib/libstdc++.exp	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/libstdc++-v3/testsuite/lib/libstdc++.exp	2012-10-15 10:04:17.000000000 +0200
@@ -95,6 +95,8 @@
     global tool_timeout
     global DEFAULT_CXXFLAGS
     global STATIC_LIBCXXFLAGS
+    global GXX_UNDER_TEST
+    global GCC_UNDER_TEST
 
     # We set LC_ALL and LANG to C so that we get the same error
     # messages as expected.
@@ -211,11 +213,21 @@
     set tool_timeout 600
 
     # Default settings.
-    set cxx [transform "g++"]
+    if [info exists GXX_UNDER_TEST] {
+        set cxx $GXX_UNDER_TEST
+    } else {
+    	set cxx [transform "g++"]
+    }
     set cxxflags "-g -O2 -D_GLIBCXX_ASSERT -fmessage-length=0"
     set cxxpchflags ""
     set cxxldflags ""
-    set cc [transform "gcc"]
+
+    if [info exists GCC_UNDER_TEST] {
+        set cc $GCC_UNDER_TEST
+    } else {
+    	set cc [transform "gcc"]
+    }
+    
     # Locate testsuite_hooks.h and other testsuite headers.
     set includes "-I${srcdir}/util"
     # Adapt the defaults for special circumstances.
@@ -420,6 +432,8 @@
     global cxxldflags
     global includes
     global STATIC_LIBCXXFLAGS
+    global srcdir
+    global additional_linker_flag
 
     if { [target_info needs_status_wrapper] != "" && [info exists gluefile] } {
         lappend options "libs=${gluefile}"
@@ -435,6 +449,9 @@
 
     # Flag setting based on type argument.
     if { $type == "executable" } {
+        if { [info exists additional_linker_flag] } {
+           lappend cxx_final $additional_linker_flag
+	}
 	# Link the support objects into executables.
 	lappend options "additional_flags=./libtestc++.a $cxxldflags"
     } else {
@@ -462,6 +479,8 @@
     global cc
     global cxxflags
     global STATIC_LIBCXXFLAGS
+    global srcdir
+    global additional_linker_flag
 
     if { [target_info needs_status_wrapper] != "" && [info exists gluefile] } {
         lappend options "libs=${gluefile}"
@@ -475,6 +494,10 @@
     set cc_final [concat $cc_final $STATIC_LIBCXXFLAGS]
     set cc_final [concat $cc_final $cxxflags]
     set cc_final [concat $cc_final $includes]
+    if { [info exists additional_linker_flag] } {
+        lappend cc_final $additional_linker_flag
+    }
+    
     regsub -all {\s[-]nostdinc[+][+]} $cc_final "" cc_final
 
     # This is needed for "C" tests, as this type of test may need the
diff -urN gcc-4.7.3/lto-plugin/ChangeLog.STM st40-4.7.3-13080/gcc/lto-plugin/ChangeLog.STM
--- gcc-4.7.3/lto-plugin/ChangeLog.STM	1970-01-01 01:00:00.000000000 +0100
+++ st40-4.7.3-13080/gcc/lto-plugin/ChangeLog.STM	2012-10-17 10:50:35.000000000 +0200
@@ -0,0 +1,3 @@
+2012-10-11  Laurent Alfonsi  <laurent.alfonsi@st.com>
+
+	* lto-plugin.c (claim_file_handler): Detect no symbol case.
diff -urN gcc-4.7.3/lto-plugin/lto-plugin.c st40-4.7.3-13080/gcc/lto-plugin/lto-plugin.c
--- gcc-4.7.3/lto-plugin/lto-plugin.c	2012-03-28 16:58:23.000000000 +0200
+++ st40-4.7.3-13080/gcc/lto-plugin/lto-plugin.c	2013-04-30 11:08:54.000000000 +0200
@@ -1,6 +1,7 @@
 /* LTO plugin for gold and/or GNU ld.
    Copyright (C) 2009, 2010 Free Software Foundation, Inc.
    Contributed by Rafael Avila de Espindola (espindola@google.com).
+   Copyright (c) 2013  STMicroelectronics.
 
 This program is free software; you can redistribute it and/or modify
 it under the terms of the GNU General Public License as published by
@@ -910,6 +911,9 @@
 
   status = add_symbols (file->handle, lto_file.symtab.nsyms,
 			lto_file.symtab.syms);
+  if (status == LDPS_NO_SYMS)
+    goto cleanup;
+    
   check (status == LDPS_OK, LDPL_FATAL, "could not add symbols");
 
   *claimed = 1;
